{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a revision due to the lack of clarity regarding the precise steps involved in the methodology. However, it does not provide specific guidance on what aspects of the methodology need clarification or how to improve the presentation. The comment implies that the authors should clarify their methodology, but it lacks concrete steps or examples of what needs to be addressed. As a result, the action is implicit and vague, making it difficult for the authors to know exactly what changes to make. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a revision due to the lack of clarity regarding the precise steps involved in the methodology. However, it does not specify which part of the paper this issue pertains to, such as sections, tables, or figures. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting that the presentation and clarity of the methodology need improvement, but it lacks full grounding as it does not explicitly mention the sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a revision due to the lack of clarity regarding the precise steps involved in the methodology. However, it does not provide specific examples or detailed reasoning to support this claim. The comment implies that the methodology seems to perform better than the baselines, but it lacks specific evidence or comparisons to substantiate this claim. Additionally, the suggestion to clarify the methodology is not accompanied by detailed guidance or examples, making it difficult for the authors to understand the exact areas that need improvement. Therefore, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks specific evidence or detailed reasoning.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the methodology presented in the paper, suggesting that the lack of detailed steps and presentation makes it difficult for readers to fully understand the approach. While it highlights a specific area for improvement, the comment lacks specific suggestions or guidance on how to address this issue. It does not provide actionable feedback or examples of what steps the authors could take to improve the clarity of their methodology. As a result, the comment is somewhat helpful, as it points out a potential weakness but does not offer detailed guidance for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the practical relevance of the modified TD learning algorithm defined in Definition 5.1 compared to the original proposal (Algorithm 1). While it identifies a potential issue, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what specific aspects of the practical relevance should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the practical relevance of the modified TD learning algorithm compared to the original proposal (Algorithm 1). This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the practical relevance of the modified TD learning algorithm defined in Definition 5.1 compared to the original proposal (Algorithm 1). However, it does not provide any supporting evidence, reasoning, or references to justify why the original proposal might be more practical. Without such justification, the claim remains unverifiable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the practical relevance of the modified TD learning algorithm defined in Definition 5.1 compared to the original proposal (Algorithm 1). It prompts the authors to consider the practical implications of their theoretical analysis, which is an important consideration for the paper\\'s contribution. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the practical relevance should be considered. While it identifies a relevant concern, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant concern regarding the practical utility of the data quality metric, specifically the diversity coefficient, which is suggested as a potential metric. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this concern, such as suggesting experiments or validation methods to demonstrate the metric's utility. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"diversity coefficient\" as a potential data quality metric, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the concern regarding the lack of empirical validation for this metric and its relevance to the paper\\'s emphasis on Task2Vec and model diversity. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks empirical validation for the suggested data quality metric, the diversity coefficient. This is a significant concern, as the paper emphasizes Task2Vec and model diversity. However, the comment does not provide specific examples or references to support the claim that the diversity coefficient is not empirically validated. Without detailed evidence or reasoning, the authors may find it challenging to address the concern effectively. Therefore, the claim is considered borderline verifiable, as it provides some basis but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the practical utility of the data quality metric, specifically the diversity coefficient, which is suggested as a potential metric. It points out that the paper lacks empirical validation for this claim, which is a critical issue given the emphasis on Task2Vec and model diversity. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or validate the metric empirically. While it highlights a significant gap in the paper, the feedback lacks actionable advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that using canary clients is less efficient than using canary examples and that more resource allocation might be needed. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to improve efficiency. The comment lacks concrete details on how to implement the suggested changes, such as suggesting specific resource allocation strategies or explaining why canary clients are less efficient. As a result, the authors are left with a vague suggestion that requires further exploration and interpretation to implement effectively. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that using canary clients is less efficient than using canary examples and that more resource allocation might be needed. However, it does not specify which part of the paper discusses the use of canary clients or where the authors should make changes. The authors cannot confidently determine which section or aspect of the paper is being addressed, making it weakly grounded. The comment is specific in suggesting that using canary clients might be less efficient and that more resource allocation might be needed, but without explicit references to the paper, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using canary clients is less efficient than using canary examples and suggests that more resource allocation might be needed. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide details on why canary clients are less efficient or how more resource allocation might address this issue. Without additional context or examples, the authors may find it challenging to understand and address the claim effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential inefficiency in the use of canary clients compared to canary examples, suggesting that more resource allocation might be needed. However, it lacks specificity and does not provide actionable guidance on how the authors might address this issue or what changes they should consider to improve efficiency. Without detailed suggestions or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the relevance of Carefl to the paper and suggests that it might be a standard definition of a nonlinear SEM. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or clarify the relevance of Carefl to the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Carefl\" and \"Equation (6),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the relevance of Carefl to the paper and suggesting that it might be a standard definition of a nonlinear SEM. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the relevance of Carefl to the paper and suggests that it might be a standard definition of a nonlinear SEM. The reviewer provides a reference to Equation (4) in \"On Causal Discovery with Cyclic Additive Noise Models\" to support their claim. This reference provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by further elaboration or explanation of why Carefl is not relevant to the paper. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment questions the relevance of Carefl to the paper and suggests that it might be a standard definition of a nonlinear SEM. It provides a reference to Equation (4) in \"On Causal Discovery with Cyclic Additive Noise Models\" to support its claim. While the comment identifies a potential issue with the paper\\'s relevance, it lacks specific guidance or suggestions on how the authors might address this concern or clarify the relevance of Carefl. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proposed approach, noting that it is compute-intensive due to the pretraining of the GAA model on the same dataset as the QA model needs to be trained on. It also raises a concern about the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, suggesting that this could lead to longer annotation times and question the speedup claim. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the assumptions and potential limitations of their approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the compute-intensive nature of the proposed approach, specifically mentioning the pretraining of the GAA model on the same dataset as the QA model needs to be trained on. It also raises a concern about the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, which could lead to longer annotation times and question the speedup claim. This provides clear guidance on what needs to be addressed, making the comment fully grounded as it explicitly mentions the dataset and the QA model. The comment is also specific in detailing the potential issue with the assumption and its implications. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed approach is compute-intensive due to the pretraining of the GAA model on the same dataset as the QA model needs to be trained on. It also raises a concern about the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, suggesting that this could lead to longer annotation times and question the speedup claim. The comment provides a logical reasoning and a potential concern, but it lacks specific examples or references to substantiate the claim. This makes the comment somewhat verifiable, as it provides a basis for the claim but requires further elaboration to fully support it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed approach, noting that it is compute-intensive due to the pretraining of the GAA model on the same dataset as the QA model needs to be trained on. It also raises a concern about the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, suggesting that this could lead to longer annotation times and question the speedup claim of the proposed approach. This feedback is clear and actionable, as it highlights a specific area of concern that the authors should address to improve the robustness of their method. By pointing out the potential limitations and implications, the comment provides valuable insights for the authors to consider in refining their draft. However, it could be more helpful if it offered suggestions on how to mitigate these issues or provided examples of alternative approaches. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation of the proposed method, which is its high dependence on the server dataset. It suggests that this dependence limits the method's potential use cases and reduces its generality. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might mitigate this limitation or broaden the applicability of their method. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation of the proposed method, specifically its high dependence on the server dataset, which significantly limits its potential use cases and reduces its generality. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing the issue of dependence on the server dataset and its implications, but without explicit references to sections or figures, the authors cannot confidently determine where to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method has a high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the extent of this limitation and how it affects the method\\'s applicability. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation of the proposed method, specifically its high dependence on the server dataset, which significantly limits its potential use cases and reduces its generality. This feedback is valuable as it highlights a critical issue that the authors need to address to broaden the applicability of their method. However, the comment could be more helpful if it provided suggestions on how to mitigate this limitation or expand the method\\'s applicability. Despite this, the comment still offers a clear direction for improvement, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to include additional downstream search methods, such as BO and LS, in addition to the single method currently provided (EA). While the comment implies that the authors should consider adding these methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their methodology. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it would be beneficial to include additional downstream search methods, such as BO and LS, in addition to the single method currently provided (EA). However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of additional methods, but without explicit references to sections or specific methodologies, the authors may struggle to identify the exact areas that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the inclusion of a single downstream search method (EA) and suggests that it would be beneficial to include additional methods, such as BO and LS. However, the comment does not provide any specific reasoning or evidence to support why these additional methods are necessary or how they would enhance the study. Without detailed justification or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial to include additional downstream search methods, such as BO and LS, in addition to the single method currently provided (EA). This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting the inclusion of additional methods. However, the comment lacks specificity and does not provide detailed guidance on how to implement these changes or why they would be beneficial. Without further explanation or examples, the authors may find it challenging to fully understand and address the suggestion. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper does not sufficiently highlight the comparison between FLOPs and FPS in sparse network research, particularly in the context of pDETR. It points out that while FLOPs for pDETR are listed in Table 7, a direct comparison with other sparse models is missing. This provides a clear and concrete action for the authors to take, which is to include a direct comparison with other sparse models. The comment is specific and provides a clear direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FLOPs and FPS\" and \"Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of a direct comparison with other sparse models, particularly in the context of pDETR. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not sufficiently highlight the comparison between FLOPs and FPS in sparse network research, particularly in the context of pDETR. The reviewer supports this claim by mentioning that FLOPs for pDETR are listed in Table 7 but that a direct comparison with other sparse models is missing. This provides a logical reasoning for the claim, as it highlights a specific aspect of the paper\\'s omission. However, the comment could be strengthened by providing specific examples of other sparse models that should be compared, which would further substantiate the claim. Overall, the comment is mostly verifiable, as it provides a clear rationale for the claim but lacks detailed examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical omission in the paper, specifically the lack of a direct comparison between FLOPs and FPS in sparse network research, particularly in the context of pDETR. It highlights that while FLOPs for pDETR are listed in Table 7, a direct comparison with other sparse models is missing. This feedback is clear and actionable, as it provides the authors with a specific area to focus on for improvement. By addressing this gap, the authors can enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it suggested specific models or approaches for comparison, which would guide the authors more directly. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the metrics described in Appendix A.1, noting that they are difficult to understand and that the results in the tables are unclear. The reviewer provides a specific example of a discrepancy in the accuracy calculation for binary boolean questions, suggesting that reversing the prediction would yield an inaccurate result of 97%. This feedback is explicit and provides a concrete example of what needs to be addressed, making it highly actionable. The authors know exactly what needs to be corrected to improve the clarity of their metrics and results.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A.1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the metrics, explaining that they are difficult to understand and providing an example of a discrepancy in the accuracy calculation. This level of detail helps the authors understand the problem and how to address it. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metrics described in Appendix A.1 are difficult to understand and that the results in the tables are unclear. The reviewer provides a specific example of a discrepancy in the accuracy calculation for binary boolean questions, suggesting that reversing the prediction would yield an inaccurate result of 97%. This example is logical and provides a clear explanation of the issue, making the claim mostly verifiable. However, the comment could be strengthened by providing additional references or examples to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the metrics described in Appendix A.1, noting that they are difficult to understand. It provides a concrete example of a discrepancy in the accuracy calculation for binary boolean questions, highlighting that reversing the prediction would yield an inaccurate result of 97%. This feedback is clear and actionable, as it points out a specific area where the authors need to improve the clarity and accuracy of their results. By addressing this issue, the authors can enhance the transparency and reliability of their work. Therefore, the comment is highly helpful, as it offers a clear and constructive suggestion for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the Gaussian assumption and its applicability in practice. It asks if this is a typical situation and if it is always possible to compute the effective variance for non-Gaussian outputs. Additionally, it inquires about a finite-N expansion that characterizes the departure from Gaussianity in the non-ideal case. While the questions are explicit, they lack concrete guidance on how the authors should address these issues. The authors know they need to consider these points but may not know exactly how to respond or what specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the Gaussian assumption and its applicability in practice, specifically asking if it is a typical situation and if it is always possible to compute the effective variance for non-Gaussian outputs. It also inquires about a finite-N expansion that characterizes the departure from Gaussianity in the non-ideal case. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the analysis and assumptions made in the work. The authors can infer that it pertains to the theoretical or methodological aspects of the paper. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions and requests for clarification regarding the Gaussian assumption and its applicability in practice. It does not contain any subjective opinions, judgments, or suggestions that require verification. The questions are factual and seek clarification, making them purely descriptive. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several questions about the Gaussian assumption and its applicability in practice. It inquires about whether this is a typical situation and if it is always possible to compute the effective variance for non-Gaussian outputs. Additionally, it asks about a finite-N expansion that characterizes the departure from Gaussianity in the non-ideal case. These questions are relevant and could prompt the authors to reconsider their assumptions and provide more detailed explanations or justifications for their methodology. However, the comment lacks specific suggestions or guidance on how the authors might address these issues, which limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but could be more actionable with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the approach to the math and science categories, suggesting an open vocabulary problem that is not clearly addressed. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the open vocabulary problem or what specific steps to take to improve the approach. As a result, the authors are left without any actionable steps to take, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the approach to the math and science categories, suggesting an open vocabulary problem that is not clearly tackled. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the approach and suggesting that it could be tackled by addressing the open vocabulary problem. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the approach to the math and science categories suggests an open vocabulary problem that is not clearly tackled. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. The mention of Wikipedia and a popularity metric suggests that these categories are addressed, but without further explanation or context, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the approach to the math and science categories, suggesting that an open vocabulary problem is not clearly tackled. It also mentions that other categories are addressed through Wikipedia and a popularity metric. While the comment highlights a specific area for improvement, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential weakness but does not offer detailed advice on how to improve the draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the comparison against stochastic routing should be discussed more thoroughly, implying that the similarity between the work and stochastic routing is significant. However, it does not provide specific guidance on how to conduct this discussion or what aspects should be covered. The action is implicit and somewhat vague, as the authors can infer that they need to expand the discussion but are not given concrete steps to follow. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the comparison against stochastic routing should be discussed more thoroughly, indicating that the similarity between the work and stochastic routing is significant at a more fundamental level. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in suggesting that the discussion should be more thorough, but without explicit references to sections or details, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the comparison against stochastic routing is significant and warrants a more thorough discussion. However, it does not provide specific reasoning or examples to support why this comparison is important or how it relates to the work. Without detailed justification or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the comparison against stochastic routing is significant and warrants a more thorough discussion. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to conduct this discussion or what aspects should be covered. The comment highlights a potential gap in the paper but does not provide actionable feedback or detailed suggestions for enhancing the discussion. As a result, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider convergence in direction as convergence, given that the CE loss cannot be minimized due to the exponential. However, the comment does not provide explicit instructions or concrete steps on how to implement this suggestion. It lacks specific guidance on whether this change should be made in the methodology, results, or discussion sections. As a result, the authors are left without a clear understanding of how to address the issue or what specific changes to make. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider convergence in direction as convergence, given that the CE loss cannot be minimized due to the exponential. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where this issue is discussed. The authors can infer that it relates to the methodology or results sections, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting that convergence in direction should be considered as convergence, but it does not provide detailed guidance on how to implement this change. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should consider convergence in direction as convergence, given that the CE loss cannot be minimized due to the exponential. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change should be made. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how it would improve their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should consider convergence in direction as convergence, given that the CE loss cannot be minimized due to the exponential. This feedback is somewhat helpful as it identifies a potential issue with the methodology and provides a direction for improvement. However, the comment lacks specific guidance or examples on how to implement this change or what impact it might have on the results. To be more helpful, the comment could offer suggestions on how to incorporate this change into the analysis or discuss its implications. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors claim that components can be replaced by other models for flexibility but did not attempt any changes or alternatives to prove the robustness of the proposed framework. This implies that the authors should conduct experiments to demonstrate the robustness of their framework with alternative models. However, the comment does not provide specific guidance on which models to use or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of experimental evidence to support the claim that components can be replaced by other models for flexibility. It points out that the authors did not attempt any changes or alternatives to prove the robustness of the proposed framework. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely, the need for experiments to demonstrate the robustness of the framework with alternative models. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors did not attempt any changes or alternatives to prove the robustness of their proposed framework. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact issue or how to address it. Without concrete evidence or detailed reasoning, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the lack of experimental evidence to support the claim that components can be replaced by other models for flexibility. It points out that the authors did not attempt any changes or alternatives to prove the robustness of their proposed framework. This feedback is somewhat helpful as it highlights an area where the authors could enhance their work by providing more experimental evidence. However, the comment could be more helpful if it suggested specific models or experiments to conduct, which would provide more actionable guidance. Overall, the comment is somewhat helpful as it directs the authors to a critical area for improvement but lacks detailed suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of 30 disentangled factors for the Atari game experiments, suggesting that it might be difficult to specify for an arbitrary domain. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific changes they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Atari game experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of 30 disentangled factors and suggesting that it might be difficult to specify for an arbitrary domain. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of 30 disentangled factors for the Atari game experiments, suggesting that it might be difficult to specify for an arbitrary domain. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or how it might impact the results. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of 30 disentangled factors for the Atari game experiments, suggesting that it might be difficult to specify for an arbitrary domain. While this point highlights a potential issue with the experimental setup, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to address this concern or what alternative approaches might be considered. As a result, the feedback is somewhat helpful, as it points out a potential weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the use of colloquial expressions, specifically mentioning the example of \"By the way, our training stage ... ...\". However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable advice or concrete steps for improvement, leaving the authors uncertain about what changes they need to make. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions the use of colloquial expressions, specifically referencing the example of \"By the way, our training stage ... ....\" This provides full grounding as it allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the use of colloquial expressions. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that colloquial expressions are unprofessional, specifically referencing the example of \"By the way, our training stage ... ...\". However, the comment does not provide any reasoning, evidence, or examples to support why this particular expression is considered unprofessional. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out the use of colloquial expressions, specifically mentioning the example of \"By the way, our training stage ... ...\". While this feedback identifies a potential issue with the professional tone of the paper, it lacks depth and does not provide specific suggestions or guidance on how to address this concern. The comment highlights a potential area for improvement but does not offer actionable advice or examples of how to improve the language used in the paper. As a result, the comment is somewhat helpful, as it provides some insight but does not fully support the authors in making meaningful changes to their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific abbreviations (\"LLH,\" \"OOD,\" and \"ECE\") that have not been defined or explained in the paper. It explicitly states that these abbreviations are important metrics in the line of work but have not been defined or explained. This provides clear and direct guidance on what the authors need to do to improve their draft: they must define these abbreviations and provide explanations for their use. The action is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"LLH,\" \"OOD,\" and \"ECE,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the definitions of these abbreviations and the lack of explanation for their use. This provides clear guidance on how to improve the paper. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that certain abbreviations (\"LLH,\" \"OOD,\" and \"ECE\") have not been defined or explained in the paper, despite their importance in the line of work. This claim is somewhat verifiable as it highlights a specific issue with the clarity of the paper, but it lacks detailed reasoning or examples to fully substantiate the importance of these abbreviations or their absence in the paper. The reviewer could provide more context or references to support the claim, making it more robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific abbreviations (\"LLH,\" \"OOD,\" and \"ECE\") that have not been defined or explained in the paper, despite their importance in the line of work. This feedback is clear and actionable, as it directs the authors to provide definitions or explanations for these abbreviations to enhance the clarity and comprehensibility of their work. By addressing this issue, the authors can improve the readability and accessibility of their paper, making it more valuable to both the academic community and potential readers. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, suggesting that the probability of failure cases increases due to stochastic/random projection at each layer. It explicitly asks the authors to justify the stability of their method and what happens when stacking more layers. This feedback provides a clear and direct action for the authors to take, which is to address the stability concerns and provide a justification for their method. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"stochastic/random projection\" and \"WLS units,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a concern about the stability of the proposed method when stacking multiple layers and suggests that the authors should justify the stability of their method. The comment provides a clear direction for improvement by asking the authors to address the stability concerns and what happens when stacking more layers. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, suggesting that the probability of failure cases increases due to stochastic/random projection at each layer. The comment provides a logical reasoning by explaining the potential impact of stochastic/random projection on the method's stability. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and substantiate the claim to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the stability of the proposed method when stacking multiple layers of WLS units, suggesting that the probability of failure cases increases due to stochastic/random projection at each layer. It raises a valid concern about the method's robustness and suggests that the authors should justify the stability of their method and what happens when stacking more layers. This feedback is clear and actionable, providing the authors with a specific direction for improvement by addressing the stability concerns and potential impact on the method's performance. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of similar scenarios where stability was maintained. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that certain sections, such as the computation of the Bottleneck Distance in Definition 4.1, lack clarity. This provides a clear and direct action for the authors to take, which is to clarify the computation in those sections. The comment is specific about what needs to be addressed, making it highly actionable. Authors know exactly what part of the paper needs clarification and how to implement it, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be clarified, namely the computation of the Bottleneck Distance. This provides clear guidance on what needs to be improved in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"some sections of the paper lack clarity,\" specifically mentioning the computation of the Bottleneck Distance in Definition 4.1. However, the comment does not provide specific examples or detailed reasoning to support this claim, such as explaining why the computation is unclear or how it affects the overall understanding of the paper. Without additional context or evidence, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where clarity is lacking, specifically the computation of the Bottleneck Distance in Definition 4.1. This feedback is clear and actionable, as it directs the authors to a specific section where clarification is needed. By addressing this issue, the authors can improve the readability and comprehension of their paper, which is valuable guidance. However, the comment could be more helpful if it provided additional context or suggestions on how to improve the clarity of the computation. Overall, the comment is mostly helpful as it effectively directs the authors to a specific area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper should provide a longer exemplar and make color assignment consistent with the topics listed in Figure 4 to enhance the visualization. This feedback is clear and provides specific actions for the authors to take, such as expanding the exemplar and aligning color assignments with the topics. The comment is explicit and concrete, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the visualization and the consistency of color assignment with the topics listed in Figure 4. This provides clear guidance on how to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper has a weaker visualization compared to Balikas COLING16's work, which makes the authors doubt the actual segmenting and assigning results of documents. The comment suggests that the paper could be more convincing by providing a longer exemplar and aligning color assignments with the topics listed in Figure 4. While the comment identifies a specific issue with the visualization, it lacks detailed reasoning or references to support the claim that the visualization is weaker. The suggestion to provide a longer exemplar and align color assignments is logical, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s visualization, noting that it is weaker compared to Balikas COLING16\\'s work. It suggests that the paper could be more convincing by providing a longer exemplar and aligning color assignments with the topics listed in Figure 4. This feedback is clear and actionable, as it offers a concrete suggestion for improvement that could enhance the paper\\'s visual presentation. However, the comment could be more helpful if it provided additional details or examples on how to achieve this alignment or what specific improvements would be beneficial. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the use of P5-small as the backbone model and expresses confusion about the purpose of using a parameter-efficient training method. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve their draft. There is no guidance on whether the authors should consider alternative models or methods, nor is there any indication of what specific aspects of the training method should be clarified or improved. As a result, the comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of P5-small as the backbone model and questions the purpose of using a parameter-efficient training method. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its questioning of the choice of model and the training method, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of P5-small as the backbone model and expresses confusion about the purpose of using a parameter-efficient training method. However, it does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or inappropriate. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the use of P5-small as the backbone model and expresses confusion about the purpose of using a parameter-efficient training method. While it identifies a potential area for improvement, it lacks specificity and does not provide any actionable guidance or suggestions on how the authors might address this issue. The comment does not offer any insights into why this choice might be problematic or how it could be improved, leaving the authors without a clear path forward. Therefore, the comment is rated as barely helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors propose a method for creating a challenging set but that it is specific and not scalable. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the method more scalable or how to improve its scalability. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the authors\\' proposal for creating a challenging set, noting that it is specific and not scalable. However, it does not specify which part of the paper this critique pertains to, making it weakly grounded. The comment is specific in its critique of the scalability of the proposed method, but without explicit references to sections or details, the authors may struggle to identify the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method for creating a challenging set is specific and not scalable. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that the proposed method for creating a challenging set is specific and not scalable. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or make their method more scalable. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the proposed method, specifically the reliance on the optimal value function corresponding to the reward function. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out a potential issue with the proposed method, specifically the reliance on the optimal value function corresponding to the reward function. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspect of the reliance on the optimal value function is problematic or how it could be addressed. Without clear guidance on where to focus the revision or what changes are needed, the authors are left without a clear understanding of what improvements are necessary. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed method relies heavily on the optimal value function corresponding to the reward function. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the proposed method, specifically the reliance on the optimal value function corresponding to the reward function. This observation highlights a potential weakness in the methodology, which could be addressed by providing more detailed explanations or justifications for the choice of reward function. However, the comment lacks specificity and does not offer actionable suggestions or guidance on how the authors might address this issue. Without detailed feedback or constructive advice, the authors may find it challenging to understand and implement the necessary changes. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not provide sufficient guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the approach is derivative, meaning it combines two existing approaches. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the derivative nature of the approach or suggestions for making it more original. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the approach is derivative, meaning it combines two existing approaches. However, it does not specify which part of the paper discusses this approach or where the authors should address this issue. The lack of specificity and grounding makes it difficult for the authors to identify the exact section that needs revision. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that the approach is derivative, meaning it combines two existing approaches. However, it does not provide any reasoning, evidence, or examples to support why this is a problem or how it could be improved. The comment lacks specificity and does not offer guidance on how to address the issue of derivative nature. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the claim. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges that the approach is derivative, meaning it combines two existing approaches. However, it does not provide any specific feedback or suggestions on how to improve the derivative nature of the approach or why it might be problematic. Without actionable guidance or constructive criticism, the authors are left without a clear path forward. The comment lacks depth and specificity, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of comparisons against potential baseline approaches in the evaluation, specifically mentioning a simple photographic style transfer method as an example. While the comment implies that the authors should include such comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons to other baseline approaches. However, the comment provides a specific example of what could be included, which offers some guidance. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"motivation\" and \"evaluation,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing: the lack of comparisons against potential baseline approaches, including a suggestion of a simple photographic style transfer method as an example. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are no comparisons against potential baseline approaches in the evaluation, specifically mentioning a simple photographic style transfer method as an example. The reviewer supports this claim by suggesting that such a method could achieve similar or better results. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim. While it provides an example, it does not fully explain why the photographic style transfer method would be a suitable baseline or how it would be compared to the existing evaluation. Therefore, the comment is somewhat verifiable, as it provides a logical suggestion but lacks detailed justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the evaluation section, noting the absence of comparisons against potential baseline approaches. It provides a specific example by suggesting a simple photographic style transfer method as a baseline that could achieve similar or better results. This feedback is clear and actionable, as it directs the authors to include comparisons that could enhance the robustness and credibility of their evaluation. However, the comment could be more helpful if it offered additional guidance on how to conduct these comparisons or what specific metrics to consider. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement and provides a concrete suggestion for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the mapping of symbols in Figure 2 to those in the equations, noting that the authors did not explain the meaning of certain symbols in the context of the proposed method. It also points out that S_i in Figure 2 is different from the calligraphic S_j in line 431, but the method for computing S_i is not explained. The comment provides explicit actions for the authors to take, such as explaining the meaning of the symbols and providing guidance on how to compute them. The feedback is clear and concrete, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"the equations,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the mapping of symbols and the lack of explanation for certain symbols, such as C_i, Q_i, R_i, and A_i, and the difference between S_i and calligraphic S_j. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a specific issue with the mapping of symbols in Figure 2 to those in the equations, noting that the authors did not explain the meaning of certain symbols in the context of the proposed method. It also points out that S_i in Figure 2 is different from the calligraphic S_j in line 431, but the method for computing S_i is not explained. The comment provides a clear and specific observation about the lack of clarity in the paper, which is supported by logical reasoning and specific examples. This makes the claim mostly verifiable, as it provides a detailed basis for the critique. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the mapping of symbols in Figure 2 to those in the equations, noting that the authors did not explain the meaning of certain symbols in the context of the proposed method. It also points out that S_i in Figure 2 is different from the calligraphic S_j in line 431, but the method for computing S_i is not explained. This feedback is clear and actionable, as it provides the authors with specific areas to address in order to improve the clarity and comprehensibility of their draft. By addressing these issues, the authors can enhance the reader's understanding of the proposed method and its implementation. Therefore, the comment is highly helpful, as it offers detailed and constructive suggestions for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests studying the number of backtracking steps and the acceptance rate in addition to the hyper-parameter $I$. While it implies that these additional parameters should be analyzed, it does not provide explicit instructions or concrete steps on how to conduct this analysis. The authors are left to infer that they need to explore these parameters, but without specific guidance, the action remains vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests studying the number of backtracking steps and the acceptance rate in addition to the hyper-parameter $I$. However, it does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in suggesting the need for additional analysis, but without explicit references to sections or figures, the authors may struggle to identify the exact areas that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests studying the number of backtracking steps and the acceptance rate in addition to the hyper-parameter $I$. However, it does not provide any reasoning, evidence, or examples to support why these additional parameters should be analyzed or how they might impact the results. Without such justification, the claim remains unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests studying the number of backtracking steps and the acceptance rate in addition to the hyper-parameter $I$. While it identifies a potential area for further exploration, it lacks specificity and does not provide guidance on how to conduct this analysis or what insights might be gained. The comment is somewhat helpful as it points out a potential area for improvement, but it does not offer actionable steps or detailed suggestions for the authors to follow. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the objective function for GSdyn and FABOLAS, specifically inquiring about the accuracy metric used in the DNN model. It highlights a potential inconsistency in the paper regarding the objective function, noting that the validation dataset or test dataset might be used. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this inconsistency. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the objective function and specify which dataset is used for accuracy. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the objective function for GSdyn and FABOLAS, asking for clarification on which accuracy metric is used (validation or test dataset). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the objective function for GSdyn and FABOLAS, specifically inquiring about the accuracy metric used in the DNN model. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the objective function for GSdyn and FABOLAS, noting that the DNN's accuracy is mentioned as the objective function but without clarification on which accuracy metric is used (validation or test dataset). This feedback is clear and actionable, as it prompts the authors to provide more detailed information about the objective function and the dataset used for evaluating the model. By addressing this question, the authors can improve the clarity and accuracy of their paper. However, the comment could be more helpful if it suggested ways to clarify the objective function or provided examples of how other studies have addressed similar issues. Overall, the comment is mostly helpful, as it directs the authors to a critical area needing clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that section 3.1 should be moved to the related work section and that the proposal should be placed in a new section 3. Additionally, the reviewer suggests that the new section 3 should be split more properly. While the comment provides a clear action to move the content and suggests a reorganization, it lacks specific guidance on how to implement these changes or what the new structure should look like. The authors are given a general direction but not detailed instructions on how to execute the suggested reorganization. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests moving section 3.1 to the related work section and proposing a new section 3 with the proposal. It also suggests splitting the new section 3 more properly. However, the comment does not specify which part of the paper these suggestions pertain to, such as sections 3.1 or 3.2. This makes it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment lacks specificity regarding how the sections should be reorganized or what the new structure should look like. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that section 3.1 should be moved to the related work section and proposes a new section 3 with the proposal. However, the comment does not provide any reasoning, evidence, or references to support why this reorganization is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific reorganization of the paper by proposing to move section 3.1 to the related work section and creating a new section 3 for the proposal. This feedback provides a clear and actionable suggestion for improving the structure and organization of the paper, which could enhance the clarity and coherence of the content. However, the comment could be more helpful if it included additional details or examples on how to implement this reorganization effectively. Overall, the comment is mostly helpful as it offers a concrete suggestion for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about how the authors obtain the priors and requests examples. It implies that the authors should provide a practical method for obtaining the required prior, but it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples and a practical method. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about how the authors obtain the priors, specifically asking for examples. However, it does not specify which part of the paper this question pertains to, such as the numerical experiment section or a particular section discussing priors. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for examples, but without full grounding, it is difficult for the authors to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about how the authors obtain the priors, specifically asking for examples. However, it does not provide any supporting evidence, reasoning, or references to justify why the authors should address this issue or how it affects the paper\\'s validity. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about how the authors obtain the priors, specifically asking for examples. It highlights a potential gap in the paper\\'s explanation, which could be a critical issue for the validity of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern. While it identifies a potential weakness, it does not offer actionable advice or detailed feedback, making it somewhat helpful. The authors are given a direction to explore but lack specific guidance on how to improve their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should perform additional evaluation on the VOT dataset to compare their method with other methods in terms of different metrics such as Accuracy, Robustness, and EAO. While the comment implies that the authors should conduct this additional evaluation, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors need to infer the specific metrics to be evaluated and the exact nature of the additional evaluation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific datasets (OTB-50, OTB-100, OTB-2015, and LASOT) and suggests additional evaluation on the VOT dataset. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what additional evaluation is needed (comparing methods in terms of Accuracy, Robustness, and EAO) and why it is important. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should perform additional evaluation on the VOT dataset to compare their method with other methods in terms of different metrics such as Accuracy, Robustness, and EAO. While the comment provides a logical reasoning for why this additional evaluation is necessary, it lacks specific examples or references to support the claim that these metrics are necessary or how they would improve the evaluation. The suggestion is somewhat verifiable, as it provides a clear direction but could benefit from more detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending additional evaluation on the VOT dataset to compare the proposed method with other methods in terms of different metrics such as Accuracy, Robustness, and EAO. This feedback is actionable and constructive, as it guides the authors on how to enhance their evaluation by considering additional metrics that could provide a more comprehensive understanding of their method's performance. However, the comment could be more helpful if it explained why these metrics are important or how they might impact the overall evaluation. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern that the method is not compared to any state-of-the-art unsupervised semantic segmentation technique. It highlights the lack of comparison to both supervised and unsupervised segmentation methods, noting that the paper claims performance comparability to supervised methods but does not report any state-of-the-art unsupervised method performance. While the comment identifies a gap in the comparison, it does not provide explicit guidance on how to address this issue. The authors can infer that they need to include comparisons to state-of-the-art unsupervised methods, but the comment lacks concrete details on how to execute this action. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"method\" and the \"performance of the proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of comparison to state-of-the-art unsupervised semantic segmentation techniques. The comment provides a clear direction for improvement by suggesting that the authors should include comparisons to both supervised and unsupervised segmentation methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is not compared to any state-of-the-art unsupervised semantic segmentation technique, despite the paper's claim of comparable performance. The reviewer supports this claim by pointing out that the paper does not report any state-of-the-art (supervised nor unsupervised) method performance. This provides a logical reasoning and specific examples to substantiate the claim, making it mostly verifiable. The comment could be strengthened by referencing specific state-of-the-art methods, but the overall argument is clear and provides a solid basis for the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting that the method is not compared to any state-of-the-art unsupervised semantic segmentation technique. It highlights the claim of comparable performance to supervised methods but points out the lack of reporting on state-of-the-art unsupervised methods. This feedback is clear and actionable, as it directs the authors to include comparisons to both supervised and unsupervised methods to provide a more comprehensive evaluation of their work. However, the comment could be more helpful if it suggested specific methods or approaches to include in the comparisons. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a lack of understanding regarding the first curve-finding part and questions the explanation of the FGE work. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify the explanation or what specific aspects need improvement. Without actionable advice or suggestions, the authors are left without a clear path to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the first curve-finding part of the paper, specifically questioning the explanation of the FGE work and the cyclical learning rate scheduling. However, it does not specify which part of the paper this pertains to, such as a particular section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the explanation but lacks grounding, as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the explanation of the first curve-finding part and the FGE work, specifically regarding the cyclical learning rate scheduling. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the explanation is unclear or inadequate. Without additional context or examples, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the clarity of the explanation provided for the first curve-finding part, specifically regarding the FGE work and the cyclical learning rate scheduling. It points out that the cyclical learning rate scheduling could perturb the weight around the initial converged weight but does not guarantee that the weight changes along the described curve. While the comment identifies a potential area for improvement, it lacks specific suggestions or guidance on how the authors might clarify their explanation or address this concern. The feedback is somewhat helpful as it highlights a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should present a case study, preferably with synthetic datasets, to demonstrate why and when a distillation strategy is better. It also questions the authors\\' analysis in Table 3, where LFADS-Hard seems to perform better than LFADS-Soft, but NDT NDT-Correlation generally performs better. The reviewer asks if the authors checked the reasons behind these observations and suggests providing more reasoning or hypotheses based on the performance. While the comment provides explicit actions for the authors to take, such as conducting a case study and offering more reasoning, it does not specify how to implement these actions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a case study to demonstrate why and when a distillation strategy is better, and it questions the authors\\' analysis in Table 3. The comment provides a clear direction for improvement by suggesting the inclusion of a case study and offering a hypothesis about the performance differences. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should present a case study, preferably with synthetic datasets, to demonstrate why and when a distillation strategy is better. It questions the authors\\' analysis in Table 3, where LFADS-Hard seems to perform better than LFADS-Soft, yet NDT NDT-Correlation generally performs better. The reviewer asks if the authors checked the reasons behind these observations and suggests providing more reasoning or hypotheses based on the performance. This comment is mostly verifiable as it provides a logical request for additional analysis and reasoning, but it lacks specific examples or references to support the claim about the performance differences. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improvement by recommending the inclusion of a case study, preferably with synthetic datasets, to demonstrate the effectiveness of a distillation strategy. It also questions the authors\\' analysis in Table 3, specifically pointing out the discrepancy between LFADS-Hard and LFADS-Soft, and NDT NDT-Correlation. The comment prompts the authors to consider the reasons behind these observations and provides a direction for further exploration and hypothesis development. This feedback is highly beneficial as it offers a concrete way for the authors to enhance their draft by incorporating a case study and providing more reasoning or hypotheses based on the performance. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should create cloze-style or question answering evaluation sets that focus exclusively on the generation of factual knowledge. This feedback provides a clear and explicit action for the authors to take, which is to develop a new evaluation method that specifically addresses the generation of factual knowledge. The comment also explains why the current evaluation method is not sufficient, by pointing out that only a few tokens in a sentence are related to facts. This level of detail and specificity makes the action explicit and concrete, allowing the authors to understand exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the focus on evaluation of LM loss throughout the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement: creating cloze-style or question answering evaluation sets that focus exclusively on the generation of factual knowledge. This feedback is detailed and provides a concrete direction for the authors to enhance their evaluation method. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation of LM loss throughout the paper is not clean enough because only a few tokens in a sentence are related to facts. The reviewer proposes creating cloze-style or question answering evaluation sets that focus exclusively on the generation of factual knowledge. This claim is somewhat verifiable as it provides a logical reasoning for the need to improve the evaluation method, but it lacks specific examples or references to support the claim. The suggestion is somewhat supported by the rationale, but further elaboration or evidence would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the evaluation method in the paper. It points out that the current evaluation of LM loss throughout the paper is not clean enough because only a few tokens in a sentence are related to facts. The reviewer proposes creating cloze-style or question answering evaluation sets that focus exclusively on the generation of factual knowledge. This feedback is clear and constructive, offering a concrete way for the authors to enhance the evaluation of their work. By addressing this suggestion, the authors can improve the clarity and effectiveness of their evaluation method. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the theoretical or topological aspects of the RTD score, which is sensitive to cluster, and suggests that the authors should explain why it works specifically for network representation. While the comment implies that the authors should provide an explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide theoretical or topological explanations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the key contribution of the paper, specifically the claim that the RTD score is sensitive to cluster and the experimental verification of this claim. It raises a question about the theoretical or topological aspects of the RTD score, suggesting that the authors should explain why it works specifically for network representation. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for an explanation of the theoretical or topological aspects, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the theoretical or topological aspects of the RTD score, suggesting that the authors should explain why it is sensitive to cluster and specifically works for network representation. The comment raises a valid point about the need for theoretical or topological explanations, but it does not provide specific examples or references to support the claim. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but lacks specific examples or references to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper's explanation of the RTD score, specifically questioning the theoretical or topological aspects that make it sensitive to cluster and specific to network representation. It suggests that the authors should provide an explanation for these aspects, which is a valuable point for improving the clarity and depth of the paper. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a direction for enhancing the paper\\'s explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a claim made in the paper regarding the complexity of ROCK compared to the original model. It suggests that the authors should provide inference timings to support this claim, which is a clear and explicit action. Additionally, it suggests an ablation study to demonstrate the contribution of each auxiliary task on object detection performance in ROCK and standard MTL. This feedback is specific and provides concrete steps for the authors to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L88-89,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely providing inference timings to support the claim about ROCK's complexity and suggesting an ablation study to demonstrate the contribution of each auxiliary task on object detection performance. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim made in the paper regarding the similarity of complexity between ROCK and the original model. The reviewer suggests that providing inference timings would be necessary to support this claim. The comment also suggests an ablation study to demonstrate the contribution of each auxiliary task on object detection performance. While the comment provides a logical reasoning for the need for evidence, it lacks specific examples or references to support the claim. This makes the comment somewhat verifiable, as it provides a clear direction for improvement but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific claim made in the paper regarding the complexity of ROCK compared to the original model. It suggests that the authors should provide inference timings to support this claim, which is a clear and actionable suggestion. Additionally, it provides a constructive suggestion for an ablation study to demonstrate the contribution of each auxiliary task on object detection performance in ROCK and standard MTL. This feedback is valuable as it guides the authors on how to strengthen their argument and provide more robust evidence to support their claims. However, the comment could be more helpful if it included specific examples or references to similar studies that have demonstrated the importance of inference timings or ablation studies. Overall, the comment is mostly helpful as it provides actionable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how to calculate the joint probability P(y_1, y_2, ...| y_{<i}, X) if this part is not autoregressive, and suggests adding the equation to the paper for clarity. While the comment implies that the authors should include the equation to clarify the calculation, it does not explicitly instruct them to do so. The action is concrete, as it specifies the addition of an equation, but it is somewhat vague due to the lack of detailed guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 197-198,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about how to calculate the joint probability P(y_1, y_2, ...| y_{<i}, X) if this part is not autoregressive and suggests adding the equation to the paper for clarity. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on how to calculate the joint probability P(y_1, y_2, ...| y_{<i}, X) if this part is not autoregressive. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the calculation of the joint probability P(y_1, y_2, ...| y_{<i}, X) in a non-autoregressive context. It suggests adding the equation to the paper for clarity, which is a clear and actionable suggestion. However, the comment could be more helpful if it provided additional context or explanation on why this equation is important or how it relates to the overall paper. Despite this, the feedback is mostly helpful as it directs the authors to clarify a critical aspect of their work, which is valuable for improving the clarity and accessibility of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations, and how the model might behave on noisy or imbalanced real-world medical datasets. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they should include more discussion on these topics, but the comment lacks concrete suggestions or examples of what specific aspects should be covered. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not offer detailed guidance on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations, and how the model might behave on noisy or imbalanced real-world medical datasets. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the areas that need more discussion, such as rare conditions, imaging variations, and real-world dataset behavior. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations, and how the model might behave on noisy or imbalanced real-world medical datasets. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it highlights a potential gap but lacks sufficient justification or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the discussion regarding the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations, and how the model might behave on noisy or imbalanced real-world medical datasets. It highlights a critical area for improvement, as the dataset is a crucial component of the study. However, the comment lacks specific suggestions or examples on how the authors might address these issues, such as which datasets to consider or how to ensure the model's robustness. While it points out a significant area for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight into a critical area for improvement but does not offer detailed guidance for implementation.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the reproducibility of the results due to the lack of code for training or testing. It explicitly states that the training details provided do not guarantee reproducibility. However, it does not provide specific guidance on how the authors should address this issue, such as suggesting how to make the code available or what steps to take to ensure reproducibility. The action is implicit and vague, leaving the authors to infer that they need to make their code available, but without detailed instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the overall model, which is comprised of multiple components, and the training process, which requires multiple separate stages. It points out that the lack of code for training or testing makes the results unreproducible. However, the comment does not specify which part of the paper this issue is discussed in, leaving the authors to infer that it relates to the model architecture or training process sections. While the comment is specific in detailing the issue of reproducibility, it lacks grounding as it does not explicitly mention the sections of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model is comprised of multiple components and that training requires multiple separate stages, which makes the results unreproducible due to the lack of code. The comment provides a logical reasoning by pointing out the absence of code, which is a common expectation in scientific research. However, it lacks specific examples or references to support the claim about reproducibility, such as mentioning a specific standard or benchmarking study that requires code availability. This makes the claim somewhat verifiable, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the reproducibility of the results due to the lack of code for training or testing. It highlights a critical aspect of the paper\\'s methodology that could impact its credibility and impact. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of code or offering alternative approaches to ensure reproducibility. While it points out a critical weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a critical omission in the paper, specifically the total number of agents available in Flow\\'s default configuration. While it identifies a specific issue, it does not provide explicit guidance on how the authors should address this omission. The comment implies that the authors should include this information, but it lacks concrete steps or suggestions on how to incorporate it into the paper. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"critical setup information,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of information about the total number of agents available in Flow\\'s default configuration. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"critical setup information is missing,\" specifically mentioning the total number of agents available in Flow\\'s default configuration. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this omission or how it affects the paper\\'s overall quality. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical omission in the paper, specifically the lack of information about the total number of agents available in Flow\\'s default configuration. This is a significant oversight that could impact the readers\\' understanding of the setup and the results presented. However, the comment does not provide specific guidance on how the authors might address this issue or suggest ways to incorporate the missing information. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the claim of being the \"first deep generative model for unsupervised scene-graph discovery\" by pointing out that there are many works that infer structures in an unsupervised way. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what specific aspects of the claim need to be revised. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim of being the \"first deep generative model for unsupervised scene-graph discovery,\" which is a specific part of the paper. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out that there are many works that infer structures in an unsupervised way, questioning the narrow definition of \"scene graph\" and the claim of being the first. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim of being the \"first deep generative model for unsupervised scene-graph discovery\" by pointing out that there are many works that infer structures in an unsupervised way. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or reasoning makes the claim unverifiable, as it lacks the necessary support to substantiate the claim. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the claim of being the \"first deep generative model for unsupervised scene-graph discovery\" by pointing out that there are many works that infer structures in an unsupervised way. It highlights the narrowness of the definition of \"scene graph\" and the claim of being the first, which is a valid point. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve their claim. While it raises an important issue, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the ablation study, noting that it does not provide the effect of different numbers of projectors on distillation when the feature dimensions are different. However, it does not offer any guidance or suggestions on how the authors should address this issue. The comment lacks explicit instructions or concrete steps for the authors to take, leaving them uncertain about how to improve their draft. As a result, the action is implicit and vague, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of information on the effect of different numbers of projectors on distillation when the feature dimensions are different. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study does not provide the effect of different numbers of projectors on distillation when the feature dimensions are different. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the ablation study, noting that it does not provide the effect of different numbers of projectors on distillation when the feature dimensions are different. This feedback is clear and actionable, as it highlights a gap in the experimental analysis that the authors should address to improve the comprehensiveness of their study. However, the comment could be more helpful if it provided suggestions on how to conduct the missing analysis or what specific insights this analysis might offer. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more experiments on diverse datasets are needed to demonstrate the generalization capabilities of the model beyond the three categories mentioned (chair, airplane, car). Additionally, it recommends evaluating more complex shapes with various topologies to better demonstrate the core idea of the proposed method. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors know they need to conduct more experiments but may not be entirely sure which datasets or shapes to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more experiments on diverse datasets are needed to demonstrate the generalization capabilities of the model beyond the three categories mentioned (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to better demonstrate the core idea of the proposed method. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the experimental results and methodology sections. The suggestion to conduct more experiments on diverse datasets is specific, but the recommendation to evaluate complex shapes could be more detailed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experiments on diverse datasets are needed to demonstrate the generalization capabilities of the model beyond the three categories mentioned (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to better demonstrate the core idea of the proposed method. While the comment provides a logical reasoning for why additional experiments are necessary, it lacks specific examples or references to support the claim that diverse datasets or complex shapes are necessary. This makes the claim somewhat verifiable, as the authors would need to infer the importance of these additions themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that more experiments on diverse datasets are needed to demonstrate the generalization capabilities of the model beyond the three categories mentioned (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to better demonstrate the core idea of the proposed method. This feedback is clear and actionable, as it provides specific directions for the authors to enhance their experimental evaluation and demonstrate the broader applicability of their method. By suggesting additional experiments and complex shapes, the comment offers a concrete way for the authors to improve their draft, making it mostly helpful. However, it could be more comprehensive by providing examples of diverse datasets or complex shapes to consider. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a comparison against methods that require more training time is necessary, as the neural networks proposed by Park & Van Hentenryck (2023) and others do not necessitate extensive training time. The reviewer also points out that low computational requirements are important to understand, as they may render certain restrictions (e.g., a hard limit of 10 minutes of training time on a single CPU core) unnecessary. While the comment implies that the authors should conduct a comparison and consider the implications of low computational requirements, it does not provide explicit instructions or concrete steps on how to conduct this comparison or what specific aspects to focus on. The action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be done but without detailed guidance on execution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a comparison against methods that require more training time, specifically mentioning the neural networks proposed by Park & Van Hentenryck (2023) and others. It also highlights the importance of understanding the implications of low computational requirements, as they may render certain restrictions unnecessary. However, the comment does not specify which part of the paper this comparison should be included in, nor does it provide detailed guidance on how to conduct the comparison or what aspects to focus on. While the authors can infer that the comment relates to the experimental setup or results section, the lack of explicit grounding makes it weakly grounded. The comment is specific in its suggestion to include a comparison against methods with more training time, but without detailed guidance on execution, it remains somewhat specific. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison against methods that require more training time is necessary, as the neural networks proposed by Park & Van Hentenryck (2023) and others do not necessitate extensive training time. The reviewer also highlights the importance of understanding the implications of low computational requirements, as they may render certain restrictions unnecessary. The claim is somewhat verifiable as it provides a logical reasoning for the need of a comparison and the importance of understanding computational requirements. However, it lacks specific examples or references to support the claim, such as mentioning specific methods or studies that have demonstrated the impact of low computational requirements. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to conduct a comparison against methods that require more training time, specifically mentioning the neural networks proposed by Park & Van Hentenryck (2023) and others. This is important because it highlights the significance of understanding the implications of low computational requirements, which could render certain restrictions unnecessary. The comment also emphasizes the importance of understanding the computational requirements of the proposed methods, especially in light of the low training time. This feedback is valuable as it directs the authors to a critical aspect of their work that could impact its practical applicability. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or what aspects to focus on. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should provide more comparisons between DetNAS and other networks constructed with efficient blocks, such as ShuffleNetv2. It also provides a specific suggestion to include the result of a 3.8G FLOPs ShuffleNetv2 in Table 2. This feedback is clear and provides concrete actions for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The explicit nature of the suggestion and the detailed guidance on how to implement it make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison between DetNAS and ResNet, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unfairness of the comparison and the suggestion to include more comparisons with other networks constructed with efficient blocks, such as ShuffleNetv2. Additionally, it provides a specific example of the inclusion of a 3.8G FLOPs ShuffleNetv2 in Table 2. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between DetNAS and ResNet is unfair due to the efficiency of the ShuffleNetv2 block compared to the Residual block in ResNet. The reviewer suggests that the authors should provide more comparisons with other networks constructed using efficient blocks, such as ShuffleNetv2. The comment provides a specific suggestion to include the result of a 3.8G FLOPs ShuffleNetv2 in Table 2, which adds a level of detail and specificity to the claim. This makes the comment mostly verifiable, as it provides a logical reasoning and a concrete example to support the claim. However, the comment could be strengthened by referencing specific studies or experiments that demonstrate the efficiency of the ShuffleNetv2 block compared to ResNet. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison between DetNAS and ResNet, noting that the ShuffleNetv2 block is more efficient than the Residual block in ResNet. This feedback is valuable as it highlights a potential bias in the comparison, which could affect the authors\\' conclusions. The comment suggests a more comprehensive comparison by recommending the inclusion of other networks constructed with efficient blocks, such as ShuffleNetv2. Additionally, it provides a specific example of the inclusion of a 3.8G FLOPs ShuffleNetv2 in Table 2, which offers a concrete action for the authors to take. This level of detail and guidance makes the comment mostly helpful, as it directs the authors to a specific area for improvement and provides a clear path for enhancing their analysis. However, the comment could be more helpful if it explained why the comparison between DetNAS and ResNet is unfair or why the authors should focus on other networks with efficient blocks. Overall, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation in the input and output spaces/representations, suggesting that they are restricted to either the group itself under the regular or trivial representation or a homogeneous space of the group. The reviewer implies that this limitation is not as general as other papers mentioned in point (3), which can work with any finite-dimensional representation. However, the comment does not provide explicit guidance on how the authors should address this limitation or suggest specific improvements. The action is implicit and somewhat vague, as the authors need to infer that they should expand the input and output spaces/representations to be more general. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the input and output spaces/representations, and suggests that they are restricted to either the group itself under the regular or trivial representation or a homogeneous space of the group. This provides some grounding by allowing the authors to identify the part of the paper being discussed, namely the sections related to input and output spaces/representations. However, the comment lacks specificity as it does not detail what needs to be addressed or improved in these sections. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the input and output spaces/representations are restricted to either the group itself under the regular or trivial representation or a homogeneous space of the group, which is not as general as other papers mentioned in point (3). The reviewer supports this claim by referencing two papers that can work with any finite-dimensional representation. However, the comment lacks specific examples or detailed reasoning from the referenced papers to fully substantiate the claim. While the reference to other papers provides some context, the comment could be strengthened by offering more detailed comparisons or specific examples to support the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks comprehensive evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the input and output spaces/representations, suggesting that they are restricted to either the group itself under the regular or trivial representation or a homogeneous space of the group. This feedback highlights a potential weakness in the generality of the approach compared to other papers mentioned in point (3), which can work with any finite-dimensional representation. While the comment points out a specific area for improvement, it lacks detailed guidance or suggestions on how the authors might address this limitation or expand their approach. The feedback is somewhat helpful as it provides insight into a potential issue but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential complexity in the practical applications of the system, specifically in real-world image editing tasks involving multiple objects and flexible prompts. It notes that specifying a source prompt, blend word, and various conditions can complicate the process and restrict its usability for typical users seeking simpler image adjustments. However, the comment does not provide explicit guidance or suggestions on how the authors might address this complexity or simplify the process. While it identifies an area of concern, it lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the practical applications of the system, specifically in real-world image editing tasks involving multiple objects and flexible prompts. It highlights the complexity of specifying source prompts, blend words, and various conditions, which may restrict the practical usability of the system for typical users seeking simpler image adjustments. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing the complexity and its potential impact on practical usability. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the practical applications of the system are complex due to the need to specify source prompts, blend words, and various conditions, which may restrict its usability for typical users seeking simpler image adjustments. The comment provides a logical reasoning by highlighting the potential complexity in real-world image editing tasks involving multiple objects and flexible prompts. However, it lacks specific examples or references to support the claim that this complexity restricts practical usability. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential complexity in the practical applications of the system, specifically in real-world image editing tasks involving multiple objects and flexible prompts. It highlights the need to specify source prompts, blend words, and various conditions, which can complicate the process and restrict its usability for typical users seeking simpler image adjustments. While the comment provides a clear understanding of the issue, it lacks actionable suggestions or guidance on how the authors might address this complexity or simplify the process. This limits the comment\\'s usefulness, as it points out a problem but does not offer specific steps for improvement. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper's contributions are not significant, despite the novelty of the technique. It also points out the lack of comparison with traditional classification or manifold learning literature. However, it does not provide explicit guidance on how the authors should address these issues, such as suggesting specific comparisons or improvements to the contribution section. The feedback is vague and lacks concrete steps for the authors to take, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the technique is novel but that the contributions of the paper are not significant, and it points out the lack of comparison with traditional classification or manifold learning literature. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in identifying the lack of significance and the need for comparison, but it is not grounded as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technique is novel but that the contributions of the paper are not significant, and it suggests a lack of comparison with traditional classification or manifold learning literature. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes it challenging for the authors to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s contributions, suggesting that while the technique is novel, the paper\\'s contributions are not significant. It also points out the lack of comparison with traditional classification or manifold learning literature. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or enhance the significance of their contributions. Without actionable feedback or detailed advice, the authors are left without a clear path forward, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a discussion on the impact of few-shot datasets for the sparsity ratio is necessary. It acknowledges that larger datasets could provide more accurate estimates but would also require more time to compute. The reviewer references two external works, [1] and [2], to support their claim. However, the comment does not explicitly instruct the authors to include this discussion or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on this topic. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a discussion on the impact of few-shot datasets for the sparsity ratio is necessary. It references external works [1] and [2] to support this suggestion. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the impact of few-shot datasets and the trade-off between accuracy and computational time. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a discussion on the impact of few-shot datasets for the sparsity ratio is necessary. It references two external works, [1] and [2], to support the claim that larger datasets could provide more accurate estimates but would require more time to compute. This provides a logical basis for the suggestion, but the comment could be strengthened by including specific examples or further elaboration on how the discussion could be structured. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the impact of few-shot datasets on the sparsity ratio. It suggests that a discussion on this topic is necessary, providing a rationale based on the trade-off between accuracy and computational time. The comment references two external works to support its claim, which adds credibility to the suggestion. However, the comment could be more helpful if it offered specific suggestions on how to structure the discussion or what aspects to consider in the analysis. Overall, the comment provides a clear direction for improvement but lacks detailed guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors do not provide a rationale for why it is better to keep representations in the same hidden space and that it has not been experimentally verified that they are in the same hidden space. While the comment identifies a gap in the paper, it does not explicitly instruct the authors on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale or experimental evidence to support their claims. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of rationale or experimental evidence to support the claim that representations are kept in the same hidden space. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the absence of a rationale or experimental evidence to support the claim. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not provide a rationale or experimental evidence to support the claim that representations are kept in the same hidden space. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes it challenging for the authors to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the rationale for keeping representations in the same hidden space and the lack of experimental evidence to support this claim. This feedback is clear and actionable, as it highlights a specific area where the authors need to provide more detailed justification or evidence to strengthen their argument. However, the comment could be more helpful if it suggested specific experiments or analyses that could be conducted to address this issue. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of novelty in the methodology, specifically noting that the paper extends Karwande et al. (2022) by using Faster R-CNN (Ren et al., 2015). It suggests that this approach does not offer significant advancement beyond existing methods, which could limit its contribution to the NLP community. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or enhance the novelty of their methodology. The action is implicit and somewhat vague, as the authors can infer that they need to demonstrate more novelty or innovation in their approach, but the comment does not specify how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the paper\\'s methodology, noting that it lacks sufficient novelty by extending Karwande et al. (2022) with Faster R-CNN (Ren et al., 2015). It suggests that this approach does not offer significant advancement beyond existing methods, potentially limiting its contribution to the NLP community. However, the comment does not specify which part of the paper discusses this methodology or where the lack of novelty is particularly evident. This makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in detailing the issue with the novelty of the methodology, but without explicit grounding, it aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient novelty in its methodology, specifically noting that it extends Karwande et al. (2022) by using Faster R-CNN (Ren et al., 2015). The comment suggests that this approach does not offer significant advancement beyond existing methods, potentially limiting its contribution to the NLP community. However, the comment does not provide specific examples or references to existing methods or literature that could substantiate the claim of lack of novelty. Without detailed comparisons or references, the claim is somewhat verifiable, as it relies on the reader\\'s understanding of the context and existing literature. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s methodology, noting that it lacks sufficient novelty by extending Karwande et al. (2022) with Faster R-CNN (Ren et al., 2015). It suggests that this approach does not offer significant advancement beyond existing methods, which could limit its contribution to the NLP community. While the comment highlights a potential weakness in the paper\\'s originality, it does not provide actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their methodology. The feedback is somewhat helpful as it points out a critical area for improvement, but it lacks depth and specificity, making it difficult for the authors to fully understand and act upon the feedback. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper overlooks various SSM-based approaches that address the issue of keeping $\\\\Delta t$ fixed. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should incorporate these approaches into their work or address the issue of $\\\\Delta t$ fixation. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"S5,\" which provides a specific example of an SSM-based approach that addresses the issue of keeping $\\\\Delta t$ fixed. This allows the authors to identify the part of the paper being addressed, making the comment fully grounded. However, the comment lacks specificity as it does not detail what aspects of the paper need to be revised or improved in relation to these SSM-based approaches. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the paper overlooks various SSM-based approaches that address the issue of keeping $\\\\Delta t$ fixed. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it overlooks various SSM-based approaches that address the issue of keeping $\\\\Delta t$ fixed. By mentioning specific approaches like S5, the comment provides a clear direction for improvement by suggesting that the authors incorporate these approaches into their work. However, the comment could be more helpful if it offered additional guidance on how to integrate these approaches or why they are important. Despite this, the feedback is mostly helpful as it highlights a gap in the paper and provides a specific area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the paper, including the claim that data generation mechanism 3 is presented when it isn\\'t, the suggestion to discuss causal graphs instead of the label inference process, and the difficulty in understanding definition 4 due to the lack of clarity on which graph should be considered for determining independencies. While the comment identifies specific issues, it does not provide explicit guidance on how to address these concerns. The authors are left to infer that they need to clarify the data generation mechanism, discuss causal graphs, and improve the clarity of definition 4. The feedback is somewhat actionable as it highlights areas that need attention but lacks concrete steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 2\" and \"definition 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the data generating mechanism, the label inference process, and the definition of independencies, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that data generation mechanism 3 is presented when it isn\\'t, and suggests discussing causal graphs instead of the label inference process. The reviewer also criticizes the difficulty in understanding definition 4 due to the lack of clarity on which graph should be considered for determining independencies. The comment provides some reasoning by pointing out specific issues with the paper, such as the misrepresentation of the data generation mechanism and the lack of clarity in definition 4. However, it lacks detailed evidence or references to support these claims, making the verifiability somewhat borderline. The authors would need to make a significant effort to understand and address the issues raised, but the comment provides a starting point for improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the claim that data generation mechanism 3 is presented when it isn\\'t, the suggestion to discuss causal graphs instead of the label inference process, and the difficulty in understanding definition 4 due to the lack of clarity on which graph should be considered for determining independencies. The reviewer also points out that the proof of Theorem is hard to read. While the comment highlights specific areas that need attention, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it directs the authors\\' attention to specific areas needing improvement, but it lacks actionable advice or detailed instructions. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the circumstances under which evaluating the gradient of a conjugate function is expensive or infeasible, and suggests including more examples in machine learning to motivate a dual-free approach. While the comment implies that the authors should provide more examples or clarify the context, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include examples or clarify the context. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the circumstances under which evaluating the gradient of a conjugate function is expensive or infeasible, and suggests including more examples in machine learning to motivate a dual-free approach. However, it does not specify which part of the paper this question pertains to, nor does it provide details on what specific examples should be included. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the circumstances under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests including more examples in machine learning to motivate a dual-free approach. However, the comment lacks specific examples or references to support the claim that evaluating the gradient is expensive or infeasible. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the circumstances under which evaluating the gradient of a conjugate function is expensive or infeasible, suggesting that including more examples in machine learning could motivate a dual-free approach. While the comment identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how to address this issue or what examples should be included. The feedback is somewhat helpful as it points out a potential weakness but does not offer detailed suggestions or examples to help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind selecting a probability for the appearance of an unobservable data point in the data approximation technique. It explicitly asks the authors to explain the reason for selecting from [0, Pcj(0)], providing a clear and direct action for the authors to take. This feedback is explicit and concrete, as it specifies the exact part of the algorithm that needs clarification and offers a specific question for the authors to address. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"step 3 of Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the rationale behind selecting a probability for the appearance of an unobservable data point and requests an explanation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the rationale behind selecting a probability for the appearance of an unobservable data point in the data approximation technique. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where the authors need to provide more explanation, specifically regarding the rationale behind selecting a probability for the appearance of an unobservable data point in the data approximation technique. It is a clear and actionable feedback, as it prompts the authors to clarify their methodology and provide a rationale for their choice. This feedback is valuable as it directs the authors to a specific part of the paper that requires further explanation, which could enhance the clarity and transparency of their work. However, the comment could be more helpful if it offered suggestions on how to improve the explanation or provided examples of how other approaches might address this issue. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a precise definition or informal description of the concept of \"spectrum of distributions and their characteristic functions.\" This feedback is explicit, as it clearly identifies a specific area where the paper could be improved by providing more detailed information. The action is concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by suggesting that the text would benefit from a precise definition or informal description of the concept of \"spectrum of distributions and their characteristic functions.\" This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks a precise definition or informal description of the concept of \"spectrum of distributions and their characteristic functions.\" While it identifies a potential gap in the paper, it does not provide specific examples or references to support the claim that this lack of definition is problematic. The comment is somewhat verifiable as it highlights an area for improvement, but it could be strengthened with additional justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the paper could benefit from a precise definition or informal description of the concept of \"spectrum of distributions and their characteristic functions.\" This feedback is clear and actionable, as it directs the authors to provide more detailed information in a specific part of the paper. By addressing this suggestion, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or examples of how this definition or description might be presented. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues with the paper: the lack of clarity regarding the challenges of the AIG-generation task and the need for more background information, and the suggestion to benchmark the proposed method on existing datasets. While the comment implies that more background information should be provided and that benchmarking would be beneficial, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more background information and conduct benchmarking. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the AIG-generation task and suggests that more background information is needed for readers unfamiliar with the area of logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a). While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections. The comment is specific in suggesting the need for more background information and benchmarking, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the AIG-generation task is not convincing and suggests that more background information is needed for readers unfamiliar with the area of logic synthesis. The reviewer also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to enhance the paper\\'s credibility. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support the claim that the task is not convincing. The suggestion for benchmarking is logical, but the lack of specific examples or detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the AIG-generation task, noting that it is not convincing and lacks background information for readers unfamiliar with the area of logic synthesis. It suggests that more background information should be provided to enhance the paper\\'s credibility. Additionally, the reviewer recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), which would further strengthen the paper\\'s argument. This feedback is clear and actionable, providing the authors with specific suggestions for improving the paper\\'s clarity and credibility. However, it could be more helpful if it included examples of what specific background information should be included or how the benchmarking could be conducted. Overall, the comment is mostly helpful as it directs the authors toward meaningful enhancements that can significantly improve the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that some statements in the paper lack detail and analysis. However, it does not specify which statements are lacking or provide any concrete guidance on what additional detail or analysis is needed. The authors are left to infer that they need to provide more information or analysis, but without specific examples or suggestions, the action remains vague. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that some statements in the paper lack detail and analysis, but it does not specify which statements are being referred to. This makes it difficult for the authors to pinpoint the exact parts of the paper that need improvement. Additionally, the comment lacks specificity regarding what kind of detail or analysis is missing, leaving the authors without clear guidance on how to address the issue. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that some statements in the paper lack detail and analysis. However, it does not provide specific examples or reasoning to support this claim, making it difficult for the authors to understand which statements are lacking and how they could improve them. Without specific examples or references, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a general issue with the paper, stating that some statements lack detail and analysis. However, it does not provide specific examples or guidance on which statements are lacking in depth or detail, nor does it suggest how the authors might improve these areas. Without specific feedback or actionable suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a comparison with other generative models, such as VAE, could be more informative. It also highlights the unique features of diffusion models, such as diffusion timesteps, and suggests that an analysis of how these differences affect feature learning would add significant value. While the comment implies that the authors should include such a comparison or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a comparison with other generative models, such as VAE, could be more informative. It also highlights the unique features of diffusion models, such as the diffusion timesteps, and suggests that an analysis of how these differences affect feature learning would add significant value. However, the comment does not specify which part of the paper this comparison should be included in, nor does it provide detailed guidance on how to conduct the analysis. While the authors can infer that it relates to the discussion or results sections, the lack of explicit grounding makes it weakly grounded. The suggestion is specific, but the lack of grounding reduces the overall actionability. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison with other generative models, such as VAE, could be more informative. It also highlights the unique features of diffusion models, such as the diffusion timesteps, and proposes an analysis of how these differences affect feature learning. While the comment provides a logical reasoning for why such a comparison could be beneficial, it lacks specific examples or references to support the claim that these differences significantly affect feature learning. This makes the claim somewhat verifiable, as it provides a rationale but requires further elaboration to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive suggestion for enhancing the paper by including a comparison with other generative models, such as VAE. It highlights the unique features of diffusion models, such as the diffusion timesteps, and suggests that an analysis of how these differences affect feature learning could be valuable. This feedback is actionable and offers a clear direction for the authors to enhance their work by incorporating a more comprehensive comparison. However, the comment could be more helpful if it provided specific guidance on how to conduct the analysis or which aspects of the comparison should be emphasized. Overall, the comment is mostly helpful as it identifies a meaningful area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the effectiveness of the DaPI task in table 4, noting that its memory usage is not significant despite the doubling of GPU memory. It also questions the absence of experiments to show the influence of the number of negatives in the ICoL method. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The authors are left to infer that they should conduct experiments to demonstrate the effectiveness of the ICoL method and potentially explore the impact of the number of negatives. The feedback is somewhat actionable as it highlights areas for improvement but lacks concrete steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 4\" and \"DaPI task,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the combination of tasks and questions the effectiveness of the DaPI task, as well as the absence of experiments to show the influence of the number of negatives in the ICoL method. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the effectiveness of the DaPI task in table 4, noting that its memory usage is not significant despite the doubling of GPU memory. It also questions the absence of experiments to show the influence of the number of negatives in the ICoL method. The reviewer references the TAS-B, which suggests that the quality of negatives is more important than the quantity. While the comment identifies specific issues, it lacks detailed reasoning or references to support why the combination of tasks is not complementary or why the effectiveness of the DaPI task is not significant. The absence of experiments to demonstrate the influence of the number of negatives is also not fully explained. Therefore, the claim is somewhat verifiable, as it provides some insight but lacks comprehensive justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper, particularly regarding the effectiveness of the DaPI task in table 4 and the absence of experiments to demonstrate the influence of the number of negatives in the ICoL method. It references the TAS-B, which suggests that the quality of negatives is more important than the quantity. This feedback is clear and actionable, as it highlights areas where the authors can improve their work by conducting experiments to demonstrate the influence of the number of negatives and potentially exploring the impact of the quality of negatives. However, the comment could be more helpful if it provided suggestions on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward meaningful enhancements to their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that a caption should be added to Figure 3 to clarify the difference between the three plots on the same row. This feedback provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the difference between the three plots on the same row. The comment provides a clear suggestion for improvement by recommending the addition of a caption to emphasize the difference. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Figure 3 is not clear due to the similarity of three plots on the same row. However, it does not provide specific examples or detailed reasoning to support why this is unclear or how it could be improved. The comment lacks supporting evidence or references to guide the authors in addressing the issue. As a result, the claim is not fully verifiable, as it does not provide sufficient justification or examples to substantiate the claim. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that the three plots on the same row are similar and lack clarity. It suggests that a caption should be added to emphasize the difference between them. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the figure\\'s clarity and understanding. However, the comment could be more helpful if it offered additional guidance on how to effectively use captions or what specific information should be included. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement, making it a valuable contribution to the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should provide a deeper dive into the computational complexity of GPSE, particularly when compared to hand-crafted PSEs and other encoding strategies. While the comment implies that the authors should explore this topic further, it does not explicitly instruct them to do so or offer specific guidance on how to approach this analysis. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the computational complexity more thoroughly. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"hand-crafted PSEs\" and \"GPSE's computational complexity,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a deeper dive into the computational complexity of GPSE compared to hand-crafted PSEs and other encoding strategies. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a deeper exploration of the computational complexity of GPSE, particularly when compared to hand-crafted PSEs and other encoding strategies. While the comment highlights a potential limitation, it does not provide specific examples or references to support the claim that hand-crafted PSEs are complex. The lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to infer the complexity of hand-crafted PSEs and other encoding strategies to fully understand the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically the lack of a deeper exploration into the computational complexity of GPSE compared to hand-crafted PSEs and other encoding strategies. It provides a clear direction for improvement by suggesting that the paper should delve deeper into this topic. However, the comment lacks specific suggestions or examples on how to conduct this analysis or what aspects of computational complexity should be emphasized. While it highlights an important area for improvement, the feedback could be more actionable with additional guidance. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but lacks depth in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to report the results on the test-standard split instead of the test-dev split, as per the guidelines from the VQA dataset authors. This feedback is clear and provides a direct action for the authors to take, ensuring that their results align with best practices. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1\" and refers to the VQA dataset guidelines, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely reporting the results on the test-standard split instead of the test-dev split, as per the guidelines. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results on the VQA dataset are reported on the test-dev split, which is not recommended by the dataset authors. The reviewer supports this claim by referencing the guidelines from the VQA dataset authors, providing a clear and specific rationale for the suggestion. This makes the claim fully verifiable, as it offers a logical and well-supported argument for the authors to consider.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the reporting of results on the VQA dataset, noting that the test-dev split is used instead of the test-standard split as recommended by the dataset authors. This feedback is clear and actionable, as it provides the authors with a specific guidance on how to improve their reporting of results. By following this suggestion, the authors can ensure their results align with best practices and are more robust. However, the comment could be more helpful if it explained why this recommendation is important or how it affects the interpretation of the results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how to choose parameters $\\\\beta$, $\\\\alpha$, and $\\\\eta$ to ensure a certain decision-making loss level while optimizing the Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss could improve the impact of the theoretical result. However, the comment does not provide explicit guidance or suggestions on how to address this issue. The authors are left to infer that they should consider this trade-off, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about how to choose parameters $\\\\beta$, $\\\\alpha$, and $\\\\eta$ to ensure a certain decision-making loss level while optimizing the Brier scores. It suggests managing the trade-off between prediction accuracy and decision-loss to improve the impact of the theoretical result. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for guidance on choosing these parameters and managing the trade-off, providing clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question seeking clarification on how to choose parameters for a specific theoretical result. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about how to choose parameters for a theoretical result, specifically asking how to manage the trade-off between prediction accuracy and decision-loss. It identifies a potential area for improvement by suggesting that managing this trade-off could enhance the impact of the theoretical result. However, the comment lacks specific guidance or suggestions on how to address this issue or what specific steps the authors could take to manage the trade-off. While it points out a potential area for improvement, the feedback is incomplete and does not provide actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the applicability of LBEN to more structured layers like convolutions, noting that while it can be applied to convolutional networks without significant modification, its performance trails that of MON. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the applicability of their method to non-fully connected architectures. The comment implies that the authors should consider extending their method to these architectures, but it lacks concrete steps or detailed advice on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the applicability of LBEN to more structured layers like convolutions, noting that while it can be applied to convolutional networks without significant modification, its performance trails that of MON. However, it does not specify which part of the paper this concern relates to, such as a specific section or experiment. The authors can infer that it relates to the applicability section or results, but this inference is not direct. The comment is specific in its critique of the performance comparison, but it lacks grounding as it does not specify where in the paper this issue is discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of LBEN to more structured layers like convolutions, noting that its performance trails that of MON. However, the comment lacks specific examples or references to support the claim that LBEN's performance trails MON. Without detailed evidence or comparisons, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the applicability of LBEN to more structured layers like convolutions, noting that while it can be applied to convolutional networks without significant modification, its performance trails that of MON. This observation suggests that the method presented may not be ready for extension to non-fully connected architectures. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve the applicability of their method. While it identifies a potential limitation, the feedback lacks actionable advice, making it somewhat helpful. The authors are given a direction to consider but without detailed guidance, which limits the comment\\'s utility. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the difficulty in evaluating the refactoring process but suggests that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that the authors could consider for their next benchmark. While the comment implies that the authors should consider these metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these metrics. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment acknowledges the difficulty in evaluating the refactoring process but suggests that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that the authors could consider for their next benchmark. However, the comment does not specify which part of the paper discusses the refactoring process or the unit tests, making it weakly grounded. The suggestion is specific, as it provides a list of potential metrics, but without explicit references to the relevant sections, the authors may struggle to identify the exact parts needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the difficulty in evaluating the refactoring process and suggests that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that the authors could consider for their next benchmark. However, the comment lacks specific examples or detailed reasoning to support why the metrics listed are better alternatives. While it offers a starting point, the justification is not fully developed, making the claim somewhat verifiable. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the difficulty in evaluating the refactoring process and suggests that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that the authors could consider for their next benchmark. This feedback is somewhat helpful as it points out a limitation in the current evaluation process and offers a direction for improvement. However, the comment could be more helpful if it provided more detailed guidance on how to apply these metrics or why they are better alternatives. While it provides a starting point, the authors need more detailed guidance to fully address the issue. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the Wiener deconvolution has been proposed before, suggesting that the main contribution of the paper is not substantial. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the contribution or what specific aspects of the paper need attention. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the main contribution of the paper is not substantial because the Wiener deconvolution has been proposed before. However, it does not specify which part of the paper discusses the Wiener deconvolution or how it relates to the main contribution. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main contribution of the paper is not substantial because the Wiener deconvolution has been proposed before. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main contribution of the paper is not substantial because the Wiener deconvolution has been proposed before. However, it does not provide any specific feedback or suggestions on how the authors might enhance their contribution or address this issue. Without actionable advice or guidance, the comment lacks helpfulness, leaving the authors without a clear path forward. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several areas where the connection to spin glasses is weak and lacks explanation. It explicitly states that the regularization term and energy function do not fully explain the connection, and it points out specific questions that need to be addressed. These include the effect on Parisi's order parameter, the role of temperature, and how the regularization helps escape local minima. The comment provides clear and concrete actions for the authors to take, such as explaining the role of the regularization term and temperature, and addressing the questions about Parisi's order parameter and local minima. This level of explicit guidance makes the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the connection to spin glasses, the role of the regularization term, the effect on Parisi's order parameter, and the role of temperature. This provides clear guidance on what aspects of the paper need improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the connection to spin glasses is weak and lacks explanation, specifically regarding the role of the regularization term, Parisi's order parameter, and temperature. The reviewer provides some reasoning by pointing out that the regularization term and energy function do not fully explain the connection, and that these aspects are crucial to understanding the spin glass theory of neural networks. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further develop the explanation to fully substantiate the claim, but the feedback provides a clear direction for improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas where the connection to spin glasses is weak and lacks explanation. It points out that the regularization term and energy function do not fully explain the connection, and it highlights specific questions that need to be addressed, such as the effect on Parisi's order parameter, the role of temperature, and the role of the regularization term in escaping local minima. This feedback is clear and actionable, providing the authors with specific areas to focus on in order to strengthen their connection to spin glasses and improve the clarity of their explanation. By addressing these points, the authors can enhance the depth and rigor of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the self-training scheme is a direct application and that the contribution is limited. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the contribution or what specific aspects of the self-training scheme could be further explored. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the self-training scheme is a direct application and that the contribution is limited. However, it does not specify which part of the paper discusses the self-training scheme or where the contribution is limited. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. The comment lacks specificity and is not grounded, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the self-training scheme is a direct application and that the contribution is limited. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific details or references, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the self-training scheme is a direct application and that the contribution is limited. While it identifies a potential limitation in the paper, it does not provide specific suggestions or guidance on how the authors might enhance the contribution or address the issue. The comment lacks actionable feedback or detailed insights into how the authors might improve their work. As a result, it offers limited value to the authors, making it barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality of the results. This feedback is explicit and provides a clear action for the authors to take, which is to include these zoomed-in regions in their paper. The suggestion is concrete, as it specifies exactly what the authors need to do to improve the clarity of their results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the results shown in the paper are low-resolution and recommends providing zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality. However, it does not specify which part of the paper this feedback pertains to, such as a specific figure or section. The authors can infer that it relates to the results or images presented, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in its suggestion for improvement. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the results presented in the paper are low-resolution and recommends providing zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality. However, the comment does not provide any supporting evidence or reasoning to justify why the current resolution is insufficient or how providing zoomed-in regions would improve the results. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results presented in the paper, noting that they are low-resolution. It suggests a potential solution by recommending the inclusion of zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and detail of the results. However, the comment could be more helpful if it explained why the current resolution is insufficient or how the suggested zoomed-in regions would enhance the understanding of the results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the comparative inference method: the increase in inference cost due to multiple forward passes and the need for post-hoc calibration validation data, which may not be readily available for open-ended generation tasks. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The authors are left to infer that they need to consider the computational cost and the availability of validation data when applying the method. The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific concerns about the comparative inference method, including the increase in inference cost due to multiple forward passes and the need for post-hoc calibration validation data, which may not be readily available for open-ended generation tasks. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the inference cost and validation data, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparative inference method increases the inference cost significantly due to multiple forward passes, which may be a concern for real-world applications with limited computational resources. It also notes that the post-hoc calibration requires validation data, which may not be readily available for open-ended generation tasks, limiting the method's applicability. These claims are supported by logical reasoning and common knowledge about computational limitations in real-world applications. However, the comment could be strengthened by providing specific examples or references to studies that have experienced similar issues. Despite this, the claims are mostly verifiable, as they are based on reasonable assumptions and observations.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two significant issues with the comparative inference method: the increase in inference cost due to multiple forward passes and the need for post-hoc calibration validation data, which may not be readily available for open-ended generation tasks. These points highlight potential limitations and concerns that the authors should consider when applying the method in real-world scenarios. However, the comment does not provide specific suggestions or guidance on how to address these issues, such as suggesting alternative approaches or methods to mitigate the computational cost or validate the calibration. While it points out important considerations, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors\\' decision to not perform gradient clipping to avoid exploding gradients, suggesting that this would be a more robust approach. However, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The comment implies that the authors should consider gradient clipping, but it lacks detailed guidance on how to implement it or what specific values to use. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L265,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the authors\\' decision not to perform gradient clipping to avoid exploding gradients, suggesting that this would be a more robust approach. The comment provides a clear suggestion for improvement, making it specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' decision not to perform gradient clipping to avoid exploding gradients, suggesting that this would be a more robust approach. However, the comment lacks specific reasoning or evidence to support why gradient clipping is a better solution or why the current approach is considered hacky. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the authors\\' decision not to perform gradient clipping to avoid exploding gradients, suggesting that this would be a more robust approach. It points out that simply reinitializing the model is considered hacky. While the comment identifies a potential issue with the methodology and provides a suggestion for improvement, it lacks depth and does not offer specific guidance or examples on how to implement gradient clipping effectively. The feedback is somewhat helpful as it highlights a potential weakness but does not provide actionable steps for the authors to address it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for a more detailed explanation of the term \"common pattern,\" indicating that the authors need to clarify this concept. This feedback is clear and provides a specific action for the authors to take, which is to provide a more detailed explanation of the term. The comment is concrete, as it directly instructs the authors on what to include in their draft to improve clarity. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the exact meaning of \"common pattern\" and the need for a more detailed explanation. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment consists of a request for clarification regarding the term \"common pattern.\" It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual request for additional information. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the term \"common pattern,\" which is not adequately explained in the paper. It requests a more detailed explanation of this concept, indicating that the current explanation is insufficient. This feedback is clear and actionable, as it directs the authors to clarify an important aspect of their work that could enhance its clarity and understanding. However, the comment could be more helpful if it provided suggestions on how to improve the explanation or offered examples of what a detailed explanation might entail. Overall, the comment is mostly helpful as it guides the authors toward a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the generalizability of the pre-trained model to datasets outside of Reddit, specifically mentioning Twitter and Facebook. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might test or evaluate the model's ability to generalize to these other sources. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the generalizability of the pre-trained model to datasets outside of Reddit, specifically mentioning Twitter and Facebook. However, it does not specify which part of the paper this concern is related to, such as the methodology or results sections. The authors cannot confidently determine which part of the paper is being addressed, making this comment weakly grounded. The comment is specific in its concern about the generalizability of the model, but without explicit references to specific sections, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the pre-trained model to datasets outside of Reddit, specifically mentioning Twitter and Facebook. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the generalizability of the pre-trained model to datasets outside of Reddit, specifically mentioning Twitter and Facebook. This is a relevant concern that the authors should consider when evaluating the applicability and robustness of their model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or methods to test generalizability. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the authors quality check the generated dataset, specifically mentioning that LLM often hallucinates. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific steps the authors should take to ensure the quality of their dataset or how to address the issue of LLM hallucinating. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the quality check of the generated dataset, specifically mentioning that LLM often hallucinates. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where the dataset is discussed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in its question about the quality check process, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking how the authors quality check the generated dataset, specifically mentioning that LLM often hallucinates. This is a factual statement that does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, not a claim. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the quality check process of the generated dataset, specifically mentioning that LLM often hallucinates. This is a relevant point that could prompt the authors to consider the robustness and reliability of their dataset. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their dataset quality checks. Without actionable advice or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the comparison across four models, suggesting that the fine-tuned wav2vec model might perform better than the others. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern, such as suggesting ways to improve the comparison or provide more context for the models. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the comparison across four models, specifically questioning the validity of the comparison due to the fine-tuning of only one model (wav2vec). However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in its concern about the potential bias in the comparison due to fine-tuning, but without explicit references to specific sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the validity of the comparison across four models, suggesting that the fine-tuned wav2vec model might perform better due to its fine-tuning. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to other studies or literature that might substantiate the claim. As a result, the comment is considered borderline verifiable, as it raises a valid concern but lacks sufficient justification or evidence to fully support the claim. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment raises a valid concern about the comparison across four models, suggesting that the fine-tuned wav2vec model might perform better than the others due to its fine-tuning. However, it does not provide specific suggestions or guidance on how to address this issue or improve the comparison. The comment identifies a potential weakness in the study but lacks actionable feedback or detailed advice for the authors to enhance their analysis or interpretation. As a result, the comment is somewhat helpful, as it points out a potential limitation but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is well-written but dense, and recommends adding more examples, such as Figure 2, to help alleviate this density. While the comment implies that the authors should include more examples, it does not explicitly instruct them to do so or provide specific guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should include more examples to improve the readability of the paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper is well-written but dense, and recommends adding more examples, such as Figure 2, to help alleviate this density. However, it does not specify which part of the paper is considered dense or how the addition of examples would improve the readability. The authors cannot confidently determine which part of the paper is being addressed, making this comment weakly grounded. The suggestion to include more examples is specific, but without explicit references to the sections or examples, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper is well-written but dense, and recommends adding more examples to help alleviate this density. However, the comment does not provide specific examples or reasoning to support why the paper is considered dense or how adding examples would improve its readability. Without detailed justification or references, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper is well-written but dense, which could be improved by adding more examples, such as Figure 2. This feedback provides a specific suggestion for enhancing the readability of the paper, which is actionable and constructive. However, the comment could be more helpful if it offered additional guidance on how to effectively incorporate these examples or why Figure 2 is particularly relevant. Despite this, the feedback is mostly helpful as it identifies a clear area for improvement and provides a concrete suggestion for enhancing the paper. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the introduction of high-level intuition in section 4.2 and its absence in section 4.1. While it identifies a potential issue, it does not provide explicit guidance on how to address this discrepancy. The authors are left to infer that they should ensure consistency in the introduction of high-level intuition across sections. The action is implicit and somewhat vague, as it lacks concrete steps on how to implement the suggested improvement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"4.2\" and \"4.1,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies the issue by pointing out the absence of high-level intuition in section 4.1 and its presence in section 4.2. This provides clear guidance on what needs to be addressed in these sections. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that section 4.2 provides high-level intuition while section 4.1 does not. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the introduction of high-level intuition in section 4.2 and its absence in section 4.1. This feedback highlights an area where the paper could be improved by ensuring consistency in the introduction of high-level intuition across sections. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue. While it points out a potential weakness, it does not offer actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it provides a general direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more discussions on the obtained permutation matrices, specifically mentioning Figure (e)(j)(o) in Figure 3. While the comment implies that the authors should include additional discussions, it does not explicitly instruct them to do so or provide specific guidance on what aspects of the discussion should be included. The action is implicit and somewhat vague, as the authors need to infer that they should add more discussions but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure (e)(j)(o)\" in Figure 3, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of more discussions on the obtained permutation matrices. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Figure (e)(j)(o) in Figure 3 represents obtained permutation matrices and recommends including more discussions on these matrices. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these permutation matrices are important or how they should be discussed further. Without additional context or explanation, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that Figure (e)(j)(o) in Figure 3 represents obtained permutation matrices and recommends including more discussions on these matrices. While the comment identifies a specific area for improvement, it lacks depth and does not provide detailed guidance on what aspects of the discussion should be included or how the authors might enhance the representation of these matrices. The feedback is somewhat helpful as it points out a potential area for improvement but does not offer actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the crowd workers, such as who they were, how they were recruited, and how they were trained. While it implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to include this information but may not know exactly how to present it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the crowd workers, such as who they were, how they were recruited, and how they were trained. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for information about the crowd workers, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions about the crowd workers, such as who they were, how they were recruited, and how they were trained. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the crowd workers, such as who they were, how they were recruited, and how they were trained. These questions are relevant to understanding the methodology and potential biases in the study. However, the comment lacks specific guidance or suggestions on how the authors might address these questions or incorporate this information into their paper. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a gap in the paper but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. It also emphasizes the importance of human evaluations. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or improve their evaluation methods. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider human evaluations more thoroughly. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Weakly Correlated Human Evaluation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications and questioning the validity and robustness of the conclusions. The comment also emphasizes the importance of human evaluations. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the correlation between automatic metrics and human evaluations is weak, suggesting that the automatic metrics may not fully capture the quality of the simplifications. This claim is somewhat verifiable as it logically follows from the observation of a weak correlation, but it lacks specific examples or references to support the assertion about the validity and robustness of the conclusions. The comment could be strengthened by providing more detailed evidence or references to substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. It highlights the importance of human evaluations in assessing the results. While the comment points out a relevant concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve their evaluation methods. The feedback is somewhat helpful as it prompts the authors to consider the limitations of their current evaluation methods, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to be more specific about the \"Chain of Reasoning\" section, particularly line 276. This feedback provides a clear and direct action for the authors to take, specifying the exact part of the paper that needs more detail. The comment is explicit and concrete, as it specifies the exact line and section that requires attention, making it highly actionable. Authors know exactly what needs to be done to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 276,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the \"Chain of Reasoning\" section and line 276. This provides clear guidance on what the authors need to improve in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests more specificity in the \"Chain of Reasoning\" section, particularly line 276. However, it does not provide any reasoning, evidence, or examples to support why this specificity is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area of the paper that needs more detail, particularly the \"Chain of Reasoning\" section and line 276. This feedback is clear and actionable, as it directs the authors to provide more specific information in a particular part of the paper. However, the comment could be more helpful if it offered suggestions on what kind of details or examples would be beneficial for clarity. Overall, the comment provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a sample quality metric on the CARLA data, specifically mentioning the common metric minADE or minMSD. While the comment provides a specific suggestion for improvement, it does not offer detailed guidance on how to implement this change or which metrics to use. The action is explicit but somewhat vague, as the authors need to determine which metrics to include and how to integrate them into their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the ability to perform \"hypothetical inference\" or planning, specifically mentioning the use of a graphical model and likelihood function to condition on goal states of one agent and plan latent variables to infer how other agents might respond. It also suggests the inclusion of a sample quality metric, such as minADE or minMSD, on the CARLA data. While the comment provides specific examples of what needs to be addressed, it does not explicitly mention which part of the paper these issues are discussed in. The authors can infer that it relates to the methodology or results sections, but the comment is not fully grounded. It is specific about the need for a sample quality metric but lacks grounding in terms of the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper demonstrates the ability to perform \"hypothetical inference\" or planning using a graphical model and likelihood function to condition on goal states of one agent and plan latent variables to infer how other agents might respond. It also suggests that the inclusion of a sample quality metric, such as minADE or minMSD, would improve forecasting performance. The comment provides some support by referencing a specific metric (minADE or minMSD) and its use in evaluating sample quality. However, it lacks detailed explanation or examples of how this metric would be applied or integrated into the paper. Therefore, the claim is somewhat verifiable, as it provides some context but requires further elaboration for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the inclusion of a sample quality metric, such as minADE or minMSD, on the CARLA data. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\\'s methodology. By including this metric, the authors can demonstrate the effectiveness of their approach in a more comprehensive manner. However, the comment could be more helpful if it provided additional context or examples on how to implement this metric or how it relates to the paper\\'s contributions. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the assumption that every constraint can be naturally associated with its corresponding discriminator. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this assumption or what specific changes they should make to their draft. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the assumption that every constraint can be naturally associated with its corresponding discriminator. However, it does not specify which part of the paper this assumption is discussed in, nor does it provide any context or guidance on how the authors should address this question. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity in detailing what needs to be clarified or improved regarding the assumption. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the assumption that every constraint can be naturally associated with its corresponding discriminator. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the assumption that every constraint can be naturally associated with its corresponding discriminator. While it highlights a potential issue in the paper, it does not provide any guidance or suggestions on how the authors might address this assumption or improve their draft. Without actionable feedback or constructive criticism, the comment offers limited value to the authors in terms of enhancing their work. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors might consider discussing Wasserstein GAN (WGAN) as a baseline method or even adding it to their work. While the comment implies that the authors should include WGAN as a baseline, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include WGAN in their work. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Optimal Transport (OT)\" and \"Wasserstein Distance,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issue by suggesting that the authors might discuss Wasserstein GAN (WGAN) as a baseline method or even add it to their work. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using Optimal Transport (OT) or Wasserstein Distance in GANs is first seen in the Wasserstein GAN paper, specifically mentioning the Wasserstein GAN (WGAN) by Arjovsky et al. (ICML 2017). The comment suggests that discussing WGAN or adding it as a baseline might be beneficial. However, the comment does not provide specific examples or references to support the claim that WGAN is a novel approach or why it should be considered a baseline. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of WGAN and its relevance to their work.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific aspect of the paper that could be improved by discussing Wasserstein GAN (WGAN) or adding it as a baseline method. It provides a clear and actionable suggestion for enhancing the paper by including a relevant and potentially beneficial baseline method. This feedback is valuable as it guides the authors toward a more comprehensive and comparative analysis of their work. However, the comment could be more helpful if it included specific reasons why WGAN is relevant or why it should be considered a baseline. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies the absence of important related work on MCMC in discrete spaces, specifically mentioning that several methods have applied Langevin MCMC to sample discrete sequences. It suggests that this work should be discussed, as it is relevant to the paper. The comment also notes that the paper may not yet meet the standards expected for a conference publication due to issues with clarity and organization. While the comment implies that the authors should discuss related work and improve the clarity and organization of their paper, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of important related work on MCMC in discrete spaces, allowing the authors to identify the specific part of the paper being addressed. It also specifies the issue by suggesting that the paper should discuss methods that have applied Langevin MCMC to discrete sequences, such as those mentioned in references 1 and 2. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not suitable for a conference publication due to issues with clarity and organization, despite presenting preliminary results. The reviewer supports this claim by referencing specific related work on MCMC in discrete spaces, such as Zhang et al. (ICML 2022) and Sun et al. (ICML 2023), which have applied Langevin MCMC to discrete sequences. This provides a logical basis for the claim, as it highlights the relevance of related work and the need for discussion. However, the comment could be strengthened by providing more detailed comparisons or analysis of the methods mentioned. Overall, the claim is mostly verifiable, as it is supported by relevant references and logical reasoning, but it could be further enhanced with additional details.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of important related work on MCMC in discrete spaces. It suggests that the paper should discuss methods that have applied Langevin MCMC to discrete sequences, such as those mentioned in references 1 and 2. This feedback is clear and actionable, as it provides specific guidance on how to enhance the paper by incorporating relevant related work. Additionally, the comment acknowledges the preliminary nature of the results and the need for improvement in clarity and organization, which is constructive feedback that can help the authors refine their work. Overall, the comment is highly helpful as it offers detailed and actionable suggestions for improvement, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the different methods used by DS-FedDRO and FedDRO to estimate $g$. While it does not explicitly instruct the authors to clarify this point, it implies that the authors should address this issue by providing a clear explanation or comparison between the two methods. The comment is somewhat actionable because it implies a specific action, but it lacks concrete guidance on how to implement it. Therefore, the authors can infer that they need to provide a detailed explanation or comparison, but the action is not explicitly stated.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the different methods used by DS-FedDRO and FedDRO to estimate $g$. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where these methods are discussed. This makes it difficult for the authors to identify the exact part of the paper that needs clarification. Additionally, the comment lacks specificity regarding what aspects of the methods are unclear or how they differ. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the different methods used by DS-FedDRO and FedDRO to estimate $g$. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the different methods used by DS-FedDRO and FedDRO to estimate $g$. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or improve their explanation. The comment lacks depth and does not offer actionable feedback, making it barely helpful. The authors are left with a vague request to clarify the methods but without any concrete direction on how to enhance their explanation. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that there should be a discussion about the differences between Nicekl Kiela and l. However, it does not provide any explicit guidance or suggestions on how the authors should approach this discussion or what specific aspects they should focus on. The action is implicit and vague, as the authors are left to infer that they need to include a discussion on the differences but without any concrete direction on what to discuss or how to structure it. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that there should be a discussion about the differences between Nicekl Kiela and l. However, it does not specify which part of the paper this discussion should be included in, nor does it provide any context or guidance on what aspects of the differences should be discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what aspects of the differences should be discussed, making it difficult for the authors to understand the exact changes needed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that there should be a discussion about the differences between Nicekl Kiela and l. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary information to guide the authors in improving their draft. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that there should be a discussion about the differences between Nicekl Kiela and l. However, it does not provide any context or explanation about why this discussion is important or how it could enhance the paper. Without additional information or guidance, the authors are left to infer the relevance and potential benefits of including this discussion. As it stands, the comment lacks depth and specificity, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. However, it does not provide explicit guidance on how the authors should address these issues. The comment implies that the authors should conduct the experiments multiple times and perform variance analysis, but it lacks concrete steps or suggestions on how to implement these changes. As a result, the action is implicit and vague, making it difficult for the authors to know exactly what steps to take to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of multiple experiment runs and variance analysis for the results. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the issues of multiple experiment runs and variance analysis, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the experimental design, noting that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. This feedback is clear and actionable, as it highlights a specific area where the authors need to improve their methodology. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific approaches for conducting multiple runs or suggesting ways to analyze variance. Despite this, the comment still offers valuable insights that can guide the authors in improving their draft, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights gaps in the paper regarding real-world datasets, specifically mentioning the inherent differences between AL experiments and the goal of achieving label efficiency with a human in the loop. It points out that factors such as dataset qualities and temporal drifts in data distributions, which are characteristic of real-world data, are not accounted for in the experiments. However, the comment does not provide explicit guidance on how the authors should address these gaps or suggest specific actions to improve the paper. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"gaps with real-world datasets\" and the \"inherent gaps between AL experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that factors such as dataset qualities and temporal drifts in data distributions are not accounted for in the experiments. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are gaps in the paper regarding real-world datasets, specifically mentioning inherent differences between AL experiments and the goal of achieving label efficiency with a human in the loop. The reviewer acknowledges that factors such as dataset qualities and temporal drifts in data distributions are not accounted for in the experiments. This claim is somewhat verifiable as it highlights a gap in the paper\\'s experimental setup, but it lacks specific examples or references to support the assertion that these factors are inherent in real-world datasets. The authors would need to make a concerted effort to address this issue, which is not fully substantiated by the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the use of real-world datasets for evaluating the proposed method. It points out that the paper does not account for factors such as dataset qualities and temporal drifts in data distributions, which are characteristic of real-world data. This feedback is valuable as it highlights an important area for improvement in the paper, specifically the need to incorporate real-world datasets for a more comprehensive evaluation. However, the comment could be more helpful if it provided specific suggestions on how to address these gaps or what additional experiments could be conducted to improve the paper\\'s relevance to real-world applications. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical area for improvement, but it lacks detailed guidance on how to implement the suggested changes.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the communication cost provided in the paper (O(SAH^2) or O(MSAH^2)) is not particularly low or noteworthy, given that other federated Q-learning algorithms have demonstrated that O(H) communication rounds are sufficient. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue, such as suggesting ways to improve the communication efficiency or providing examples of other algorithms that have achieved better results. As a result, the authors are left without any clear direction on how to respond to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the communication cost provided in the paper, specifically mentioning the values O(SAH^2) or O(MSAH^2). However, it does not specify which part of the paper discusses this communication cost, making it weakly grounded. The comment is specific in its critique of the communication cost being not particularly low or noteworthy, given that other federated Q-learning algorithms have demonstrated O(H) communication rounds as sufficient. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the communication cost provided in the paper is not particularly low or noteworthy, as other federated Q-learning algorithms have demonstrated that O(H) communication rounds are sufficient. However, the comment lacks specific examples or references to these algorithms, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or references, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the communication cost, specifically mentioning that it is not particularly low or noteworthy, given that other federated Q-learning algorithms have demonstrated that O(H) communication rounds are sufficient. This feedback is somewhat helpful as it points out a specific area where the paper may be lacking in comparison to other works. However, the comment does not provide actionable suggestions or guidance on how the authors might address this issue or improve their communication efficiency. While it highlights a potential weakness, it lacks depth and specificity, making it somewhat helpful but not fully comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the main idea of using an ensemble of neural networks is common in machine learning literature and that the paper does not provide any specific adaptation to the homomorphic encryption domain. However, it does not offer any guidance on how the authors might address this issue or suggest specific adaptations. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors without a clear path forward. As a result, the action is implicit and vague, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the paper for not providing specific adaptations to the homomorphic encryption domain, despite using an ensemble of neural networks, which is a common practice in machine learning. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the lack of adaptation to the homomorphic encryption domain, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the main idea of using an ensemble of neural networks is trivial and common in machine learning literature, and that the paper does not provide any specific adaptation to the homomorphic encryption domain. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the main idea of using an ensemble of neural networks is common in machine learning literature and that the paper lacks specific adaptations to the homomorphic encryption domain. This feedback highlights a gap in the paper\\'s originality and contribution, which is crucial for the paper to stand out in the field. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the paper\\'s contribution. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding why and how the new model works better than the previous state-of-the-art, MH, in the experiments on a few benchmark datasets. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide more detailed explanations or comparisons to justify the improvement, but it lacks concrete steps or examples of what should be included. As a result, the action is implicit and vague, making it difficult for the authors to know exactly how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of clarity regarding why and how the new model works better than the previous state-of-the-art, MH, in the experiments on a few benchmark datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks clarity regarding why and how the new model works better than the previous state-of-the-art, MH, in the experiments on a few benchmark datasets. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the lack of clarity in the paper regarding why and how the new model works better than the previous state-of-the-art, MH, in the experiments on a few benchmark datasets. While it points out an important issue, the comment lacks depth and does not provide specific suggestions or examples on how the authors might address this gap in their explanation. Without actionable feedback or detailed guidance, the authors may struggle to understand how to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the formula used in the Adjective Projection part, suggesting that it is not reasonable. It provides a specific suggestion for improvement, recommending that the authors first calculate the similarity between \"large\" and the object, then \"small\" and the object, respectively, before calculating the difference between the two similarities. This feedback is explicit and provides a clear action for the authors to take, making it highly actionable. The authors know exactly what needs to be done to address the issue, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment critiques the formula used in the Adjective Projection part, specifically suggesting that it is not reasonable. However, it does not specify which part of the paper this critique pertains to, such as a particular section or figure. The authors can infer that it relates to the methodology or results section, but this inference is not direct. The comment is specific in detailing what is wrong with the formula, suggesting a different approach, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the formula used in the Adjective Projection part, suggesting that it is not reasonable. The reviewer provides a logical reasoning by explaining that the similarity between \"large\" and the object should be calculated first, followed by the similarity between \"small\" and the object. This reasoning is based on the need to estimate whether the object is large or small, which is a clear and logical explanation. However, the comment could be strengthened by providing specific examples or references to similar methods or studies that support this reasoning. Despite this, the claim is mostly verifiable, as it offers a clear and logical explanation for the critique.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment critiques the formula used in the Adjective Projection part, suggesting that it is not reasonable. It provides a specific suggestion for improvement by recommending that the authors first calculate the similarity between \"large\" and the object, then \"small\" and the object, respectively, before calculating the difference between the two similarities. This feedback is clear and actionable, as it guides the authors on how to address the issue by suggesting a more logical approach to estimating whether an object is large or small. However, the comment could be more helpful if it explained why the current formula is problematic or provided additional context or references to support the suggested approach. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the meaning of \\xe2\\x80\\x9csigma_k=sigmoid(\\xe2\\x80\\x9csigma_k)\\xe2\\x80\\x9d in line 121 and suggests elaborating on the issues mentioned. While the comment implies that the authors should clarify the meaning of the equation and provide more information about the issues, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the equation and address the issues mentioned. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 121,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \\xe2\\x80\\x9csigma_k=sigmoid(\\xe2\\x80\\x9csigma_k)\\xe2\\x80\\x9d and suggests elaborating on the issues listed. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the meaning of a specific equation and a suggestion to elaborate on the issues mentioned. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of a specific equation in the paper, specifically \\xe2\\x80\\x9csigma_k=sigmoid(\\xe2\\x80\\x9csigma_k)\\xe2\\x80\\x9d, and suggests elaborating on the issues listed. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions on how to address the issues or clarify the equation. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss and compare their work to more recent works that specifically focus on any-resolution image generation. It provides specific references to two recent works, [1] and [2], which are relevant to the topic. However, the comment does not explicitly instruct the authors to conduct this comparison or provide guidance on how to structure the discussion. While the references are helpful, the action is implicit and lacks concrete details on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should discuss and compare their work to more recent works that specifically focus on any-resolution image generation, providing specific references to two papers. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in suggesting the need for a comparison with recent works, but without explicit guidance on where to integrate this information, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should discuss and compare their work to more recent works that specifically focus on any-resolution image generation. The reviewer provides specific references to two recent works, [1] and [2], which are relevant to the topic. This provides a clear rationale for the suggestion, making the claim verifiable. The references offer a logical basis for the comparison, making the comment mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that the authors should discuss and compare their work to more recent works that specifically focus on any-resolution image generation. It provides specific references to two recent works, [1] and [2], which are relevant to the topic. This feedback is actionable and constructive, as it directs the authors to consider how their work fits within the broader context of recent advancements in the field. However, the comment could be more helpful if it offered additional guidance on how to structure this comparison or what specific aspects of the recent works should be considered. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several concerns about the paper, including the limited number of subjects in the CT experiment, the lack of discussion on limitations in Section 6, and the need for a discussion on theoretical assumptions and implementation considerations. It also questions the relative improvement of ODER over RED (Unfold) or RED (Denoising) and suggests discussing the training time comparison with online learning alternatives. While the comment identifies specific areas that need attention, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, as the authors need to infer that they should address these issues. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific concerns about the CT experiment, including the limited number of subjects and the need for a discussion on limitations in Section 6. It also questions the relative improvement of ODER over RED (Unfold) or RED (Denoising) and suggests discussing the training time comparison with online learning alternatives. While the comment does not explicitly mention a specific section or line in the paper, it is clear that it relates to the experimental results and limitations discussed in the paper. The authors can infer that it pertains to sections discussing the CT experiment, limitations, and training time comparisons. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the limited number of subjects in the CT experiment, suggesting that this could lead to overfitting. It also questions the sufficiency of the discussion on limitations in Section 6 and suggests that the authors discuss theoretical assumptions and implementation considerations. Additionally, it questions the relative improvement of ODER over RED (Unfold) or RED (Denoising) and asks about the training time comparison with online learning alternatives. While the comment identifies potential issues and questions, it lacks specific examples or references to support the claims. The authors would need to make inferences and conduct further research to fully address the concerns. Therefore, the comment is somewhat verifiable, as it provides a basis for the authors to explore these topics but requires additional evidence or reasoning to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, including the limited number of subjects in the CT experiment, the lack of discussion on limitations in Section 6, and the need for a discussion on theoretical assumptions and implementation considerations. It also questions the relative improvement of ODER over RED (Unfold) or RED (Denoising) and suggests discussing the training time comparison with online learning alternatives. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific suggestions on how to address these issues or provided examples of what a thorough discussion might entail. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the paper regarding the bound on the 2-Wasserstein, noting that it is stated as $O(\\\\epsilon^2)$ but is actually the bound on the 2-Wasserstein squared. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this discrepancy. The action is implicit and somewhat vague, as the authors need to infer that they should correct the discrepancy in the bound. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 216 and 217,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the bound on the 2-Wasserstein, noting that it is stated as $O(\\\\epsilon^2)$ but is actually the bound on the 2-Wasserstein squared. This provides clear guidance on what needs to be corrected in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the bound on the 2-Wasserstein is stated as $O(\\\\epsilon^2)$ but is actually the bound on the 2-Wasserstein squared. This is a factual observation that does not require any subjective interpretation or judgment. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific discrepancy in the paper regarding the bound on the 2-Wasserstein, noting that it is stated as $O(\\\\epsilon^2)$ but is actually the bound on the 2-Wasserstein squared. This is a clear and actionable feedback that the authors can use to correct an error in their work. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as explaining the implications of the discrepancy or suggesting a correction method. Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing attention.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the difference between the proposed multi-scale hierarchical predictor and previous methods, such as IEConv, CDConv, and others. It provides a list of references to these methods, which is helpful. However, the comment does not explicitly instruct the authors to compare their method to these others or suggest how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should compare their method to these others and provide a detailed analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"multi-scale hierarchical predictor\" and provides a list of references to other methods, such as IEConv, CDConv, and others. This allows the authors to identify the specific part of the paper being addressed. The comment is also specific because it asks for clarification on the difference between the proposed method and the previously mentioned methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the difference between the proposed method and previous methods. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the difference between the proposed multi-scale hierarchical predictor and previous methods, such as IEConv, CDConv, and others. It provides a list of references to these methods, which is helpful in guiding the authors to explore and compare their method with existing approaches. However, the comment lacks specific guidance or suggestions on how the authors might address this difference or what aspects of their method need improvement. While it points out a relevant area for comparison, it does not provide actionable feedback or detailed suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper does not read well and suggests that more careful proofreading is needed. However, it does not provide any specific guidance on how to improve the readability or suggest what aspects need more careful proofreading. The action is implicit and vague, as the authors are left to infer that they need to improve the readability but without concrete steps on how to achieve this. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper does not read well and needs more careful proofreading. However, it does not specify which parts of the paper are particularly problematic or where the issues with readability lie. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment lacks specificity, making it difficult for the authors to understand and address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper does not read well and suggests that more careful proofreading is needed. However, the comment does not provide any specific examples or reasoning to support why the paper is difficult to read or how it could be improved. Without detailed evidence or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper does not read well and needs more careful proofreading. However, it lacks specificity and does not provide any guidance on which parts of the paper are particularly problematic or where the issues with readability lie. Without actionable feedback or suggestions on how to improve the readability, the authors are left without a clear path for addressing the issue. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include an analysis of the distribution of addressing coefficients (Betas) with and without sequential addressing, as this difference is important for the synthetic task. It also questions the value of the trade-off parameter (Theta) and asks about its selection process. Additionally, the reviewer inquires about the baseline performance if the attention from the previous question is simply used. While the comment provides explicit actions for the authors to take, such as conducting the analysis and explaining the trade-off parameter, it lacks specific guidance on how to implement these actions. The suggestion to compare the baseline with the previous question's attention is somewhat vague, as it does not provide detailed instructions on how to conduct this comparison. Overall, the comment is mostly actionable, as it clearly identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the distribution of addressing coefficients (Betas) and the trade-off parameter (Theta), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the importance of analyzing the distribution with and without sequential addressing and questions the value of the trade-off parameter. Additionally, it asks about the selection process of the trade-off parameter and suggests comparing the baseline with the previous question's attention. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that an analysis of the distribution of addressing coefficients (Betas) with and without sequential addressing is important for the synthetic task. It also questions the value of the trade-off parameter (Theta) and asks about its selection process. The comment further inquires about the baseline performance if the attention from the previous question is simply used. These questions are based on logical reasoning and assumptions, but they do not provide specific references or examples to support the claims. The comment lacks detailed evidence or examples to fully substantiate the claims, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for the authors to improve their draft. It highlights the importance of analyzing the distribution of addressing coefficients (Betas) with and without sequential addressing, which is crucial for understanding the performance of the synthetic task. The comment also questions the value of the trade-off parameter (Theta) and asks about its selection process, prompting the authors to clarify this aspect. Additionally, it inquires about the baseline performance if the attention from the previous question is simply used, which could help the authors evaluate the robustness of their approach. These suggestions are clear and actionable, offering the authors specific areas for improvement and enhancing the comprehensiveness of their analysis. However, the comment could be more helpful if it provided additional context or examples to support the analysis of the distribution of Betas. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the necessity of Proposition 1, suggesting that it is a standard regression problem and that the application of a standard concentration inequality is appropriate. The reviewer expresses a personal opinion that decorative math is not needed, as the paper is already interesting. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve the paper. It lacks actionable details, such as recommending specific changes or alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the necessity of Proposition 1, suggesting that it is a standard regression problem and that the application of a standard concentration inequality is appropriate. However, it does not specify which part of the paper discusses Proposition 1 or where this proposition is located. The authors can infer that it relates to the paper\\'s methodology or results section, but this inference is not direct. The comment is specific in its critique of the necessity of the proposition, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of Proposition 1, suggesting that it is a standard regression problem and that the application of a standard concentration inequality is appropriate. The reviewer expresses a personal opinion that decorative math is not needed, as the paper is already interesting. However, the comment lacks specific reasoning or examples to support why Proposition 1 is unnecessary or how it detracts from the paper\\'s overall contribution. Without detailed justification or references, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the necessity of Proposition 1, suggesting that it is a standard regression problem and that the application of a standard concentration inequality is appropriate. The reviewer expresses a personal opinion that decorative math is not needed, as the paper itself is already interesting. However, the comment does not provide specific feedback or suggestions on how the authors might address this concern or improve the paper. It lacks actionable guidance or constructive advice, leaving the authors without a clear path forward. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the evaluation of defense techniques, specifically in the context of backdooring classification. It suggests that the evaluation of defenses relying on input perturbation is crucial for a comprehensive understanding of attacks. The reviewer provides specific references to relevant works by Doan et al. (2021) and others, which could serve as a starting point for the authors to conduct their evaluation. However, the comment does not explicitly instruct the authors to conduct this evaluation or provide detailed guidance on how to do so. While the action is implicit, it is concrete because it specifies the need for an evaluation and provides references to relevant works. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the evaluation of defense techniques in the context of backdooring classification. It mentions the need to evaluate defenses relying on input perturbation and provides references to specific works by Doan et al. (2021) and others. This provides clear guidance on what aspect of the paper needs attention. However, the comment does not explicitly mention which section of the paper this issue pertains to, making it weakly grounded. The authors can infer that it relates to the discussion of defense techniques, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a limited evaluation of defense techniques in the context of backdooring classification. The reviewer supports this claim by referencing specific works by Doan et al. (2021) and others, which demonstrate the importance of evaluating defenses relying on input perturbation. This provides a logical basis for the claim, as it highlights the need for a comprehensive understanding of attacks. However, the comment could be strengthened by providing more detailed explanations or examples of how these defenses could be evaluated in the context of the paper. Overall, the claim is mostly verifiable, as it is supported by references and logical reasoning, but it could be further substantiated with additional details.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of defense techniques, specifically in the context of backdooring classification. It suggests that the evaluation of defenses relying on input perturbation is crucial for a comprehensive understanding of attacks. The comment provides specific references to relevant works by Doan et al. (2021) and others, which could serve as a starting point for the authors to conduct their evaluation. This feedback is clear and actionable, as it directs the authors to a specific area for improvement and offers a foundation for further exploration. However, the comment could be more helpful if it provided additional guidance on how to conduct the evaluation or suggested specific methods to consider. Overall, the comment is mostly helpful, as it effectively points out a gap in the evaluation and offers a direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the related work section should be more focused and include similar datasets for non-English and underrepresented languages. It also points out that the context and evidence-based methods are presented too shallowly in the related work. While the comment implies that the authors should expand their related work section and provide more detailed information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should enhance their related work section. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the related work section should be more focused and include similar datasets for non-English and underrepresented languages. It also critiques the presentation of context and evidence-based methods as being too shallow. However, the comment does not specify which part of the paper this feedback pertains to, such as the related work section or the context and evidence-based methods. Without explicit references to sections or specific elements, the authors cannot confidently determine the exact parts of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be improved or expanded in the related work section. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the related work section is too broad and lacks depth, specifically mentioning the need for more focused content and the inclusion of similar datasets for non-English and underrepresented languages. The comment also critiques the presentation of context and evidence-based methods as being too shallow. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the specific aspects that need attention, such as which datasets or contextual elements are missing. Therefore, the comment is somewhat verifiable, as it provides a general direction for improvement but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the related work section, suggesting that it should be more focused and include similar datasets for non-English and underrepresented languages. It also critiques the presentation of context and evidence-based methods as being too shallow. This feedback is clear and actionable, as it provides the authors with a concrete direction for enhancing their related work section and making it more comprehensive. However, the comment could be more helpful if it offered specific examples or guidance on how to present these datasets or contextual elements. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the authors\\' argument that BN can be folded into conv layers, suggesting that BN after ReLU can be folded into the next Conv op. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their argument. It lacks actionable details, such as specific suggestions for how to reframe the argument or provide evidence to support the claim. As a result, the authors are left without a clear understanding of what changes they need to make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific paragraph (Table 2) and the experiment, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the authors\\' argument about folding BN into conv layers, suggesting that BN after ReLU can be folded into the next Conv op. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' argument about folding BN into conv layers, suggesting that BN after ReLU can be folded into the next Conv op. The reviewer provides some reasoning by pointing out that all activation in the same conv feature map shares the same mean / var / scale / offset in BN implementation. However, the comment lacks specific examples or references to support the claim that BN after ReLU can be folded into the next Conv op. This makes the claim somewhat verifiable, as it provides some reasoning but requires further elaboration or evidence to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the authors\\' argument regarding the folding of BN into conv layers. It questions the authors\\' claim that BN after ReLU can be folded into the next Conv op, suggesting that all activation in the same conv feature map shares the same mean / var / scale / offset in BN implementation. While the comment identifies a potential weakness in the authors\\' argument, it lacks specific suggestions or guidance on how the authors might address this issue or improve their reasoning. The feedback is somewhat helpful as it points out a potential flaw but does not provide actionable advice for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of large-scale experiments in the paper and suggests that it would be beneficial to include experiments that vary the size of the network and show a trend indicating whether the results from small-scale experiments will extend to larger scale experiments. While the comment implies that the authors should conduct larger-scale experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct larger-scale experiments to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the lack of large-scale experiments and the need for experiments that vary the size of the network to show a trend indicating whether the results from small-scale experiments will extend to larger scale experiments. This provides clear guidance on what the authors need to address to improve their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the models used in the experiments are small, with 80 hidden neurons for MNIST experiments and a single convolutional layer with 40 channels for SVHN experiments. The reviewer suggests that it would be beneficial to include experiments that vary the size of the network and show a trend indicating whether the results from small-scale experiments will extend to larger scale experiments. This claim is somewhat verifiable as it provides a logical reasoning for why larger-scale experiments would be beneficial, but it lacks specific examples or references to support the need for such experiments. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of large-scale experiments and suggesting that it would be beneficial to include experiments that vary the size of the network to show a trend indicating whether the results from small-scale experiments will extend to larger scale experiments. This feedback is clear and actionable, as it provides a specific area for improvement and offers a concrete suggestion for enhancing the paper\\'s robustness. However, the comment could be more helpful if it included examples of how such experiments might be conducted or what specific trends should be examined. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about what happens when W is an identity matrix and how the results compare with prior work. While it implies that the authors should address this issue, it does not provide explicit instructions or concrete guidance on how to do so. The comment lacks specific details or suggestions on how to incorporate this analysis or what specific aspects of prior work should be compared. As a result, the authors are left with a vague idea of what needs to be done but without clear steps on how to execute it. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about what happens when W is an identity matrix and how the results compare with prior work. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the results should be compared with prior work or how the spherical case is relevant to the analysis. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about what happens when W is an identity matrix and how the results compare with prior work. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about what happens when W is an identity matrix and how the results compare with prior work. While it identifies a potential area for further exploration, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or what aspects of prior work should be compared. The comment is somewhat helpful as it prompts the authors to consider a potential direction for their analysis, but it does not offer actionable steps or detailed feedback. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper focuses on CO problems on graphs rather than general MILP or QUBO problems, which limits its application scope. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or broaden the scope of their work. There is no guidance on whether the authors should consider expanding their focus to include other types of optimization problems or how to do so. As a result, the comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation in the scope of the paper, specifically that it focuses on CO problems on graphs rather than general MILP or QUBO problems. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the scope of the paper, but without explicit references to sections or specific elements, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper focuses on CO problems on graphs rather than general MILP or QUBO problems, which limits its application scope. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the paper, noting that it focuses primarily on CO problems on graphs rather than addressing general MILP or QUBO problems. This feedback highlights an area where the paper could broaden its application scope and potentially attract a wider audience. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand their focus. While it points out a relevant issue, it does not provide actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that learning both low- and high-frequency information in balance is not novel and suggests that the authors should analyze or compare their work with related works that have used stochastic frequency masking to improve super-resolution and denoising networks. The reviewer provides specific references to several related works, including the dates and journals where they were published. This feedback is explicit and provides concrete details on what the authors need to do to improve their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific works that have explored the topic of learning low- and high-frequency information in balance, such as \"Stochastic Frequency Masking to Improve Super-Resolution and Denoising Networks\" and \"FSDR: Frequency Space Domain Randomization for Domain Generalization.\" This allows the authors to identify the exact parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of analysis or comparison with these related works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that learning both low- and high-frequency information in balance is not novel, citing several references to works that have explored this topic. The reviewer provides specific references to these works, which supports the claim by demonstrating that the authors have not contributed anything new to the field. However, the comment could be strengthened by providing more detailed comparisons or analysis of how these works differ from the authors\\' approach. Despite this, the references provide sufficient evidence to support the claim, making it mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the novelty of the paper, noting that learning both low- and high-frequency information in balance is not novel. It provides a detailed list of references to related works that have explored this topic, including specific dates and journals. This feedback is clear and actionable, as it directs the authors to conduct a thorough analysis or comparison of their work with these related works. By addressing this feedback, the authors can significantly enhance the originality and impact of their contribution. However, the comment could be more helpful if it offered suggestions on how to improve the originality or presentation of their work in light of these related works. Overall, the comment is mostly helpful, as it provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly recommends comparing the compression bandwidth of PC+IDF with IDF. This provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve their draft. The comment is specific and provides a concrete step for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of the compression bandwidth of PC+IDF with IDF. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the compression bandwidth of PC+IDF compared with IDF is recommended. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is important or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improvement. It recommends comparing the compression bandwidth of PC+IDF with IDF, which is a clear and concrete step for the authors to take. This feedback is valuable as it directly addresses a potential area for enhancement in the paper, offering a specific direction for the authors to improve their draft. However, the comment could be more helpful if it included additional context or justification for why this comparison is important or how it could impact the overall analysis. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model names T5-ind and T5-seq are misleading and proposes alternative names, such as Desc-ind/seq, Eg-ind, and Demo-ind/seq. While the comment provides a specific suggestion for alternative naming, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should consider the proposed names. However, the comment does provide a concrete suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of misleading model names, specifically suggesting alternative names like Desc-ind/seq, Eg-ind, and Demo-ind/seq. However, it does not specify which part of the paper these model names are mentioned in, making it weakly grounded. The comment is specific in suggesting alternative names, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model names T5-ind and T5-seq are misleading, suggesting alternative names like Desc-ind/seq, Eg-ind, and Demo-ind/seq. However, the comment does not provide any reasoning, examples, or references to support why these names are misleading or why the suggested alternatives are more appropriate. Without additional context or justification, the claim remains unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the model names T5-ind and T5-seq, suggesting that they are misleading. It proposes alternative names, such as Desc-ind/seq, Eg-ind, and Demo-ind/seq, which could be more descriptive and informative. While the comment highlights a specific area for improvement, it lacks depth and does not provide detailed reasoning or guidance on why the current names are misleading or how the suggested alternatives might be more appropriate. This limits the comment\\'s usefulness, making it somewhat helpful. However, it does offer a clear suggestion for improvement, which is a positive aspect. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of the acronym \"AR\" for \"artificial intelligence\" and notes its reuse in line 055. While the comment raises a concern about consistency, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to review and potentially revise the acronym usage, but the comment lacks concrete details on how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the acronym \"AR\" for \"artificial intelligence\" and its reuse in line 055, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the choice of acronym and its reuse, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of the acronym \"AR\" for \"artificial intelligence\" and its reuse in line 055. However, it does not provide any reasoning or evidence to support why this choice is problematic or inappropriate. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the choice of acronym \"AR\" for \"artificial intelligence\" and its reuse in line 055. While it identifies a potential inconsistency, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential problem, but it does not offer actionable advice or detailed feedback for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the core idea of the paper is to find a parameter to control the ratio of task-specific features to task-shared features, but it questions the motivation of the gating design for MTL. It suggests that the gating mechanism is not a new story in MTL, but it does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete suggestions or actions for the authors to take, leaving them uncertain about how to improve their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the core idea of the paper, which is to find a parameter to control the ratio of task-specific features to task-shared features. It also questions the motivation of the gating design for MTL, suggesting that the gating mechanism is not a new story in MTL. However, the comment does not specify which part of the paper discusses these ideas, making it weakly grounded. The comment is specific in detailing what needs clarification or improvement, such as the motivation of the gating design and its relation to MTL. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the core idea of the paper is to find a parameter to control the ratio of task-specific features to task-shared features, and questions the motivation of the gating design for MTL. The comment suggests that the gating mechanism is not a new story in MTL. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim borderline verifiable, as it requires further elaboration to be fully understood and addressed by the authors.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s core idea, noting that the motivation for the gating design in MTL is not clear. It suggests that the gating mechanism is not a new story in MTL, which could be a significant concern for the authors. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the clarity of their motivation. While it points out a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. The authors are given a direction to consider but lack specific guidance on how to improve their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the practical scenarios presented by the authors are impaired by the strong assumptions required to train the model, such as the availability of ground truth and DMs decisions. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific steps they could take to improve the practicability of their model. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the practical scenarios presented by the authors and highlights the limitations caused by the strong assumptions required to train the model. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in detailing the limitations of the practical scenarios due to assumptions, but it lacks grounding as it does not specify where this issue is discussed in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the practical scenarios presented by the authors are impaired by the strong assumptions required to train the model, such as the availability of ground truth and DMs decisions. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the practical scenarios presented by the authors, noting that the strong assumptions required to train the model, such as the availability of ground truth and DMs decisions, may impair the practicability of the model. This feedback highlights an important aspect of the paper that could impact its applicability and real-world relevance. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the practicability of their model. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental part is less convincing, specifically mentioning that the LR and SVM-based baselines are too weak compared to deep learning approaches. However, it does not provide any explicit or implicit suggestions for how the authors might improve the experimental part or address this issue. There is no guidance on potential modifications, additional experiments, or ways to enhance the baselines. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental part of the paper, specifically mentioning that the LR and SVM-based baselines are too weak compared to deep learning approaches. However, it does not specify which part of the experimental section is less convincing or where the weaknesses lie. The authors can infer that it relates to the baselines, but the comment lacks full grounding as it does not explicitly mention sections or figures. Additionally, while the comment highlights a specific issue, it does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the experimental part is less convincing due to the weakness of the LR and SVM-based baselines compared to deep learning approaches. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the assertion, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the claim. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental part of the paper, noting that the LR and SVM-based baselines are too weak compared to deep learning approaches. This feedback highlights a potential weakness in the paper\\'s experimental evaluation, which could impact the credibility of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as suggesting alternative baselines or methods to strengthen the baselines. Without actionable advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the motivation of the GLASU algorithm is to save communication, but neither the theorem nor the experiment discuss the communication cost. This implies that the authors should include a discussion of the communication cost in their paper to fully support their contribution. However, the comment does not explicitly instruct the authors to include this discussion, leaving it somewhat vague. The action is implicit and somewhat vague, as the authors can infer that they need to address this issue but may not know exactly how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"communication-efficient\" and \"GLASU algorithm,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the theorem and experiment do not discuss the communication cost, which undermines the contribution of the paper. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation of the GLASU algorithm is to save communication but that neither the theorem nor the experiment discuss the communication cost, which undermines the contribution of the paper. This claim is somewhat verifiable as it highlights a potential gap in the paper\\'s discussion of communication efficiency. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the communication cost themselves to fully address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, noting that the motivation of the GLASU algorithm is to save communication but that neither the theorem nor the experiment discuss the communication cost. This feedback highlights a significant gap in the paper\\'s discussion, which undermines the contribution. By pointing out this oversight, the comment provides the authors with a clear and actionable suggestion for improvement. However, it could be more helpful if it offered specific guidance on how to address this issue, such as recommending the inclusion of a discussion on communication cost or suggesting ways to measure and analyze it. Overall, the comment is mostly helpful as it directs the authors\\' attention to a crucial area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to explicitly state the contributions of their paper. This feedback is clear and provides a direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and provides a concrete action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to explicitly state the contributions of the paper. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explicit statement of contributions. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the contributions of the paper should be explicitly stated. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment highlights a specific area for improvement by suggesting that the contributions of the paper should be explicitly stated. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that needs clarification and enhancement. By addressing this point, the authors can improve the clarity and impact of their paper, making it more effective in communicating its contributions. However, the comment could be more helpful if it provided examples or guidance on how to effectively state the contributions. Overall, the comment is mostly helpful as it identifies a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the motivation of the work is not clear and that the explanation is not convincing. It suggests that the authors should justify the claim \"different densities directly cause semantic conflicts\" either experimentally or theoretically. While the comment provides a specific action for the authors to take, it does not offer detailed guidance on how to conduct the experiments or provide theoretical justification. The action is explicit but somewhat vague, as the authors know what needs to be done but may not have a clear understanding of the exact steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"different densities directly causing semantic conflicts\" and suggests that this claim should be justified either experimentally or theoretically. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in the motivation and explanation of the work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation of the work is not clear and that the explanation is not convincing. It suggests that the authors should justify the claim \"different densities directly cause semantic conflicts\" either experimentally or theoretically. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence makes the claim unverifiable, as it does not provide sufficient support for the authors to improve their draft. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity and persuasiveness of the motivation and explanation in the paper. It points out that the authors mention the potential conflict between different densities without providing a clear justification or experimental evidence to support this claim. The comment suggests that the authors should either justify this claim experimentally or theoretically, which is a clear and actionable suggestion for improvement. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct the experiments or provide theoretical justification. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a concrete direction for the authors to enhance the clarity and rigor of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the training method of the three transformer modules in the proposed approach, asking whether they are trained iteratively or in an end-to-end manner. It also mentions that Figure 5 shows a similar visualization to Figure 1 and suggests that repeating visualizations without demonstrating new points is unnecessary. While the comment implies that the authors should clarify the training method and potentially justify the repetition of visualizations, it does not provide explicit instructions or concrete steps for how to address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information or justify the repetition. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the proposed approach\" and \"Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the training method of the transformer modules and questions the repetition of visualization in Figure 5. The comment provides clear guidance on what needs to be addressed, namely the clarification of the training method and the justification for repeating visualizations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the training method of the transformer modules in the proposed approach. It also mentions that Figure 5 shows a similar visualization to Figure 1 and suggests that repeating visualizations without demonstrating new points is unnecessary. The comment does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the training method of the transformer modules in the proposed approach, asking whether they are trained iteratively or in an end-to-end manner. It also points out that Figure 5 shows a similar visualization to Figure 1 and suggests that repeating visualizations without demonstrating new points is unnecessary. While the comment identifies a potential issue with the repetition of visualizations, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the paper. The feedback is somewhat helpful as it highlights a potential area for clarification and improvement, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific points for improvement, such as clarifying the terms \"parameters of BFNs\" versus \"parameters of BFN-produced distributions.\" It also suggests that the authors should explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that aren\\'t due to BFNs. These points are explicit and provide clear guidance on what the authors need to do to improve their draft. The action is concrete, as it specifies exactly what needs to be clarified and how to differentiate the proposed method from existing work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"parameters of BFNs\" versus \"parameters of BFN-produced distributions,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear guidance on what needs to be clarified and how to distinguish the proposed method from existing work. The comment suggests that the authors should explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that aren\\'t due to BFNs. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the writing could benefit from greater precision and clarity, providing specific examples of areas that need improvement, such as \"parameters of BFNs\" versus \"parameters of BFN-produced distributions.\" It also suggests that the proposed method is closely related to infoDiffusion, with the main adaptation being its application to BFNs. The comment further recommends that the authors explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that aren\\'t due to BFNs. This feedback is mostly verifiable as it provides specific examples and logical reasoning to support the claim. However, it could be strengthened by referencing external works or providing more detailed examples of how the authors might clarify their contributions. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the clarity and precision of the writing. It identifies specific areas where the authors need to improve, such as the use of terms like \"parameters of BFNs\" versus \"parameters of BFN-produced distributions.\" This feedback is clear and directs the authors to make specific changes that can enhance the readability and comprehensibility of their draft. Additionally, the comment suggests that the authors should explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that aren\\'t due to BFNs. This suggestion is valuable as it helps the authors differentiate their work from existing methods and provide a clearer picture of their contributions. Overall, the comment is mostly helpful as it offers concrete and actionable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the discussion in lines 60-74 and the text, suggesting that the authors may have implied a focus on a situation where the gradient of the sum is not the sum of individual gradients. The reviewer also notes that this paragraph could be discussed in less space, as it is a common setting in all ERM approaches. The comment provides a specific observation and a suggestion for clarification, but it does not offer explicit guidance on how to address this issue or improve the text. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the discrepancy and potentially revise the discussion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lines 60-74, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a discrepancy between the discussion and the text, suggesting that the authors may have implied a focus on a situation where the gradient of the sum is not the sum of individual gradients. This is a clear and specific critique, providing the authors with a clear direction for improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion in lines 60-74 (beginning of Section 2) suggests a focus on a situation where the gradient of the sum is not the sum of individual gradients, which is not communicated in the text. The reviewer provides a specific example of a common setting in all ERM approaches, suggesting that this paragraph could be discussed in less space. The comment is somewhat verifiable as it provides a logical reasoning for the claim, but it lacks specific references or examples to fully substantiate the claim. The authors would need to make a concerted effort to verify the claim themselves, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a discrepancy between the discussion in lines 60-74 and the text, suggesting that the authors may have implied a focus on a situation where the gradient of the sum is not the sum of individual gradients. This is a specific and actionable observation, as it points out a potential miscommunication in the text. The reviewer also suggests that this paragraph could be discussed in less space, as it is a common setting in all ERM approaches. This feedback is valuable as it highlights an area where the authors may need to clarify their message or rephrase their discussion to avoid confusion. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested specific changes to the text. Overall, the comment is mostly helpful as it identifies a critical area for clarification and improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the proposed question-rewrite strategy, specifically questioning whether it covers a sufficiently large number of questions. The reviewer provides specific data from Table 4 in the appendix to support their claim, noting that 23% of passages become invalid and 44% of questions are attributed to unresolved coreference. Additionally, the reviewer points out that the proposed method rewrites only 12% of questions for all models, which they consider insignificant. While the comment identifies a concern, it does not provide explicit guidance or suggestions on how the authors might address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider the effectiveness of their question-rewrite strategy but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed question-rewrite strategy\" and provides specific data from Table 4 in the appendix to support the concern. It also references the L373 line, allowing the authors to pinpoint the exact part of the paper being addressed. The comment is specific because it details the concerns about the method\\'s effectiveness, questioning whether it covers a sufficiently large number of questions and noting that the method rewrites only 12% of questions for all models. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the proposed question-rewrite strategy, questioning whether it covers a sufficiently large number of questions. The reviewer provides specific data from Table 4 in the appendix, noting that 23% of passages become invalid and 44% of questions are attributed to unresolved coreference. Additionally, the reviewer references L373 to support their claim that the proposed method rewrites only 12% of questions for all models, which they consider insignificant. This provides a robust basis for the claim, making it mostly verifiable. The authors can understand the basis of the concern but may need to further analyze the data and methodology to fully address the critique. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the proposed question-rewrite strategy, questioning its effectiveness in covering a sufficiently large number of questions. The reviewer provides specific data from Table 4 in the appendix, noting that 23% of passages become invalid and 44% of questions are attributed to unresolved coreference. Additionally, the reviewer references L373 to support their claim that the proposed method rewrites only 12% of questions for all models, which they consider insignificant. This feedback is somewhat helpful as it identifies a potential weakness in the methodology and provides specific data to support the critique. However, the comment could be more helpful if it offered suggestions on how the authors might address this concern or improve their method. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of L2 distance in equation (4) and suggests that earth mover's distance might be more common in OT. It does not provide explicit instructions or suggestions for the authors to follow, but it implies that the authors should consider the benefits of using L2 distance over earth mover's distance. While the comment highlights an area for potential improvement, it lacks concrete guidance on how to address this issue or what specific benefits of earth mover's distance should be considered. The action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (4)\" and \"L2 distance,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of L2 distance in the context of OT and suggests that earth mover's distance might be more common. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the use of L2 distance in equation (4) and suggests that earth mover's distance might be more common in OT. However, it does not provide any supporting evidence, reasoning, or references to justify why earth mover's distance is preferred over L2 distance. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the use of L2 distance in equation (4) and suggests that earth mover's distance might be more common in OT. While it identifies a potential inconsistency in the choice of distance metric, it does not provide any guidance or suggestions on how the authors might address this issue or why earth mover's distance might be a better choice. The comment lacks depth and specificity, leaving the authors without actionable feedback or direction on how to improve their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the description of related work is scattered throughout the paper and recommends a broader discussion on how the algorithm compares to other offline RL algorithms. While the comment implies that the authors should expand their discussion of related work, it does not provide specific guidance on how to structure this discussion or what aspects to include. The action is implicit and somewhat vague, as the authors need to infer that they should expand the related work section and include a comparison to other offline RL algorithms. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the description of related work, specifically mentioning that it is scattered throughout the paper. It suggests a broader discussion on how the algorithm compares to other offline RL algorithms. However, it does not specify which sections of the paper contain the related work discussion, making it weakly grounded. The comment is specific in its suggestion for a broader discussion, but without explicit references to sections, the authors may struggle to pinpoint the exact parts needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the description of related work is scattered throughout the paper, with specific references to papers like [14,15]. However, it does not provide a detailed analysis or reasoning for why this scattering is problematic or how it affects the paper\\'s overall coherence or significance. The comment lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered borderline verifiable, as it provides some context but lacks sufficient evidence or reasoning to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization and presentation of the related work section, noting that it is scattered throughout the paper. It suggests a broader discussion on how the algorithm being discussed compares to other offline RL algorithms. While the comment highlights an area for improvement, it lacks specific guidance on how to structure this discussion or what aspects to include. The authors are given a general direction but without detailed suggestions or examples, making the feedback somewhat helpful. It provides a clear direction for improvement but could be more actionable and comprehensive. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the final solution when all increments are available at the same time, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific changes they should consider. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the final solution when all increments are available at the same time, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine whether it relates to a specific section, table, or figure. Additionally, the comment lacks specificity as it does not provide details on what aspect of the solution would change or how this change would impact the paper. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the final solution when all increments are available at the same time. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the final solution when all increments are available at the same time, which could be a relevant consideration for the authors. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this question or what potential implications it might have on their work. Without actionable feedback or context, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the use of multiple feature spaces, specifically mentioning the 25-feature space of Mitchell et al. and the full/pruned glove model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or suggestions for improvement. Without actionable advice, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the use of multiple feature spaces, specifically mentioning the 25-feature space of Mitchell et al. and the full/pruned glove model. This provides full grounding as it allows the authors to accurately identify the specific parts of the paper being addressed. The comment is also specific because it clearly specifies the issue with the technique, which is the potential for circular reasoning. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technique of using multiple feature spaces is \"convoluted and potentially circular.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of multiple feature spaces, specifically mentioning the 25-feature space of Mitchell et al. and the full/pruned glove model. It points out that this technique could be convoluted and potentially circular, which is a valuable observation that could lead to improvements in the paper. However, the comment lacks specific suggestions or guidance on how to address this issue or improve the technique. While it highlights a potential weakness, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include comparisons with other works that use MobileNetV3 search space, such as AtomNAS, in Table 7. It also questions why the results of OFA with progressive shrink are not included in the table. This feedback provides clear and concrete actions for the authors to take, specifying exactly what needs to be added to the table and why. The explicit nature of the request and the detailed guidance on what to include make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of comparisons with other works that use MobileNetV3 search space, such as AtomNAS, and the inclusion of results of OFA with progressive shrink in the table. This provides clear guidance on what needs to be added to the table. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that comparisons with other works using MobileNetV3 search space, such as AtomNAS, should be included in Table 7. It also questions why the results of OFA with progressive shrink are not included in the table. While the comment provides a logical request for additional information, it lacks specific examples or references to support the claim that these comparisons are necessary or beneficial. This makes the claim somewhat verifiable, as the authors would need to infer the importance of these comparisons themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that Table 7 should include comparisons with other works that use MobileNetV3 search space, such as AtomNAS. It also questions why the results of OFA with progressive shrink are not included in the table. This feedback is clear and actionable, as it provides the authors with a concrete direction for enhancing their work by including relevant comparisons and data. However, the comment could be more helpful if it offered additional guidance on how to interpret or analyze these comparisons, or if it suggested specific ways to present the data in the table. Overall, the comment is mostly helpful as it directs the authors to a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors include a brief discussion explaining why hallucinations are undesirable and why they need to be fixed, in addition to pointing to existing work. This feedback provides a clear and explicit action for the authors to take, which is to include a discussion on the undesirable aspects of hallucinations and their relevance to the work. The suggestion is concrete, as it specifies what needs to be added to the paper, and it offers a specific direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including a brief discussion on why hallucinations are undesirable and why they need to be fixed, in addition to pointing to existing work. However, it does not specify which part of the paper this discussion should be included in, nor does it provide detailed guidance on what aspects of hallucinations need to be addressed. The authors may infer that it relates to the discussion or results sections, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific in detailing what needs to be addressed.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that a brief discussion on why hallucinations are undesirable and why they need to be fixed should be included, along with references to existing work. However, the comment does not provide any specific reasoning or evidence to support why hallucinations are undesirable or why they need to be fixed. Without additional context or examples, the claim lacks sufficient justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors include a brief discussion on why hallucinations are undesirable and why they need to be fixed, in addition to pointing to existing work. This feedback is somewhat helpful as it provides a specific direction for improvement by suggesting a potential addition to the paper. However, it lacks depth and does not offer detailed guidance on how to address the issue of hallucinations or what specific aspects of the discussion should be included. While the comment identifies a potential area for improvement, it could be more helpful with additional context or suggestions on how to effectively integrate the discussion into the paper. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, noting that lines 50-54 mention terms like Type-1 error, Type-2 error, and false positive rate before clearly stating the null hypothesis. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting a specific order or clarification of the null hypothesis. The action is implicit and somewhat vague, as the authors can infer that they need to reorder or clarify the content, but the comment lacks concrete details on how to implement this action. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (50-54) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific issue with the order of terms and the null hypothesis statement, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that lines 50-54 mention terms like Type-1 error, Type-2 error, and false positive rate before clearly stating the null hypothesis. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this order is problematic or how it affects the clarity of the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that lines 50-54 mention terms like Type-1 error, Type-2 error, and false positive rate before clearly stating the null hypothesis. This feedback is somewhat helpful as it points out a potential confusion or lack of clarity in the paper, which the authors can address to improve the presentation of their ideas. However, the comment could be more helpful if it provided suggestions on how to clarify the null hypothesis or reorder the content for better flow. Overall, the comment offers some guidance but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reliability of the model due to uncertainty in the estimates from the continuous importance weight function. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the reliability of the model due to uncertainty in the estimates from the continuous importance weight function. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the probabilistic process and the potential impact on the model's reliability. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the reliability of the model due to uncertainty in the estimates from the continuous importance weight function. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reliability of the model due to uncertainty in the estimates from the continuous importance weight function. It raises a valid concern about the impact of this uncertainty on the model's performance. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the model's reliability. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the correlation between human judgments and the SFAM scorers used in the LISA embedding. It suggests that this may make the LISA more content-focused than style-focused. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks actionable details, such as recommending specific changes or improvements to the SFAM scorers or the LISA embedding. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"SFAM scorers\" and \"LISA embedding,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the correlation between human judgments and the SFAM scorers, suggesting that this may make the LISA more content-focused than style-focused. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the SFAM scorers used in the LISA embedding do not correlate well with human judgments on linguistics-relevant styles, such as simplification and linguistic acceptability. This claim is somewhat verifiable as it provides a specific example of sentiment and emotion, which are considered semantics-relevant, and suggests that the LISA may be more content-focused than style-focused. However, the comment lacks detailed evidence or references to support the claim that the SFAM scorers do not correlate well with human judgments on linguistics-relevant styles. Providing more detailed reasoning or examples would strengthen the claim, making it more fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the SFAM scorers used in the LISA embedding, noting that they do not correlate well with human judgments on linguistics-relevant styles such as simplification and linguistic acceptability. This feedback highlights a potential limitation in the LISA's ability to capture both content and style, which could impact the overall effectiveness of the model. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the model. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments should include evaluation on other real-world datasets like DexYCB with more recent hand-object pose estimation pipelines to predict the initial hand-object poses. While the comment implies that the authors should consider this additional evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this evaluation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should include evaluation on other real-world datasets like DexYCB with more recent hand-object pose estimation pipelines to predict the initial hand-object poses. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. This makes it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the evaluation should be addressed or how the inclusion of these datasets would enhance the study. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the experiments should include evaluation on other real-world datasets like DexYCB with more recent hand-object pose estimation pipelines to predict the initial hand-object poses. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this evaluation is necessary or how it would improve the study. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the experiments should include evaluation on other real-world datasets like DexYCB with more recent hand-object pose estimation pipelines to predict the initial hand-object poses. This feedback is somewhat helpful as it identifies a potential area for improvement in the experiments, which could enhance the study\\'s relevance and applicability. However, the comment lacks specific guidance on how to implement this suggestion or what specific aspects of the evaluation should be considered. To be more helpful, the comment could provide examples of how this additional evaluation could be conducted or what specific metrics should be used. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of explicit explanation in the paper regarding important components, such as the design of sequential models and the attention model update. It explicitly states that this is critical for understanding the rationale of the proposed work. However, the comment does not provide specific guidance on how to address this issue, such as suggesting what aspects need more detail or how to improve the explanation. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations but are not given concrete steps to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the design of sequential models\" and \"the attention model update,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explicit explanation on these important components. This provides clear guidance on what the authors need to improve in their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks explicit explanation on important components, such as the design of sequential models and the attention model update, which are critical for understanding the rationale of the proposed work. However, the comment does not provide specific examples or detailed reasoning to support why these components are crucial or how their absence affects the paper\\'s comprehensibility. Without concrete evidence or references, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is somewhat verifiable, as it provides a general idea of what needs to be improved but lacks specificity and detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of explicit explanation on important components such as the design of sequential models and the attention model update. This is a significant oversight, as these components are crucial for understanding the rationale of the proposed work. The comment highlights a specific area where the paper could be improved, providing clear guidance on what needs to be addressed. However, it does not offer suggestions or examples on how to improve the explanation or provide more detail, which would make the feedback more actionable. Overall, the comment is mostly helpful as it points out a significant gap in the paper\\'s explanation but lacks detailed guidance on how to address it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be helpful to make the entire code accessible in case the paper is accepted. While this is an explicit request, it lacks specific guidance on how to achieve this accessibility or what aspects of the code should be made available. The authors are left with a clear action to take but without detailed instructions on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it would be helpful to make the entire code accessible in case the paper is accepted. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for code accessibility, providing clear guidance on what needs to be done. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be helpful to make the entire code accessible in case the paper is accepted. However, it does not provide any reasoning, evidence, or examples to support why this is necessary or beneficial. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it would be helpful to make the entire code accessible in case the paper is accepted. While this is a reasonable suggestion, it lacks specificity and does not provide guidance on why this accessibility is important or how it would benefit the paper. The comment does not offer any context or examples to help the authors understand the potential benefits or impact of making the code accessible. As a result, the feedback is somewhat helpful, as it identifies a potential area for improvement but does not provide actionable steps for the authors to take. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the explanations of specific processes, such as spike-driven token selection and intra- and inter-stage feature fusion, could be clearer. It explicitly recommends including pseudo-code or flow diagrams to enhance the reader\u2019s understanding of the model\u2019s operation. This feedback provides a clear and concrete action for the authors to take, ensuring that they know exactly what steps to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific processes of \"spike-driven token selection\" and \"intra- and inter-stage feature fusion,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the explanations of these processes, and suggests including pseudo-code or flow diagrams to enhance understanding. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the explanations of specific processes, such as spike-driven token selection and intra- and inter-stage feature fusion, could be clearer. It recommends including pseudo-code or flow diagrams to enhance the reader\\'s understanding of the model\\'s operation. This claim is somewhat verifiable as it provides a logical reasoning for improving the clarity of the explanations, but it lacks specific examples or references to support the suggestion. The authors would need to infer the exact benefits of including pseudo-code or flow diagrams, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the explanations of specific processes, such as spike-driven token selection and intra- and inter-stage feature fusion, could be clearer. It provides a concrete suggestion by recommending the inclusion of pseudo-code or flow diagrams to enhance the reader\\'s understanding of the model\\'s operation. This feedback is actionable and offers a clear direction for the authors to improve the clarity and comprehensibility of their explanations. However, the comment could be more helpful if it provided examples of how these diagrams might be structured or what specific aspects of the processes should be highlighted. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and offers a clear suggestion for enhancing the clarity of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a critique of the proposed method, stating that it is an incremental improvement on existing AutoAugment but does not yield significant performance improvements compared to recent methods. It also points out that the standard deviation (std) is very large, which raises concerns about generalizability. However, the comment does not offer any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issues raised, such as suggesting specific improvements or experiments to conduct. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the proposed method, stating that it is an incremental improvement on existing AutoAugment but does not yield significant performance improvements compared to recent methods. It also points out that the standard deviation (std) is very large, which raises concerns about generalizability. However, the comment does not specify which part of the paper discusses the method or the performance improvements, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in detailing the issues with the method\\'s performance and generalizability, but it lacks grounding as it does not specify where these issues are discussed in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is an incremental improvement on existing AutoAugment but does not yield significant performance improvements compared to recent methods. It also mentions that the standard deviation (std) is very large, which raises concerns about generalizability. However, the comment lacks specific references or detailed evidence to support these claims. Without detailed comparisons or examples, the authors may find it challenging to understand the basis of these claims and address them effectively. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a critique of the proposed method, stating that it is an incremental improvement on existing AutoAugment but does not yield significant performance improvements compared to recent methods. It also points out that the standard deviation (std) is very large, which raises concerns about generalizability. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their method. Without actionable feedback or detailed advice, the authors are left without clear direction on how to enhance their draft. Therefore, the comment is barely helpful, as it identifies areas for improvement but does not provide sufficient guidance for the authors to make meaningful changes.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a weakness in the comparison by pointing out the lack of reference to existing prior art and the significant performance gaps between the proposed method and the latest methods. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific references or methods to improve the comparison. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context or references to strengthen the comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"comparison\" and \"existing prior arts,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of reference to existing prior art and the significant performance gaps between the proposed method and the latest methods. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison is weak due to the lack of reference to existing prior art and the significant performance gaps between the proposed method and the latest methods. However, the comment does not provide specific references to the prior art or examples of the performance gaps, making it difficult for the authors to understand the basis of the claim. The lack of detailed evidence or examples makes the claim unverifiable, as it does not provide sufficient support for the critique. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the lack of reference to existing prior art and the significant performance gaps between the proposed method and the latest methods. It highlights the need for a stronger comparison by suggesting that the authors should reference relevant prior work and provide more detailed performance comparisons. While the comment points out a critical issue, it does not offer specific suggestions or guidance on how to address these gaps or improve the comparison. This limits the comment\\'s helpfulness, as it provides insight but lacks actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors argue for the diversity of the data gathered but do not provide quantification, which is considered a minor issue. The reviewer suggests that even a simple types vs. token statistic would be useful. This feedback is explicit in its request for additional quantification, providing clear guidance on what the authors should add to their draft. The action is concrete, as it specifies exactly what kind of quantification is needed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the authors\\' argument for the diversity of the data gathered, noting the lack of quantification and suggesting that even a simple types vs. token statistic would be useful. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion for providing quantification, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors argue for the diversity of the data gathered but do not provide quantification, which is considered a minor issue. The reviewer suggests that even a simple types vs. token statistic would be useful. This claim is somewhat verifiable as it highlights a gap in the paper\\'s presentation but lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion for quantification is clear, but the comment could be strengthened by providing more context or examples of what kind of quantification would be beneficial. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of quantification to support the authors\\' argument for the diversity of the data gathered. It suggests that even a simple types vs. token statistic would be useful. This feedback is clear and actionable, as it provides a concrete suggestion for how the authors can enhance their paper by adding quantitative data. However, the comment could be more helpful if it explained why quantification is important or how it would strengthen the argument. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims to create a more diverse set of positive instance pairs but lacks a suggested measure of diversity and no comparison with earlier works regarding the diversity of examples. This feedback implies that the authors should provide a method or metric for measuring diversity and include a comparison with previous studies. However, the comment does not explicitly instruct the authors to include these elements, leaving the action somewhat implicit. The authors can infer that they need to address these points, but the exact steps for doing so are not explicitly stated. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim made in the paper regarding the creation of a more diverse set of positive instance pairs. It points out that the paper lacks a suggested measure of diversity and no comparison with earlier works regarding the diversity of examples. However, the comment does not specify which part of the paper discusses these claims, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what is missing\u2014a suggested measure of diversity and a comparison with earlier works\u2014but it does not provide guidance on how to address these issues. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s claim of creating a more diverse set of positive instance pairs is not supported by a suggested measure of diversity or a comparison with earlier works regarding diversity. This claim is somewhat verifiable as it provides a logical reasoning for why the claim lacks sufficient evidence or comparison. However, the comment could be strengthened by providing specific examples or references to earlier works that demonstrate the need for a more comprehensive evaluation of diversity. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper\\'s claims regarding the creation of a more diverse set of positive instance pairs. It points out that the paper lacks a suggested measure of diversity and no comparison with earlier works regarding the diversity of examples. This feedback is clear and actionable, as it highlights a critical area where the authors need to provide more detailed information or evidence to support their claims. By addressing these points, the authors can enhance the credibility and comprehensiveness of their work. However, the comment could be more helpful if it suggested specific measures or comparisons that could be used to evaluate diversity. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the approach would compare to other inputs, specifically mentioning structured information, and notes that AUCROC seems high in other models in literature. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or what specific comparisons they should make. The action is implicit and vague, as the authors are left to infer that they should make comparisons and provide additional context. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about how the approach would compare to other inputs, specifically mentioning structured information and noting that AUCROC seems high in other models in literature. However, it does not specify which part of the paper this comparison should be made in, nor does it provide detailed guidance on how to address this concern. The authors can infer that it relates to the discussion or results section, but the lack of explicit grounding makes it weakly grounded. The comment is specific in its request for a comparison, but without clear grounding, it is difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about how the approach would compare to other inputs, specifically mentioning structured information and noting that AUCROC seems high in other models in literature. However, the comment lacks specific examples or references to support the claim that AUCROC is high in other models. Without detailed evidence or comparisons, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient evidence or reasoning to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a pertinent question about the comparison of the approach to other inputs, specifically mentioning structured information and noting that AUCROC seems high in other models in literature. This prompts the authors to consider how their approach would perform in relation to other methods, which is an important aspect of evaluating the novelty and effectiveness of their work. However, the comment lacks specific guidance or suggestions on how to conduct this comparison or what specific aspects to focus on. While it highlights a relevant area for improvement, the lack of actionable feedback limits its usefulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides several explicit suggestions for improvement. First, it explicitly instructs the authors to state the objective function in experiments, along with Monte Carlo estimates of the expectations. It also questions whether Eq. 7 should have a reverse inequality sign due to the expected loss. Additionally, it suggests that some parts of Section 3 are too technical and could be revised to better explain the main method in Section 4. The comment also recommends leaving more space in Section 4 to explain the training procedure, which could enhance the reader's understanding. These suggestions are clear and provide specific actions for the authors to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3\" and \"sec. 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the objective function in experiments, the reverse inequality sign in Eq. 7, and the technicality of Section 3. The comment also provides suggestions for improvement, such as leaving more space in Section 4 to explain the training procedure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the objective function in experiments and the sign of the inequality in Eq. 7. It also suggests that some parts of Section 3 are too technical and could be revised to better explain the main method in Section 4. While the comment provides logical reasoning by questioning the sign of the inequality and suggesting improvements, it lacks specific examples or references to support the claims. The suggestion to leave more space in Section 4 is somewhat vague, as it does not provide detailed guidance on how to achieve this. Overall, the comment is somewhat verifiable, as it provides some reasoning but lacks comprehensive evidence or examples to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improvement. It explicitly instructs the authors to state the objective function in experiments, along with Monte Carlo estimates of the expectations, which is a clear and specific action. Additionally, it questions the sign of the inequality in Eq. 7 and suggests that some parts of Section 3 are too technical, recommending that the authors leave more space in Section 4 to explain the training procedure. This feedback is constructive and provides the authors with a clear path to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered additional guidance on how to effectively communicate the objective function or how to simplify the technical sections. Overall, the comment is mostly helpful as it provides actionable suggestions for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for an explanation of why the Disc. reward for SPACE and f-PCPO is decreasing in the Grid (Fig.3, top right plot). This is a clear and direct request, providing the authors with a specific action to take. The comment is specific and provides a concrete direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Grid (Fig.3, top right plot),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation of why the Disc. reward for SPACE and f-PCPO is decreasing in the Grid, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for an explanation of why the Disc. reward for SPACE and f-PCPO is decreasing in the Grid (Fig.3, top right plot). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the behavior of the Disc. reward for SPACE and f-PCPO in the Grid (Fig.3, top right plot), which is a clear and actionable point. By asking for an explanation, the reviewer prompts the authors to clarify an aspect of their work that may be confusing or misleading. This feedback is valuable as it directs the authors to provide a more comprehensive and accurate representation of their results. However, the comment could be more helpful if it offered suggestions on how to address this issue or what specific aspects of the explanation should be emphasized. Overall, the comment is mostly helpful as it identifies a critical area for clarification and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of key implementation details, such as the resolutions at which images successfully achieve adversarial effects. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include this information, but it lacks concrete steps or examples on how to incorporate it. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, namely the lack of key implementation details, such as the resolutions at which images successfully achieve adversarial effects. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in identifying the missing information, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact location of the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"key implementation details are missing,\" specifically mentioning the resolutions at which images successfully achieve adversarial effects. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, namely the absence of key implementation details, such as the resolutions at which images successfully achieve adversarial effects. This feedback is clear and actionable, as it highlights a critical aspect of the paper that needs to be addressed. However, the comment could be more helpful if it provided suggestions on how to incorporate this information or what specific resolutions should be included. Despite this, the comment still offers valuable insights that can guide the authors in improving their draft. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should explore improvements to the motion guidance strategy itself to enhance training efficiency. While it implies that the current approach is effective in reducing training time, it does not provide specific guidance on how to improve the motion guidance strategy or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should explore improvements to the motion guidance strategy. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section on data preprocessing, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the approach, suggesting that the current method does not significantly simplify the overall complexity and recommends exploring improvements to the motion guidance strategy. This feedback is detailed and provides a clear direction for the authors to consider, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach in the section on data preprocessing is effective in reducing training time but does not significantly simplify the overall complexity. It suggests that exploring improvements to the motion guidance strategy itself would enhance training efficiency. The comment provides a logical reasoning for the need to improve the motion guidance strategy, but it lacks specific examples or references to support the claim. The suggestion is somewhat verifiable, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive critique of the approach in the section on data preprocessing, suggesting that while the current method effectively reduces training time, it does not significantly simplify the overall complexity. It recommends exploring improvements to the motion guidance strategy itself to enhance training efficiency. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a direction for the authors to consider. However, the comment could be more helpful if it offered specific suggestions or examples of how to improve the motion guidance strategy. Overall, the comment is mostly helpful as it provides valuable insights and guidance for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the statistics of relation phrases and how often rarer relation phrases are predicted in a sentence. It also mentions the potential issue of heavy tail in relations, which could be more severe than heavy tail in words. However, the comment does not provide explicit instructions or suggestions on how the authors should address these issues or improve their draft. The action is implicit and vague, as the authors are left to infer that they should investigate the statistics and consider the heavy tail in relation phrases. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the statistics of relation phrases and how often rarer relation phrases are predicted in a sentence. It also mentions the potential issue of heavy tail in relations, which could be more severe than heavy tail in words. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its inquiry about the statistics and the issue of heavy tail in relation phrases, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the statistics of relation phrases and how often rarer relation phrases are predicted in a sentence. It also mentions the potential issue of heavy tail in relations, which could be more severe than heavy tail in words. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or reasoning makes the claim borderline verifiable, as it provides some insight but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises important questions about the statistics of relation phrases and how often rarer relation phrases are predicted in a sentence. It also highlights the potential issue of heavy tail in relations, which could be more severe than heavy tail in words. While the comment identifies a significant area for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is somewhat helpful as it prompts the authors to consider these aspects, but it could be more beneficial with additional actionable advice or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the statement regarding robustness in dynamic regions, specifically mentioning edge cases where random samples of points may not be sufficient. It suggests two potential solutions: masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to implement these solutions or provide detailed guidance on how to implement them. The action is explicit but somewhat vague, as the authors know what needs to be done but may not have a clear understanding of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Dynamic Regions\" statement, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, noting that it is generally true but may not be robust enough for edge cases like the Bonn dataset, where moving objects can occupy over 50% of the image. The comment provides specific suggestions for addressing this issue, such as masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement regarding robustness in dynamic regions is generally true but identifies edge cases where more robust approaches are needed. The reviewer provides a specific example of the Bonn dataset, where moving objects like humans can occupy over 50% of the image. The comment suggests potential solutions, such as masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. This provides a clear and specific example of an edge case, along with actionable suggestions for improvement. The claim is fully verifiable, as it is supported by a concrete example and detailed guidance on how to address the issue.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s discussion of robustness in dynamic regions. It points out that the statement is generally true but highlights edge cases where more robust approaches are needed, such as when moving objects like humans occupy over 50% of the image in the Bonn dataset. The comment suggests two potential solutions: masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the robustness of their approach in dynamic regions. By offering concrete suggestions, the comment helps the authors improve the robustness of their method and address potential limitations. Therefore, it is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments in the paper focus solely on the comparison between various models proposed by the authors and do not include a comparison with other methods. This implies that the authors should expand their experimental scope to include comparisons with other methods. However, the comment does not provide specific guidance on which methods to include or how to structure these comparisons. While the action is implicit, it is somewhat vague as it lacks concrete details on how to implement the suggested improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the experimental setup, noting that the experiments only focus on comparisons between various models proposed by the authors and lack comparisons with other methods. This provides clear guidance on what aspect of the paper is lacking, namely the absence of comparisons with other methods. However, it does not specify which models or methods should be included in the comparisons, leaving the authors to infer the exact details. Therefore, the comment is weakly grounded as it does not explicitly mention a specific section or part of the paper, but it is specific in detailing what is missing. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments in the paper focus solely on comparisons between various models proposed by the authors and lack comparisons with other methods. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that the experiments focus solely on comparisons between various models proposed by the authors and lack comparisons with other methods. This feedback is clear and actionable, as it highlights a gap in the experimental setup that could enhance the paper\\'s comprehensiveness and relevance. However, the comment could be more helpful if it provided suggestions on which methods to include in the comparisons or how to structure these comparisons. Despite this, the feedback is mostly helpful as it directs the authors\\' attention to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a minor issue with the notation used in Tables 3 and 4, specifically noting that the \"math specialist\" label is applied to some models but not to the MAVIS models themselves. The reviewer suggests that the MAVIS models should also be considered math specialists. While the comment identifies a specific issue, it does not provide explicit guidance on how to address it, such as suggesting a change in notation or explaining why the MAVIS models should be considered math specialists. The action is implicit and somewhat vague, as the authors need to infer that they should add an asterisk to the MAVIS models. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 and 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation used for the \"math specialist\" models, suggesting that the MAVIS models should also be considered math specialists. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation used in Tables 3 and 4 is inconsistent, as it includes an asterisk for some models but not for others. The reviewer suggests that the MAVIS models should also be considered math specialists, as they are described as such in the text. However, the comment lacks specific examples or references to support the claim that the MAVIS models should be labeled as math specialists. Without additional context or evidence, the claim is somewhat verifiable, as it provides a logical reasoning but lacks detailed justification. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a minor issue with the notation used in Tables 3 and 4, specifically noting that the \"math specialist\" label is applied to some models but not to the MAVIS models themselves. The reviewer suggests that the MAVIS models should also be considered math specialists, providing a clear and actionable suggestion for improvement. This feedback is valuable as it highlights a potential inconsistency in the notation and offers a straightforward way for the authors to enhance the clarity and accuracy of their work. However, the comment could be more helpful if it included additional context or explanation on why the MAVIS models should be considered math specialists. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the technical novelty of the paper is limited, as KNN-based methods are widely studied in LM and MT. It points out that the paper provides few insights into a non-parametric method for text classification. However, the comment does not provide explicit guidance or suggestions on how the authors could enhance the novelty or insights of their work. It lacks actionable details, such as recommending specific areas for improvement or additional experiments to explore. As a result, the authors are left without clear direction on how to address the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical novelty of the paper is limited, as KNN-based methods are widely studied in LM and MT. It points out that the paper provides few insights into a non-parametric method for text classification. However, the comment does not specify which part of the paper discusses KNN-based methods or how the authors could enhance the novelty or insights of their work. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical novelty of the paper is limited, as KNN-based methods are widely studied in LM and MT. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the technical novelty of the paper is limited, as KNN-based methods are widely studied in LM and MT. It points out that the paper provides few insights into a non-parametric method for text classification. However, the comment lacks specificity and actionable suggestions on how the authors could enhance the novelty or insights of their work. It does not provide guidance on potential areas for improvement or additional experiments that could be conducted to differentiate the paper from existing literature. As a result, the comment is barely helpful, as it identifies a weakness but does not offer concrete steps for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper overstates the extensive enhancement of IM for existing RL algorithms and lacks a comparison with the latest work, particularly non-pixel-based approaches to address data efficiency. While the comment identifies a gap in the paper\\'s content, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they should include a comparison with the latest work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"extensive enhancement\" of IM for existing RL algorithms and the \"most recent description of the mainstream RL algorithms in related work,\" which is SAC in 2018. It also specifies the issue by pointing out the lack of a comparison with the latest work, particularly non-pixel-based approaches to address data efficiency. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper overstates the extensive enhancement of IM for existing RL algorithms and lacks a comparison with the latest work, particularly non-pixel-based approaches to address data efficiency. The comment provides a specific observation about the content of the paper, noting that the description of mainstream RL algorithms is outdated. However, it does not provide specific examples or references to support the claim that the enhancement is overstated or that the comparison is missing. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to verify the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it overstates the extensive enhancement of IM for existing RL algorithms and lacks a comparison with the latest work, particularly non-pixel-based approaches to address data efficiency. This feedback is clear and actionable, as it points out a gap in the paper\\'s content and suggests a specific area for improvement. By addressing this issue, the authors can enhance the relevance and comprehensiveness of their work. However, the comment could be more helpful if it provided examples or references to support the claim about the overstatement or suggested specific non-pixel-based approaches to include. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should expand the background discussion in Section 2 and related work by providing further background knowledge on adversarial examples, as well as on white-box, grey-box, and black-box threat models in the context of poisoning. It also recommends referencing relevant surveys to clarify the threat model and position at the state-of-the-art (SoA) and to facilitate understanding for non-expert readers. While the comment provides explicit actions\u2014expanding the background discussion and referencing surveys\u2014it does not specify which surveys should be referenced or how to integrate this information into the paper. The action is clear but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests expanding the background discussion in Section 2 and related work, specifically by providing further background knowledge on adversarial examples and threat models in the context of poisoning. It also recommends referencing relevant surveys to clarify the threat model and position at the state-of-the-art (SoA) and to facilitate understanding for non-expert readers. While the comment does not explicitly mention a specific section or part of the paper, it is clear that it relates to the background discussion and related work sections. The suggestion to reference surveys is specific, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests expanding the background discussion on adversarial examples and threat models in the context of poisoning. It recommends referencing relevant surveys to clarify the threat model and position at the state-of-the-art (SoA) and to facilitate understanding for non-expert readers. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that these additions would clarify the threat model or enhance understanding. This makes the claim somewhat verifiable, as it provides a direction for improvement but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for expanding the background discussion in Section 2 and related work. It recommends including further background knowledge on adversarial examples and threat models in the context of poisoning, specifically suggesting that the authors reference relevant surveys to clarify their threat model and position at the state-of-the-art (SoA). This feedback is specific and offers a concrete way for the authors to enhance their draft, making it more comprehensive and accessible to both experts and non-experts. By addressing these points, the authors can significantly improve the clarity and depth of their background discussion, which is valuable for both the academic community and potential readers. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a lack of clarity regarding the importance of the proposed multiple-span answer setting in real-world applications. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of the setting need clarification. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a lack of clarity regarding the importance of the proposed multiple-span answer setting in real-world applications. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs clarification. Additionally, the comment lacks specificity regarding what aspects of the setting are unclear or how they could be clarified. Without explicit references or detailed guidance, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed multiple-span answer setting is unclear in its relevance to real-world applications. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses a lack of clarity regarding the importance of the proposed multiple-span answer setting in real-world applications. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or what aspects of the setting need clarification. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests mixing the train set examples with hypernyms and non-hypernyms. While the comment implies that this could be a beneficial approach, it does not provide explicit instructions or concrete guidance on how to implement this suggestion. The authors are left to infer that they should consider this approach, but without detailed guidance, the action remains vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests mixing the train set examples with hypernyms and non-hypernyms. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The suggestion is specific in terms of the action being proposed, which is to mix the train set examples with hypernyms and non-hypernyms. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests mixing the train set examples with hypernyms and non-hypernyms. However, it does not provide any reasoning, evidence, or examples to support why this would be beneficial or how it would improve the study. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary justification for the authors to understand and act upon it. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests mixing the train set examples with hypernyms and non-hypernyms. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to implement this suggestion or why it might be beneficial. The comment does not offer examples or explain the potential benefits of this approach, leaving the authors with a general idea but without actionable steps to follow. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests the results for the AdpCLR_full approach for the ResNet-50 architecture, similar to the results provided for AdpCLR_pre in Table 1. This is a clear and direct action that the authors can easily follow, as it specifies the exact information needed and where it should be presented. The comment is specific and provides concrete guidance on what additional data should be included, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"AdpCLR_full approach for the ResNet-50 (1x,2x,4x) architecture,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies what additional results are needed, namely the results for AdpCLR_full in Table 1. This provides clear guidance on what the authors need to include in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for additional information, specifically the results for the AdpCLR_full approach for the ResNet-50 architecture. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is a normal statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area where additional information is needed. By requesting the results for the AdpCLR_full approach for the ResNet-50 architecture, the comment prompts the authors to provide a complete comparison of their method across different architectures. This feedback is actionable and can guide the authors in enhancing the comprehensiveness and clarity of their results section. However, the comment could be more helpful if it provided additional context or suggestions on how to present these results effectively. Overall, the comment is clear and constructive, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the similarity between \"N trajectories\" and the concept of replay in the Dyna model. While it raises an interesting point, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should clarify their explanation, provide additional context, or address this issue in their draft. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the similarity between \"N trajectories\" and the concept of replay in the Dyna model. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the similarity between these concepts, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the similarity between \"N trajectories\" and the concept of replay in the Dyna model. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is a normal statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the similarity between \"N trajectories\" and the concept of replay in the Dyna model. While it raises an interesting point, it does not provide any actionable feedback or suggestions for improvement. The authors are left with a question but no guidance on how to address it or what aspects of their work might need clarification. Without actionable advice or constructive feedback, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a suspicious observation in the experimental results, specifically mentioning Tables 16 and 17, which share the same result despite changing the 2-hop EG into 3-hop EG. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific changes should be made to improve the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 16 and 17,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experiment results, specifically pointing out that the tables share the same result despite changing the 2-hop EG into 3-hop EG. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some experiment results are suspicious, specifically mentioning Tables 16 and 17 sharing the same result despite changing the 2-hop EG into 3-hop EG. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suspicion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental results, specifically pointing out that Tables 16 and 17 share the same result despite changing the 2-hop EG into 3-hop EG. This observation highlights a potential inconsistency or error in the experimental setup, which could impact the validity of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the experimental design. While it raises an important concern, the feedback is incomplete and does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the experimental results, which show some advantages of the proposed algorithms, but notes that these advantages are not very significant. It also suggests that the algorithms are still competitive with state-of-the-art algorithms. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the significance of the advantages or how to enhance the competitiveness with other algorithms. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to the experimental results and their significance, but it does not specify which part of the paper these results are discussed in. The authors cannot confidently determine which section or sections of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the results are considered insignificant or how they compare to state-of-the-art algorithms. Without clear guidance on what needs to be addressed or improved, the authors are left without a clear understanding of the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experimental results show some advantages of the proposed algorithms but are not very significant. It also suggests that the algorithms are still competitive with state-of-the-art algorithms. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the experimental results, which show some advantages of the proposed algorithms, but notes that these advantages are not very significant. It also suggests that the algorithms are still competitive with state-of-the-art algorithms. However, the comment lacks specificity and actionable feedback, leaving the authors without a clear understanding of what aspects need improvement or how to enhance the significance of their results. Without detailed guidance or suggestions, the authors are left without a clear path forward. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the per-sentence assessment protocol, suggesting that it may be prone to overconfidence from language models (LLMs). However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes or modifications are needed to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the per-sentence assessment protocol, specifically mentioning its use to identify and fix inconsistencies. However, it does not specify which part of the paper discusses this protocol, making it weakly grounded. The comment is specific in pointing out a potential issue with the protocol, namely its susceptibility to overconfidence from language models (LLMs). This provides clear guidance on what needs to be addressed, but without explicit references to specific sections, the authors may struggle to pinpoint the exact part of the paper that needs revision. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the per-sentence assessment protocol may be prone to overconfidence from language models (LLMs), specifically mentioning that it prefers its predictions even if they are incorrect. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks the necessary detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the per-sentence assessment protocol, suggesting that it may be prone to overconfidence from language models (LLMs). This is a valuable observation that could lead to improvements in the methodology or analysis. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or mitigate the overconfidence. Without detailed suggestions or examples, the authors are left without a clear path forward, making the feedback somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the specificity of the statement regarding the minimization of $L_{smo}$ and the role of sampled $\\\\tilde{z}_{proj}$ in ensuring smooth non-semantic diversity modeling. It does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions on how to address this issue. The comment lacks actionable guidance, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W6.3\" and \"App. C,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by questioning why the statement only addresses non-semantic diversity and not semantic diversity. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the statement regarding the minimization of $L_{smo}$ and the role of sampled $\\\\tilde{z}_{proj}$ in ensuring smooth non-semantic diversity modeling. It seeks clarification on why this statement only addresses non-semantic diversity and not semantic diversity. The comment is somewhat verifiable as it raises a logical question based on the statement, but it lacks specific examples or references to support the claim. The authors might need to provide additional context or reasoning to fully address the reviewer\\'s concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the statement regarding the minimization of $L_{smo}$ and the role of sampled $\\\\tilde{z}_{proj}$ in ensuring smooth non-semantic diversity modeling. It seeks clarification on why this statement only addresses non-semantic diversity and not semantic diversity. This feedback is somewhat helpful as it prompts the authors to clarify their statement and ensure that their modeling approach is comprehensive. However, the comment lacks specific suggestions or guidance on how to address this issue, such as providing additional context or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the promising experimental result is due to the superiority of the method or an accidental result from a specific kernel function and feature map. While it implies that the authors should clarify this point, it does not provide explicit instructions or concrete suggestions on how to address this issue. The comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the nature of the promising experimental result, whether it is due to the superiority of the method or an accidental result from a specific kernel function and feature map. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the nature of the experimental result, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the nature of the promising experimental result, questioning whether it is due to the superiority of the method or an accidental result from a specific kernel function and feature map. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the nature of the promising experimental result, questioning whether it is due to the superiority of the method or an accidental result from a specific kernel function and feature map. This is a valuable point as it prompts the authors to consider the validity and reliability of their findings. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or clarify their results. While it identifies an important area for consideration, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of a description of the estimation of $\\\\mu_t^a$ in the algorithm, which is a critical component for understanding the methodology. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should include this information, but it lacks concrete details on how to implement this suggestion. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions the absence of a description of the estimation of $\\\\mu_t^a$ in the algorithm, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what needs to be addressed or how this omission affects the paper. The comment is specific about the absence of a particular aspect but lacks detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no description of the estimation of $\\\\mu_t^a$ in the algorithm. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, namely the absence of a description of the estimation of $\\\\mu_t^a$ in the algorithm. This is a critical component of the methodology, and its absence could lead to confusion or misunderstanding. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it points out a significant gap, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors discuss the computational costs associated with training the proposed method, which involves modified Gromov-Hausdorff distances and hypergraph structures. While the comment implies that the authors should include this discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on computational costs. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a discussion of the computational costs associated with training the proposed method, which involves modified Gromov-Hausdorff distances and hypergraph structures. This provides clear guidance on what the authors need to address in order to improve their paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is complex, involving modified Gromov-Hausdorff distances and hypergraph structures, which may increase time complexity. The reviewer supports this claim by mentioning that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides some evidence, it could be strengthened by providing more detailed examples or references to support the assertion. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the complexity of the proposed method, which involves modified Gromov-Hausdorff distances and hypergraph structures. It suggests that this complexity could increase time complexity, and it acknowledges that the time complexity of each component is theoretically analyzed in Appendix B. However, the comment points out that a discussion of the computational costs associated with training the method is missing. This feedback is somewhat helpful as it highlights an area for improvement, but it could be more beneficial if it provided specific suggestions on how to address the computational costs. Overall, the comment offers a clear direction for the authors to enhance their draft, but it could be more actionable with additional guidance. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper effectively builds upon existing strategies but does not effectively distinguish its proposed method from existing contrastive decoding techniques. It suggests that the paper lacks a clear understanding of the unique contributions and advantages of the new approach. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting specific ways to differentiate the method or highlighting the unique aspects of the approach. The action is implicit and somewhat vague, leaving the authors to infer that they need to clarify the distinction between their method and existing techniques. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s contribution and suggests that while it effectively builds upon existing strategies, it may not represent a groundbreaking innovation within the field. It also points out that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, leaving readers without a clear understanding of the unique contributions and advantages of the new approach. However, the comment does not specify which part of the paper should address these issues, such as sections or specific sections where the distinction could be made. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas for improvement. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method may not represent a groundbreaking innovation within the field, as it effectively builds upon existing strategies. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The comment also suggests that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, which further undermines the originality of the work. Without specific examples or references, the claim lacks verifiability, making it challenging for the authors to address the feedback effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s contribution, suggesting that while it effectively builds upon existing strategies, it may not represent a groundbreaking innovation within the field. It points out that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, leaving readers without a clear understanding of the unique contributions and advantages of the new approach. This feedback is somewhat helpful as it highlights a specific area for improvement, namely the need to better differentiate the method from existing techniques. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how other papers have effectively distinguished their contributions. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Figure 4\\'s tabular representation of node agent interactions is not intuitive. However, it does not provide any explicit or implicit suggestions for how the authors might improve the figure\\'s clarity or make it more intuitive. There is no guidance on what changes should be made or how to address the issue. As a result, the authors are left without any actionable steps to take, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely that the tabular representation of node agent interactions is not intuitive. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 4\\'s tabular representation of node agent interactions is not intuitive. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 4, noting that the tabular representation of node agent interactions is not intuitive. This feedback is clear and actionable, as it points out a specific area where the authors need to improve the clarity and understandability of their figure. However, the comment could be more helpful if it provided suggestions on how to make the figure more intuitive or offered examples of how similar information has been presented in other works. Despite this, the comment still provides valuable insights that can guide the authors in enhancing their draft. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: whether the benefit of the proposed method is prioritizing learning on examples with less irreducible uncertainty and how the use of the PU loss impacts calibration. It also questions the appropriateness of using PU as a baseline and suggests that uncertainty estimation is important for downstream use cases of AI text detectors. While the comment implies that the authors should consider alternative frameworks and evaluate the impact of the PU loss on calibration, it does not provide explicit instructions or concrete steps for how to address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should consider alternative frameworks and evaluate the impact of the PU loss on calibration. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions: whether the benefit of the proposed method is prioritizing learning on examples with less irreducible uncertainty and how the use of the PU loss impacts calibration. It also questions the appropriateness of using PU as a baseline and suggests that uncertainty estimation is important for downstream use cases of AI text detectors. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions are specific, as they outline areas for consideration and potential improvements, but the lack of grounding makes it difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions: whether the benefit of the proposed method is prioritizing learning on examples with less irreducible uncertainty and how the use of the PU loss impacts calibration. It also questions the appropriateness of using PU as a baseline and suggests that uncertainty estimation is important for downstream use cases of AI text detectors. While the questions themselves are not claims, the comment provides some reasoning by suggesting that alternative frameworks might be more appropriate baselines and highlighting the importance of uncertainty estimation. However, the comment lacks specific examples or references to support the claims, making it somewhat verifiable. The authors would need to further explore and substantiate the claims themselves, so the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two questions that are relevant to the paper\\'s content and contribution. First, it questions whether the proposed method prioritizes learning on examples with less irreducible uncertainty, suggesting that other frameworks besides PU might be more appropriate as baselines. This is a thoughtful observation that prompts the authors to consider alternative approaches and potential limitations of their method. Second, it inquires about the impact of the PU loss on calibration and the importance of uncertainty estimation for downstream use cases of AI text detectors. By highlighting these areas for consideration, the comment provides valuable insights that could guide the authors in refining their methodology and broadening the scope of their work. However, the comment could be more helpful if it offered specific suggestions or examples of alternative frameworks or methods to consider. Overall, the comment is mostly helpful as it prompts the authors to reconsider their approach and provides a direction for further exploration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential Multi-Task Learning (MTL). It suggests that TL is a broader term for the phenomenon of learning from one task benefiting another, while Fine-tuning is a sequential approach. The reviewer does not provide explicit guidance on how the authors should address this issue, but the comment implies that the authors should reconsider their characterization of TL and FT. While the action is implicit, it is clear that the authors need to reevaluate their characterization, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential Multi-Task Learning (MTL), suggesting that TL is a broader term and that Fine-tuning is a sequential approach. The comment provides a clear rationale for why the characterization is inaccurate, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential Multi-Task Learning (MTL). The reviewer provides a logical reasoning by explaining that TL is a broader term for the phenomenon of learning from one task benefiting another, while Fine-tuning is a sequential approach. This explanation is based on a clear understanding of the concepts and their distinctions, making the claim verifiable. The reviewer supports their argument with a clear distinction between TL and FT, providing a solid foundation for the claim. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a specific critique of the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential Multi-Task Learning (MTL). It offers a clear and detailed explanation of the distinction between TL and FT, suggesting that TL is a broader term for the phenomenon of learning from one task benefiting another, while FT is a sequential approach. This feedback is highly helpful as it not only challenges the authors\\' characterization but also provides a clear and actionable suggestion for improvement. By offering a more accurate understanding of these concepts, the comment empowers the authors to enhance their draft and improve the clarity of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks a Limitation section, which is important. This provides a clear and direct action for the authors to take, namely, to include a Limitation section in their draft. The comment is specific and provides a concrete action for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the absence of a \"Limitation\" section, which provides full grounding as it allows the authors to accurately identify the part of the paper being addressed. It is specific because it clearly specifies what is missing (a Limitation section) and why it is important. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a Limitation section, which is important. However, the comment does not provide any reasoning, examples, or references to support why this section is necessary or how it would enhance the paper. Without additional context or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, namely the absence of a Limitation section. This is an important point, as it highlights a potential gap in the paper\\'s coverage and completeness. However, the comment lacks depth and does not provide specific guidance on what a Limitation section should include or how it could enhance the paper. While it points out a critical area for improvement, it does not offer actionable advice or detailed suggestions for addressing this issue. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides several explicit actions for the authors to take. First, it suggests that Section 2.1 needs more detailed explanations, which is a direct request for clarification. Similarly, it implies that Section 2.2 should include more detailed explanations regarding the CLIP guidance. Additionally, it points out that the works of Choi et al. (2021) and Meng et al. (2021) are not explained, which is a clear action for the authors to address. Lastly, it mentions that captions of figures are often not explanatory, providing specific examples. Each of these points is explicit and provides clear guidance on what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"Section 2.1\" and \"Section 2.2,\" allowing the authors to accurately identify the parts being addressed. It also provides specific feedback by suggesting that these sections need more detailed explanations and mentions specific figures, such as Figures 3, 4, 7, and 8. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the lack of detailed explanations in Section 2.1 and the need for more detailed explanations in Section 2.2. It also mentions that the captions of figures are often not explanatory, providing examples. These claims are somewhat verifiable as they point out specific areas that need improvement, but they do not provide detailed reasoning or references to support the need for more detailed explanations or the importance of the suggested improvements. The comment could be strengthened by offering more detailed explanations or references to support the claims, making it mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides several specific and actionable suggestions for improvement. It identifies areas where the paper lacks detailed explanations, particularly in Section 2.1 and Section 2.2, and suggests that these sections need more detailed explanations. Additionally, it points out that the captions of figures are often not explanatory, providing examples. This feedback is clear and directs the authors to specific areas where they can enhance the clarity and comprehensiveness of their work. By addressing these points, the authors can significantly improve the quality of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include the term \"tensor completion\" in the title of their paper, as it is the only application of the new model presented. This feedback is clear and provides a direct action for the authors to take, ensuring that the title accurately reflects the content of the paper. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"title\" of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the title, namely the term \"tensor completion,\" which is the only application of the new model presented in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the title of the paper should include the term \"tensor completion\" because it is the only application of the new model presented. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this addition is necessary or beneficial. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment provides a specific and actionable suggestion for improving the paper\\'s title. It points out that the term \"tensor completion\" should be included, as it is the only application of the new model presented in the paper. This feedback is clear and direct, offering a straightforward way for the authors to enhance the clarity and accuracy of their title. By addressing this suggestion, the authors can improve the overall comprehensibility and relevance of their paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a comparison of their proposed method with prior methods, specifically mentioning a baseline like character frequencies. This feedback is explicit and provides a clear action for the authors to take, which is to include a comparison in their empirical evaluation. The comment also explains why this comparison is necessary to make the paper more persuasive. The action is concrete, as it specifies exactly what the authors need to do to improve their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"empirical evaluation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison with prior methods and the suggestion to include a baseline like character frequencies. This provides clear guidance on how to enhance the empirical evaluation section. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison with prior methods, specifically suggesting the inclusion of a baseline like character frequencies. The reviewer provides a logical reasoning by explaining that such a comparison would make the paper more persuasive. However, the comment does not provide specific examples or references to prior works that could be used for comparison, which would strengthen the claim. The lack of detailed evidence or references makes the claim somewhat verifiable, as it provides a clear direction but lacks comprehensive support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that the proposed method lacks a comparison with prior methods. It suggests that the inclusion of a baseline like character frequencies would enhance the empirical evaluation and make the paper more persuasive. This feedback is clear and actionable, providing the authors with a specific and concrete suggestion for improvement. By addressing this point, the authors can strengthen the empirical evaluation section and make their work more robust. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential limitation in the practicality of the proposed method in reducing computational load. It identifies specific challenges, such as the difficulty in applying a uniform activation pattern across all tokens due to different tokens activating different channels. The comment also points out that the method relies on precomputed PPL and activation patterns, which may not generalize well to other tokens. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve the method. The action is implicit and somewhat vague, as the authors can infer that they need to consider these challenges but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the practicality of reducing computational load in the proposed method. It identifies challenges such as different tokens activating different channels, making it difficult to apply a uniform activation pattern across all tokens. The comment also points out that the method relies on precomputed PPL and activation patterns, which may not generalize well to other tokens. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the challenges and potential limitations of the method, but without explicit references to specific sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method faces challenges in reducing computational load due to the activation patterns of different tokens. It provides a logical reasoning by explaining that the method relies on precomputed PPL and activation patterns, which may not generalize well to other tokens. This reasoning is somewhat verifiable as it highlights a potential limitation but lacks specific examples or references to support the claim. The comment could be strengthened by providing more detailed evidence or examples to substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the practicality of the proposed method, noting that it may face challenges in reducing computational load due to the activation patterns of different tokens. It highlights a potential issue with the method's reliance on precomputed PPL and activation patterns, which may not generalize well to other tokens. This feedback is clear and actionable, as it points out a specific area where the method could be improved. However, it could be more helpful if it provided suggestions on how the authors might address these challenges or improve the method's applicability. Overall, the comment is mostly helpful as it directs the authors' attention to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the core motivation of the paper is not clear, specifically mentioning that the abstract does not effectively convey the main problem to be solved. It suggests that the abstract should provide more clarity on the motivation, such as by explaining why it is difficult to demarcate task boundaries in actual tasks. While the comment implies that the authors should clarify the motivation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the motivation, but it is not as concrete as it could be. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abstract, stating that the motivation is not clear and suggesting that the abstract should provide more clarity on the problem to be solved. This feedback is detailed and actionable, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the core motivation of the paper is not clear, specifically mentioning that the abstract does not effectively convey the main problem to be solved. The comment suggests that the stacked statements in the abstract do not capture the main problem, implying that the motivation needs to be clarified. However, the comment lacks specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors would need to infer the need for clarification themselves, which is not as direct as it could be. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s core motivation, noting that the abstract does not effectively convey the main problem to be solved. It suggests that the abstract should provide more clarity on the motivation, such as by explaining why it is difficult to demarcate task boundaries in actual tasks. This feedback is clear and actionable, as it directs the authors to clarify the motivation and main problem of their work. However, the comment could be more helpful if it offered specific suggestions on how to improve the clarity of the abstract. Overall, the comment is mostly helpful as it provides valuable insights for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the sequence inference classifier used to filter data, noting that the task seems different from the original MNLI distribution. It suggests providing examples of the filtered data to better understand the process. While the comment implies that the authors should include examples to clarify the filtering process, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include examples to address the concern. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the sequence inference classifier used to filter data, noting that the task seems different from the original MNLI distribution. It suggests providing examples of the filtered data to better understand the process. However, the comment does not specify which part of the paper discusses the sequence inference classifier, making it weakly grounded. The suggestion to include examples is specific, but without full grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the sequence inference classifier used to filter data, suggesting that the task seems different from the original MNLI distribution. The reviewer implies that examples of the filtered data would be helpful to understand the process. However, the comment lacks specific examples or detailed reasoning to support the claim that the task is different from the original distribution. Without concrete evidence or references, the claim is somewhat verifiable, as it provides a general observation but lacks detailed justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the sequence inference classifier used to filter data, noting that the task seems different from the original MNLI distribution. It suggests providing examples of the filtered data to better understand the process. This feedback is somewhat helpful as it identifies a potential issue with the methodology and offers a specific suggestion for improvement. However, the comment could be more helpful if it provided more detailed guidance on how to present the examples or what specific aspects of the filtering process should be highlighted. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including the potential for biases in the application experiments due to the limited dataset and reliance on a single model. It suggests that the paper requires an in-depth editorial review to address these concerns. The comment provides specific guidance on areas that need improvement, such as the need to conduct comprehensive experiments, verify the effectiveness of the proposed methods, and improve the structure, argumentation, and language clarity. Additionally, it points out issues with the equation numbering and formatting of Algorithm 1. While the comment provides clear and concrete actions for the authors to take, such as conducting comprehensive experiments and improving the presentation of their work, it could be more helpful if it included specific suggestions on how to address these issues. Overall, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the application experiments, the use of a single model (DALL-E), and the small dataset (30 famous paintings and 30 generated paintings), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experiments, such as potential biases and the need for comprehensive experiments to verify the effectiveness of the proposed methods. Additionally, it provides specific feedback on the structure, argumentation, and language clarity of the paper, including the chaotic equation numbering and the formatting of Algorithm 1. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the application experiments may have biases due to the limited dataset and reliance on a single model (DALL-E). It suggests that the experiment results are difficult to be convincing without comprehensive experiments. The comment also recommends an in-depth editorial review and provides specific feedback on the structure, argumentation, and language clarity of the paper. The reviewer suggests that the equation numbering is chaotic and that the format of Algorithm 1 lacks indentation. While the comment provides some logical reasoning and specific examples, such as the chaotic equation numbering, it could be strengthened by providing more detailed evidence or references to support the claim about potential biases. Overall, the comment is mostly verifiable, as it provides a clear rationale and specific examples, but it could be further strengthened with additional evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the application experiments may be biased due to the limited dataset and reliance on a single model (DALL-E). It suggests that the paper requires an in-depth editorial review to address this concern and ensure the validity of the results. The comment provides specific feedback on areas that need improvement, such as conducting comprehensive experiments, verifying the effectiveness of the proposed methods, and improving the structure, argumentation, and language clarity of the paper. It also points out specific issues with the presentation, such as the chaotic equation numbering and the formatting of Algorithm 1. This feedback is clear and actionable, offering the authors a clear path to enhance the quality and credibility of their work. Therefore, the comment is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should comment on the practical applications of their work, specifically regarding the use of datasets that are constructed by concatenating manipulated samples. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comment on the practical applications. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should comment on the practical applications of their work, specifically regarding the use of datasets that are constructed by concatenating manipulated samples. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental setup or discussion, but the lack of explicit reference makes it weakly grounded. The comment is specific in suggesting a potential area for commentary, but without full grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments in the paper are based on datasets constructed by concatenating manipulated samples from standard benchmarks, which raises a question about the practical applications of the work. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that the experiments are based on datasets constructed by concatenating manipulated samples from standard benchmarks. It suggests that there may be real tasks with available data for which the model could be more practical. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or explore practical applications. The feedback is somewhat helpful as it prompts the authors to consider the practical implications of their work, but it could be more actionable and detailed to be fully helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the selection of m' in the CAL-MIR method, specifically asking whether it is done exhaustively over all loss minimizer subsets. The reviewer implies that this might be prohibitively expensive or time-consuming. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks actionable details, such as recommending a specific approach or suggesting ways to optimize the selection process. As a result, the authors are left without a clear understanding of how to proceed with this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the selection of m' in the CAL-MIR method, specifically asking whether it is done exhaustively over all loss minimizer subsets. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the selection process and the potential prohibitive cost, but without explicit references to sections or figures, the authors cannot confidently identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the selection process of m' in the CAL-MIR method. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the selection process of m' in the CAL-MIR method, specifically asking whether it is done exhaustively over all loss minimizer subsets. This is a relevant point that could impact the efficiency and scalability of the method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the method. It highlights a potential area for improvement but does not offer actionable advice or detailed feedback. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the \"Robustness\" section should consider other backdoor detection methods that are input data-free, such as detecting backdoors with weight matrix statistics or matrix factorization. While the comment implies that the authors should consider these methods, it does not explicitly instruct them to do so or provide specific guidance on how to integrate them into their analysis. The action is implicit and somewhat vague, as the authors need to infer that they should consider these methods but may not know exactly how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Robustness\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering other backdoor detection methods that are input data-free, such as detecting backdoors with weight matrix statistics or matrix factorization. This provides clear guidance on what additional analysis should be included in the \"Robustness\" section. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the \"Robustness\" section should consider other backdoor detection methods that are input data-free, such as detecting backdoors with weight matrix statistics or matrix factorization. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these methods should be considered or how they would enhance the analysis of algorithm performance. Without additional context or examples, the claim remains vague and lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the \"Robustness\" section by suggesting that the authors consider other backdoor detection methods that are input data-free, such as detecting backdoors with weight matrix statistics or matrix factorization. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the analysis of algorithm performance. By considering these additional methods, the authors can broaden their understanding of robustness and potentially improve the robustness of their analysis. However, the comment could be more helpful if it included specific examples or references to these methods, which would guide the authors in implementing the suggestion more effectively. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific issues with the paper: the incompleteness of the relation works section and the need for clarification on the problem definition methodology, particularly regarding the view of the knowledge graph assumption. While the comment highlights these areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they need to address these issues, but without detailed guidance on how to do so, the action remains vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"relation works section\" and the \"problem definition methodology,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the incompleteness of the relation works section and the need for clarification on the problem definition methodology, particularly regarding the view of the knowledge graph assumption. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the relation works section is incomplete and that the authors need to clarify the problem definition methodology, particularly regarding the view of the knowledge graph assumption. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the incompleteness of the relation works section. It also points out the need for clarification regarding the problem definition methodology, particularly regarding the view of the knowledge graph assumption. This feedback is clear and actionable, as it directs the authors to specific areas that need improvement. However, the comment could be more helpful if it provided examples or detailed guidance on how to address these issues. Overall, the comment is mostly helpful as it offers valuable insights for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a comparison of their method's accuracy on a specific task (regression) against strong baselines. It highlights the importance of evaluating the contribution of the method, which is not currently part of the proposal. The comment provides a clear and explicit action for the authors to take, which is to include this comparison in their evaluation. The suggestion is concrete and specific, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the problem setup and the contribution of the paper, specifically mentioning the use of black box optimization techniques and the focus on regression to make predictions on $\\\\hat{y}$. It suggests comparing the accuracy of the method against strong baselines, which is a specific request for additional evaluation. However, the comment does not explicitly mention which section of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request for an additional evaluation, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contribution of the paper revolves around regression to make predictions on $\\\\hat{y}$ and suggests comparing the accuracy of the method against strong baselines. The reviewer provides a logical reasoning by explaining that the optimization is a downstream task that should not be affected by the method of regression. However, the comment lacks specific examples or references to support the claim about the contribution of the paper. While the reasoning is clear, the lack of detailed evidence or references makes the claim somewhat verifiable. The authors would need to make a significant effort to understand and address the suggestion, so the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the contribution of the paper, which is the focus on regression to make predictions on $\\\\hat{y}$. It suggests that the authors should include a comparison of their method's accuracy against strong baselines, which is a valuable suggestion for improving the evaluation of the method. The comment highlights the importance of evaluating the contribution of the method, which is not currently part of the proposal. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or suggested specific baselines to consider. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the technical design lacks theoretical support, specifically mentioning the need for more justification regarding the update derivation for the intrinsic reward parameters. While it highlights a potential issue, it does not provide explicit guidance on how the authors should address this lack of theoretical support or how to improve the derivation. The comment implies that the authors should provide more detailed explanations or justifications, but it does not offer specific steps or suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the technical design of the paper, specifically mentioning the lack of theoretical support and the need for more justification regarding the update derivation for the intrinsic reward parameters. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for more justification and the reference to Sorg et al. 2010. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical design lacks theoretical support, specifically questioning the justification for the update derivation of the intrinsic reward parameters. The reviewer references Sorg et al. 2010 as a potential source of justification, but does not provide further details or examples from the referenced work to substantiate the claim. This lack of detailed reasoning or specific references makes the claim somewhat verifiable, as it requires additional information to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the technical design of the paper, specifically noting the lack of theoretical support for the update derivation of the intrinsic reward parameters. It highlights the need for more justification and references to Sorg et al. 2010, which could provide a basis for the design. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve the theoretical foundation of their work. While it points out a critical area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the authors\\' claim of an adaptive variance reduction property, specifically questioning the choice of parameter \u03b2. It suggests that this choice does not align with the adaptive nature of the method, such as AdaGrad. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the claim. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their choice of parameter \u03b2 and potentially adjust their method to better align with adaptive methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"adaptive variance reduction property\" and the \"small enough\" \u03b2 parameter, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the adaptivity claim and comparing it to adaptive methods like AdaGrad. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim of an adaptive variance reduction property, specifically challenging the choice of parameter \u03b2. The reviewer provides a logical reasoning by comparing the method to adaptive methods like AdaGrad, which suggests that the claim of adaptivity is misplaced. However, the comment lacks specific examples or references to support the claim that AdaGrad or other adaptive methods do not use a similar parameter choice. While the reasoning is clear, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' claim of an adaptive variance reduction property, specifically questioning the choice of parameter \u03b2. It suggests that this choice does not align with the adaptive nature of the method, such as AdaGrad, and challenges the adaptivity claim. While the comment highlights a potential weakness in the paper\\'s argument, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their claim. The feedback is somewhat helpful as it points out a potential problem but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the value of different augmentation techniques is unclear and points out that DINOv2 seems to be the best-performing model. It recommends further investigation into why DINOv2 performs well and how to improve it further. While the comment provides a clear direction for the authors to investigate the best-performing model and its underlying reasons, it does not explicitly instruct them to conduct this investigation or specify how to do so. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DINOv2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the value of different augmentation techniques and the suggestion to further investigate why DINOv2 performs well and how to improve it. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the value of different augmentation techniques is unclear and suggests further investigation into why DINOv2 performs well and how to improve it. However, the comment lacks specific examples or detailed reasoning to support the claim that DINOv2 is the best-performing model. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some indication but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, namely the lack of clarity regarding the value of different augmentation techniques. It suggests that the authors further investigate why DINOv2 performs well and how to improve it further. This feedback is clear and actionable, as it provides a specific direction for the authors to explore and enhance their work. However, the comment could be more helpful if it offered suggestions on how to conduct the investigation or what specific aspects to focus on. Overall, the comment is mostly helpful as it guides the authors toward a meaningful area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the acronym \"follow the top perturbed leader\" might be confusing because it is similar to the common abbreviation \"FTL,\" which usually stands for \"Follow the Leader.\" The reviewer provides a clear and direct action for the authors to consider changing the acronym to avoid confusion. This feedback is explicit and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the acronym \"follow the top perturbed leader,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the acronym, suggesting that it might be confusing due to its similarity to the common abbreviation \"FTL.\" Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the acronym \"follow the top perturbed leader\" might be confusing because it is similar to the common abbreviation \"FTL,\" which usually stands for \"Follow the Leader.\" The comment provides a logical reasoning by explaining the potential confusion and suggesting a change to avoid it. However, it lacks specific examples or references to literature where \"FTL\" is used, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a reasonable argument but could be more robust with additional evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the acronym \"follow the top perturbed leader,\" noting that it might be confusing due to its similarity to the common abbreviation \"FTL,\" which usually stands for \"Follow the Leader.\" This feedback is clear and actionable, as it suggests a specific change to avoid confusion and improve the clarity of the paper. However, the comment could be more helpful if it provided examples or additional guidance on how to address this issue effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the selection of attacks in Table 1, noting that they are not state-of-the-art and suggesting that there are better attacks available, such as MIDIFGSM. The reviewer also requests additional information, such as the number of iterations the attacks are run for. While the comment provides explicit actions (e.g., mentioning the number of iterations), it does not specify how to implement these changes or provide detailed guidance on how to improve the selection of attacks. The authors are given clear instructions but may need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the selection of attacks, noting that they are not state-of-the-art and suggesting that better attacks exist, such as MIDIFGSM. The comment also requests additional information, such as the number of iterations the attacks are run for. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the selection of attacks in Table 1 is arbitrary and not state-of-the-art, suggesting that there are better attacks available, such as MIDIFGSM. The reviewer provides a reference to a survey that allegedly analyzes these attacks in depth. However, the comment lacks specific examples or detailed reasoning to support the claim that the current attacks are not state-of-the-art. The reference to the survey provides some evidence but does not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the selection of attacks in Table 1, noting that they are not state-of-the-art and suggesting that there are better attacks available, such as MIDIFGSM. The reviewer also requests additional information, such as the number of iterations the attacks are run for, which could enhance the transparency and comprehensiveness of the table. This feedback is clear and actionable, providing the authors with specific guidance on how to improve the quality and relevance of their work. However, it could be more helpful if it included suggestions on how to incorporate these improvements or how to evaluate the impact of the suggested attacks. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement and provides a clear path for enhancing their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the method, specifically that it is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this limitation or suggest improvements. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"limitations and conclusion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the method may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed evidence or reasoning, the claim remains unverifiable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the method, specifically that it is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). This feedback is somewhat helpful as it highlights a potential weakness in the methodology, which the authors should consider addressing or explaining in the paper. However, the comment lacks specific suggestions or guidance on how to address this limitation or whether it is a significant concern that should be further explored. To be more helpful, the comment could provide suggestions for potential experiments or analyses to validate the method's performance with other pre-training methods. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the qualitative analysis, specifically regarding the determination of two input sentences for qualitative analysis (Section 4.5.5, Figure 1) and the attribution values in Figure 1. It also questions whether the examples occurred during the fine-tuning process and whether the attribution map for the input examples that failed to be classified works well. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should provide more detailed information about the qualitative analysis and the determination of the input sentences. The feedback is somewhat actionable as it highlights specific areas that need clarification, but it lacks detailed guidance on how to address these issues.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.5.5, Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the qualitative analysis, such as the determination of input sentences and the attribution values in Figure 1. The comment further questions whether the examples occurred during the fine-tuning process and whether the attribution map for the input examples that failed to be classified works well. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the qualitative analysis, specifically regarding the determination of input sentences for qualitative analysis and the attribution values in Figure 1. It also questions whether the examples occurred during the fine-tuning process and whether the attribution map for the input examples that failed to be classified works well. While the comment identifies areas that need clarification, it does not provide specific examples or references to support the claims. The authors would need to make a significant effort to verify the claims, as the feedback lacks detailed justification or evidence. Therefore, the comment is considered borderline verifiable, as it provides some indication of potential issues but requires further elaboration to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific areas of the paper that require clarification and provides detailed questions about the qualitative analysis. It questions the determination of input sentences for qualitative analysis and the attribution values in Figure 1, asking whether these examples occurred during the fine-tuning process. Additionally, it questions whether the attribution map for the input examples that failed to be classified works well. This feedback is clear and actionable, as it directs the authors to provide more detailed information about the qualitative analysis and its methodology. By addressing these questions, the authors can significantly improve the clarity and robustness of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors include examples of practical applications where specific types of tensors need to be equivariant and clarify how these scenarios validate the advantages of using equivariant tensor functions. While the comment implies that the authors should provide examples and clarify the advantages, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples and clarify the advantages. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, it does not specify which part of the paper should include these examples or how they should be integrated. The authors can infer that it relates to sections discussing equivariant tensor functions, but this inference is not direct. The comment is specific in its request for examples and clarification, but it lacks full grounding as it does not explicitly mention a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these examples are necessary or how they would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors include examples of practical applications where specific types of tensors need to be equivariant and clarify how these scenarios validate the advantages of using equivariant tensor functions. This feedback is somewhat helpful as it provides a clear direction for the authors to enhance their draft by adding concrete examples and explanations. However, the comment could be more helpful if it offered specific examples or detailed guidance on how to integrate these examples into the paper. Overall, the comment provides a valuable suggestion for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific issues with the tables, including Table 2, where the methods ERM, cRT, and LWS are not referenced properly. It also notes that Section 3.2.3 does not fully align with the table. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to clarify the references and align the sections with the tables. This makes the comment somewhat actionable, as the authors know they need to make improvements but may not be entirely sure how to do so.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Section 3.2.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the tables, such as the lack of proper references for methods like ERM, cRT, and LWS, and the misalignment between the section and the table. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are issues with the tables, specifically mentioning Table 2, where methods like ERM, cRT, and LWS are not referenced properly. Additionally, it notes that Section 3.2.3 does not fully align with the table. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact nature of the issues. Without additional context or evidence, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific issues with the tables, particularly Table 2, noting that the methods ERM, cRT, and LWS are not referenced properly. It also points out that Section 3.2.3 does not fully align with the table. This feedback is clear and actionable, as it provides the authors with specific areas to address in order to improve the clarity and accuracy of their tables. However, the comment could be more helpful if it offered suggestions on how to properly reference these methods or align the sections with the tables. Overall, the comment is mostly helpful as it directs the authors toward meaningful improvements, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take. It suggests that the authors should provide more details on the suitability of the model for sarcastic/non-sarcastic utterances and explain why the eye-movement data is useful for sentiment classification beyond textual features. These actions are clear and concrete, as they specify exactly what the authors need to address in their draft. The comment also provides specific questions that the authors should answer, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the suitability of the model for sarcastic/non-sarcastic utterances and questions the usefulness of eye-movement data for sentiment classification beyond textual features. This provides clear guidance on what aspects need further exploration or clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions and suggestions for improvement. It does not contain any subjective claims or opinions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying areas where the paper could be improved. It raises questions about the suitability of the model for sarcastic/non-sarcastic utterances and questions the usefulness of eye-movement data for sentiment classification beyond textual features. By offering these points for further analysis, the comment prompts the authors to provide more detailed explanations and potentially expand their work. This level of guidance is valuable for the authors to enhance their draft, making the comment mostly helpful. However, it could be more helpful if it included suggestions on how to address these questions or what specific details to include in the analysis. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results are limited to two small-scale/resolution datasets and questions the professionalism of the tables, specifically noting that DDIM is a sampling method rather than a model. However, it does not provide explicit guidance on how the authors should expand their experiments or improve the presentation of their results. The feedback lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to address the issues raised. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table1\" and \"table2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the limited number of experiments and the confusion regarding DDIM as a sampling method rather than a model. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results are limited to two small-scale/resolution datasets and questions the professionalism of the tables, specifically noting that DDIM is a sampling method rather than a model. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental results, noting that the paper only conducts experiments on two small-scale/resolution datasets. It also points out an issue with the presentation of the tables, specifically mentioning that DDIM is a sampling method rather than a model. While the comment highlights areas for improvement, it lacks specific suggestions or guidance on how the authors might expand their experiments or clarify the presentation of their results. This limits the comment\\'s usefulness in helping the authors enhance their draft. Therefore, the feedback is somewhat helpful, as it provides some insight but does not offer actionable steps for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide more clarification about why the proposed method is important, specifically by addressing the influence on utility and privacy levels. While the comment implies that the authors should provide more information, it does not explicitly instruct them to do so or offer specific guidance on how to present this information. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional clarification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the importance of the proposed method, specifically questioning the influence on utility and privacy levels. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for clarification about the influence on utility and privacy levels, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the importance of the proposed method, suggesting that it is merely adjusting the variance level of DPSGD and does not provide a clear explanation of its impact on utility and privacy levels. The comment implies that the authors should present what is lost in privacy levels or what is derived from the method. However, the comment lacks specific examples or references to support the claim that the method is merely adjusting variance levels. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely in providing more clarification about the importance of the proposed method. It suggests that the authors should explain how the method influences utility and privacy levels, and what potential trade-offs might be involved. While the comment highlights an important aspect of the paper, it lacks specific suggestions or guidance on how to address this issue. The authors are given a direction to consider but are not provided with detailed steps or examples to follow. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the empirical result is illustrative rather than demonstrative and recommends conducting a bigger-scale experiment. It also specifies that a longer-horizon example would be beneficial, which could be presented in a tabular format. While the comment provides a clear action for conducting a larger-scale experiment, it does not explicitly instruct the authors on how to implement this suggestion or what specific aspects of the experiment should be included. The action is concrete but lacks detailed guidance, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"empirical result\" and suggests that it is illustrative rather than demonstrative. It also provides specific feedback by recommending a bigger-scale experiment and a longer-horizon example, which could be presented in a tabular format. This level of detail allows the authors to accurately identify the parts of the paper being addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the empirical result is illustrative rather than demonstrative, implying that a larger-scale experiment would be beneficial. The reviewer provides a specific recommendation for a longer-horizon example, which could be presented in a tabular format. This claim is somewhat verifiable as it provides a logical reasoning for the need of a larger-scale experiment and a more demonstrative result. However, the comment lacks detailed justification or references to support the claim, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the empirical result, suggesting that it is illustrative rather than demonstrative. It provides a specific recommendation for a larger-scale experiment, which could be beneficial for demonstrating the effectiveness of the method. Additionally, the comment suggests a longer-horizon example, which could be presented in a tabular format. This feedback is clear and actionable, offering the authors a concrete direction for improving their draft. However, it could be more helpful if it provided additional guidance on how to design and conduct the larger-scale experiment or what specific aspects of the empirical result should be emphasized. Overall, the comment is mostly helpful as it provides valuable insights and suggestions for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests additional information about how Equation (13) is solved in the experiments and its computational complexity. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment provides a concrete suggestion for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (13),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a closed-form solution for Equation (13) and the need for details about how it is solved in the experiments and its computational complexity. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Equation (13) does not have a closed-form solution in general and suggests that additional details about how it is solved in the experiments and its computational complexity would be helpful. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a problem or how it affects the paper\\'s overall quality. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Equation (13) by pointing out that it does not have a closed-form solution in general. It suggests that additional details about how it is solved in the experiments and its computational complexity would be helpful. This feedback is clear and actionable, as it provides a concrete suggestion for improvement by asking the authors to clarify the methodology. However, the comment could be more helpful if it offered specific guidance on how to address this issue or provided examples of similar cases where closed-form solutions were addressed. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper should analyze what tasks have reasonable proximity metrics and demonstrate failures on those that don\\'t. This feedback provides a clear and concrete action for the authors to take, which is to analyze the tasks and demonstrate failures in the context of proximity metrics. The comment is specific about what needs to be addressed and how it could be improved, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of discussion on the choice of \"proximity\" and the nature of the task, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the paper should analyze what tasks have reasonable proximity metrics and demonstrate failures on those that don\\'t. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks discussion on the choice of \"proximity\" and the nature of the task. It provides a specific example by stating that proximity on the fingertip Cartesian positions is strongly correlated with proximity in the solution space, but this relationship does not hold for certain tasks, such as in a complicated maze or robotic tasks with obstacles. The comment suggests that the paper would be improved by analyzing which tasks have reasonable proximity metrics and demonstrating failures on those that don\\'t. This claim is supported by logical reasoning and specific examples, making it mostly verifiable. However, it could be strengthened by providing more detailed examples or references to support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's discussion, specifically the lack of analysis on the choice of 'proximity' and the nature of the task. It provides a specific example by explaining how proximity on the fingertip Cartesian positions is strongly correlated with proximity in the solution space, but this relationship doesn't hold for certain tasks, such as in a complicated maze or robotic tasks with obstacles. The comment suggests that the paper would be improved by analyzing which tasks have reasonable proximity metrics and demonstrating failures on those that don't. This feedback is clear and actionable, offering a concrete direction for the authors to enhance their draft. However, it could be more helpful if it provided additional guidance on how to conduct this analysis or suggested specific tasks to focus on. Overall, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments lack implementation details, which are necessary for readers to fully understand and reproduce the results. However, it does not provide specific guidance on what these details should include or how they should be presented. The comment refers to \"Questions\" for more information, but this does not offer a concrete action for the authors to take. Without explicit instructions or concrete examples, the authors are left without a clear understanding of what changes need to be made to improve the clarity of the experiments. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of implementation details in the experiments, which are necessary for readers to fully understand and reproduce the results. However, it does not specify which experiments or sections are lacking these details, making it difficult for the authors to pinpoint the exact areas that need improvement. The comment refers to \"Questions\" for more information, but this does not provide enough guidance to be fully grounded. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the experiments lack implementation details, which are necessary for readers to fully understand or reproduce the results. However, the comment does not provide specific examples or detailed reasoning to support this claim. It refers to \"Questions\" for more information, but this does not offer sufficient justification or evidence to substantiate the claim. As a result, the comment is considered borderline verifiable, as it highlights a potential issue but lacks sufficient detail to fully support the claim. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experimental implementation details, noting that they are lacking and necessary for readers to fully understand and reproduce the results. While it highlights a critical area for improvement, the comment does not provide specific guidance or suggestions on how to address this issue. It refers to \"Questions\" for more information, leaving the authors with a vague understanding of what is expected of them. This lack of actionable feedback limits the comment\\'s helpfulness, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the comparison between SSUL and the paper, specifically regarding the use of off-the-shelf saliency-map detectors versus the pretrained Mask2Former model. It suggests that this comparison may be unfair due to differences in data and model size. The reviewer poses two questions: \"What if SSUL also adopts Mask2Former to detect unseen classes?\" and \"What if SSUL can generate object proposals in an unsupervised way without additional data or heavy models?\" These questions imply that the authors should consider adopting Mask2Former or exploring alternative methods for generating object proposals. However, the comment does not provide explicit instructions or concrete steps for the authors to take, leaving the action somewhat vague. The authors can infer that they need to reconsider their approach, but the lack of detailed guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SSUL\" and \"Mask2Former,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a concern about the fairness of the comparison between SSUL and the paper, suggesting that the use of off-the-shelf saliency-map detectors may introduce an unfair comparison due to differences in data and model size. The comment further specifies that Mask2Former is trained on COCO and has larger parameters, prompting the authors to consider whether SSUL should also adopt Mask2Former or explore alternative methods for generating object proposals. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the fairness of the comparison between SSUL and the paper, specifically regarding the use of off-the-shelf saliency-map detectors versus the pretrained Mask2Former model. It suggests that this comparison may be unfair due to differences in data and model size. The reviewer provides a logical reasoning by pointing out that Mask2Former is trained on COCO and has larger parameters than the off-the-shelf detector. However, the comment lacks specific examples or references to support the claim that this unfairness might impact the results. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of the comparison between SSUL and the paper, specifically regarding the use of off-the-shelf saliency-map detectors versus the pretrained Mask2Former model. It suggests that this comparison may be unfair due to differences in data and model size, and it poses two questions to guide the authors: \"What if SSUL also adopts Mask2Former to detect unseen classes?\" and \"What if SSUL can generate object proposals in an unsupervised way without additional data or heavy models?\" These questions prompt the authors to consider alternative approaches or modifications to their current methodology. While the comment does not provide specific suggestions or detailed guidance, it offers valuable insights into potential areas for improvement and encourages the authors to reevaluate their methodology. Therefore, the comment is somewhat helpful, as it provides a direction for the authors to explore but could be more comprehensive with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the metrics used to validate the performance of the proposed approach, specifically mentioning the use of style accuracy based on a style classifier. It points out that the accuracy may not be a reliable indicator for capturing the styleness of the proposed algorithm. Additionally, it raises a concern about verifying the transfer results based on a styled input. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the metrics used for validation and possibly explore alternative methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experiments\" and \"the metrics,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the metrics used to validate the performance of the proposed approach, specifically pointing out the limitations of using style accuracy based on a style classifier and the difficulty in verifying transfer results based on a styled input. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the validity of the metrics used to evaluate the performance of the proposed approach. It suggests that the style accuracy, based on a style classifier, may not accurately capture the styleness of the proposed algorithm. Additionally, it points out that verifying the transfer results based on a styled input may be challenging. While the comment identifies potential issues, it lacks specific examples or references to support the claims. The reasoning is logical but lacks detailed evidence or references, making it somewhat verifiable. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the metrics used to validate the performance of the proposed approach. It points out that the style accuracy, which is based on a style classifier, may not accurately capture the styleness of the proposed algorithm. Additionally, it raises a concern about verifying the transfer results based on a styled input. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it provides insight into potential weaknesses but does not offer actionable steps for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding how individual preferences are generated and interpreted in the proposed method. It explicitly asks the authors to clarify how preferences are generated and whether they are based on rules or policies learned from experiences. This feedback provides a clear and direct action for the authors to take, ensuring that they understand the basis of their claims and can improve the clarity of their draft. The action is explicit and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors argue that the proposed method considers individual preferences when simulating agents. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the generation and interpretation of individual preferences. The comment provides a clear direction for the authors to improve the clarity of their argument by explaining how preferences are generated and interpreted. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of how individual preferences are generated and interpreted in the proposed method. It suggests that the authors need to clarify how certain agents are more risk-averse than others. The comment is somewhat verifiable as it highlights a potential gap in the explanation of the method, but it lacks specific examples or references to support the claim. The authors would need to provide additional clarification to fully address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the generation and interpretation of individual preferences in the proposed method. It points out that while the paper argues that the method considers individual preferences, it lacks clarity on how these preferences are generated and whether they are based on rules or policies learned from experiences. This feedback is clear and actionable, as it directs the authors to clarify their explanation of the method, which could enhance the understanding and credibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify these points or examples of how other methods have addressed similar issues. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the clarity and comprehensibility of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about Figure 4, including the meaning of \"1-200 frames,\" how values are computed, and the changing precision and recall with trajectory length. It also asks about \"action repeat.\" While the comment identifies specific areas of confusion, it does not provide explicit guidance on how the authors should address these issues. The questions are implied, and the authors are left to infer that they need to clarify or provide more information. However, the comment is somewhat actionable as it highlights specific areas that need clarification, which gives the authors a general direction for improvement. Therefore, this comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the meaning of \"1-200 frames,\" how values are computed, and the changing precision and recall with trajectory length. Additionally, it asks about \"action repeat,\" providing clear guidance on what needs to be clarified or addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification, rather than making subjective claims or suggestions. It does not contain any opinions, judgments, or statements requiring verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific areas of confusion in Figure 4, such as the meaning of \"1-200 frames\" and how values are computed. It also questions the changing precision and recall with trajectory length and asks about \"action repeat.\" This feedback is clear and actionable, as it directs the authors to clarify these points in their paper. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered additional context to enhance understanding. Overall, the comment is mostly helpful as it effectively guides the authors toward improving the clarity and comprehensibility of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the arbitrary nature of some design decisions, such as the number of initial ground truth examples and the number of labeled examples. It suggests that the performance of LLaMAA versus finetuning could be compared if finetuning was performed on a number of samples equivalent in cost to the additional samples from the LLM. The comment implies that the authors should provide justification for these design decisions to improve the soundness of their work. While the comment implies that the authors should provide additional information or justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide justification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the design decisions regarding the number of initial ground truth examples and the number of labeled examples, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the performance of LLaMAA versus finetuning could be compared if finetuning was performed on a number of samples equivalent in cost to the additional samples from the LLM. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the arbitrary nature of some design decisions, such as the number of initial ground truth examples and the number of labeled examples. It suggests that the performance of LLaMAA versus finetuning could be compared if finetuning was performed on a number of samples equivalent in cost to the additional samples from the LLM. The comment suggests that providing justification for these design decisions could increase the soundness of the work. However, the comment lacks specific examples or references to support the claim that cost-effectiveness is a primary motivation. While the suggestion is logical, the lack of detailed evidence or examples makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the design decisions regarding the number of initial ground truth examples and the number of labeled examples, suggesting that these choices may be arbitrary. It further suggests that a comparison of LLaMAA versus finetuning could be valuable, particularly if finetuning is performed on a number of samples equivalent in cost to the additional samples from the LLM. The comment provides a clear direction for the authors to consider, which is to justify their design decisions and potentially enhance the soundness of their work. However, the comment could be more helpful if it offered specific suggestions or examples of how to justify these decisions. Overall, the comment is mostly helpful as it highlights a potential area for improvement and provides a direction for the authors to explore, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the motivation for investigating a graph-structured model and questions the complexity of the approach. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might clarify or improve their motivation or approach. Without actionable suggestions or concrete steps, the authors are left without a clear understanding of what changes they should make to address the reviewer\\'s concerns. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the motivation for investigating a graph-structured model and questions the complexity of the approach. However, it does not specify which part of the paper this discussion pertains to, such as a particular section or figure. The authors can infer that it relates to the introduction or motivation section, but this inference is not direct. The comment is specific in its critique of the motivation and approach, but it lacks grounding as it does not explicitly mention a section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation for investigating a graph-structured model and suggests that the complexity of the approach is unclear. However, the comment lacks specific examples or references to support the claim that the approach is complex or unclear. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the reviewer\\'s concerns. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the motivation for investigating a graph-structured model and questions the complexity of the approach. It points out that the encoder and decoder are based on Transformer, which can draw global dependencies in a sentence. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might clarify their motivation or approach, nor does it suggest ways to address the reviewer\\'s confusion. As a result, the comment is barely helpful, as it identifies a potential issue but does not provide meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide videos showing different policies controlling cars on different tracks to enhance understanding of their methods. It also points out that some implementation details are missing from the main paper, making it difficult to reproduce the results. However, the comment does not specify which implementation details are missing or how they should be addressed. While the action of providing videos is explicit, the lack of concrete guidance on the missing implementation details makes the comment somewhat actionable. The authors know they need to provide videos but are not given specific details on what else is missing or how to address it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide videos showing different policies controlling cars on different tracks to enhance understanding of their methods. It also mentions that some implementation details are missing from the main paper, making it difficult to reproduce the results. However, the comment does not specify which sections or details are lacking, nor does it provide specific guidance on how to address these issues. This makes it weakly grounded because the authors cannot confidently determine which parts of the paper are being addressed, and it is under-specific because it lacks detailed guidance. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should provide videos showing different policies controlling cars on different tracks to enhance understanding of their methods. However, the comment lacks specific examples or references to support why this would be beneficial or how it would improve the paper. Additionally, the claim about the lack of implementation details is somewhat vague, as it does not specify which implementation details are missing or how they affect reproducibility. This makes the comment somewhat verifiable, as it provides some reasoning but lacks detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it suggests that the authors should provide videos showing different policies controlling cars on different tracks to enhance the readers\\' understanding of the methods. This is a clear and actionable suggestion that could significantly improve the clarity and accessibility of the paper. Second, it points out that some implementation details are missing from the main paper, making it difficult to reproduce the results. This feedback is also valuable as it highlights a potential issue with reproducibility, which is important for scientific rigor. However, the comment could be more helpful if it specified which implementation details are missing or how they affect the results. Overall, the comment is mostly helpful as it provides actionable suggestions for improving the clarity and reproducibility of the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the approximation in Equation 11 and suggests that the authors should conduct more experiments and theoretical analyses to explore the effect of the order of layers with the same parameters on the network. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct these experiments or what specific analyses should be conducted. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more experiments and theoretical analyses to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 11\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the approximation in Equation 11 and suggesting that the authors should conduct more experiments and theoretical analyses to explore the effect of the order of layers with the same parameters on the network. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the approximation in Equation 11 and suggests that the authors should conduct more experiments and theoretical analyses to explore the effect of the order of layers with the same parameters on the network. While the comment identifies a potential issue with the approximation, it lacks specific examples or references to support the claim that the approximation does not account for the effect of layer order. The suggestion to conduct more experiments is reasonable, but the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the approximation in Equation 11 and suggests that the authors should conduct more experiments and theoretical analyses to explore the effect of the order of layers with the same parameters on the network. This feedback is clear and actionable, as it provides a concrete direction for the authors to improve their work by addressing a gap in their analysis. However, the comment could be more helpful if it offered specific suggestions on which experiments or analyses to conduct or how to interpret the results. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that addressing offline-to-online learning adaptation appears to be incremental, as most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. The reviewer implies that implementing online fine-tuning on existing benchmarks is feasible. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or implement online fine-tuning. The action is implicit and somewhat vague, as the authors are left to infer that they should consider online fine-tuning but without specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of offline-to-online learning adaptation, suggesting that it appears to be incremental due to the nature of previous offline RL benchmarks based on simulation environments and rule-based reward functions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the incremental nature of addressing offline-to-online learning adaptation, but without explicit references to specific sections or details, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that addressing offline-to-online learning adaptation appears to be incremental due to the nature of previous offline RL benchmarks based on simulation environments and rule-based reward functions. The reviewer suggests that implementing online fine-tuning on existing benchmarks is feasible. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it provides a logical argument but requires more substantiation to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper regarding the incremental nature of addressing offline-to-online learning adaptation, which is based on the prevalence of simulation environments and rule-based reward functions in previous offline RL benchmarks. The reviewer suggests that implementing online fine-tuning on existing benchmarks is feasible. However, the comment lacks specific guidance or suggestions on how the authors might address this limitation or implement online fine-tuning effectively. While it points out a relevant issue, the feedback does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a contradiction in the evidence presented in Table 6, specifically noting that AT achieves a worse F1 score than BERTsynth despite using emotion classification data, and that GAS achieves the lowest F1 score despite fine-tuning with multiple emotion classification datasets. The reviewer suggests that this contradicts the claim that emotion-awareness is useful for synthetic text detection. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to resolve the contradiction. The feedback is somewhat actionable as it highlights a potential problem but lacks detailed instructions on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the contradiction in the evidence presented, specifically pointing out that AT achieves a worse F1 score than BERTsynth despite using emotion classification data, and that GAS achieves the lowest F1 score despite fine-tuning with multiple emotion classification datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 6 provides contradicting evidence, specifically noting that AT achieves a worse F1 score than BERTsynth despite using emotion classification data, and that GAS achieves the lowest F1 score despite fine-tuning with multiple emotion classification datasets. This suggests that emotion-awareness might not be useful for synthetic text detection. The comment provides logical reasoning by pointing out the discrepancy in the results, which is a clear observation. However, it lacks specific examples or references to support the claim that emotion-awareness is not useful. Therefore, the comment is somewhat verifiable, as it provides a logical argument but requires more detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a contradiction in the evidence presented in Table 6, specifically noting that AT achieves a worse F1 score than BERTsynth despite using emotion classification data, and that GAS achieves the lowest F1 score despite fine-tuning with multiple emotion classification datasets. This suggests that emotion-awareness might not be useful for synthetic text detection. The comment provides clear and actionable feedback by highlighting a potential issue with the evidence presented, which could lead to a reevaluation of the authors\\' claims about the effectiveness of emotion-awareness. However, the comment could be more helpful if it offered suggestions on how the authors might address this contradiction or improve their analysis. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical area needing clarification or revision.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests conducting more experiments to address the research question and provides specific guidance on testing with various models, such as Vision Transformers (ViT). It also recommends including results under more complex input noise models, such as multiplicative distortions. These explicit actions provide clear direction for the authors to follow, ensuring that they know exactly what steps to take to improve their draft. The feedback is concrete and specific, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments to address the research question and provides specific guidance on testing with various models, such as Vision Transformers (ViT). It also recommends including results under more complex input noise models, such as multiplicative distortions. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental section or methodology. The comment is specific in detailing what additional experiments should be conducted and how they would enhance the evaluation. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting more experiments to address the research question and provides specific guidance on testing with various models, such as Vision Transformers (ViT). It also recommends including results under more complex input noise models, such as multiplicative distortions. This feedback is mostly verifiable as it provides logical reasoning and specific examples of models that could be tested, along with a rationale for why this would enhance the evaluation. However, the comment could be strengthened by referencing specific studies or examples of how these models have been used in similar contexts. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the authors conduct more experiments to address the research question. It specifically recommends testing with various models, such as Vision Transformers (ViT), and includes a suggestion to include results under more complex input noise models, such as multiplicative distortions. This feedback is detailed and offers a concrete direction for the authors to improve their draft, making it highly helpful. By addressing these suggestions, the authors can enhance the comprehensiveness and robustness of their evaluation. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the number of human annotators mentioned in the D.2 appendix should be increased from two to four, based on the author responses. This is a clear and direct action that the authors can easily implement by updating the appendix accordingly. The comment is specific and provides concrete guidance on how to correct the error, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"D.2 appendix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the number of human annotators, which should be increased from two to four. This provides clear guidance on what needs to be addressed in the appendix. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the number of human annotators mentioned in the D.2 appendix should be increased from two to four, based on the author responses. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the D.2 appendix, noting that the number of human annotators mentioned should be increased from two to four, based on the author responses. This is a clear and actionable piece of feedback that the authors can easily address by updating the appendix accordingly. However, the comment could be more helpful if it provided additional context or explained why this change is necessary or beneficial. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a better motivation for the encoder and decoder structure would be beneficial in understanding the value of the proposed approach. However, it does not provide specific guidance on what kind of motivation would be more effective or how to incorporate it into the paper. The action is implicit and vague, as the authors are left to infer that they need to provide a better motivation but without clear instructions on how to achieve this. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that a better motivation for the encoder and decoder structure would help to better understand the value of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, methodology, or results sections. The authors can infer that it relates to the motivation or justification for the proposed approach, but this inference is not direct. The comment is specific in suggesting a need for a better motivation but lacks grounding as it does not explicitly mention which part of the paper should be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a better motivation for the encoder and decoder structure would help to better understand the value of the proposed approach. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential weakness in the paper, suggesting that a better motivation for the encoder and decoder structure would enhance the understanding of the proposed approach. This feedback is somewhat helpful as it points out an area where the authors could improve their draft, but it lacks specificity and does not provide actionable guidance on how to achieve this improvement. The comment highlights a potential gap in the paper but does not offer detailed suggestions or examples on how to address it. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the novelty of the explored loss functions, which are not considered new. It also points out that the attacks are white-box and that the absence of black-box evaluation is a limitation. Additionally, it suggests that the paper should consider targeted attacks to showcase the strength of the proposed attack method. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, as the authors need to infer that they should consider black-box evaluation and extend the analysis to targeted attacks. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the novelty of the explored loss functions, which are not considered new. It also critiques the white-box nature of the attacks and suggests that the absence of black-box evaluation is a significant limitation. Additionally, it recommends extending the analysis to targeted attacks. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections. The comment is specific in detailing what needs to be addressed, such as the novelty of the loss functions and the need for black-box evaluation. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the novelty of the explored loss functions, which are not considered new. The reviewer suggests that the use of these functions appears to be a simple \"plug and play\" of existing loss functions. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Additionally, the comment mentions the absence of black-box evaluation and the consideration of untargeted attacks, but it does not provide detailed reasoning or evidence to substantiate these points. The suggestion to extend the analysis to targeted attacks is somewhat helpful, but the overall comment lacks sufficient justification and evidence, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement, including the novelty of the explored loss functions, the white-box nature of the attacks, and the absence of black-box evaluation. It also suggests extending the analysis to targeted attacks to showcase the strength of the proposed attack method. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific suggestions on how to address these issues, such as which loss functions are considered new or how to conduct black-box evaluations. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the results for CIFAR10 are not impressive and suggests that a direct comparison with other approaches is necessary. It also mentions the desire to see results for CIFAR100. While the comment implies that the authors should conduct a direct comparison and provide results for CIFAR100, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison and provide additional results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"CIFAR10\" and \"CIFAR100,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of impressive results for CIFAR10 and the need for direct comparisons with other approaches. Additionally, it suggests conducting experiments with CIFAR100. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results for CIFAR10 are not impressive and suggests that a direct comparison with other approaches is necessary. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim borderline verifiable, as it requires more information to fully substantiate the claim. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results presented for CIFAR10, noting that the results are not impressive and suggesting that a direct comparison with other approaches is necessary. It also expresses a desire to see results for CIFAR100. While the comment highlights a potential weakness in the paper, it lacks specific suggestions or guidance on how to improve the results or conduct the comparisons. The feedback is somewhat helpful as it points out a potential area for improvement but does not provide detailed guidance on how to address it. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while hyperbolic space is well-suited for hierarchical datasets, none of the experiments in the paper demonstrate this. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or what specific experiments should be conducted to demonstrate the suitability of hyperbolic space. The comment lacks actionable guidance, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of demonstrating the suitability of hyperbolic space for hierarchical datasets, but it does not specify which part of the paper this critique pertains to. The authors cannot confidently determine whether it relates to specific experiments, sections, or figures. Additionally, the comment lacks specificity regarding what aspects of the experiments should be improved or how the demonstration could be enhanced. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that hyperbolic space is well-suited for hierarchical datasets but that none of the experiments in the paper demonstrate this. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper, noting that while hyperbolic space is well-suited for hierarchical datasets, the experiments do not clearly demonstrate this. This feedback highlights an area where the authors could enhance their work by providing more detailed evidence or examples to support their claims. However, the comment lacks specific suggestions or guidance on how to address this issue, leaving the authors with a general understanding of the need for improvement but without actionable steps. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the main strength of MixBoost, specifically whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide a clearer explanation of the strengths of MixBoost, but the comment does not offer specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the main strength of MixBoost, specifically whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the main strength of MixBoost, but without explicit references to sections or details, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the main strength of MixBoost. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the main strength of MixBoost, specifically whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. While it identifies a potential area for clarification, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential gap in the paper, but it does not offer actionable advice or detailed insights for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the statement \"Unlike previous works which use the test set for hyperparameter tuning\" and suggests that the wording is unclear. The reviewer agrees that hyperparameter tuning is important but questions the phrasing. Additionally, the reviewer suggests that the \"smaller training set\" (line 245) could be avoided by training the network with optimal parameters on the complete train+val set. While the comment identifies areas for improvement, it does not provide explicit guidance on how to revise the phrasing or suggest specific actions to address the issue. The authors are left to infer that they should clarify the phrasing and consider training with the complete train+val set, but the feedback lacks concrete details on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 243,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the phrasing of \"Unlike previous works which use the test set for hyperparameter tuning,\" suggesting that the wording is unclear. Additionally, it provides a specific suggestion to avoid the \"smaller training set\" issue by training the network with optimal parameters on the complete train+val set. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the phrasing of \"Unlike previous works which use the test set for hyperparameter tuning\" and suggests that the wording is unclear. The reviewer agrees that proper hyperparameter tuning is essential in ML but finds the phrasing difficult. The comment also suggests that the \"smaller training set\" (line 245) could be avoided by training the network with optimal parameters on the complete train+val set. While the comment identifies a potential issue with the phrasing, it lacks specific examples or references to support the claim about the clarity of the wording. The suggestion to train with optimal parameters on the complete train+val set is logical but not fully substantiated. Therefore, the comment is somewhat verifiable, as it provides some justification but lacks detailed evidence or references to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the phrasing of a statement regarding hyperparameter tuning, suggesting that it is unclear. It provides a constructive suggestion by recommending that the authors clarify the phrasing to make it more precise. Additionally, the reviewer offers a specific improvement by suggesting that the \"smaller training set\" issue could be avoided by training the network with optimal parameters on the complete train+val set. This feedback is actionable and provides clear guidance for improving the clarity and accuracy of the statement. However, the comment could be more helpful if it included examples or additional suggestions on how to improve the phrasing or the overall presentation of the idea. Overall, the comment is mostly helpful as it effectively identifies a specific area for improvement and offers actionable advice.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper\\'s writing needs improvement, particularly in the introduction, which is described as obscure and high-level. It recommends that the authors provide more detailed information about how they tokenize parameters and use DDPM to predict actual parameters. This feedback is explicit and provides concrete guidance on what the authors should do to improve their draft. The suggestion is clear and specific, giving the authors a clear path to enhance the clarity and depth of their introduction. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely the obscurity and high-level nature of the introduction. The comment suggests that the authors should provide more detailed information about how they tokenize parameters and use DDPM to predict actual parameters, which is a clear and actionable suggestion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the writing of the paper needs improvement, particularly in the introduction, which is described as obscure and high-level. The reviewer suggests that the authors should provide more detailed information about how they tokenize parameters and use DDPM to predict actual parameters, which could help clarify the paper. However, the comment lacks specific examples or references to support the claim that the introduction is obscure or high-level. While the suggestion is logical, the lack of detailed justification or evidence makes it somewhat verifiable. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper\\'s writing, particularly in the introduction. It points out that the introduction is obscure and high-level, lacking detailed information about the actual implementation of the tokenization and DDPM processes. The comment suggests that the authors should provide more detailed information to help readers gain a clearer understanding of the paper\\'s content. This feedback is clear and actionable, offering a concrete suggestion for improvement that could enhance the clarity and comprehensibility of the introduction. However, it could be more helpful if it included specific examples or guidance on how to improve the writing style or structure. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the presentation is not good and instructs the authors to name a few examples. However, it does not provide specific guidance on what aspects of the presentation are problematic or how the authors should address these issues. The action is implicit and vague, as the authors are left to infer that they need to identify and improve the presentation, but without concrete details on what to focus on or how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that the presentation is not good, but it does not specify which part of the presentation is problematic. It lacks grounding as it does not reference specific sections, figures, or examples that need improvement. The comment is specific in its request for examples, but without grounding, it is difficult for the authors to identify the exact areas that need attention. Therefore, this comment is not grounded and specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the presentation is not good without providing any specific examples or reasoning to support the claim. Without detailed feedback or evidence, the authors are left without a clear understanding of what aspects of the presentation are problematic or how they could improve it. This lack of specificity and justification makes the claim unverifiable, as it does not provide sufficient guidance for the authors to address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment states that the presentation is not good, but it does not provide any specific examples or details about what aspects of the presentation are problematic. Without this information, the authors are left without a clear understanding of what needs to be improved or how to address the issue. The comment lacks depth and actionable guidance, making it barely helpful. It does not assist the authors in identifying areas for improvement or offering constructive feedback. Therefore, the comment aligns with a score of 2, indicating that it is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly mentions the omission of a specific work by Rieck et al. [2] when discussing the correlation of topological complexity with generalization ability. This provides a clear and direct action for the authors to include this reference in their work. The comment is explicit and concrete, as it specifies exactly what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discuss the correlation of topological complexity with generalization ability, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the omission of the work by Rieck et al. [2]. This provides clear guidance on what the authors need to include to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have omitted a specific work by Rieck et al. [2] when discussing the correlation of topological complexity with generalization ability. However, the comment does not provide any supporting evidence, references, or reasoning to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the significance of the omission or how it affects their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the related work section, noting the absence of a reference to the work by Rieck et al. [2] when discussing the correlation of topological complexity with generalization ability. This feedback is clear and actionable, as it directs the authors to include a relevant reference that could enhance their analysis. However, the comment could be more helpful if it provided additional context or insights into why this reference is important or how it might impact the paper\\'s conclusions. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the usefulness of the exploration parameter gamma in the context of Alg 1 and Thm 3.1, as only upper-bounds on the pseudo-regret are provided. It suggests that the choice of gamma=0 might be optimal and questions the role of gamma in the analysis. The reviewer also suggests that a remark on high-probability upper-bounds and the role of gamma might be interesting. However, the comment does not provide explicit instructions or concrete steps for the authors to take. While it highlights areas for potential improvement, it lacks actionable guidance on how to address these issues. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer specific steps for the authors to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Alg 1\" and \"Thm 3.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises concerns about the usefulness of the exploration parameter gamma and questions the choice of gamma=0 as optimal. The comment suggests a remark on high-probability upper-bounds and the role of gamma, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the usefulness of the exploration parameter gamma in the context of Alg 1 and Thm 3.1, as only upper-bounds on the pseudo-regret are provided. The reviewer questions whether the choice of gamma=0 is optimal and suggests that a remark on high-probability upper-bounds and the role of gamma might be interesting. The comment also asks whether the analysis, which is heavily based on expectations, can be extended to high-probability bounds on the regret. While the comment identifies a potential issue with the analysis and suggests a direction for improvement, it lacks specific examples or references to support the claim that gamma is useless or that gamma=0 is optimal. This makes the claim somewhat verifiable, as it provides a logical basis but requires further elaboration or evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the usefulness of the exploration parameter gamma in the context of Alg 1 and Thm 3.1, as only upper-bounds on the pseudo-regret are provided. It questions the relevance of gamma and suggests that the choice of gamma=0 might be optimal. The comment also raises an interesting point about the role of gamma in the analysis, which is heavily based on expectations, and whether it can be extended to high-probability bounds on the regret. While the comment highlights a potential weakness in the analysis, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. The feedback is somewhat helpful as it points out a potential area for improvement but lacks actionable advice, making it somewhat beneficial for the authors.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to either restate the definition of the LCA relaxation from Wang et al. in the body of the paper or add a description to the appendix. This provides a clear and direct action for the authors to take, ensuring that the definition is properly defined and accessible to the reader. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 150,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a direct definition of the LCA relaxation and suggests adding a restatement or description in the body or appendix. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the LCA relaxation is referenced on line 150 but not directly defined. It suggests adding a restatement of the definition from Wang et al. or a description in the appendix. This claim is somewhat verifiable as it provides a specific suggestion for improvement, which could help clarify the definition for readers. However, it lacks detailed reasoning or references to Wang et al. to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the LCA relaxation is referenced on line 150 but not directly defined. It provides a clear and actionable suggestion by recommending either restating the definition from Wang et al. in the body of the paper or adding a description to the appendix. This feedback is valuable as it directs the authors to a specific area needing clarification, ensuring that readers can understand the concept fully. However, the comment could be more helpful if it included a brief explanation of why the definition is important or how it relates to the context of the paper. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and completeness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that providing more information on how validation and test splits influence model training could strengthen reproducibility. While it implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more information on how validation and test splits influence model training could strengthen reproducibility. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where this information is discussed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The suggestion is specific in terms of what additional information is needed, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more information on how validation and test splits influence model training could strengthen reproducibility. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that more information on how validation and test splits influence model training could strengthen reproducibility. This feedback is somewhat helpful as it points out a specific aspect that could enhance the robustness and reliability of the study. However, the comment lacks depth and does not provide detailed guidance on how to incorporate this information or what specific aspects to focus on. To be more helpful, the comment could offer suggestions on how to present this information or provide examples of how other studies have addressed this issue. As it stands, the feedback provides a general direction for improvement but lacks actionable steps, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scope of the proposed solution and suggests exploring other regularization techniques, such as L2 regularization, data augmentation, and adding noise. It also questions the use of dropout as a sole regularization technique and suggests considering other techniques like ZeroLiers. While the comment implies that the authors should consider these additional techniques, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their scope and consider other methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the scope of the proposed solution and suggests exploring other regularization techniques, such as L2 regularization, data augmentation, and adding noise. It also questions the use of dropout as a sole regularization technique and suggests considering other techniques like ZeroLiers. However, the comment does not specify which part of the paper this critique pertains to, making it weakly grounded. The suggestion to explore other techniques is specific, but the lack of grounding makes it difficult for the authors to pinpoint the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the scope of the proposed solution and suggests exploring other regularization techniques, such as L2 regularization, data augmentation, and adding noise. It also questions the use of dropout as a sole regularization technique and suggests considering other techniques like ZeroLiers. While the comment highlights potential areas for improvement, it lacks specific examples or references to support the claim that other techniques should be considered. This makes the claim somewhat verifiable, as it provides a logical basis for exploration but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid point about the scope of the proposed solution, questioning why the authors limit themselves to dropout as a regularization technique. It suggests exploring other techniques like L2 regularization, data augmentation, and adding noise, which are commonly used in practice. The comment also questions the use of dropout as a sole regularization technique and suggests considering other techniques like ZeroLiers. This feedback is clear and actionable, providing the authors with a comprehensive list of alternative regularization techniques to consider. However, it could be more helpful if it included specific examples or references to support the suggestion. Overall, the comment is mostly helpful as it guides the authors toward a broader exploration of regularization techniques, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about how to generalize the assumption of overlap (Assumption A) from a tabular setting to a function approximation setting. It suggests that the authors should discuss this in the context of consistency. While the comment implies that the authors should provide a discussion on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue in their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption A (overlap)\" and \"the function approximation setting,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by asking how the assumption of overlap can be generalized from a tabular setting to a function approximation setting, and suggests discussing this in the context of consistency. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about generalizing the assumption of overlap (Assumption A) from a tabular setting to a function approximation setting. It suggests that this should be discussed in the context of consistency. While the comment identifies a potential gap in the discussion, it lacks specific examples or references to support the claim that this assumption is not valid in the function approximation setting. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific assumption (Assumption A, or overlap) that is reasonable in a tabular setting but raises questions about its applicability in a function approximation setting. It suggests that the authors should discuss this issue in the context of consistency. While the comment highlights a potential gap in the discussion, it does not provide detailed guidance or suggestions on how to address this issue. The authors are given a direction to consider but are left without specific steps or examples to follow. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It explicitly instructs them to make Table 1 one column wide and to adjust the figure widths, specifically mentioning Figures 3, 5, and 6. Additionally, it suggests that the paper could be improved by making it easier to understand, which implies that the authors should consider reorganizing or clarifying their content. These direct actions are clear and specific, giving the authors a clear path to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Figures 3, 5, and 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be done, suggesting that Table 1 should be one column wide and that the figures could benefit from a two-column width. The comment also suggests that the paper was not easy to understand during the first read and provides a general suggestion for improvement. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Table 1 should be one column wide and that Figures 3, 5, and 6 would benefit from a two-column width. It also claims that the paper was not easy to understand during the first read and suggests that major improvements could be achieved by straightening up the content. However, the comment lacks specific examples or detailed reasoning to support these claims, making it somewhat verifiable. The authors would need to infer the specific improvements needed to address the issues raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the layout and organization of the paper. It suggests that Table 1 should be one column wide, while Figures 3, 5, and 6 would benefit from a two-column width. This feedback is clear and offers a concrete way for the authors to improve the presentation of their data. Additionally, the comment acknowledges that the paper was not easy to understand during the first read and suggests that it could be improved by straightening up the content. This feedback is valuable as it identifies a potential source of confusion and provides a clear direction for improvement. However, the comment could be more helpful if it included specific suggestions on how to improve the content organization or clarity. Overall, the comment is mostly helpful as it provides actionable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests repeating the Text-DPO baseline but with the generated images used for DPO as images for additional image-question-answer triplets. It also speculates that training with perturbed images is providing the additional performance benefit for the method, rather than the specific DPO objective. While the comment provides a clear action to repeat the baseline with perturbed images, it lacks specific guidance on how to implement this suggestion or what specific changes to make. The action is explicit but the lack of detailed instructions makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests repeating the Text-DPO baseline with the generated images used for DPO as images for additional image-question-answer triplets. It also speculates on the potential impact of training with perturbed images on performance. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology or results section where the baseline and performance comparisons are discussed. The comment is specific in suggesting a potential modification to the baseline and provides a rationale for the suggestion. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests repeating the Text-DPO baseline with the generated images used for DPO as images for additional image-question-answer triplets. The reviewer provides a rationale based on their suspicion that training with perturbed images is providing the additional performance benefit for the method, rather than the specific DPO objective. This reasoning is logical and provides a plausible explanation, but it lacks specific references or detailed evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the suggestion but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the methodology by repeating the Text-DPO baseline with the generated images used for DPO as images for additional image-question-answer triplets. This feedback is actionable and offers a clear and concrete way for the authors to enhance their methodology. Additionally, the comment includes a rationale based on the reviewer\\'s suspicion that training with perturbed images is providing the additional performance benefit for the method, rather than the specific DPO objective. This insightful observation could prompt the authors to reconsider their approach and potentially lead to a more robust and effective method. However, the comment could be more helpful if it included additional details or examples to further substantiate the rationale. Overall, the comment is mostly helpful as it provides clear and actionable feedback with a logical basis for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a final assumption that there is no difference in expertise between Alice and Bob, which may not hold in real-world tasks. It suggests that there could be non-linear interactions between success-rate and speed-up due to different levels of expertise. However, the comment does not provide explicit guidance or suggestions on how the authors should address this assumption or explore the potential non-linear interactions. The action is implicit and somewhat vague, as the authors can infer that they need to consider the potential impact of expertise on the success-rate and speed-up, but the comment lacks concrete details on how to implement this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a final assumption regarding the expertise of Alice and Bob, suggesting that there could be non-linear interactions between success-rate and speed-up due to different levels of expertise. However, it does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in pointing out the potential issue with the assumption and the potential non-linear interactions, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the assumption that there is no difference in expertise between Alice and Bob, suggesting that this may not hold in real-world tasks. It raises the possibility of non-linear interactions between success-rate and speed-up due to different levels of expertise. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that such interactions are common or relevant in human-AI collaboration. The reasoning is somewhat logical but could be strengthened with more detailed evidence or examples. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential assumption that may not hold in real-world tasks, specifically the assumption that there is no difference in expertise between Alice and Bob. It suggests that there could be non-linear interactions between success-rate and speed-up due to different levels of expertise. This feedback is valuable as it highlights a potential weakness in the paper\\'s assumptions and encourages the authors to consider the impact of expertise on the performance of the human-AI collaboration. However, the comment could be more helpful if it provided specific examples or references to support the claim or suggested ways to explore this assumption further. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical aspect of their work that requires further consideration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation of the mitigation strategies proposed in the paper, specifically noting that they are data set specific and might not be applicable more broadly. It also points out that the framework\\'s applicability to other LLMs and datasets might be limited due to its specificity. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or make their framework more generalizable. The action is implicit and vague, as the authors are left to infer that they need to consider broader applicability and generalizability. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the applicability and generalizability of the mitigation strategies proposed in the paper, specifically mentioning the issue of data set specificity and its impact on the framework\\'s applicability to other LLMs and datasets. However, it does not specify which part of the paper discusses these strategies or where the issue of generalizability is discussed, making it weakly grounded. The comment is specific in detailing the limitations of the framework\\'s applicability, but without explicit references to sections or specific elements, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the mitigation strategies proposed in the paper are data set specific and might not be applicable more broadly. The reviewer supports this claim by pointing out that the framework\\'s applicability to other LLMs and datasets might be limited due to its specificity. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the specific issues and limitations themselves, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the applicability and generalizability of the mitigation strategies proposed in the paper. It points out that these strategies are data set specific and might not be applicable more broadly, which could limit the framework\\'s applicability to other LLMs and datasets. This feedback is valuable as it highlights a potential weakness in the paper\\'s contribution, prompting the authors to consider broader applicability and generalizability. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this limitation. Overall, the comment is mostly helpful as it directs the authors\\' attention to an important area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies that the paper is not sufficiently clear in certain aspects and provides a list of questions. However, it does not explicitly instruct the authors on how to address these issues or clarify the questions. The action is implicit and vague, as the authors are left to infer that they need to clarify these aspects but without specific guidance on how to do so. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions that the paper is not sufficiently clear in certain aspects, but it does not specify which aspects are unclear or provide a list of questions. This lack of specificity makes it difficult for the authors to identify the exact areas that need clarification. Additionally, the comment suggests that the weaknesses could be fixed before the final paper submission, but it does not provide any detailed guidance on how to achieve this. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is not sufficiently clear in certain aspects, but it does not specify which aspects are unclear or provide examples or reasoning to support this claim. The comment suggests that the weaknesses could be fixed before the final paper submission, but it lacks detailed guidance or evidence to substantiate the claim. As a result, the comment is unverifiable, as it does not provide sufficient justification or evidence to support the claim. Therefore, it should be rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies that the paper is not sufficiently clear in certain aspects, which is a valid point. However, it does not provide specific questions or examples of what is unclear, leaving the authors without actionable feedback on how to improve clarity. The comment suggests that the weaknesses could be fixed before the final paper submission, but without detailed guidance or suggestions, it does not offer much value to the authors. Therefore, the comment is barely helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2. It also asks about the specific task that participants are performing. While the comment implies that the authors should clarify these aspects, it does not provide explicit instructions or concrete guidance on how to address these questions. The authors can infer that they need to provide more information or clarification, but the lack of detailed suggestions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2. It also asks about the specific task that participants are performing. However, it does not specify which part of the paper these questions pertain to, such as a particular section or figure. The authors might infer that it relates to Figure 2, but this inference is not direct. The comment is specific in its request for clarification on the task conditions and the relationship between audio signals, but it lacks grounding as it does not explicitly mention a section or figure. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2. It also inquires about the specific task that participants are performing. This feedback is somewhat helpful as it prompts the authors to clarify and provide more detailed information about their experimental setup. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of what additional information might be needed. While it highlights areas for improvement, the lack of actionable guidance limits its usefulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper did not address certain problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense and facts. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these issues or what specific aspects of the paper need to be revised. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s omission of certain problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense and facts. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the problems that need to be addressed, providing clear guidance on what aspects of the paper are lacking. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not address certain problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense and facts. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact issues and how to address them. Without detailed reasoning or evidence, the claim remains unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by addressing certain problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense and facts. While it highlights a potential gap in the paper\\'s coverage, it does not provide actionable feedback or suggestions on how the authors might address these issues. The comment points out a relevant area for improvement but lacks depth and specificity, making it somewhat helpful. The authors are given a direction for improvement but not detailed guidance on how to implement it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with the paper regarding the lack of statistical distribution on paper venues, specifically questioning the number of papers from ACL and EMNLP versus those from Arxiv. It also raises concerns about the inclusion of Arxiv papers in the study, suggesting that they may not be considered as significant publications due to their unreviewed nature. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of statistical distribution on paper venues, specifically questioning the number of papers from ACL and EMNLP versus those from Arxiv. It also raises concerns about the inclusion of Arxiv papers in the study, suggesting that they may not be considered as significant publications due to their unreviewed nature. However, the comment does not specify which part of the paper this issue pertains to, such as sections or figures, making it weakly grounded. The comment is specific in detailing the concerns about the inclusion of Arxiv papers and the potential bias they may introduce. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks statistical distribution on paper venues, specifically questioning the number of papers from ACL and EMNLP versus those from Arxiv. The reviewer expresses skepticism about the significance of the results presented in the paper due to the inclusion of Arxiv papers, which are not peer-reviewed and considered informal publications. The reviewer supports this claim by referencing the unreviewed nature of Arxiv papers, suggesting that they may introduce bias. However, the comment lacks specific examples or references to support the claim about the bias introduced by Arxiv papers. This makes the claim somewhat verifiable, as it provides some reasoning but requires further elaboration to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper regarding the lack of statistical distribution on paper venues, specifically questioning the number of papers from ACL and EMNLP versus those from Arxiv. It raises concerns about the inclusion of Arxiv papers in the study, suggesting that they may not be considered as significant publications due to their unreviewed nature. The reviewer expresses skepticism about the results presented in the paper and questions the bias that may be introduced by including Arxiv papers. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the paper. The feedback is somewhat helpful as it points out a significant issue but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus more on the proposed problem and framework, rather than spending a significant amount of space on applications. While the comment implies that the authors should prioritize the former, it does not provide specific guidance on how to achieve this balance or what aspects of the applications should be reduced or revised. The action is implicit and somewhat vague, as the authors need to infer that they should focus more on the problem and framework but are not given concrete steps to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should focus more on the proposed problem and framework, rather than spending a significant amount of space on applications. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in its suggestion to prioritize the problem and framework, but without explicit references to sections or details, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should focus more on the proposed problem and framework rather than spending a significant amount of space on applications. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this focus is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should focus more on the proposed problem and framework, rather than spending a significant amount of space on applications. While it identifies a potential imbalance in the paper, it lacks specificity and does not provide actionable guidance on how to achieve this balance or what aspects of the applications should be reduced or revised. The feedback is somewhat helpful as it points out a potential issue, but it does not offer detailed suggestions or examples to help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper is \"marginally above acceptance threshold\" and acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to enhance the paper or what specific aspects need attention. As a result, the authors are left without any clear direction on how to address the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the paper is \"marginally above acceptance threshold,\" which suggests that it is close to being accepted but not quite there. However, it does not specify which part of the paper is being addressed, such as the introduction, methodology, or results sections. Additionally, it does not provide any specific details on what aspects of the paper need improvement or how the authors have addressed the limitations and potential negative societal impact. Without clear guidance on what needs to be improved or where the issues lie, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is \"marginally above acceptance threshold\" and acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, the comment lacks specific details or examples to support these claims, making it difficult for the authors to understand the basis of the critique or how to improve their draft. The lack of supporting evidence or reasoning makes the claim unverifiable, as it does not provide sufficient guidance for the authors to address the feedback effectively. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the paper is \"marginally above acceptance threshold\" and notes that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, it does not provide any specific feedback or suggestions for improvement, leaving the authors without actionable guidance on how to enhance their draft. Without detailed feedback or constructive criticism, the authors are left without a clear path forward, making this comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the current dataset is simple and could be solved by an agent translating natural language into <source, path, destination> triples, followed by using code or search libraries. It also mentions that the natural language is generated by patterns, making natural language understanding easy. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to improve their draft. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to apply the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the current dataset is simple and could be solved by an agent translating natural language into <source, path, destination> triples, followed by using code or search libraries. It also mentions that the natural language is generated by patterns, making natural language understanding easy. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Additionally, while the comment suggests that the paper may have limited research impact, it does not provide specific suggestions or examples of how the authors could address this concern. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the current dataset is simple and could be solved by an agent translating natural language into <source, path, destination> triples, followed by using code or search libraries. It also mentions that the natural language is generated by patterns, making natural language understanding easy. The comment implies that the paper may have limited research impact due to the potential use of existing methods like PAL or LLMs with code interpreters. However, the comment lacks specific examples or detailed reasoning to support the claim about the paper's impact. The suggestion to follow the path of the GSM8K dataset is mentioned but not fully developed. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the current dataset is simple and could be solved by an agent translating natural language into <source, path, destination> triples, followed by using code or search libraries. It also mentions that the natural language is generated by patterns, making natural language understanding easy. This feedback highlights a potential limitation of the dataset and suggests that the paper may have limited research impact due to the potential use of existing methods like PAL or LLMs with code interpreters. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the research impact. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors might need to revise a statement about the maximum likelihood estimation, specifically questioning the limitations of the proposed measure. It points out that the paper does not discuss the theoretical connection to generalization or experimental performance compared to competing measures. While the comment provides a clear direction for revision, it does not offer specific guidance on how to address these issues or what changes should be made. The action is explicit but somewhat vague, as the authors know they need to revise the statement but may not have a clear understanding of the exact changes required. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"25: masures 242,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be revised, namely the statement about maximum likelihood estimation and the limitations of the proposed measure. The comment provides a detailed critique of the paper, highlighting the lack of discussion on theoretical connections and experimental performance compared to competing measures. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement about maximum likelihood estimation lacks a discussion of its limitations and does not provide a stronger theoretical connection to generalization than competing measures. The reviewer supports this claim by referencing the presentation, which suggests that the proposed measure does not outperform other measures experimentally. This provides a logical reasoning and specific examples to substantiate the claim, making it mostly verifiable. However, the comment could be strengthened by including more detailed examples or references to support the critique. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of discussion on the limitations of the proposed measure and its theoretical connection to generalization. It points out that the paper does not provide a stronger theoretical connection or experimental performance compared to competing measures. This feedback is clear and actionable, as it directs the authors to address these gaps in their analysis and discussion. However, the comment could be more helpful if it provided suggestions on how to improve the presentation or what specific aspects of the theoretical connection or experimental performance should be emphasized. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of results for fine-tuned open-source LLMs, which is considered important for a domain-specific benchmark. However, it does not provide explicit guidance on what specific results should be included or how to address this gap. The action is implicit and vague, as the authors are left to infer that they need to include results for fine-tuned open-source LLMs, but without detailed instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the lack of results for fine-tuned open-source LLMs, which is important for a domain-specific benchmark. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table where these results should be included. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in identifying the issue of missing results but lacks grounding as it does not explicitly mention a section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of results for fine-tuned open-source LLMs is important for a domain-specific benchmark. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate why this is a significant issue or how it affects the benchmark. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, namely the absence of results for fine-tuned open-source LLMs, which is considered important for a domain-specific benchmark. This feedback is clear and actionable, as it highlights a critical aspect that the authors should address to enhance the quality and comprehensiveness of their work. However, the comment could be more helpful if it provided suggestions on how to incorporate these results or what specific aspects of fine-tuning should be included. Despite this, the feedback is mostly helpful as it directs the authors to a significant area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the training process of the regression model, including the input and output, as well as the parameter space for different models with varying feature sizes. It also questions whether the model performance is affected by the number of parameters. While these questions provide a clear direction for the authors to explore, they do not offer explicit guidance on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should provide detailed information about the training process and model performance. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions about the training process of the regression model, including the input and output, as well as the parameter space for different models with varying feature sizes. It also questions whether the model performance is affected by the number of parameters. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions themselves are specific, as they ask for detailed information about the training process and model performance. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions about the training process of the regression model, including the input and output, as well as the parameter space for different models with varying feature sizes. It also questions whether the model performance is affected by the number of parameters. These questions are factual and seek clarification, rather than making subjective claims or suggestions. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several questions about the training process of the regression model, including the input and output, as well as the parameter space for different models with varying feature sizes. It also questions whether the model performance is affected by the number of parameters. These questions are relevant and could prompt the authors to provide more detailed information about their methodology and results. However, the comment does not offer specific suggestions or guidance on how to address these questions or improve the paper. While it highlights areas for further exploration, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the operator after w_i should be the multiplication of the underlying vector space and not \\cross_g, which is an operator between a scalar and a tensor, rather than just between two scalars. This provides a clear and concrete action for the authors to take, as it specifies the exact change needed to be made in the equations. The comment also provides a rationale for the change, making it easy for the authors to understand and implement the suggested correction. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq 6 and related equations,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion regarding the operator after w_i, suggesting that it should be the multiplication of the underlying vector space rather than \\cross_g. This provides clear guidance on what needs to be corrected in the equations. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the operator after w_i should be the multiplication of the underlying vector space and not \\cross_g, which is an operator between a scalar and a tensor, rather than just between two scalars. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with equation 6 and related equations, suggesting that the operator after w_i should be the multiplication of the underlying vector space and not \\cross_g, which is an operator between a scalar and a tensor, rather than just between two scalars. This feedback is clear and actionable, providing the authors with a precise correction to make in their draft. However, the comment could be more helpful if it explained why this change is necessary or how it would improve the clarity or accuracy of the equations. Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing correction, which is valuable for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should add more ablation experiments to demonstrate the effectiveness of their proposed model. It specifies two potential areas for investigation: the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. While the comment provides clear and concrete actions for the authors to take, it does not offer detailed guidance on how to conduct these experiments or what specific aspects to focus on. The authors are given a clear direction but may need to infer additional details to fully implement the suggestions. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors should add more ablation experiments to demonstrate the effectiveness of the proposed model. It specifies two potential areas for investigation: the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. However, the comment does not explicitly mention which sections of the paper these experiments should be added to, making it weakly grounded. The suggestions are specific, as they provide clear areas for investigation and potential improvements. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should conduct additional ablation experiments to demonstrate the effectiveness of their proposed model. The comment provides specific suggestions for these experiments, such as exploring the role of different updating methods in decoupling the selecting and weighting outputs and the role of reweighting after selection. This provides a clear and actionable direction for the authors to improve their draft. However, the comment lacks detailed justification or references to support the importance of these experiments, which would make it more fully verifiable. Therefore, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors should conduct additional ablation experiments to demonstrate the effectiveness of their proposed model. It suggests two potential areas for investigation: the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. This feedback is clear and offers concrete suggestions for improving the draft, empowering the authors to enhance the robustness and clarity of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experimental results could be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also mentions specific baseline approaches, like those by Phan et al. (2017; 2019; 2020) and other related works, for comparison. While the comment implies that the authors should consider these improvements, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments to more complex datasets and tasks. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experimental results could be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also mentions specific baseline approaches, like those by Phan et al. (2017; 2019; 2020) and other related works listed below. However, the comment does not specify which part of the paper these suggestions pertain to, such as the experimental section or the discussion. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting improvements and providing examples of baseline approaches, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experimental results could be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. The comment provides a specific suggestion to consider baseline approaches like those by Phan et al. (2017; 2019; 2020) and other related works for comparison. This provides a clear direction for improvement, making the claim mostly verifiable. The authors can understand the need for more complex datasets and tasks and the relevance of the suggested baseline approaches. However, the comment could be strengthened by providing more detailed reasoning or examples of how these changes would enhance the results. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a constructive suggestion for improving the experimental results by suggesting the use of more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also mentions specific baseline approaches, like those by Phan et al. (2017; 2019; 2020) and other related works, for comparison. This feedback is clear and actionable, as it guides the authors on how to enhance the scope and depth of their experiments. By suggesting the use of more complex datasets, the authors can potentially strengthen the validity and generalizability of their results. However, the comment could be more helpful if it provided additional details on how these changes would impact the results or why these specific baseline approaches are relevant. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the experimental results, specifically questioning the effectiveness of PRESENCE. It points out that the relationship between temperature $\\\\tau$ and downstream performance in Figure 5 does not justify the two-stage pre-training and suggests that using a positive or negative $\\\\tau$ could yield improvement over no reweighting. Additionally, the reviewer questions the importance of using PRESENCE based on the results from Table 4, which do not show the advantage of using PRESENCE. However, the comment does not provide explicit guidance on how the authors should address these concerns or improve their experimental design. The actions are implicit and somewhat vague, leaving the authors to infer that they need to reconsider their experimental setup and results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5\" and \"Table 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the relationship between temperature $\\\\tau$ and downstream performance, suggesting that the results do not justify the two-stage pre-training. Additionally, it raises concerns about the cross-lingual zero-shot transfer results from Table 4, questioning the advantage of using PRESENCE. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the experimental results, specifically questioning the effectiveness of PRESENCE. It suggests that the relationship between temperature $\\\\tau$ and downstream performance in Figure 5 does not justify the two-stage pre-training and that using a positive or negative $\\\\tau$ could yield improvement over no reweighting. The reviewer also questions the importance of using PRESENCE based on the results from Table 4, which do not show the advantage of using PRESENCE. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or references makes the claim somewhat verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific concerns about the experimental results, particularly questioning the effectiveness of PRESENCE. It points out that the relationship between temperature $\\\\tau$ and downstream performance in Figure 5 does not justify the two-stage pre-training and suggests that using a positive or negative $\\\\tau$ could yield improvement over no reweighting. Additionally, the reviewer questions the importance of using PRESENCE based on the results from Table 4, which do not show the advantage of using PRESENCE. These observations are clear and provide the authors with actionable insights into potential weaknesses in their experimental design. However, the comment could be more helpful if it offered suggestions on how to address these concerns or improve the experimental setup. Overall, the feedback is somewhat helpful as it highlights areas for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with Table 2, specifically noting that the results for k=1 are better than the baselines, suggesting that the performance gain might be due to a reason different from applying Equation 10. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what specific steps they should consider to improve their draft. As a result, the comment is unactionable, as it does not offer any direction for the authors to follow.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific observation about the results for k=1, suggesting that the performance gain might be due to a reason different from applying Equation 10. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results for k=1 in Table 2 are better than the baselines, suggesting that the performance gain might be due to a reason different from applying Equation 10. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 2, noting that the results for k=1 are better than the baselines, which suggests that the performance gain might be due to a reason different from applying Equation 10. This observation is valuable as it highlights a potential area for further exploration or explanation. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what additional analyses might be needed. While it points out a relevant observation, the feedback could be more helpful with additional context or actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the proposed method, such as the lack of solid grounding and the unclear justification for the choice of mixed-integer programming. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to justify the choice of mixed-integer programming or how to clarify the advantages over alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies specific issues with the proposed method, such as the lack of solid grounding and the unclear justification for the choice of mixed-integer programming. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in detailing what needs to be addressed, but it lacks grounding as it does not specify where in the paper these issues are discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method lacks solid grounding and that the choice of mixed-integer programming is not fully justified. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some indication of the problem but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed method, specifically the lack of solid grounding and unclear justification for the choice of mixed-integer programming. It also points out the need for clarification on the advantages over alternative approaches. While the comment highlights important areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it directs the authors\\' attention to critical areas needing attention, but it lacks actionable advice or detailed guidance. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the confusion caused by the notation in Equation 1 and the missing reference to Pedersen et al 2007 in the reference section. While the first issue is explicitly stated, the comment does not provide any guidance on how to address the confusion in the notation or how to include the missing reference. The second issue is also clearly stated but lacks actionable details, such as suggesting how to include the reference in the reference section. The lack of concrete steps or suggestions makes it difficult for the authors to know exactly what changes to make. Therefore, the comment is somewhat actionable, as it identifies specific issues but does not provide detailed guidance on how to resolve them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 1\" and \"Line 361,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues: the notation in Equation 1 is confusing due to the use of \"c\" instead of \"o,\" and the reference to Pedersen et al 2007 is missing from the reference section. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two claims: the notation in Equation 1 is confusing and the reference to Pedersen et al 2007 is missing in the reference section. The first claim is somewhat verifiable as it points out a specific issue with the notation, but it lacks detailed explanation or examples to fully substantiate the confusion. The second claim is also somewhat verifiable, as it identifies a missing reference but does not provide context or reasoning for why it is important. The lack of detailed justification or examples makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues: the notation in Equation 1 is confusing due to the use of \"c\" instead of \"o,\" and the reference to Pedersen et al 2007 is missing from the reference section. These are clear and actionable points that the authors can address to improve the clarity and accuracy of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the notation or suggested ways to include the missing reference. Despite this, the feedback is mostly helpful as it directs the authors to specific areas needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the proposed combination of SSMs with Attention is not new and has been previously proposed in MEGA and Block-state Transformer. It also notes that the architecture in Figure 5 looks similar to the proposed architecture in Mega, and suggests that the similarities and differences between S++ and this work should be discussed thoroughly and ablated. This feedback provides clear and explicit actions for the authors to take, such as discussing the similarities and differences and possibly modifying the architecture to differentiate it from existing work. The concrete details on what needs to be addressed and the references to external work make the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"second contribution of the paper,\" which is the proposal to combine SSMs with Attention. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the proposed architecture is not new and has been previously discussed in MEGA and Block-state Transformer, providing clear guidance on what needs to be addressed. The suggestion to discuss the similarities and differences between S++ and this work is also specific, as it provides a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed combination of SSMs with Attention is not new and has been previously discussed in MEGA and Block-state Transformer. The reviewer provides references to these works, which supports the claim by providing external evidence. However, the comment could be strengthened by providing specific examples or detailed comparisons between the proposed architecture and the existing works. Despite this, the claim is mostly verifiable due to the references to external sources, which provide a solid foundation for the authors to understand the claim and address it.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s second contribution, which is the proposal to combine SSMs with Attention. It points out that this combination has been previously proposed in MEGA and Block-state Transformer, which are cited but not discussed in the paper. This feedback is valuable as it highlights a potential gap in the paper\\'s originality and contribution. Additionally, the comment suggests that the similarities and differences between the proposed architecture and existing works should be discussed thoroughly and ablated. This feedback is clear and actionable, providing the authors with a specific direction to enhance the originality and comprehensiveness of their contribution. However, the comment could be more helpful if it offered suggestions on how to address the similarities and differences or provided examples of how other works have handled this issue. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear path for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the specific reason for reporting results on knowledge transfer only in a few select environments. While it implies that the authors should provide a rationale for this choice, it does not explicitly instruct them to do so. The comment lacks concrete guidance on how to address this issue, such as suggesting alternative environments to consider or providing specific examples of why certain environments were chosen. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the specific reason for reporting results on knowledge transfer only in a few select environments, which is mentioned as section 4.3. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the rationale for the choice of environments, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for a specific reason behind the choice of environments for reporting results on knowledge transfer. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is a normal statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the specific reason for reporting results on knowledge transfer only in a few select environments, which is relevant for understanding the scope and limitations of the study. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their reporting. Without actionable feedback or context, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of specific ablation experiments and suggests that the performance improvement might be due to the pre-trained weights rather than the method proposed in the manuscript. It points out the absence of detailed ablation comparisons, which could lead to confusion. While the comment identifies a potential issue, it does not provide explicit guidance on how to address this issue, such as suggesting specific ablation experiments or comparisons to include. The action is implicit and somewhat vague, as the authors can infer that they need to conduct more detailed ablation experiments but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of specific ablation experiments and suggests that the performance improvement might be due to pre-trained weights rather than the method proposed in the manuscript. It also points out the absence of detailed ablation comparisons, which could lead to confusion. However, the comment does not specify which part of the paper lacks these experiments or comparisons, making it weakly grounded. The authors can infer that it relates to the results or methodology sections, but this inference is not direct. The comment is specific in detailing what is missing and why it is important, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance improvement might be due to pre-trained weights rather than the method proposed in the manuscript. It suggests that the absence of detailed ablation comparisons could lead to confusion. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim is not fully verifiable, as it relies heavily on inference rather than concrete examples or data. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the manuscript, namely the lack of specific ablation experiments and detailed ablation comparisons. It suggests that the performance improvement might be attributed to pre-trained weights rather than the method proposed in the manuscript, which could lead to confusion. This feedback is clear and actionable, as it highlights a critical area for improvement in the experimental design and methodology. However, the comment could be more helpful if it provided specific suggestions on how to conduct these ablation experiments or what comparisons to include. Overall, the comment is mostly helpful as it directs the authors to a crucial area for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the lemmatizer that removes suffixes from words that are already lemmas but end with a suffix substring. This is identified as a major concern for real-world texts with evolving vocabularies. However, the comment does not provide any explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how the authors might improve their approach or what specific steps they should consider to mitigate this issue. As a result, the authors are left without a clear understanding of how to address the concern, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific limitation in the lemmatizer, which removes suffixes from words that are already lemmas but end with a suffix substring. This is a clear and specific concern, as it highlights a potential issue with the lemmatizer\\'s behavior. However, the comment does not explicitly mention which part of the paper discusses this limitation, making it weakly grounded. The authors can infer that it relates to the lemmatization process, but this inference is not direct. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lemmatizer\\'s behavior of removing suffixes from words that are already lemmas but end with a suffix substring is a major concern for real-world texts with evolving vocabularies. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the full extent of the concern. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered borderline verifiable, as it provides some rationale but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the lemmatizer, which removes suffixes from words that are already lemmas but end with a suffix substring. This is a major concern for real-world texts with evolving vocabularies. However, the comment does not provide any actionable feedback or suggestions on how the authors might address this issue or improve their approach. It lacks depth and does not guide the authors on how to mitigate this concern or improve their draft. As a result, the comment is barely helpful, as it points out a potential problem but does not offer any constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with Table 2, noting that the use of pre-trained DGCNN for semantic segmentation in each completion method for comparison is not meaningful. The reviewer suggests that the comparison of the segmentation metric is not useful, as it only indicates that the segmentation of those methods plus DGCNN is worse than the proposed method. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the comparison methodology. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison of semantic segmentation metrics using pre-trained DGCNN for each completion method. The comment provides a clear rationale for why the comparison is not meaningful and suggests that it only indicates that the segmentation of those methods plus DGCNN is worse than the proposed method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison of semantic segmentation metrics in Table 2 is not meaningful because it only indicates that the segmentation of methods with pre-trained DGCNN is worse than the proposed method. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some basis but requires further elaboration to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison of semantic segmentation metrics in Table 2, noting that the use of pre-trained DGCNN for each completion method is not meaningful. It points out that the comparison only indicates that the segmentation of those methods plus DGCNN is worse than the proposed method, without providing additional context or insights into why this is the case. While the comment highlights a potential weakness in the paper\\'s methodology, it lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve the comparison. As a result, the comment is somewhat helpful, as it provides some direction but could be more actionable with additional details. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the difficulty in obtaining rules in real-world applications and suggests that statistical rules learned from data may be feasible. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of obtaining rules or how to improve the feasibility of statistical rules learned from data. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the difficulty in obtaining rules in real-world applications and suggests that statistical rules learned from data may be feasible. However, it does not specify which part of the paper this observation pertains to, nor does it provide any guidance on how to address the issue. Without explicit references to sections or specific aspects of the paper, the authors cannot confidently determine which parts need revision. The comment is not grounded and lacks specificity, making it difficult for the authors to understand and act upon the feedback. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges the difficulty in obtaining rules in real-world applications and suggests that statistical rules learned from data may be feasible. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges the difficulty in obtaining rules in real-world applications and suggests that statistical rules learned from data may be feasible. However, it lacks specificity and actionable guidance for the authors to address this issue or improve their draft. Without detailed feedback or suggestions on how to incorporate this insight into their work, the comment provides limited value to the authors. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a comparison with dynamic sparse training-based and other sparsity-based methods is missing. While it implies that this comparison should be included, it does not explicitly instruct the authors to add it. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a comparison with dynamic sparse training-based and other sparsity-based methods is missing. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting what is missing, but without explicit references to sections or details, the authors may struggle to identify the exact areas that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison with dynamic sparse training-based and other sparsity-based methods is missing. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is important or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by suggesting that a comparison with dynamic sparse training-based and other sparsity-based methods is missing. This feedback is somewhat helpful as it points out an area where the paper could be expanded to provide a more comprehensive analysis. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, making it somewhat helpful. The authors are given a direction for improvement but are not provided with detailed instructions or examples to fully address the issue. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the reasoning behind the claim that the intractability of $p_\\\\theta(y|x)$ in a latent variable model is due to the intractability of $p_\\\\theta(z|x)$, suggesting that this may not be the only reason. It points out that both the posterior and the likelihood can be tractable, while $p_\\\\theta(y|x)$ may still be intractable. The comment implies that the authors should reconsider their reasoning or provide additional evidence to support their claim. However, it does not explicitly instruct the authors on how to address this issue or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their reasoning or provide additional evidence. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sentence \"The intractability of $p_\\\\theta(y|x)$ in a latent variable model is due to the intractability of $p_\\\\theta(z|x)$, since $p_\\\\theta(y|x, z)$ is tractable.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it challenges the authors\\' reasoning by questioning the causal relationship between the intractability of $p_\\\\theta(z|x)$ and $p_\\\\theta(y|x)$. It suggests that the posterior and likelihood can be tractable while $p_\\\\theta(y|x)$ remains intractable, providing a counterexample with a Bernoulli likelihood and a Gaussian posterior. This level of detail helps the authors understand the issue and address it effectively. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that the intractability of $p_\\\\theta(y|x)$ in a latent variable model is due to the intractability of $p_\\\\theta(z|x)$, suggesting that this may not be the only reason. The reviewer provides a logical reasoning by pointing out that both the posterior and the likelihood can be tractable while $p_\\\\theta(y|x)$ remains intractable, as demonstrated by a Bernoulli likelihood with a Gaussian posterior. This provides a clear and logical explanation for why the claim might be flawed, making the comment mostly verifiable. However, it could be strengthened by providing specific examples or references to similar cases where this reasoning has been applied. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a constructive critique of the authors\\' reasoning regarding the intractability of $p_\\\\theta(y|x)$ in a latent variable model. It challenges the assumption that the intractability is solely due to the intractability of $p_\\\\theta(z|x)$, suggesting that the posterior and likelihood can still be tractable while $p_\\\\theta(y|x)$ remains intractable. This feedback is valuable as it prompts the authors to reconsider their reasoning and potentially revise their argument to provide a more robust basis for their claims. However, the comment could be more helpful if it offered specific suggestions on how the authors might address this issue or what alternative explanations might be considered. Overall, the comment is mostly helpful as it encourages the authors to reevaluate their reasoning and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper\\'s datasets are inaccessible, making it difficult for others to reproduce the work. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the datasets more accessible or how to improve reproducibility. Without actionable steps, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper\\'s datasets being inaccessible, making it difficult for others to reproduce the work. However, it does not specify which part of the paper discusses the datasets or where the issue is located. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed regarding the datasets or how they could be made more accessible. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is irreproducible due to inaccessible datasets. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the reproducibility of the paper due to the inaccessibility of the datasets. This is a critical observation that could impact the credibility and impact of the work. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue, such as suggesting ways to make the datasets more accessible or how to improve reproducibility. Without actionable feedback, the authors are left without a clear path forward, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether there is a missing equation before \"where p is the firing rate\" in section 3.4.1. While it identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment lacks actionable details, such as recommending specific changes or providing context for what might be missing. As a result, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"sec 3.4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether there is a missing equation before \"where p is the firing rate,\" providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking whether there is a missing equation before \"where p is the firing rate\" in section 3.4.1. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about a missing equation in section 3.4.1, which could be a potential issue in the paper\\'s presentation. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve the clarity of the section. Without actionable feedback or context, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it is rated as barely helpful, as it identifies a potential problem but lacks depth and specificity in its feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the evaluation of sentiment word detection and correction is lacking, and it suggests conducting experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This provides clear and concrete actions for the authors to take, such as conducting experiments or including additional analyses to address this gap in their work. The comment is specific and provides detailed guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"detection of sentiment word errors\" and \"SWRM,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be evaluated, namely the effects of the sentiment word position detection module and the predicted sentiment word candidates. This provides clear guidance on what aspects of the paper need attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation of sentiment word detection and correction is lacking, specifically mentioning that the key ideas of SWRM are the detection and correction of possible sentiment word errors. The comment suggests conducting experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This claim is somewhat verifiable as it provides a logical reasoning for why the evaluation is necessary, but it lacks specific examples or references to support the claim fully. The authors would need to conduct their own experiments to validate the claim, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the evaluation of sentiment word detection and correction, which is a crucial aspect of the SWRM system. It suggests conducting experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft. By addressing this gap, the authors can enhance the rigor and comprehensiveness of their evaluation, which is valuable for strengthening the paper. However, the comment could be more helpful if it included suggestions on how to conduct these experiments or what specific metrics to use. Overall, the comment is mostly helpful as it effectively guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to report the results of KMLM-XLM-R_{large} (ours) in all the result tables, noting that the authors have not reported all the performance of KMLM-large without logical reasoning. This feedback is clear and provides a specific action for the authors to take, ensuring that they include the missing results in their tables. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"all the result tables,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the results of KMLM-XLM-R_{large} (ours) and the lack of reporting all the performance of KMLM-large without logical reasoning. This provides clear guidance on what needs to be included in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the absence of results for KMLM-XLM-R_{large} (ours) in the result tables and notes that the authors have not reported all the performance of KMLM-large without logical reasoning. This claim is somewhat verifiable as it highlights a potential gap in the paper\\'s reporting, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the missing information themselves, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting the absence of results for KMLM-XLM-R_{large} (ours) in the result tables. It also points out that the authors have not reported all the performance of KMLM-large without logical reasoning. This feedback is clear and actionable, as it directs the authors to include the missing results and provide a logical explanation for their absence. By addressing this issue, the authors can improve the clarity and completeness of their results section. However, the comment could be more helpful if it provided suggestions on how to present the missing results or what additional context might be needed. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the results, specifically that many in-context learning baselines, such as static few-shot and chain-of-thought, underperform the backbone in many items. It suggests that this may be due to large variance or uncareful design of the baselines. The comment implies that additional explanations are needed to support the reliability of the claims. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this concern, such as suggesting specific explanations or methods to improve the baselines. The action is implicit and somewhat vague, leaving the authors to infer the necessary steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"many in-context learning baselines, such as static few-shot and chain-of-thought,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, suggesting that the baselines may be due to large variance or uncareful design, and that additional explanations are needed to support the reliability of the claims. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that many in-context learning baselines, such as static few-shot and chain-of-thought, underperform the backbone in many items. The reviewer suggests that this may be due to large variance or uncareful design of the baselines. However, the comment lacks specific examples or detailed reasoning to support the claim that the baselines are unreliable. Without additional evidence or detailed explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks the necessary evidence or detailed reasoning to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the results, noting that many in-context learning baselines, such as static few-shot and chain-of-thought, underperform the backbone in many items. It suggests that this may be due to large variance or uncareful design of the baselines. The comment highlights the need for additional explanations to support the reliability of the claims. While it points out a critical area for improvement, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the reliability of their results. This limits the comment\\'s usefulness, as it offers insight but lacks actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify the key innovation driving the improvements in the GFNSeqEditor method. It provides a clear and specific action for the authors to take, which is to better articulate the novel techniques or insights that lead to the claimed improvements. This feedback is concrete and provides a direct path for the authors to enhance the clarity and understanding of their method. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Key Innovation\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the key innovation driving the improvements in the GFNSeqEditor method. The comment provides a clear direction for the authors to enhance the clarity and understanding of their method, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks clarity regarding the key innovation driving the improvements in the GFNSeqEditor method. It suggests that the authors should better articulate the novel techniques or insights that lead to these improvements, thereby enhancing the reader\\'s understanding of the method\\'s unique value. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of supporting evidence or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of ambiguity in the paper, namely the lack of clarity regarding the key innovation driving the improvements in the GFNSeqEditor method. It suggests that the authors should better articulate the novel techniques or insights that lead to these improvements, thereby enhancing the reader\\'s understanding of the method\\'s unique value. This feedback is clear and actionable, providing the authors with a direct and specific way to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered examples or suggestions on how to articulate these innovations. Overall, the comment is mostly helpful as it effectively guides the authors in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors need to demonstrate the faithfulness of their proposed approach by conducting at least a simple experiment. This feedback is explicit, as it clearly instructs the authors to provide experimental evidence to support their claim. However, it does not specify which experiment or how to conduct it, leaving some room for interpretation. The action is concrete, as it identifies a specific requirement for the authors to address, but it lacks detailed guidance on how to implement it. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the faithfulness of the proposed approach, specifically mentioning the authors\\' response about their method being less susceptible to biases than others. However, it does not specify which part of the paper this discussion is located in, making it weakly grounded. The comment is specific in its request for an experiment to demonstrate the faithfulness, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors need to demonstrate the faithfulness of their proposed approach by conducting at least a simple experiment. However, the comment does not provide any specific reasoning or evidence to support why this claim is necessary or how it would address the issue of bias susceptibility. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors demonstrate the faithfulness of their proposed approach by conducting at least a simple experiment. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to address the claim about bias susceptibility. However, the comment could be more helpful if it offered guidance on which experiment or metrics to use for demonstrating faithfulness. Despite this, the feedback is mostly helpful as it directs the authors to a critical aspect of their work that needs further exploration. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is limited to operating with discrete state-action spaces, which is not ideal for real-world applications that are continuous in nature. It suggests that the sentence about motivation is not the best choice, but it does not provide explicit guidance on how to improve the motivation or suggest alternative phrasing. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the motivation section, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sentence about motivation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is problematic about the motivation section, namely that the proposed method is limited to operating with discrete state-action spaces, which is not ideal for real-world applications that are continuous in nature. This provides clear guidance on what needs to be addressed in the motivation section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is limited to operating with discrete state-action spaces, which is not ideal for real-world applications that are continuous in nature. The reviewer supports this claim by referencing the nature of most real-world applications, which are continuous. However, the comment lacks specific examples or references to support the claim that discrete state-action spaces are not ideal for continuous applications. This makes the claim somewhat verifiable, as it provides a logical reasoning but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the proposed method, noting that it is limited to operating with discrete state-action spaces, which is not ideal for real-world applications that are continuous in nature. This feedback is valuable as it highlights a potential weakness in the manuscript\\'s motivation and suggests that the authors should reconsider their choice of motivation. However, the comment could be more helpful if it provided specific suggestions on how to address this limitation or how to better motivate the proposed method. Despite this, the feedback is mostly helpful as it directs the authors\\' attention to a critical area that needs improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete suggestions for improvement. It suggests moving the baseline to the ablation study and only showing the proposed method, which is a clear and actionable step for the authors to take. Additionally, it points out that the experiment results are not competitive with SOTA methods and mostly show minor improvements, indicating that the authors need to address this issue. The comment also mentions that the presentation of the main result table is unclear, which provides a specific area for improvement. Overall, the comment is highly actionable as it provides clear guidance on how to improve the paper.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"experiment results\" and \"main result Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved: moving the baseline to the ablation study and only showing the proposed method. The comment also specifies that the experiment results are not competitive with SOTA methods and mostly show minor improvements. This level of detail provides the authors with clear direction on how to enhance their work. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiment results are not competitive with SOTA methods and mostly show minor improvements. It also suggests that the presentation of the main result Table 1 is unclear due to different backbones compared to prior methods. The comment provides some reasoning by mentioning that the baseline should be moved to the ablation study, but it lacks specific examples or detailed evidence to fully substantiate the claim. While the suggestion to move the baseline is somewhat supported, the lack of detailed justification or comparisons makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improvement, which are clear and specific. It points out that the experiment results are not competitive with SOTA methods and mostly show minor improvements, indicating that the paper may need to reconsider its claims or approach. Additionally, it suggests moving the baseline to the ablation study and only showing the proposed method, which could help clarify the contribution of the proposed method. The comment also notes that the presentation of the main result Table 1 is unclear, with different backbones compared to prior methods. This feedback is valuable as it directs the authors to enhance the clarity and competitiveness of their results. Overall, the comment is highly helpful as it offers detailed and actionable guidance for improving the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the manuscript would benefit from a clearer delineation of the copyright scenario, specifically by specifying whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. While the comment implies that the authors should clarify this distinction, it does not provide explicit instructions or concrete steps on how to achieve this clarification. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the copyright scenario, but it lacks detailed guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the manuscript would benefit from a clearer delineation of the copyright scenario, specifically by specifying whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. However, it does not specify which part of the paper this delineation should be included in, making it weakly grounded. The comment is specific in its suggestion to clarify the copyright scenario, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically by specifying whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this clarification is necessary or how it would improve the manuscript. Without additional context or examples, the claim remains vague and lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the manuscript, suggesting that the copyright scenario should be clarified to specify whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the clarity and comprehensibility of their manuscript. However, the comment could be more helpful if it offered additional guidance on how to achieve this clarification or provided examples of how other studies have addressed similar issues. Overall, the comment is mostly helpful as it directs the authors toward a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the behavior of the low-rank and high-rank adapters, specifically regarding the acquisition of domain-agnostic and domain-specific knowledge. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific changes they should make to improve the explanation or justification. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the behavior of the low-rank and high-rank adapters, particularly regarding the acquisition of domain-agnostic and domain-specific knowledge. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the discrepancy between the two adapters and the need for theoretical justification or an intuitive explanation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the theoretical justification or intuitive explanation for the behavior of the low-rank and high-rank adapters in acquiring domain-agnostic and domain-specific knowledge. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the behavior of the low-rank and high-rank adapters, specifically regarding the acquisition of domain-agnostic and domain-specific knowledge. It points out that the theoretical justification or intuitive explanation for this behavior is lacking, which is a critical observation that could impact the validity and generalizability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what kind of theoretical justification would be appropriate. While it highlights an important area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the statement in line 154 regarding local explanations, specifically questioning why the data point x needs to be in the vicinity of a decision boundary for local models to be nontrivial. The reviewer asks why differences in probabilities, such as \"if feature 1 were higher, the model would be less confident in class y,\" cannot be measured. While the comment identifies a potential issue with the reasoning, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors can infer that they need to provide a more detailed explanation or justification for the statement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 154,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reasoning behind the statement regarding local models and probabilities, asking for clarification on why differences in probabilities cannot be measured. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the statement in line 154 regarding local explanations, specifically questioning why the data point x needs to be in the vicinity of a decision boundary for local models to be nontrivial. The reviewer seeks clarification on why differences in probabilities, such as \"if feature 1 were higher, the model would be less confident in class y,\" cannot be measured. This comment is a request for clarification and does not contain subjective opinions or claims that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the statement in line 154 regarding local explanations, specifically questioning the reasoning behind the assertion that local models will only be nontrivial if the data point x is in the vicinity of a decision boundary. The reviewer asks why differences in probabilities, such as \"if feature 1 were higher, the model would be less confident in class y,\" cannot be measured. This feedback is somewhat helpful as it prompts the authors to clarify their reasoning and potentially expand their explanation of local models. However, it lacks specific suggestions or guidance on how to address the issue, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments only report results on ImageNet and do not include results on classic datasets like CIFAR-10 and CIFAR-100. This implies that the authors should include results on these additional datasets to provide a more comprehensive evaluation. However, the comment does not explicitly instruct the authors to include these results or specify how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include results on additional datasets. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the experiments only report results on ImageNet and do not include results on classic datasets like CIFAR-10 and CIFAR-100. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments only report results on ImageNet and do not include results on classic datasets like CIFAR-10 and CIFAR-100. This is a factual observation that does not require justification or evidence. It is a statement of fact, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the experimental setup by pointing out that the experiments only report results on ImageNet and do not include results on classic datasets like CIFAR-10 and CIFAR-100. This feedback highlights a potential gap in the evaluation of the model, as these datasets are commonly used for benchmarking. By suggesting that the authors include results on these additional datasets, the comment provides a clear and actionable suggestion for improving the comprehensiveness and robustness of the evaluation. However, the comment could be more helpful if it offered specific guidance on how to incorporate these datasets or why they are important for the evaluation. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a confusion regarding the DinoSR part in Figure 1, specifically mentioning that the softmax layer is not clearly shown in the figure. It also notes that the encoder, according to the text description, does not include this layer. The reviewer suggests that the figure should be clearer and more consistent with the original DinoSR paper. While the comment identifies a specific issue, it does not provide explicit guidance on how to address it, such as suggesting a particular way to improve the figure or clarify the text description. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the DinoSR part in Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that the softmax layer is not clearly shown and that the figure is confusing due to this inconsistency. The comment provides a clear direction for improvement by suggesting that the figure should be clearer and more consistent with the original DinoSR paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the DinoSR part in Figure 1 is confusing because the softmax layer is not clearly shown, despite the text description indicating that the encoder does not include this layer. The reviewer compares the figure in the original DinoSR paper, which is described as clear, to the current figure. This claim is somewhat verifiable as it provides a specific comparison between the figure in the current paper and the original DinoSR paper, which could help the authors understand the issue. However, the comment lacks detailed reasoning or references to support the claim that the current figure is confusing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the DinoSR part in Figure 1, noting that the softmax layer is not clearly shown in the figure despite being mentioned in the text description. It also compares the figure to the original DinoSR paper, which is described as clear, highlighting the need for improvement. This feedback is clear and actionable, as it directs the authors to address the confusion by making the figure more consistent with the text description and the original work. However, the comment could be more helpful if it provided suggestions on how to improve the figure or clarified the text description. Overall, the comment is mostly helpful as it effectively points out a specific area for improvement and offers a clear direction for the authors to enhance the clarity of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should review related work on causal inference, specifically mentioning three references ([1], [2], and [3]). While the comment implies that the authors should include this information in their paper, it does not provide explicit instructions on how to integrate these references or what specific aspects of the work should be discussed. The action is clear but somewhat vague, as the authors need to infer the exact details of how to incorporate these references. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that related work on causal inference needs to be reviewed, specifically mentioning three references ([1], [2], and [3]). However, it does not specify which part of the paper this related work should be discussed in, nor does it provide detailed guidance on how to integrate these references or what aspects of the work should be covered. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that related work on causal inference needs to be reviewed, specifically mentioning three references ([1], [2], and [3]). However, the comment does not provide any reasoning, explanation, or justification for why these references are relevant or how they relate to the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of these references and how they should be integrated into the paper. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should review related work on causal inference, specifically mentioning three references ([1], [2], and [3]). While this feedback identifies a potential gap in the literature review, it lacks depth and does not provide specific guidance on how to integrate these references or what aspects of the work should be discussed. The comment highlights an area for improvement but does not offer actionable steps or detailed suggestions, making it somewhat helpful. The authors are given a direction but not enough detail to fully address the issue, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should use the LLM2Vec encoder, which is already cited in the paper, instead of sections 3.1 and 3.2. It also points out that the reasoning for not adopting this approach remains unclear and recommends conducting ablation studies to validate the decision. This feedback provides clear and concrete actions for the authors to take, specifying exactly what needs to be done and why. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"sections 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of the LLM2Vec encoder and the reasoning for not adopting it, along with the recommendation for ablation studies. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that sections 3.1 and 3.2 could be avoided if the authors used the LLM2Vec encoder, which is already cited in the paper. The reviewer suggests that the reasoning for not adopting this approach remains unclear and recommends conducting ablation studies to validate the decision. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion but lacks specific examples or references to support the claim. The authors would need to conduct ablation studies to understand the impact of using the LLM2Vec encoder, which is not explicitly stated in the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improvement. It points out that sections 3.1 and 3.2 could be avoided if the authors used the LLM2Vec encoder, which is already cited in the paper. The reviewer highlights the lack of clarity regarding the reasoning for not adopting this approach and recommends conducting ablation studies to validate the decision. This feedback is clear and constructive, offering a concrete step for the authors to improve their draft by considering the use of the LLM2Vec encoder. However, the comment could be more helpful if it provided additional guidance on how to conduct the ablation studies or explained why this approach might be beneficial. Overall, the comment is mostly helpful, as it directs the authors toward a specific improvement that could enhance the clarity and rigor of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and do not include real-world problems. This implies that the authors should consider incorporating real-world scenarios to test the method. However, the comment does not explicitly instruct the authors to include real-world problems or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include real-world scenarios. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments comparing the proposed Batch BORE method with existing baselines, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that only synthetic objective functions are used and suggests that real-world problems should be included. This provides clear guidance on what needs to be addressed in the experiments section. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and do not include real-world problems. This claim is somewhat verifiable as it highlights a potential limitation in the experimental setup, but it lacks specific examples or references to real-world scenarios that could be used. The comment could be strengthened by providing more detailed reasoning or examples of how real-world problems could be incorporated, which would make the claim more robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the experiments section, noting that only synthetic objective functions are used and no real-world problems are included. This feedback highlights a potential weakness in the experimental setup, suggesting that the proposed method may not be fully evaluated in real-world scenarios. However, the comment does not provide actionable guidance or suggestions on how to address this issue, such as recommending specific real-world problems to include or suggesting ways to incorporate them. While it points out a relevant area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a detailed analysis of benchmark sentence differences between explanation- and listener-focused parts could clarify the findings regarding the challenges of distinguishing roles using explanation-focused cues. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this analysis to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting a detailed analysis of benchmark sentence differences between explanation- and listener-focused parts to clarify the findings regarding the challenges of distinguishing roles using explanation-focused cues. However, it does not specify which part of the paper this analysis should be conducted in, making it weakly grounded. The comment is specific in suggesting a detailed analysis of benchmark sentence differences, but without explicit references to specific sections, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that distinguishing roles using explanation-focused cues is challenging, potentially due to LLMs relying more on language style than informational depth. The comment provides a logical reasoning by proposing a detailed analysis of benchmark sentence differences between explanation and listener-focused parts to clarify these findings. However, it lacks specific examples or references to support the claim that LLMs rely more on language style than informational depth. This makes the claim somewhat verifiable, as it provides a plausible explanation but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential challenge in distinguishing roles using explanation-focused cues and suggests a detailed analysis of benchmark sentence differences between explanation and listener-focused parts to clarify these findings. This feedback is somewhat helpful as it provides a specific direction for the authors to explore and potentially improve their work. However, it lacks detailed guidance or examples on how to conduct this analysis or what specific aspects to focus on. While it offers a clear suggestion, it could be more actionable with additional details. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with the paper: the heavy use of acronyms, particularly the acronym \"DU,\" which is mentioned without a clear definition. This provides a clear and direct action for the authors to take, which is to clarify the definition of the acronym \"DU\" or provide a definition in the paper. The comment is explicit and concrete, giving the authors a clear idea of what needs to be done to improve the readability of their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the acronym \"DU,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a clear definition for the acronym \"DU.\" This provides clear guidance on what the authors need to do to improve the readability of their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s use of acronyms affects readability, specifically mentioning the acronym \"DU\" without a clear definition. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the heavy use of acronyms, which affects readability. It highlights the lack of a clear definition for the acronym \"DU,\" which is a critical point that the authors should address to improve the clarity of their work. While the comment provides a clear and actionable suggestion, it could be more helpful if it offered additional guidance on how to improve the readability of the paper or suggested ways to introduce acronyms more effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the estimation of variance in the distribution p(q|s) and the determination of the complete covariance matrix. It suggests that the authors should clarify how they estimate the variance and whether they use a diagonal or complete covariance matrix. While the comment implies that the authors should provide more information or clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they need to address these questions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the estimation of variance in the distribution p(q|s) and the determination of the complete covariance matrix. The comment is specific because it asks for clarification on how the variance is estimated and whether a diagonal or complete covariance matrix is used. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification regarding the estimation of variance and the determination of the covariance matrix in the distribution p(q|s). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the estimation of variance and the determination of the covariance matrix in the distribution p(q|s) in section 2.3. It prompts the authors to clarify how they estimate the variance and whether they use a diagonal or complete covariance matrix. This feedback is clear and actionable, as it guides the authors to provide more detailed explanations or clarifications in their draft. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided additional context for the authors to consider. Overall, the comment is mostly helpful, as it directs the authors to improve the clarity and completeness of their explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the initial accuracy of the MIL-based baseline model being higher than the converged models, particularly for the NSCLC dataset. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific steps they should consider to improve their analysis. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the initial accuracy of the MIL-based baseline model compared to the converged models, particularly for the NSCLC dataset. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the initial accuracy of the MIL-based baseline model being higher than the converged models, particularly for the NSCLC dataset. However, it does not provide any supporting evidence, reasoning, or references to justify why this observation is significant or problematic. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in understanding or addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the initial accuracy of the MIL-based baseline model being higher than the converged models, particularly for the NSCLC dataset. This observation prompts the authors to consider the reasons behind this discrepancy, which could be a significant finding or a source of concern. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or what potential explanations might be. While it points out an area for further exploration, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it identifies a potential area for investigation but does not offer detailed guidance or suggestions for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should consider other datasets to explore the generalization of the proposed method across diverse data sources. While it implies that the authors should expand their analysis to include additional datasets, it does not provide specific guidance on which datasets to use or how to conduct the analysis. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their dataset exploration. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper primarily focuses on the MuAViC dataset and recommends considering other datasets to explore the generalization of the proposed method across diverse data sources. However, it does not specify which part of the paper discusses the MuAViC dataset or where the recommendation to consider other datasets should be integrated. This makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its suggestion to consider other datasets, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper primarily focuses on the MuAViC dataset and recommends considering other datasets to explore the generalization of the proposed method across diverse data sources. However, the comment does not provide specific reasoning or examples to support why this is necessary or how it would enhance the paper\\'s contribution. Without detailed justification or references, the claim remains vague and lacks verifiability. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s focus on the MuAViC dataset and recommends considering other datasets to explore the generalization of the proposed method across diverse data sources. This feedback is valuable as it encourages the authors to broaden their analysis and consider the applicability of their method in different contexts. However, the comment could be more helpful if it provided specific suggestions on which datasets to consider or how to assess the generalization of the method. Despite this, the feedback is clear and actionable, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the expectation of systems not being Bayes-optimal on the problems investigated in the paper. It suggests that more work is needed to establish alternative hypotheses and gear the analyses and results towards ruling them out. The reviewer implies that the current analysis is mostly confirmatory and lacks exploration of alternative hypotheses. However, the comment does not provide explicit guidance on how to address these concerns or what specific experiments should be conducted. The action is implicit and somewhat vague, as the authors can infer that they need to expand their analyses and experiments to test alternative hypotheses, but the comment does not offer detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the expectation of systems not being Bayes-optimal on the relatively straightforward problems investigated in the paper. It suggests that more work is needed to establish alternative hypotheses and gear the analyses and results towards ruling those out. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment. The authors can infer that it relates to the analyses and results sections, but this inference is not as direct as it could be. The comment is specific in its suggestion for alternative hypotheses and experiments, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the expectation of systems not being Bayes-optimal on the relatively straightforward problems investigated in the paper. It suggests that more work is needed to establish alternative hypotheses and gear the analyses and results towards ruling them out. The reviewer implies that the current analysis is mostly confirmatory and lacks exploration of alternative hypotheses. However, the comment does not provide specific examples or references to support the claim that the systems are not Bayes-optimal or that the analyses are confirmatory. The lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to infer the need for additional work based on the comment alone. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the expectation of systems not being Bayes-optimal on the relatively straightforward problems investigated. It suggests that more work is needed to establish alternative hypotheses and gear the analyses and results towards ruling them out. The reviewer implies that the current analysis is mostly confirmatory and lacks exploration of alternative hypotheses. This feedback is somewhat helpful as it points out a potential area for improvement in the paper, but it could be more beneficial if it provided specific suggestions on how to address this issue or what alternative hypotheses should be considered. Overall, the comment offers some guidance but lacks depth and actionable steps, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should add confidence intervals to their results in Table 1, which provides performance data for different fairness improvement techniques. This feedback is clear and provides a specific action for the authors to take, ensuring that the results are more informative and conclusive. The suggestion is concrete, as it specifies exactly what needs to be added to the table, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the addition of confidence intervals to the reported values in Table 1. This provides clear guidance on how to improve the paper\\'s presentation of results. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the reported values in Table 1 are very close, making it difficult to draw conclusions. The comment requests the addition of confidence intervals to provide more insight into the results. While the comment highlights a potential issue with the data presentation, it does not provide specific examples or references to support the claim that the values are too close or why confidence intervals are necessary. This makes the claim somewhat verifiable, as it provides a logical reasoning but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Table 1, noting that the reported values are very close, making it challenging to draw conclusions. The comment suggests a solution by requesting the addition of confidence intervals, which would provide more insight into the results\\' variability. This feedback is clear and actionable, as it directs the authors to a specific area for improvement and offers a concrete way to enhance the clarity and usefulness of their results. However, the comment could be more helpful if it provided additional guidance on how to interpret or analyze the confidence intervals. Overall, the comment is mostly helpful as it effectively guides the authors on how to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that certain choices are not justified or clear, but it does not specify which choices are in question. The reviewer provides a reference to \"questions for the authors,\" which implies that the authors should address these questions to clarify the issue. However, without explicit guidance on which choices need clarification or justification, the authors are left with a vague task that lacks concrete steps for improvement. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that certain choices are not justified or clear, but it does not specify which choices are being referred to. The mention of \"questions for the authors\" implies that the authors should address specific questions related to these choices, but without explicit references to specific sections or choices, the authors cannot confidently determine which parts of the paper need attention. The comment is not grounded as it does not specify which choices are being questioned, making it difficult for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and not specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that certain choices are not justified or clear, but it does not provide specific examples or reasoning to support this claim. The mention of \"questions for the authors\" implies that the reviewer expects the authors to clarify these issues, but without further elaboration, the claim remains vague and lacks verification. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that certain choices are not justified or clear, but it does not provide specific examples or detailed feedback on what aspects of the paper are unclear or in need of justification. The mention of \"questions for the authors\" implies that the authors should address these issues, but without further guidance or context, the comment lacks actionable advice. The feedback is vague and does not offer constructive suggestions for improvement, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a concern regarding hyperparameter tuning, specifically the difficulty in navigating multiple solutions that hit the same FLOPs. It suggests that the paper should provide more detailed discussions regarding the grid search process for reproducibility. While the comment implies that the authors should clarify the grid search method, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the grid search process. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a concern regarding hyperparameter tuning, specifically the difficulty in navigating multiple solutions that hit the same FLOPs. It suggests that the paper should provide more detailed discussions regarding the grid search process for reproducibility. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with hyperparameter tuning and the need for more discussion on grid search, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the difficulty in hyperparameter tuning due to multiple solutions that hit the same FLOPs. It suggests that the paper should provide more detailed discussions regarding the grid search process for reproducibility. The comment is somewhat verifiable as it logically presents a concern about the tuning process and its impact on reproducibility. However, it lacks specific examples or references to support the claim about the impact on FLOPs and accuracy. Additionally, the suggestion for detailed discussions is not fully developed, leaving the authors with a general idea of what needs to be addressed. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a concern regarding hyperparameter tuning, specifically the difficulty in navigating multiple solutions that hit the same FLOPs. It suggests that the paper should provide more detailed discussions regarding the grid search process for reproducibility. While the comment highlights an important area for improvement, it lacks specific guidance on how to address this issue or what aspects of the grid search process should be discussed. The feedback is somewhat helpful as it points out a potential weakness but does not offer actionable steps for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1, which makes it unclear about the difference between known and unknown attacks. This feedback provides a clear and direct action for the authors to take, which is to include the accuracies in Figure 1. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the accuracies of the target model using different defenses against the FGSM attack, and how this affects the clarity of the differences between known and unknown attacks. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1, which makes it unclear about the difference between known and unknown attacks. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the lack of accuracies for the target model using different defenses against the FGSM attack in Figure 1. This feedback is clear and actionable, as it directs the authors to include this information to enhance the clarity and comprehensiveness of their results. By addressing this point, the authors can provide more detailed information about the effectiveness of their model under various attacks, which is crucial for understanding and interpreting the results. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific defenses should be included. Overall, the comment is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors consider using a log-scale for the y-axis in some figures to improve readability. This feedback is clear and provides a direct action for the authors to take, ensuring that they know exactly what needs to be done to enhance the clarity of their figures. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to consider using a log-scale for the y-axis in certain figures to improve readability. This feedback is detailed and actionable, providing the authors with a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that some figures are hard to read and recommends using a log-scale for the y-axis. However, the comment does not provide any specific examples or reasoning to support why the current figures are difficult to read or how a log-scale would improve readability. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the readability of some figures, suggesting that the authors consider using a log-scale for the y-axis. This feedback is clear and actionable, providing the authors with a concrete suggestion to improve the clarity of their figures. By addressing this issue, the authors can enhance the accessibility and understanding of their results. However, the comment could be more helpful if it included additional context or examples of where the log-scale would be beneficial. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a gap in the validation of the proposed method, specifically the lack of validation using fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset. It explicitly states that the authors should have used these datasets to validate their claims about the usefulness of augmentation information. The comment provides a clear and concrete action for the authors to take, ensuring that they know exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"Introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the validation of the method using fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset. This provides clear guidance on what the authors need to do to improve their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not validated by experiments, specifically mentioning the lack of validation using fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset. This claim is somewhat verifiable as it provides a specific example of the datasets that could be used for validation, which is a logical suggestion. However, the comment lacks detailed reasoning or references to support why these datasets are particularly relevant or how they would validate the method. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires further elaboration.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the validation of the proposed method, noting that the case where \"augmentation information is useful\" is not validated by experiments. It highlights the lack of validation using fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset, which are relevant to the category of augmentation information. This feedback is clear and actionable, as it provides the authors with a concrete suggestion for improving the validation of their method. By addressing this issue, the authors can enhance the credibility and robustness of their work. However, the comment could be more helpful if it included examples of how these datasets could be used to validate the method or why they are particularly relevant. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of theoretical analysis and empirical evidence to support the claim that GEMS converges to the Nash equilibrium. While it identifies a potential gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include theoretical analyses or empirical evidence to substantiate their claim, but it lacks concrete steps or suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific claim made in the paper, which is the statement that \"Over time, those opponents will evolve toward the Nash equilibrium.\" This allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity because it does not detail what is missing or inaccurate about the theoretical or empirical analyses related to GEMS converging to the Nash equilibrium. The authors are left without clear guidance on how to address the issue. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the paper lacks theoretical analyses and empirical evidence to support the claim that GEMS converges to the Nash equilibrium. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the lack of theoretical analysis and empirical evidence to support the claim that GEMS converges to the Nash equilibrium. It points out a potential weakness in the paper\\'s argumentation, which could be a significant concern for readers. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional analyses or evidence might be needed. While it highlights an area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out several issues with Equation (1), including the purpose of defining a loss function or the optimization problem, the definition of the optimization variable, and the unusual constraints notation. While the comment identifies specific areas that need clarification or correction, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they need to clarify the purpose and definition of the optimization variable and constraints notation, but the comment lacks detailed guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer concrete steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (1),\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific feedback by pointing out the confusion regarding the purpose of defining a loss function or the optimization problem, the definition of the optimization variable, and the unusual constraints notation. This level of detail provides clear guidance on what needs to be clarified or corrected, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several issues with Equation (1), questioning the purpose of defining a loss function or the optimization problem, the definition of the optimization variable, and the unusual constraints notation. While the comment identifies specific areas of confusion, it lacks detailed reasoning or examples to fully substantiate the claims. The authors would need to infer the need for clarification and address the issues themselves. Therefore, the comment is somewhat verifiable, as it provides some basis for the claims but requires further elaboration to be fully justified.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with Equation (1), including the purpose of defining a loss function or the optimization problem, the definition of the optimization variable, and the unusual constraints notation. These points are specific and provide clear guidance on areas that need clarification or correction. The comment highlights the confusion in the presentation of the material, which is crucial for the authors to address to improve the clarity of their work. However, the comment could be more helpful if it offered suggestions on how to clarify these points or provided examples of how similar issues have been addressed in similar contexts. Overall, the comment is mostly helpful as it directs the authors to specific areas needing attention, but it lacks detailed guidance on how to improve them.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to provide more discussions or explanations regarding the unexpected performance degradation when using the collected LIV-EN parallel data for finetuning. This is a clear and direct request, giving the authors a specific action to take. The comment is concrete, as it specifies the exact line (line 257) and the need for additional discussion or explanation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 257,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for more discussions or explanations regarding the unexpected performance degradation when using the collected LIV-EN parallel data for finetuning. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the unexpected performance degradation when using the collected LIV-EN parallel data for finetuning. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance degradation when using the collected LIV-EN parallel data for finetuning. It explicitly asks for more discussions or explanations regarding this unexpected result, which is a clear and actionable request. This feedback provides the authors with a specific area to focus on and potentially improve their draft. However, the comment could be more helpful if it offered suggestions on how to address this issue or what aspects of the finetuning process might be causing the performance degradation. Overall, the comment is mostly helpful as it directs the authors to a critical area needing further exploration and explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs,\" but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might substantiate these claims or what specific references or reasoning would be helpful. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of substantiation for the conjecture about \"fine-tuning as exposure of existing capabilities in LMs.\" However, it does not specify which part of the paper this conjecture is presented in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue with the conjecture but lacks grounding, as it does not specify where in the paper this issue is discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs.\" However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of substantiation or reasoning for the conjecture about \"fine-tuning as exposure of existing capabilities in LMs.\" It points out that without adequate explanation or references, it is challenging for the reader to understand the authors\\' claims. This feedback is clear and actionable, as it highlights a critical area where the paper could be improved by providing more detailed reasoning or evidence to support the conjecture. However, the comment could be more helpful if it suggested specific ways to substantiate the conjecture or provided examples of how similar claims have been addressed in the literature. Overall, the comment is mostly helpful as it directs the authors to a crucial area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that including NaturalSpeech 3 as a baseline for voice cloning tasks might be beneficial when using FACodec. While the comment implies that the authors should consider this baseline, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should include NaturalSpeech 3 as a baseline. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors might infer that it relates to the voice cloning tasks or the use of FACodec, but this inference is not direct. The comment is specific in suggesting a potential baseline, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests considering NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. However, it does not provide any reasoning, evidence, or examples to support why this suggestion would be beneficial or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary justification to guide the authors in making changes. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests considering NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. This is a specific and actionable suggestion that could potentially improve the paper\\'s comparative analysis. However, the comment lacks depth and does not explain why NaturalSpeech 3 is particularly relevant or how it might enhance the analysis. To be more helpful, the comment could provide additional context or reasoning for why this baseline is beneficial. As it stands, the feedback is somewhat helpful, as it points the authors in a direction for improvement but does not fully guide them. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the fairness of the experiments, specifically regarding the use of data for inference by the proposed method. It suggests that other methods should use the same data for training, as the proposed method cannot do so. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to ensure fairness. The action is implicit and somewhat vague, as the authors are left to infer that they need to make adjustments to the experimental setting but are not given detailed instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a concern about the fairness of the experiments, specifically regarding the use of data for inference by the proposed method. It suggests that other methods should use the same data for training, as the proposed method cannot do so. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion that other methods should use the same data for training, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the fairness of the experiments, specifically regarding the use of data for inference by the proposed method. It suggests that other methods should use the same data for training, as the proposed method cannot do so. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some basis but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the fairness of the experiments, specifically regarding the use of data for inference by the proposed method. It suggests that other methods should use the same data for training, as the proposed method cannot do so. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how the authors might address this issue or improve the fairness of their experiments. Without actionable feedback or detailed reasoning, the authors are left without a clear path forward, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category (50%, 2:4, 4:8). While the comment implies that the authors should include these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these comparisons. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category (50%, 2:4, 4:8). However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where these comparisons should be included. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The suggestion is specific, as it clearly outlines what additional comparisons should be included. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category (50%, 2:4, 4:8). However, the comment does not provide any supporting evidence, reasoning, or references to justify why these comparisons are necessary or how they would enhance the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category (50%, 2:4, 4:8). This feedback is somewhat helpful as it identifies a specific area where the paper could provide additional comparisons, which could enhance its comprehensiveness and rigor. However, the comment lacks depth and does not explain why these comparisons are important or how they would contribute to the paper\\'s overall contribution. To be more helpful, the comment could provide additional context or suggestions on how to interpret and present these results. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of sequential bias on the VisDial results, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific steps they should consider to improve their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the impact of sequential bias on the VisDial results, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine whether it relates to a specific section, table, or figure. Additionally, the comment lacks specificity regarding what aspect of the sequential bias is being questioned or how it affects the results. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the impact of sequential bias on VisDial results. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the impact of sequential bias on the VisDial results, which could be a relevant consideration for the authors to address. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might investigate or mitigate this issue. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the experimental results and the stated goal of the LTAP method. It suggests that LTAP achieves a larger performance improvement for head classes than for tail classes, which contradicts the stated goal of strengthening parameter protection for tail classes. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their method to align with their stated goal. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ImageNet-LT dataset\" and the specific results compared to \"ATO\" and \"RReg,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a contradiction between the experimental results and the stated goal of the LTAP method, which is to strengthen parameter protection for tail classes. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results on the ImageNet-LT dataset contradict the stated goal of the LTAP method, which is to strengthen parameter protection for tail classes. The reviewer supports this claim by comparing the performance improvement for head and tail classes, suggesting that LTAP achieves a larger performance improvement for head classes than for tail classes. However, the comment lacks specific references or detailed analysis to fully substantiate the claim. While the comparison provides some basis for the claim, it could be strengthened with additional evidence or reasoning. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the experimental results and the stated goal of the LTAP method. It points out that LTAP achieves a larger performance improvement for head classes than for tail classes, which contradicts the stated goal of strengthening parameter protection for tail classes. This feedback is valuable as it highlights an area where the method may not be achieving its intended purpose, providing the authors with a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how to address this issue or potential solutions to align the method with its stated goal. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a concern about the reliability of the search process due to the dependency on LLM-based evaluation. It suggests that this dependency may introduce biases or inconsistencies in the quality assessment of generated documentations. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to mitigate these issues. The feedback lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the reward computation and its reliance on LLM-based evaluation, specifically mentioning the potential for biases or inconsistencies in the quality assessment of generated documentations due to LLMs. However, it does not specify which part of the paper this concern is related to, such as a specific section or figure where this issue is discussed. The authors can infer that it relates to the evaluation or results sections, but this inference is not direct. The comment is specific in detailing the potential issue with the reliance on LLMs for evaluation, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the reliability of the search process due to the dependency on LLM-based evaluation. It suggests that this dependency may introduce biases or inconsistencies in the quality assessment of generated documentations. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that LLMs may generate inaccurate scores. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reliability of the search process, specifically the dependency on LLM-based evaluation. It raises concerns about biases or inconsistencies in the quality assessment of generated documentations due to the possibility of inaccurate scores from LLMs. This feedback is somewhat helpful as it highlights a potential weakness in the methodology that the authors should address. However, the comment lacks specific suggestions or guidance on how to mitigate these concerns or improve the evaluation process. To be more helpful, the comment could provide examples of how other approaches have addressed similar issues or offer suggestions for alternative evaluation methods. As it stands, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more empirical examples and compare their results to those of state-of-the-art (SOTA) performance from referenced papers to support their claim of the process being surprisingly effective. While the comment implies that Equation 12 might be a relevant part of the analysis, it does not explicitly instruct the authors to focus on this equation or provide specific guidance on how to present the additional examples or comparisons. The action is implicit and somewhat vague, as the authors need to infer that they should provide more empirical evidence and comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more empirical examples and compare their results to those of state-of-the-art (SOTA) performance from referenced papers to support their claim of the process being surprisingly effective. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting the need for empirical examples and comparisons, but it lacks full grounding as it does not explicitly mention the relevant section or figure. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide more empirical examples and comparisons to support their claim of the process being surprisingly effective. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed reasoning or evidence makes it challenging for the authors to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by suggesting that the authors should provide more empirical examples and comparisons to support their claim of the process being surprisingly effective. It also points out that Equation 12 might be relevant but is unclear. While the comment highlights areas for improvement, it lacks specific guidance on how to present these examples or what aspects of Equation 12 are unclear. This limits the comment\\'s helpfulness, as it provides some direction but does not offer detailed suggestions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the difficulty of the problem and questions the assumption that the adversary cannot pick arbitrary S. It provides a detailed explanation of the assumption and its implications, suggesting that the problem might still be solvable if certain conditions are met. However, the comment does not explicitly instruct the authors to address this concern or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the assumption and its implications. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the concern about the difficulty of the problem and the assumption that the adversary cannot pick arbitrary S. The comment provides a detailed explanation of the assumption and its implications, which helps the authors understand the issue and potential solutions. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the difficulty of the problem and questions the assumption that the adversary cannot pick arbitrary S. The reviewer provides a detailed explanation of Assumption 1, which enforces that the adversary can only select samples that meet a certain condition. The reviewer also explains the implications of this assumption and suggests that the problem might still be solvable under certain conditions. This logical reasoning and explanation provide a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including specific references or examples to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the difficulty of the problem and questions the assumption that the adversary cannot pick arbitrary S. It provides a detailed explanation of Assumption 1 and its implications, suggesting that the problem might still be solvable under certain conditions. This feedback is somewhat helpful as it identifies a potential weakness in the paper\\'s assumptions and offers a logical explanation of why the problem might be more manageable than initially thought. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue or improve their analysis. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a contradiction between Figure 1 and Table 1, specifically noting that NNGS increases as k increases, which contradicts the comparison in the last two columns of Table 1. However, the comment does not provide explicit guidance on how the authors should address this contradiction or suggest specific actions to reconcile the discrepancy. The authors are left to infer that they need to reconsider their analysis or provide additional explanations, but without concrete steps, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a contradiction between the figure and table, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 1 contradicts the comparison in the last two columns of Table 1, specifically stating that NNGS increases as k increases. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a contradiction between Figure 1 and Table 1, specifically noting that NNGS increases as k increases, which contradicts the comparison in the last two columns of Table 1. This feedback is clear and actionable, as it highlights a discrepancy that the authors need to address. By pointing out this contradiction, the comment provides the authors with a specific area to focus on and potentially resolve, making it mostly helpful. However, it could be more helpful if it offered suggestions on how to reconcile the discrepancy or clarify the comparison. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the extensibility of the proposed method to a large number of tasks and questions the impact on the shared parameters. It explicitly asks the authors to address this question, providing a clear direction for improvement. The comment is explicit in its request for the authors to provide a response, making it highly actionable. The authors know exactly what needs to be done to improve their draft, which is to provide a detailed explanation or analysis of the impact of a large number of tasks on the proposed approach.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a concern about the extensibility of the proposed method to a large number of tasks and questions the impact on the shared parameters. It references the experiments, which provide results for a limited number of tasks (up to 20). However, the comment does not specify which part of the paper this concern is related to, such as the methodology, results, or discussion sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for the authors to address the question regarding the effect of the number of tasks on the proposed approach, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the extensibility of the proposed method to a large number of tasks, questioning its impact on the shared parameters. It references the experiments, which provide results for a limited number of tasks (up to 20), but does not provide specific examples or detailed reasoning to support this concern. The comment lacks detailed evidence or references to substantiate the claim, making it somewhat verifiable. The authors would need to further explore the issue themselves, which is a somewhat helpful comment. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the extensibility of the proposed method to a large number of tasks, questioning its impact on the shared parameters. It references the experiments, which provide results for a limited number of tasks (up to 20), and explicitly asks the authors to address this question. This feedback is clear and actionable, as it prompts the authors to consider the scalability of their method in a broader context. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this concern. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the data selection and filtering process for eyetracking is perplexing, as it appears to include everything with some exclusions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify or improve the data selection process, nor are there suggestions for potential improvements or changes. Without actionable advice or concrete steps, the authors are left without a clear understanding of what steps to take to address this issue. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the data selection and filtering process for eyetracking, specifically mentioning that it appears to include everything with some exclusions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the perplexing nature of the data selection and filtering process, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the eyetracking data selection and filtering process is perplexing, as it appears to include everything with some exclusions. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some indication of a problem but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a potential issue with the data selection and filtering process for eyetracking, noting that it appears to include everything with some exclusions. This feedback highlights a potential area for clarification or improvement in the paper, as it suggests that the authors may need to provide more detailed information about their data selection criteria or filtering process. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional data analysis or clarifying the rationale behind certain exclusions. While it identifies a potential weakness, the feedback is incomplete and does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the credibility of the Appendix results for InitNO, specifically questioning the reported improved text-image alignment on StableDiffusion-v1-4. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or improve the credibility of their results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix results for InitNO\" and \"Table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the credibility of the results, noting that the reported improved text-image alignment on StableDiffusion-v1-4 is lower than that of StableDiffusion-v1-4 in Table 6. This provides clear guidance on what needs to be addressed to improve the credibility of the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the credibility of the Appendix results for InitNO is questionable, based on the reported improved text-image alignment on StableDiffusion-v1-4 and the lower alignment in Table 6 for InitNO compared to StableDiffusion-v1-4. However, the comment does not provide specific details or references to support this claim, such as data or comparisons that could substantiate the claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the credibility of the Appendix results for InitNO, specifically questioning the reported improved text-image alignment on StableDiffusion-v1-4. It references Table 6, which shows that InitNO's alignment is lower than that of StableDiffusion-v1-4. This feedback is somewhat helpful as it points out a potential discrepancy that the authors should address. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve this issue or improve the credibility of the results. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete suggestions for improving the draft. It suggests that the writing could use additional editing, particularly in terms of language usage and type, rather than technical aspects. The reviewer also points out that the notation in equations can become unwieldy, and recommends considering dropping some sub/superscripts for convenience where possible. The comment provides specific guidance on what aspects of the writing need improvement, offering a clear action for the authors to take. The explicit nature of the suggestions and the concrete details on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"writing\" and \"equations\" sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on the unevenness of the writing and the complexity of the notation in the equations, suggesting that additional editing is needed. The comment also suggests dropping some sub/superscripts for convenience, which provides clear guidance on how to improve the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the writing is uneven and could benefit from additional editing, particularly in terms of language usage and type rather than technical aspects. It also points out that the notation in equations is exact but can become unwieldy, suggesting that dropping some sub/superscripts for convenience might be considered. The comment provides a logical reasoning for the need for editing, but it lacks specific examples or references to support the claim about the notation being unwieldy. The suggestion to drop sub/superscripts is somewhat vague, as it does not explain how this would improve readability or what specific sub/superscripts might be considered. Overall, the claim is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the draft, identifying areas where the writing could be improved. It points out that the writing is occasionally uneven and suggests that additional editing is needed, particularly in terms of language usage and type rather than technical aspects. The reviewer also notes that the notation in equations is exact but can become unwieldy, suggesting that dropping some sub/superscripts for convenience might be considered. This feedback is clear and provides a concrete direction for the authors to enhance the clarity and readability of their draft. By offering specific suggestions for improvement, the comment is highly helpful in guiding the authors towards a more polished and effective draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the size of the dataset relative to the development cost and suggests that the authors should explain the image acquisition cost and the manual collection process. It also points out a minor issue with the formatting of the text in Line 79, which is a suggestion for clarification. Additionally, it asks for clarification on the content of \"regulatory requirements\" in Line 263, specifically questioning what is considered \"politically sensitive.\" While the comment provides explicit actions for the authors to take, such as explaining the image acquisition cost and manual collection process, it does not specify how to address the formatting issue or the content of \"regulatory requirements.\" The action is clear but somewhat vague in execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the dataset size and the image acquisition cost, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors should explain the image acquisition cost and the manual collection process. Additionally, it provides specific feedback by asking for clarification on the content of \"regulatory requirements\" in Line 263. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the size of the dataset relative to the development cost and suggests that the authors should explain the image acquisition cost and the manual collection process. It also questions the content of \"regulatory requirements\" in Line 263, specifically asking about what is considered \"politically sensitive.\" While the comment identifies a potential issue with the dataset size, it lacks specific examples or references to support the claim about the image acquisition cost and manual collection process. The question about \"regulatory requirements\" is somewhat vague, as it does not provide context or examples of what is considered politically sensitive. Therefore, the comment is somewhat verifiable, as it provides some basis for the claims but lacks detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the size of the dataset relative to the development cost and suggests that the authors should explain the image acquisition cost and the manual collection process. This feedback is clear and actionable, as it provides specific guidance on how the authors can improve their draft by addressing a critical aspect of their methodology. Additionally, the comment raises a minor issue with the formatting of the text in Line 79 and asks for clarification on the content of \"regulatory requirements\" in Line 263, specifically questioning what is considered \"politically sensitive.\" This feedback is somewhat helpful as it offers specific suggestions for improvement, but it could be more comprehensive by providing examples or additional context. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about how the third column of Figure 7 is generated, noting that the visualizations appear not to be normalized. While the comment identifies an area of curiosity, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they should investigate the normalization process or provide additional information. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the normalization process of the third column in Fig. 7, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the normalization process of the third column in Figure 7, noting that the visualizations appear not to be normalized. However, it does not provide any supporting evidence, reasoning, or references to justify why this observation is relevant or how it affects the paper\\'s validity. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary justification for the authors to understand and address the concern. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the normalization process of the third column in Figure 7, noting that the visualizations appear not to be normalized. While this observation highlights an area of curiosity, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to address this issue or improve the clarity of the visualizations. As a result, it offers limited value to the authors in terms of enhancing their draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate the advantages of using assignment entropy maximization in the ablation experiment and discuss potential negative societal impacts of their work. While the comment implies that the authors should conduct additional experiments and consider the ethical implications, it does not provide explicit instructions on how to implement these actions. The feedback is somewhat actionable as it highlights specific areas for improvement but lacks concrete guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and \"section of benefit of assignment entropy maximization,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of the advantages of using assignment entropy maximization and the potential negative societal impacts of the work. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the investigation into assignment entropy maximization is heuristic and suggests that the advantages of using this method should be evaluated in the ablation experiment. The comment also notes that the authors did not discuss potential negative societal impacts of their work. While the comment identifies a potential limitation in the investigation and suggests additional areas for exploration, it lacks specific examples or references to support the claim about the heuristic nature of the investigation. The suggestion to evaluate the advantages of assignment entropy maximization is somewhat vague, as it does not provide detailed guidance on how to conduct this evaluation. Therefore, the claim is somewhat verifiable, as it provides a direction for improvement but lacks sufficient justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors evaluate the advantages of using assignment entropy maximization in the ablation experiment. It also points out the absence of a discussion on potential negative societal impacts of the work. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by including a more comprehensive evaluation of the method and its benefits. However, the comment could be more helpful if it offered specific suggestions on how to conduct the evaluation or what aspects of the work should be considered in the societal impact discussion. Overall, the comment is mostly helpful as it directs the authors toward meaningful enhancements in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the experimental section, noting that there is only one baseline model mentioned. While it identifies a gap in the experimental setup, it does not provide explicit guidance on how the authors should address this issue. The comment lacks actionable suggestions or concrete steps for improvement, such as recommending additional baseline models or suggesting ways to incorporate them. As a result, the authors are left without a clear understanding of what changes they should make to enhance their experimental section. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of having only one baseline model mentioned, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is only one baseline model mentioned in the experimental section. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a problem or how it affects the paper\\'s conclusions. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary justification for the authors to understand and address the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental section, noting that there is only one baseline model mentioned. This feedback highlights a potential limitation in the study\\'s comparative analysis, as it does not provide a broader perspective on the effectiveness of different models. However, the comment lacks depth and does not offer suggestions or guidance on how the authors might address this issue, such as suggesting additional baseline models or explaining why the current choice is insufficient. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a missing aspect in the results section, specifically the absence of baselines and literature comparisons, such as traditional QAT, other LLM-based QAT work, and recent PTQ baselines like SpinQuant. It suggests that understanding the benefits of using extra memory instead of relying solely on fine-tuning low-rank adapters is important. While the comment implies that the authors should include these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific comparisons and benefits to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the results section, where baselines and literature comparisons are missing. It also specifies what is missing, including traditional QAT, other LLM-based QAT work, and recent PTQ baselines like SpinQuant. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that baselines and literature comparisons are missing, specifically mentioning traditional QAT, other LLM-based QAT work, and recent PTQ baselines like SpinQuant. The reviewer provides a logical reasoning by suggesting that understanding the benefits of using extra memory instead of relying solely on fine-tuning low-rank adapters is important. However, the comment lacks specific examples or references to support the claim about the benefits of using extra memory. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the absence of baselines and literature comparisons in the results section. It highlights the need for comparisons to traditional QAT, other LLM-based QAT work, and recent PTQ baselines like SpinQuant. By pointing out these missing elements, the comment provides clear and actionable feedback that can help the authors enhance the comprehensiveness and relevance of their results. However, the comment could be more helpful if it offered specific suggestions on how to incorporate these comparisons or what aspects to focus on in the analysis. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for more detailed instructions on how to define attributes and the differences between them. This is a clear and direct request for additional information, providing the authors with a specific action to take. The comment is explicit and concrete, as it specifies exactly what needs to be added to the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for more detailed instructions on how to define attributes and the differences between them. This allows the authors to accurately identify the part of the paper being addressed, making it fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for detailed instructions on defining attributes and their differences. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual questions seeking clarification on the definition and differences between attributes. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the definition and differences between attributes, which is a critical aspect of the paper. By asking for more detailed instructions on how to define attributes and what the differences are, the comment provides a clear and actionable suggestion for improvement. This feedback is valuable as it directs the authors to clarify an important aspect of their work, ensuring that readers can better understand the concepts presented. However, the comment could be more helpful if it offered specific examples or guidance on how to provide these detailed instructions. Overall, the comment is mostly helpful as it effectively guides the authors toward improving the clarity and comprehensibility of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the theory presented in the paper may not be sufficient to predict whether a model can be trained to be robust to adversarial perturbations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific steps they could take to improve the robustness of their model. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the theory presented in the paper may not be sufficient to predict whether a model can be trained to be robust to adversarial perturbations. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity regarding what aspects of the theory are insufficient or how they could be improved. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the theory presented in the paper may not be sufficient to predict whether a model can be trained to be robust to adversarial perturbations. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples, references, or detailed explanations to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the theory presented in the paper may not be sufficient to predict whether a model can be trained to be robust to adversarial perturbations. However, it does not provide any specific feedback or suggestions on how the authors might address this concern or improve their work. Without actionable guidance or constructive criticism, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the meaning of \"scenario\" in the paper, specifically asking whether it refers to classes or instances, and where the \"agnostic\" part comes in. While the comment identifies a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors might clarify this aspect of their work. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the meaning of \"scenario\" but are not given specific steps to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the meaning of \"scenario\" in the paper, specifically asking whether it refers to classes or instances, and where the \"agnostic\" part comes in. However, it does not specify which part of the paper this confusion is related to, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its questioning of the meaning of \"scenario,\" but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the meaning of \"scenario\" in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the clarity of the term \"scenario\" in the paper, specifically asking whether it refers to classes or instances and where the \"agnostic\" part comes in. While this feedback identifies a potential area of confusion, it lacks depth and does not provide specific suggestions or guidance on how the authors might clarify this aspect of their work. The comment highlights a potential issue but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the method's name, \"Maestro,\" and its introduction in the paper. While it implies that the authors should clarify or introduce the method, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explain the method's name and its relevance to the paper. However, the comment lacks concrete guidance on how to implement this action, such as suggesting specific sections where the explanation should be included. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the method named \"Maestro\" and its introduction in the paper. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for an explanation or introduction of the method, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind the method name \"Maestro\" and its introduction in the paper. However, it does not provide any reasoning or evidence to support why the name is inappropriate or confusing. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the method name \"Maestro\" and its introduction in the paper. It points out that the method is not introduced and seems unusual, which could confuse readers. While the comment identifies a potential issue with the clarity and introduction of the method, it lacks specific guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it highlights a potential area for improvement, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify what \"best\" means within the context of the paper, specifically by defining the criteria used to determine the \"best\" candidate. This feedback is clear and provides a concrete action for the authors to take, ensuring that they understand the meaning of \"best\" and can clarify it in their draft. The comment is highly actionable as it directly guides the authors on how to improve the clarity of their writing.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the definition of \"best\" in the context of the paper. The comment provides clear guidance on how to improve the clarity of the paper by defining the criteria used to determine the \"best\" candidate. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors clarify the criteria used to determine the \"best\" candidate in the context of the paper. This is a request for clarification rather than a claim or opinion. It does not present any subjective judgments or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific area of confusion in the paper, namely the use of the term \"best\" without clarifying its meaning within the context of the paper. By explicitly defining the criteria used to determine the \"best\" candidate, the authors can improve the clarity and consistency of their writing. This feedback is clear and actionable, providing the authors with a direct and constructive way to enhance the clarity of their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some points in the paper are over-claimed, specifically mentioning that the proposed method does not consider feed-forward layers, yet some text describes it as if it does. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the text. The action is implicit and vague, as the authors are left to infer that they need to correct the text to accurately reflect the scope of their method. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"some points\" and \"the proposed method,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the method does not consider feed-forward layers, which is a clear and specific critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some points in the paper are over-claimed, specifically mentioning that the proposed method does not consider feed-forward layers, yet some text describes it as if it does. This claim is somewhat verifiable as it highlights a discrepancy between the method's scope and the text, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to further investigate the discrepancy to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that some points are over-claimed and that the proposed method does not consider feed-forward layers, yet the text describes it as if it does. This feedback is clear and actionable, as it points out a discrepancy between the method's scope and the claims made in the paper. However, the comment could be more helpful if it provided suggestions on how to address this issue or clarified the misrepresentation in the text. Despite this, the feedback is mostly helpful as it directs the authors to a critical area needing attention and correction. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments are not clearly motivated, specifically mentioning the lack of variations and the use of \"Up to 18 games\" finetuning methods. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue. There is no guidance on what specific changes or improvements could be made to improve the motivation of the experiments. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of the experiments being not clearly motivated, specifically mentioning the lack of variations and the use of \"Up to 18 games\" finetuning methods. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the lack of variations and the finetuning methods, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are not clearly motivated, specifically mentioning the lack of variations and the use of \"Up to 18 games\" finetuning methods. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these aspects are problematic or how they impact the experiments\\' effectiveness. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental design, noting that the motivation for the experiments is unclear. It highlights the lack of variations and the use of \"Up to 18 games\" finetuning methods, which could be problematic. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the motivation of their experiments. Without actionable feedback or detailed advice, the authors are left without a clear path forward. Therefore, the comment is barely helpful, as it points out a potential weakness but lacks depth and specificity in its feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate the method performance under missing modality cases, such as testing sets with different missing ratios. It also provides two references, \"A\" and \"B,\" which could be used as examples of how to evaluate the method under different missing scenarios. While the comment explicitly states what needs to be done and provides some guidance on how to implement it, it lacks specific details on how to conduct the evaluation or what specific metrics should be used. The action is concrete but somewhat vague, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1/2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: evaluating the method performance under missing modality cases, such as testing sets with different missing ratios. The comment provides a clear direction for improvement by suggesting additional testing scenarios and references, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the table only shows results for Miss-V and Miss-A, suggesting that additional evaluation is needed under missing modality cases. The reviewer provides two references, \"A\" and \"B,\" which could be used as examples of how to evaluate the method under different missing scenarios. However, the comment lacks specific details on how these references apply to the current study or what specific metrics should be used for the evaluation. This makes the claim somewhat verifiable, as it provides some guidance but requires further elaboration for full understanding. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in the paper, noting that only Miss-V and Miss-A results are shown in table 1/2. It suggests that additional evaluation is necessary to assess the method's performance under missing modality cases, such as testing sets with different missing ratios. The comment provides a clear and actionable suggestion for improvement by recommending specific testing scenarios and references, \"A\" and \"B,\" which could guide the authors in conducting a more comprehensive evaluation. However, the comment could be more helpful if it included detailed guidance on how to implement these suggestions or what specific metrics should be used. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides some guidance on how to address it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that an ablation study on the effect of using image features is needed. While it implies that the authors should include such a study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an ablation study. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting an ablation study on the effect of using image features, but it does not specify which part of the paper this suggestion pertains to. The authors cannot confidently determine whether it relates to a specific section, such as the methodology or results, making it weakly grounded. The comment is specific in suggesting the need for an ablation study, but without explicit references to the paper, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting an ablation study on the effect of using image features, which is a suggestion for improvement. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this study is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting an ablation study on the effect of using image features, which is a specific and actionable suggestion for improvement. By recommending an additional experiment, the comment provides the authors with a clear and constructive direction for enhancing their work. However, the comment could be more helpful if it offered further guidance on how to design and conduct the ablation study, such as potential variables to test or specific hypotheses to explore. Overall, the comment is mostly helpful as it directs the authors to a meaningful enhancement of their draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the approach in challenging settings, specifically mentioning the Transformer Big and deep Transformers. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should conduct additional experiments, provide more details on the current experiments, or address the question in the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the performance of the approach in challenging settings, specifically mentioning the Transformer Big and deep Transformers. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. The authors cannot confidently determine which part of the paper is being addressed, making this comment weakly grounded. The comment is specific in its question about the performance of the approach in challenging settings, but without explicit grounding, it is difficult for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance of the approach in challenging settings, specifically mentioning the Transformer Big and deep Transformers. However, it does not provide any supporting evidence, reasoning, or references to justify why these settings are considered challenging or how the approach might perform in them. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the performance of the approach in challenging settings, specifically mentioning the Transformer Big and deep Transformers. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this concern. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors' understanding of identifiability is incorrect, specifically stating that it is a property of a model assuming infinite data. The reviewer provides a clear explanation of what identifiability is and why the authors' claim is incorrect. However, the comment does not offer any guidance on how the authors should correct their understanding or improve their draft. It lacks explicit instructions or concrete suggestions for the authors to follow, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the authors\\' understanding of identifiability, specifically stating that it is a property of a model assuming infinite data. However, it does not specify which part of the paper this understanding is discussed in, making it weakly grounded. The comment is specific in detailing what is incorrect about the authors\\' understanding of identifiability, providing clear guidance on what needs to be corrected. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' understanding of identifiability is incorrect, specifically stating that it is a property of a model assuming infinite data. The comment provides a clear explanation of what identifiability is, which is a factual statement. However, it lacks supporting evidence or references to substantiate the claim that the authors' understanding is incorrect. Without additional context or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the authors\\' understanding of identifiability. It points out that the authors\\' claim is incorrect, as identifiability is a property of a model assuming infinite data. The comment provides a clear and concise explanation of what identifiability is, which is important for the authors to understand. However, the comment lacks depth and does not offer suggestions or guidance on how the authors might improve their understanding or address this issue in their draft. While it highlights a critical point, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the results do not show any significant benefit compared to the simple baseline mentioned by the authors. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their results. There is no guidance on potential modifications to the methodology, additional analyses, or ways to enhance the presentation of the results. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of significant benefit in the results compared to the simple baseline mentioned by the authors. However, it does not specify which part of the paper this comparison is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the results but lacks grounding, as it does not identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results do not show any significant benefit compared to the simple baseline mentioned by the authors. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a lack of significant benefit in the results compared to the simple baseline mentioned by the authors. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their results. Without actionable feedback or detailed insights into potential improvements, the comment offers limited value to the authors. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the method: the need for a pre-trained vocoder and the inference speed of the diffusion-based vocoder. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment implies that the authors should consider the time cost of pre-training the vocoder and the inference speed of the diffusion-based vocoder, but it does not specify how to measure or mitigate these issues. The action is implicit and somewhat vague, leaving the authors with a general understanding of what needs to be improved but without concrete steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific issues related to the training and inference processes of the method, including the need for a pre-trained vocoder and the inference speed of the diffusion-based vocoder. It provides some level of detail by mentioning the specific time cost of pre-training the vocoder and the inference speed of the diffusion-based vocoder. However, the comment does not explicitly mention which section of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the training and inference processes, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method requires a pre-trained vocoder and that the inference speed of the diffusion-based vocoder is slower than DSP and WarpNet. The comment provides some reasoning by mentioning the GPU hours of pre-training and the inference speed, which adds a level of verifiability. However, the comment could be strengthened by providing specific examples or references to support the claim about the inference speed. Overall, the comment is mostly verifiable, as it provides some evidence but lacks detailed justification or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two specific issues with the method: the need for a pre-trained vocoder and the inference speed of the diffusion-based vocoder. It highlights the time cost of pre-training the vocoder and the inference speed of the diffusion-based vocoder, which are important considerations for the authors to address. However, the comment does not provide detailed suggestions or guidance on how to address these issues, such as recommending alternative approaches or methods to improve efficiency. While it points out areas for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper mentions the generalizability of the scoring function s(\u00b7; G) for multiple goal documents or without any gold document, but this generalization is not explored. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to explore the generalization. The action is implicit and vague, as the authors are left to infer that they need to explore the generalization themselves without clear instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper regarding the generalization of the scoring function s(\u00b7; G) for multiple goal documents or without any gold document. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the lack of exploration of this generalization, which is important for the authors to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not explore the generalization of the scoring function s(\u00b7; G) for multiple goal documents or without any gold document, which makes the generalization of the framework questionable. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact issue and how to address it. Without detailed reasoning or evidence, the claim remains unverifiable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper regarding the generalization of the scoring function s(\u00b7; G) for multiple goal documents or without any gold document. It points out that while the paper mentions this generalization, it does not explore it, which raises questions about the generalizability of the framework. This feedback is clear and actionable, as it highlights a gap in the paper that the authors need to address to strengthen their work. However, the comment could be more helpful if it provided suggestions on how to explore this generalization or what specific aspects of the framework should be considered. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that including information on the success rate at each conversation turn would provide valuable insights into the framework's comparative performance throughout the recommendation process. This feedback is explicit and provides a clear action for the authors to take, which is to include this information in their paper. The comment also references a specific work that could serve as a model for how to present this data, making it concrete and actionable. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including information on the success rate at each conversation turn to provide insights into the framework\\'s comparative performance throughout the recommendation process. It references a specific work by Yiming Zhang et al. (2022) as an example of how this information could be presented. However, the comment does not explicitly mention which part of the paper this information should be included in, making it weakly grounded. The suggestion is specific, as it clearly outlines what needs to be addressed and provides a reference for how it could be done. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including information on the success rate at each conversation turn would provide valuable insights into the framework\\'s comparative performance throughout the recommendation process. The comment references a specific work by Yiming Zhang et al. (2022) as an example of how this information could be presented. This reference provides a basis for the claim, as it suggests a methodology that could be followed. However, the comment lacks detailed justification or explanation of why this information is necessary or how it would enhance the understanding of the proposed approach. Therefore, the claim is somewhat verifiable, as it provides a logical basis but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It recommends including information on the success rate at each conversation turn, which would offer insights into the framework\\'s comparative performance throughout the recommendation process. This feedback is valuable as it suggests a specific way to enhance the comprehensiveness and nuanced understanding of the proposed approach. By including this information, the authors can provide a more detailed and informative evaluation of their framework. However, the comment could be more helpful if it explained why this information is important or how it would contribute to the overall evaluation. Nonetheless, the suggestion is clear and actionable, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is dense and recommends breaking up numbered lists within paragraphs into separate lists for easier readability. While the action is explicit, it lacks concrete guidance on how to implement this suggestion, such as providing specific examples of where numbered lists should be reorganized or suggesting alternative formatting options. The authors are left with a clear direction but without detailed instructions on how to execute it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the density of the paper, specifically mentioning that numbered lists are included in paragraphs, which makes it difficult to read. However, it does not specify which sections or paragraphs this issue occurs in, leaving the authors to infer where these issues might be. The comment is specific in suggesting that the numbered lists should be easier to read by separating them into actual lists, but it lacks full grounding as it does not pinpoint the exact parts of the paper that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper is dense and difficult to read due to the inclusion of numbered lists within paragraphs. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks specificity and does not offer any evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s density, noting that numbered lists are included within paragraphs, making it difficult to read. It suggests a potential solution by recommending that these lists be separated into actual lists for easier readability. While the comment provides a clear and actionable suggestion, it could be more helpful if it offered specific examples or guidance on how to implement this change. Overall, the feedback is somewhat helpful as it directs the authors to a specific area for improvement, but it lacks depth and detailed instructions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fundamental nature of other \"fake image detectors\" and whether they rely on similar spectral cues as the simple classifier described in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this question or what specific aspects of the paper should be revised in response. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the fundamental nature of other \"fake image detectors\" and whether they rely on similar spectral cues as the simple classifier described in the paper. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its questioning of the fundamental nature of other detectors, but without explicit references to sections or details, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions whether other \"fake image detectors\" are fundamentally using the same spectral cues as the simple classifier described in the paper. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the fundamental nature of other \"fake image detectors\" and whether they rely on similar spectral cues as the simple classifier described in the paper. While it prompts the authors to consider the broader implications of their work, it lacks specificity and actionable guidance. The comment does not provide suggestions or examples of how the authors might address this question or what aspects of their work might be improved. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the visualization results are terrible and recommends analyzing both satisfied and unsatisfied cases. It also mentions that class-incremental learning for semantic segmentation does not reuse old data or labels. While the comment implies that the authors should analyze both satisfied and unsatisfied cases, it does not provide explicit instructions on how to conduct this analysis or what specific aspects to focus on. Additionally, it does not specify whether the analysis should be qualitative or quantitative, or what kind of data or labels should be considered. The action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be done but without detailed guidance on execution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"visualization results\" and \"Class-incremental learning for semantic segmentation,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis of both satisfied and unsatisfied cases, and the issue with class-incremental learning for semantic segmentation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the visualization results are \"terrible\" and suggests analyzing both satisfied and unsatisfied cases. It also mentions that class-incremental learning for semantic segmentation does not reuse old data or labels. While the comment provides some logical reasoning by suggesting an analysis of both satisfied and unsatisfied cases, it lacks specific examples or detailed justification for why the visualization results are considered terrible. The mention of class-incremental learning is more of a factual statement than a claim, as it describes a specific methodology rather than an opinion. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the visualization results, describing them as \"terrible.\" It suggests that the authors should analyze both satisfied and unsatisfied cases, which is a valuable suggestion for improving the paper. Additionally, it points out a specific methodological issue with class-incremental learning for semantic segmentation, noting that it does not reuse old data or labels. This feedback is clear and actionable, providing the authors with specific areas to focus on for improvement. However, the comment could be more helpful if it offered additional guidance on how to conduct the analysis or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward meaningful enhancements, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper, noting that its relevance is based on building upon a large body of previous work. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might mitigate the potential impact of previous work or how to improve the implementation process. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s reliance on previous work and the potential impact of any limitations or issues in those works on the validity and effectiveness of TIW. It also mentions the implementation process being similar to previous work on GAN. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the paper\\'s reliance on previous work and the need to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a potential issue with the paper\\'s reliance on previous work, noting that any limitations or issues in those works could affect the validity and effectiveness of TIW. It also mentions that the implementation process is similar to previous work on GAN. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the concern. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s reliance on previous work, noting that any limitations or issues in those works could affect the validity and effectiveness of TIW. It also mentions that the implementation process is similar to previous work on GAN. While the comment highlights a relevant concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve their work. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the selection of a policy out of many for each sub-group, questioning whether any information unavailable to the policy is used during the partitioning step. It also suggests incorporating patient characteristics that were not used in training the policy. While the comment identifies potential issues and provides a direction for improvement, it lacks explicit instructions on how to address these concerns. The authors are left to infer that they should consider incorporating patient characteristics in the policy training, but the comment does not provide specific guidance on how to do so. Therefore, the comment is somewhat actionable, as it highlights areas for improvement but lacks concrete steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the selection of a policy out of many for each sub-group and questions whether any information unavailable to the policy is used during the partitioning step. It also suggests incorporating patient characteristics that were not used in training the policy. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the policy selection and the potential use of unused patient characteristics. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the selection of a policy out of many for each sub-group, suggesting that it may not be the best approach. It raises concerns about the use of information unavailable to the policy during the partitioning step and suggests incorporating patient characteristics that were not used in training the policy. The comment provides a logical reasoning for the potential issue and suggests a potential solution, making it mostly verifiable. However, it could be strengthened by providing specific examples or references to similar practices or studies that support the claim. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a critical question about the selection of a policy out of many for each sub-group, suggesting that it may not be the best approach. It also questions whether any information unavailable to the policy is used during the partitioning step and suggests incorporating patient characteristics that were not used in training the policy. This feedback is valuable as it identifies a potential weakness in the methodology and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to incorporate patient characteristics or how to address the issue of selecting a policy out of many. Overall, the comment is mostly helpful as it highlights a significant area for improvement and provides a direction for the authors to explore, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the rendering quality of NeRF compared to other models, specifically NeuS and Geo NeuS. While it does not explicitly instruct the authors to address this question, it implies that they should provide an explanation or comparison to clarify the observed difference in rendering quality. The action is implicit but concrete, as the authors can infer that they need to provide a response or analysis to address the question. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the rendering quality of NeRF compared to other models, NeuS and Geo NeuS, and seeks an explanation or comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point poses a question about the rendering quality of NeRF compared to other models, specifically NeuS and Geo NeuS. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the rendering quality of NeRF compared to other models, NeuS and Geo NeuS. By asking for an explanation or comparison, the comment prompts the authors to address a potential weakness in their work. However, it lacks depth and does not provide specific suggestions or guidance on how to improve the rendering quality or address the comparison. While it identifies an area for improvement, the feedback is somewhat helpful as it points out a potential issue but does not fully support the authors in resolving it. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the manuscript makes a bold assumption about the suitability of purely unsupervised large-scale pretraining for NLP applications, but it does not provide any explanation or guidance on how this conclusion was reached or how it could be challenged. The comment implies that the authors should provide more detailed reasoning or evidence to support their claim, but it does not explicitly instruct them to do so. The action is implicit and vague, as the authors are left to infer that they need to provide additional information or clarification. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the assumption made in the manuscript about the suitability of purely unsupervised large-scale pretraining for NLP applications. The comment is specific because it clearly identifies the assumption and questions its validity based on the evaluation approach. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the assumption made in the manuscript about the suitability of purely unsupervised large-scale pretraining for NLP applications. The reviewer claims that this is a bold assumption and questions how it can be concluded from the proposed evaluation approach. However, the comment lacks specific examples or references to support the claim that the assumption is unjustified. Without additional context or evidence, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific assumption made in the manuscript regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. It questions how this conclusion can be drawn from the proposed evaluation approach, indicating a potential gap in the reasoning or evidence presented. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their argument. While it points out a potential weakness, it lacks actionable feedback that would help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not offer detailed guidance for addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues: the lack of discussion on recent related work, particularly [A], which achieves higher performance on SUN, and the absence of DCN [18] in the table and discussion. It also mentions that [B] is relevant with respect to transductive label propagation. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include these discussions and references, but the feedback lacks concrete guidance on how to integrate them into the paper. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not offer detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Related work 2.1\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by pointing out the missing discussion of recent related work, including [A] and DCN [18], and the relevance of [B] with respect to transductive label propagation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks discussion on recent related work, specifically mentioning [A] and DCN [18], which achieve higher performance on SUN. It also notes the absence of DCN [18] in Table 3 and suggests that [B] is relevant with respect to transductive label propagation. The comment provides specific references to external works, which supports the claim by offering concrete examples of relevant studies. This makes the claim mostly verifiable, as it provides a clear rationale for the need to include these discussions. However, the comment could be further strengthened by explaining why these works are important or how they relate to the paper\\'s contributions. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper is lacking, particularly in the discussion of recent related work. It highlights the absence of a discussion on [A], which achieves higher performance on SUN, and the omission of DCN [18] from the table and discussion, despite its superior performance compared to other prior work on CUB. Additionally, it notes the relevance of [B] with respect to transductive label propagation. While the comment effectively points out these gaps, it does not provide detailed guidance on how to address these issues or integrate the missing discussions into the paper. The feedback is somewhat helpful as it directs the authors\\' attention to specific areas that need improvement, but it lacks actionable suggestions for enhancing the draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to replace the \"add\" operator in Figure 2 with a Hadamard product between the DAG and Attention. This is a clear and direct action that the authors can easily implement, as it provides a specific correction to make in their draft. The comment is highly actionable because it clearly specifies the change needed to be made, ensuring that the authors know exactly what to do to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the operator, suggesting that it should be a Hadamard product instead of an add. This provides clear guidance on what needs to be corrected in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the operator should be a Hadamard product between the DAG and Attention, instead of an add in Figure 2. However, the comment does not provide any reasoning or evidence to support this claim. It lacks specific examples or references to justify why the change is necessary or beneficial. As a result, the claim is unverifiable, as it does not provide sufficient justification for the authors to understand or address the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the operator in Figure 2, suggesting that it should be a Hadamard product instead of an add. This feedback is clear and actionable, as it provides a direct correction to make in the draft. By addressing this issue, the authors can improve the accuracy and clarity of their figures, which is valuable guidance for enhancing the paper\\'s presentation. However, the comment could be more helpful if it explained why the change from an add to a Hadamard product is necessary or how it affects the overall understanding of the paper. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the authors have addressed the reviewer\\'s concerns in their revision and response, particularly regarding weakness 2. It provides specific feedback on the improvement in achieving optimal rates for SOBA under additional smoothness assumptions, which led to an increased score from 7 to 8. However, it also points out limitations, such as the non-standard finite sum assumption discussed in the theoretical analysis section but not mentioned in the abstract. Additionally, it notes the discrepancy between the theoretical and practical updates of SABA, which is briefly mentioned but not adequately addressed. While the comment provides some guidance on what aspects were improved and what remains to be addressed, it does not offer explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors need to infer the specific improvements needed to address the limitations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"No. 7. 2022\" and \"Post authors\\\\u0027 response,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concerns that were addressed, such as the improvement in achieving optimal rates for SOBA under additional smoothness assumptions and the partial addressing of limitations. The comment also provides specific feedback on the abstract, noting the absence of a discussion on the non-standard finite sum assumption and the discrepancy between theoretical and practical updates of SABA. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review comment provides a detailed and specific critique of the paper, noting that the authors have addressed the reviewer\\'s concerns in their revision and response. It highlights the improvement in achieving optimal rates for SOBA under additional smoothness assumptions and acknowledges the increase in the score from 7 to 8. However, it also points out limitations, such as the non-standard finite sum assumption discussed in the theoretical analysis section but not mentioned in the abstract. Additionally, it notes the discrepancy between the theoretical and practical updates of SABA, which is briefly mentioned but not adequately addressed. The comment provides logical reasoning and specific examples to support its claims, making it mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed and constructive critique of the paper, acknowledging that the authors have addressed the reviewer\\'s concerns in their revision and response. It highlights specific improvements, such as achieving optimal rates for SOBA under additional smoothness assumptions, which led to an increase in the score from 7 to 8. However, it also points out limitations, such as the non-standard finite sum assumption discussed in the theoretical analysis section but not mentioned in the abstract, and the discrepancy between the theoretical and practical updates of SABA, which is briefly mentioned but not adequately addressed. This feedback is mostly helpful as it identifies areas where the authors have made progress but also highlights areas that need further attention or clarification. The comment provides actionable guidance for the authors to enhance their draft, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the paper\\'s claim and the experimental results, specifically noting that UnKE\\'s ability to retain original knowledge is worse than the baseline. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. The comment lacks guidance on how the authors should address this issue or improve their claims, leaving them without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that UnKE\\'s ability to retain original knowledge is worse than the baseline, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that UnKE's cause-driven optimization does not preserve pre-trained knowledge during the editing process, based on experimental results. The reviewer supports this claim by referencing specific tables (Table 2 and Table 3) and a reference to a specific work, which provides a basis for the claim. However, the comment could be strengthened by providing more detailed analysis or specific examples from the experiments to further substantiate the claim. Overall, the claim is mostly verifiable, as it is supported by references and logical reasoning, but it could be more fully substantiated with additional evidence or detailed analysis.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the paper\\'s claim and the experimental results, specifically noting that UnKE\\'s ability to retain original knowledge is worse than the baseline. This is a critical observation that challenges the paper\\'s main contribution. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their experimental design. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the explanation for the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first sight. However, it does not provide explicit guidance on how the authors should improve the explanation or clarify the details. The comment lacks specific suggestions or actions for the authors to take, leaving them uncertain about how to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the explanation for the intention of BWTP/GLBW and the difficulty in understanding the details due to their location in the appendix. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the explanation and the location of the relevant information, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the explanation for the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first sight. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a weakness in the explanation for the intention of BWTP/GLBW, noting that many details are in the appendix, making it challenging for readers to understand at first sight. This feedback is somewhat helpful as it highlights an area where the paper could be improved by providing a clearer and more accessible explanation of the concepts. However, the comment lacks specific suggestions or guidance on how to enhance the explanation or integrate the appendix content more effectively into the main text. While it points out a potential issue, it does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a proof for lack of space, either in the main paper or as supplementary material. This is a clear and direct action, providing the authors with a specific task to address. The comment also suggests that the proof might fit better in the main paper, offering a potential alternative. The action is concrete, as it specifies exactly what needs to be done, and it is detailed, providing guidance on where the proof might fit. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of a proof for lack of space. The comment provides guidance on where the proof might fit, suggesting either the main paper or supplementary material. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a proof for lack of space is omitted at the end of Section 3. However, it does not provide any supporting evidence, reasoning, or references to justify why this omission is problematic or how it affects the paper\\'s overall quality or credibility. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, noting that a proof for lack of space is missing at the end of Section 3. It provides a clear and actionable suggestion for the authors to include this proof, either in the main paper or as supplementary material. This feedback is valuable as it directly addresses a gap in the paper\\'s content, offering a straightforward way for the authors to improve the clarity and completeness of their work. However, the comment could be more helpful if it provided additional context or explanation on why this proof is important or how it fits into the overall structure of the paper. Overall, the comment is mostly helpful as it guides the authors on a specific area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide specific experimental results or references to support their claim that NPPs perform worse than ETAS. This feedback is explicit and provides a clear action for the authors to take, which is to include specific data or references to substantiate their argument. The comment is concrete, as it specifies what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that specific experimental results or references should be provided to support the claim that NPPs perform worse than ETAS. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the comparison is made. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for specific experimental results or references, but without full grounding, it is difficult for the authors to pinpoint the exact area needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that specific experimental results or references should be provided to support the claim that NPPs perform worse than ETAS. However, the comment does not provide any reasoning or evidence to substantiate why this claim is valid or how it could be improved with specific results or references. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that specific experimental results or references should be provided to support the claim that NPPs perform worse than ETAS. This feedback is somewhat helpful as it identifies a potential weakness in the paper\\'s argumentation, specifically the lack of concrete evidence to substantiate the claim. However, the comment does not provide specific guidance on what kind of results or references would be beneficial or how the authors might incorporate them into their paper. While it points out an area for improvement, the comment could be more helpful with additional details or suggestions. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the implementation details, specifically regarding the connectivity patterns between layers and their application to complex architectures like UNet, ResNet, and MobileNet. It points out that these details are not included in the methodology section or the appendix, which raises concerns about understanding the paper\\'s implementation. However, the comment does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The feedback is vague and lacks concrete steps for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as the methodology section, where Equations 3 and 4 outline the connectivity patterns between layers, and Tables 1, 4, and 5. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the lack of guidance on how to apply the connectivity patterns to complex architectures like UNet, ResNet, and MobileNet, and how this affects the understanding of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the implementation details are unclear, specifically regarding the connectivity patterns between layers and their application to complex architectures like UNet, ResNet, and MobileNet. The reviewer notes that these details are not included in the methodology section or the appendix, which raises concerns about understanding the paper\\'s implementation. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed evidence or examples makes the claim somewhat verifiable, as it provides a general insight but requires more specific guidance for improvement.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the implementation details, specifically regarding the connectivity patterns between layers and their application to complex architectures like UNet, ResNet, and MobileNet. It points out that these details are not included in the methodology section or the appendix, which raises concerns about understanding the paper\\'s implementation. This feedback is valuable as it highlights a critical area for improvement in the paper, particularly for readers who may be unfamiliar with the specific architectures mentioned. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending additional explanations or examples. Overall, the comment is mostly helpful as it directs the authors\\' attention to a crucial aspect of their work that needs clarification, but it lacks detailed guidance on how to improve it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the scalability of the calculation of HTER label, which is based on automatic scripts, and suggests that the authors should experiment on other languages and annotations to verify its scalability. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is concrete, as it specifies the need for additional experiments, but it is somewhat vague in terms of how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the calculation of HTER label, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the scalability of the calculation based on automatic scripts and suggests that the authors should experiment on other languages and annotations to verify its scalability. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the calculation of HTER label relies on automatic scripts, which may not be scalable to other annotations like MQM or DA. The comment suggests that the authors should experiment on other languages and annotations to verify the scalability. However, the comment lacks specific examples or references to support the claim that the scalability is an issue. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the scalability of the calculation of HTER label, which is based on automatic scripts. It suggests that the authors should experiment on other languages and annotations to verify the scalability. This feedback is clear and actionable, as it provides a concrete direction for the authors to address the scalability issue. However, the comment could be more helpful if it offered suggestions on how to conduct these experiments or what specific annotations to consider. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the dependence of overall performance on $m$ in $G_m$. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of the performance should be considered. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the dependence of overall performance on $m$ in $G_m$, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine whether it relates to a specific section, table, or figure. Additionally, the comment lacks specificity as it does not provide details on what aspect of the performance should be considered or how it is related to $m$. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the dependence of overall performance on $m$ in $G_m$. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the dependence of overall performance on $m$ in $G_m$, which could be a relevant aspect to consider in the paper. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this question or what specific aspects of the performance should be considered. Without actionable feedback or detailed insights, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap between theory and practice in deep learning, specifically regarding the difficulty of fitting sparse neural networks. It suggests that the authors should comment on this issue to help readers understand the key elements that enable Causal-Stonet to learn sparse neural networks. While the comment implies that the authors should provide a commentary on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this gap in their paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the theoretical works on deep learning and the specific issue of sparse neural networks, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the gap between theory and practice in deep learning and the difficulty of fitting sparse neural networks. The comment provides a clear direction for the authors to address this gap in their paper, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that theoretical works on deep learning do not reflect practice, specifically mentioning the difficulty of fitting sparse neural networks. The reviewer supports this claim by referencing Farrell, Liang, and Misra ECTA 2021, which provides a basis for the assertion. However, the comment could be strengthened by providing more detailed examples or references to further substantiate the claim. Despite this, the comment is mostly verifiable, as it offers a logical reasoning and a specific reference to support the claim. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a gap between theory and practice in deep learning, specifically regarding the difficulty of fitting sparse neural networks. It suggests that the authors should comment on this issue to help readers understand the key elements that enable Causal-Stonet to learn sparse neural networks. This feedback is clear and actionable, as it provides a specific direction for the authors to address a critical aspect of their work. However, the comment could be more helpful if it offered suggestions on how to effectively address the gap or provided examples of how other works have addressed this issue. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete suggestions for improving the layout of the paper. It suggests making tables smaller or relocating them to the Appendix, and reducing the size of certain figures. The reviewer explicitly mentions specific figures and tables (e.g., Table 1 and Figure 2) and provides examples of what could be done to address the issue. This level of detail gives the authors clear guidance on how to implement the suggested changes, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improving the layout by suggesting smaller tables or relocating them to the Appendix, and reducing the size of certain figures. This level of detail provides the authors with clear guidance on how to address the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the manuscript appears to be densely packed in terms of space, with figures and tables positioned closely to the text, making the paper seem cluttered and condensed. The reviewer provides a specific example by mentioning Figure 2 and Table 1, suggesting that these elements could be relocated to the Appendix or reduced in size. The comment is mostly verifiable as it provides a logical reasoning for the issue and offers specific suggestions for improvement. However, it could be strengthened by providing more detailed reasoning or examples of how the changes would enhance the readability of the paper. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the layout and organization of the paper. It identifies a potential issue with the density of figures and tables, suggesting that they may be too closely positioned to the text, making the paper appear cluttered and condensed. The reviewer offers a concrete suggestion to address this issue by relocating certain tables to the Appendix or reducing the size of specific figures, such as Figure 2 with fewer datasets. This feedback is clear and provides the authors with a clear path to improve the presentation of their work, making it highly helpful. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides two main points of feedback. First, it notes that the research scenario is meaningful but that the ReCPE method proposed in the article is too strategic and lacks strong theoretical guarantees. The reviewer suggests that the authors could strengthen the article by addressing this issue. Second, it points out a minor spelling error in Note 2 on page 7. While the first point is explicit in its suggestion for improvement, the second point is a minor correction that does not require action. Overall, the comment is mostly actionable as it provides clear guidance on how to strengthen the article and offers a specific correction.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Note 2 on page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ReCPE method, noting that it is too strategic and lacks strong theoretical guarantees. Additionally, it suggests that the authors could strengthen the article by addressing this issue. The minor comment about the spelling of \"real world\" in Note 2 is also specific, providing clear guidance on a minor correction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ReCPE method proposed in the article is too strategic and lacks strong theoretical guarantees. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The suggestion to strengthen the article by addressing this issue is somewhat helpful, but without detailed reasoning or evidence, the claim remains somewhat verifiable. The minor comment about the spelling of \"real word\" in Note 2 is factual and does not contribute to the overall assessment of the comment.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that the ReCPE method proposed is too strategic and lacks strong theoretical guarantees. It suggests that the authors could strengthen the article by addressing this issue. Additionally, it points out a minor spelling error in Note 2 on page 7. While the comment provides some insight into areas for improvement, it could be more helpful by offering specific suggestions or examples on how to strengthen the theoretical foundation of the ReCPE method. Overall, the comment is somewhat helpful as it highlights a critical area for improvement but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the applicability of the method beyond NLU tasks, specifically asking if it can be applied to generation tasks. While this question implies that the authors should consider this aspect, it does not provide explicit guidance or suggestions on how to address this question or what specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to consider the applicability of their method to generation tasks but are not given concrete steps to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the method beyond NLU tasks, specifically asking if it can be applied to generation tasks. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the applicability of the method, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking whether the method can be applied to generation tasks beyond NLU tasks. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the method beyond NLU tasks, specifically asking if it can be applied to generation tasks. This is a relevant inquiry that prompts the authors to consider the broader applicability of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this question or what aspects of the method might be relevant for generation tasks. While it points out an area for consideration, it does not offer actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that $N_d$ is not defined and suggests that it would be beneficial to state explicitly that there could be a different number of observations per task. This feedback provides a clear and direct action for the authors to take, which is to define $N_d$ and clarify the potential variation in observations per task. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.145ff,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of definition for $N_d$ and the potential variation in observations per task. This provides clear guidance on what needs to be clarified or added to the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"$N_d$ is not defined\" and suggests that it would be beneficial to state explicitly that there could be a different number of observations per task. This is a factual observation that highlights a potential oversight in the paper. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of defining $N_d$ and the potential implications of varying observations per task. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that $N_d$ is not defined and suggesting that it would be beneficial to state explicitly that there could be a different number of observations per task. This feedback is clear and actionable, as it provides a direct suggestion for clarifying the paper\\'s notation and potentially improving its clarity. By addressing this issue, the authors can enhance the readability and comprehensibility of their draft. However, the comment could be more helpful if it included additional context or examples to further explain the importance of defining $N_d$ or the implications of varying observations per task. Overall, the comment is mostly helpful, as it directs the authors toward a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a formatting issue with the appendix, noting that it is not cut from the main paper and that the PDF provided for the main paper is a 14-page document. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue, such as recommending a specific approach or suggesting a way to integrate the appendix more effectively into the main paper. Without actionable guidance, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a formatting issue with the appendix, specifically noting that it is not cut from the main paper and that the PDF provided for the main paper is a 14-page document. However, it does not specify which part of the paper this issue pertains to, such as the appendix section or the main paper. The authors can infer that it relates to the appendix, but the lack of explicit mention makes it weakly grounded. The comment is specific in detailing the issue with the formatting, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the appendix is not cut from the main paper and that the PDF provided for the main paper is a 14-page document. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a problem or how it affects the paper\\'s overall quality or readability. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a formatting issue with the appendix, noting that it is not cut from the main paper and that the PDF provided for the main paper is a 14-page document. While this feedback points out a potential problem, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue. Without detailed instructions or examples, the authors may find it challenging to understand and implement the necessary changes. Therefore, the comment is barely helpful, as it highlights a problem but does not offer a clear path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should \"throw light into\" the ternary potential's contribution to the proposed model's improvement. It highlights the importance of this contribution by pointing out that the model does not outperform existing models without the ternary potential, except for HieCoAtt. This feedback provides a clear and direct action for the authors to take, which is to further explore and emphasize the role of the ternary potential in their model. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the contribution of the ternary potential to the proposed model's improvement. The comment highlights the importance of this contribution by pointing out that the model does not outperform existing models without the ternary potential, except for HieCoAtt. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main improvement in the proposed model comes from the ternary potential, and that without this potential, the model does not outperform existing models for a two-modalities setup, except for HieCoAtt. The comment provides a logical reasoning by pointing out the significance of the ternary potential in the model's performance. However, it lacks specific examples or references to support the claim that the ternary potential is the primary contributor to the model's improvement. This makes the claim somewhat verifiable, as it provides a reasonable basis but could be strengthened with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the contribution of the ternary potential to the proposed model's improvement. It highlights that the model does not outperform existing models without the ternary potential, except for HieCoAtt. This feedback is valuable as it prompts the authors to further explore and explain the role of the ternary potential in their model, which could be a critical aspect for understanding its performance. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or what specific aspects of the ternary potential should be emphasized. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide information about which methods use data augmentations, what architecture they use, and what objective they focus on. This feedback is explicit and provides clear guidance on what additional details should be included to enhance the assessment of comparisons in the tables. The action is concrete, as it specifies exactly what information is needed, making it easy for the authors to understand and implement the suggestion. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing additional information about data augmentations, architectures, and objectives used in the methods listed in the tables. It does not specify which part of the paper this information should be included in, making it weakly grounded. However, it is specific in detailing what additional information would be helpful for assessing the comparisons in the tables. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide additional information about data augmentations, architectures, and objectives used in the methods listed in the tables. This is a request for clarification and does not contain subjective opinions, judgments, or claims that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the clarity and comprehensiveness of the tables. It suggests that the authors should note which methods use data augmentations, what architecture they use, and what objective they focus on. This feedback is clear and offers a concrete way for the authors to enhance the assessment of comparisons in the tables, which could improve the overall understanding and reproducibility of their work. By addressing this point, the authors can significantly improve the clarity and comprehensiveness of their tables, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the paper\\'s claims regarding the superiority of hyperpruning methods over state-of-the-art architectures, specifically mentioning the use of LSTM and LSH networks. It suggests that the PTB benchmark is small and questions whether the hyperpruning method would perform as well on more recent benchmarks and architectures. The comment implies that the authors should address these concerns by providing evidence or comparisons with more recent models. However, it does not explicitly instruct the authors to do so, leaving the action implicit. The comment is somewhat actionable as it provides a direction for improvement but lacks concrete guidance on how to execute it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"hyperpruning methods\" and \"LSTM and LSH networks,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises concerns about the paper\\'s claims regarding the superiority of hyperpruning methods over state-of-the-art architectures, suggesting that the PTB benchmark is too small and questioning the method\\'s performance on more recent benchmarks and architectures. The comment provides a clear direction for improvement by recommending comparisons with more recent models. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the paper\\'s claims regarding the superiority of hyperpruning methods over state-of-the-art architectures, specifically mentioning the use of LSTM and LSH networks. The reviewer questions the relevance of these architectures for language modeling and suggests that it would be interesting to see how LSH would perform on more recent state-of-the-art models. The comment also points out that the PTB benchmark is a small data set, which raises questions about the method\\'s performance on larger benchmarks. While the comment identifies potential issues and suggests further exploration, it lacks specific references or detailed evidence to fully substantiate the claims. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the critique but requires more detailed evidence or references to fully support the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s claims regarding the superiority of hyperpruning methods over state-of-the-art architectures, specifically questioning the relevance of the LSTM and LSH networks used in the study. It suggests that the PTB benchmark is a small data set and raises concerns about the method\\'s performance on more recent benchmarks and architectures. The comment provides a clear direction for improvement by recommending comparisons with more recent models and benchmarks. This feedback is actionable and offers a specific area for the authors to address, making it mostly helpful. However, it could be more comprehensive by suggesting specific models or benchmarks to use for comparison. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include more experimental details, specifically mentioning \"neural networks and hyperparameters used,\" in the appendix. This provides a clear and direct action for the authors to take, ensuring that they know exactly what information needs to be added to improve their draft. The comment is specific and provides concrete guidance on how to implement the suggested action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more experimental details, specifically mentioning \"neural networks and hyperparameters used,\" should be included in the appendix. However, it does not specify which part of the paper this information is currently lacking or where it should be added. This makes it weakly grounded, as the authors cannot confidently determine which section or sections need to be updated. The comment is specific in detailing what additional information is needed, but it lacks grounding in terms of identifying the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experimental details, specifically mentioning \"neural networks and hyperparameters used,\" should be included in the appendix. However, the comment does not provide any reasoning, examples, or references to support why these details are necessary or how they would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more experimental details, specifically mentioning \"neural networks and hyperparameters used,\" should be included in the appendix. This feedback is somewhat helpful as it identifies a potential area for improvement by recommending the inclusion of additional information that could enhance the transparency and reproducibility of the experiments. However, the comment lacks specific guidance on how to present this information or why it is important for the appendix. While it points out a potential weakness, it does not provide detailed suggestions or examples on how to address it, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Section 5.1 does not provide sufficient information regarding why the new model is superior. However, it does not explicitly instruct the authors to include this information or suggest how they might do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed justification for the superiority of the new model, but the comment does not offer specific guidance on what aspects should be addressed or how to present this information. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the section does not provide sufficient information regarding why the new model is superior. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Section 5.1 does not provide sufficient information regarding why the new model is superior. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Section 5.1, noting that it does not provide sufficient information regarding why the new model is superior. This feedback is somewhat helpful as it highlights a gap in the paper that the authors need to address to strengthen their argument. However, the comment lacks depth and does not offer specific suggestions or examples of what additional information could be included to improve the section. While it points out a potential weakness, it does not provide actionable guidance for the authors to address it. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the single-IMP might have transferability, but not as strong as the original IMP. It implies that a comparison is necessary to evaluate this transferability. However, it does not provide explicit instructions or concrete guidance on how to conduct this comparison or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison but are not given specific details on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the single-IMP might have transferability, but not as strong as the original IMP. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section, table, or figure. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in suggesting a comparison is necessary, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the single-IMP might have transferability, but not as strong as the original IMP. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the single-IMP might have transferability, but not as strong as the original IMP. It implies that a comparison is necessary to evaluate this transferability. However, the comment lacks specificity and does not provide any guidance on how to conduct this comparison or what aspects to focus on. Without actionable advice or detailed suggestions, the authors are left without a clear path for improvement. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider checking human-factors literature to address the practical challenges of interacting with humans. While the comment implies that the authors should conduct additional research, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct further research. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific concerns about ethical considerations and limitations of the proposed methods, particularly related to practical challenges in interacting with humans. It references \"No.03. 2020\" and \"weakness and other suggestions section,\" which provide some grounding by allowing the authors to identify the part of the paper being addressed. However, the comment does not specify what specific ethical concerns or limitations need to be addressed, making it weakly grounded. The authors can infer that the comment relates to the ethical implications of the proposed methods, but the lack of detailed guidance makes it under-specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are no specific ethical concerns with the proposed methods and that the limitations are related to practical challenges in interacting with humans. The reviewer supports this claim by mentioning specific limitations and suggesting that the authors should consider checking human-factors literature. However, the comment lacks detailed examples or references to specific ethical concerns or limitations, making it somewhat verifiable. The authors would need to infer the specific ethical concerns and limitations mentioned in the \"weakness and other suggestions section,\" which could be challenging without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the ethical implications of the proposed methods, noting that there are no specific ethical concerns mentioned. It also suggests that the authors should consider checking human-factors literature to address practical challenges in interacting with humans. While the comment highlights a potential gap in the paper\\'s ethical analysis, it lacks specific guidance on which ethical concerns or literature to consider. The feedback is somewhat helpful as it points out a potential area for improvement but does not provide detailed suggestions or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scalability of the proposed model selection approach beyond MNIST-like datasets and suggests comparing it with other neural network pruning methods. While the comment implies that the authors should address these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments to include other datasets and comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the scalability of the proposed model selection approach beyond MNIST-like datasets and suggests comparing it with other neural network pruning methods. However, it does not specify which part of the paper this question pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental results or methodology, but this inference is not direct. The comment is specific in its suggestion to expand the experiments and comparisons, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the scalability of the proposed model selection approach beyond MNIST-like datasets and suggests comparing it with other neural network pruning methods. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would impact the results. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary justification to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the scalability of the proposed model selection approach beyond MNIST-like datasets and suggests comparing it with other neural network pruning methods. This feedback is somewhat helpful as it identifies a potential limitation in the current study and suggests an area for further exploration. However, it lacks specific guidance or suggestions on how to address this limitation or conduct the comparisons. To be more helpful, the comment could provide specific examples of other datasets or methods to consider, or offer suggestions on how to evaluate the scalability of the approach. As it stands, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several mathematical formulation issues and inconsistencies in the paper, providing specific examples and suggestions for improvement. Each issue is clearly stated, with explicit guidance on how to address them. For instance, it points out that Line 345 should be \"$max$\" instead of \"$min$,\" and that Line 347 should use \"$i$-th objective\" instead of \"$j$.\" Additionally, it highlights inconsistent index notation, suggesting that $i$ should be used to index objective functions in Line 344, while in Line 374, $i$ represents time steps. The comment also questions the use of $x'$ in the hypervolume formula and suggests that Line 819 should be about a uniform distribution. These explicit and concrete suggestions provide clear guidance for the authors to improve the mathematical formulation and consistency of their paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides specific examples of mathematical formulation issues and inconsistencies, such as Line 345, Line 347, Line 344, Line 374, and Line 225. It also mentions the use of $x'$ in the hypervolume formula, which is redundant. Each of these examples is clearly identified, allowing the authors to pinpoint the exact parts of the paper that need attention. The comment is fully grounded as it specifies the exact lines and equations that need to be addressed, making it easy for the authors to understand and act upon the feedback. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review comment identifies specific mathematical formulation issues and inconsistencies in the paper, providing detailed examples of where the issues occur. These examples include Line 345, Line 347, Line 344, Line 374, and Line 225, along with explanations of the discrepancies. The comment also questions the use of $x'$ in the hypervolume formula, suggesting it is redundant. This level of detail and specificity provides a clear and robust basis for the claims, making the comment fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies several mathematical formulation issues and inconsistencies in the paper, providing specific examples and detailed guidance on how to address them. Each issue is clearly stated, with explicit suggestions for correction or clarification. For instance, it points out that Line 345 should be \"$max$\" instead of \"$min$,\" and that Line 347 should use \"$i$-th objective\" instead of \"$j$.\" Additionally, it highlights inconsistent index notation, suggesting that $i$ should be used to index objective functions in Line 344, while in Line 374, $i$ represents time steps. The comment also questions the use of $x'$ in the hypervolume formula and suggests that Line 819 should be about a uniform distribution. These detailed and actionable suggestions are highly beneficial to the authors, as they can directly apply the feedback to improve the clarity and accuracy of their mathematical formulations. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include experiments demonstrating the effect of using different numbers of particles. This feedback is explicit, as it directly instructs the authors to include such experiments. However, it does not provide specific guidance on how to design or conduct these experiments, leaving some room for interpretation. While the action is clear, the comment lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include experiments demonstrating the effect of using different numbers of particles. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what aspects of the experiments should be addressed or how the results would be interpreted. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should include experiments demonstrating the effect of using different numbers of particles. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include experiments demonstrating the effect of using different numbers of particles. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting an additional experiment that could provide insight into the importance of the particle choice. However, the comment lacks specific guidance on how to design or conduct these experiments, which would make it more actionable. By providing more detailed suggestions, the comment could be more helpful in guiding the authors towards enhancing their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks a comparison of the methods on plasticity evaluation metrics, specifically mentioning the covariance metric [1]. This provides a clear and direct action for the authors to take, which is to include a comparison of the methods on plasticity evaluation metrics, including the covariance metric. The comment is specific and provides a concrete action for the authors to implement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of comparison of methods on plasticity evaluation metrics, specifically referencing the covariance metric [1]. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison of methods on plasticity evaluation metrics. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric [1]. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, namely the absence of a comparison of methods on plasticity evaluation metrics, such as the covariance metric [1]. This feedback is clear and actionable, as it directs the authors to include a critical comparison that could enhance the paper\\'s contribution. However, the comment could be more helpful if it provided additional context or examples of how this comparison could be conducted or what specific aspects of plasticity should be evaluated. Despite this, the comment offers a valuable direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide better explanations for Table 5, specifically mentioning the need to clarify the meaning of A, B, C, and D in the table. It also suggests that there should be an explanation of why positive paths lead to monotonic solutions and under what scenarios. This feedback is clear and provides specific actions for the authors to take, such as clarifying the table and providing additional context. The explicit nature of the suggestions and the concrete details on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for better explanations of A, B, C, and D in Table 5 and the need for an explanation of why positive paths lead to monotonic solutions and under what scenarios. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of explanation in Table 5 and questions why positive paths lead to monotonic solutions under certain scenarios. While the comment identifies specific areas that need clarification, it does not provide detailed reasoning or examples to support the claim that these explanations are necessary. The lack of supporting evidence or examples makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is somewhat verifiable, as it highlights a potential issue but lacks the necessary detail to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires better explanation, namely Table 5. It points out the need for clarification on the meaning of A, B, C, and D in the table and questions why positive paths lead to monotonic solutions under certain scenarios. This feedback is clear and actionable, as it provides the authors with a concrete direction for improving the clarity and comprehensibility of their work. By addressing these points, the authors can enhance the understanding and accessibility of their results, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the long time it takes to obtain a single US accuracy and suggests exploring proxy/surrogate ways to estimate this metric more efficiently. It also questions the reliability of early predictions of US accuracy for model selection, as evidenced by the saturated curve in Figure 1. The reviewer provides specific references to the Appendix figures F6, F7, F8, and F9, which could be used to investigate this further. While the comment implies that the authors should explore these references and consider alternative methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific concerns about the long time it takes to obtain a single US accuracy and suggests exploring proxy/surrogate ways to estimate this metric more efficiently. It also questions the reliability of early predictions of US accuracy for model selection, based on the saturated curve in Figure 1. The comment references specific figures in the Appendix (F6, F7, F8, F9) to support its argument. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or discussions sections. The comment is specific in detailing the concerns and suggestions for improvement, making it fully grounded. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the long time it takes to obtain a single US accuracy and suggests exploring proxy/surrogate ways to estimate this metric more efficiently. It questions the reliability of early predictions of US accuracy for model selection, based on the saturated curve in Figure 1. The reviewer references specific figures in the Appendix (F6, F7, F8, F9) to support their argument. This provides a logical basis for the claim, but the comment could be strengthened by including more detailed reasoning or examples to fully substantiate the suggestion. Therefore, the comment is somewhat verifiable, as it provides a foundation for the claim but lacks comprehensive evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical concern about the long time it takes to obtain a single US accuracy, suggesting that there may be a need to explore proxy/surrogate ways to estimate this metric more efficiently. It also questions the reliability of early predictions of US accuracy for model selection, based on the saturated curve in Figure 1. The reviewer provides specific references to the Appendix figures F6, F7, F8, and F9, which could be used to investigate this further. This feedback is clear and actionable, as it prompts the authors to consider alternative methods for estimating US accuracy and evaluating its reliability. However, the comment could be more helpful if it offered additional guidance or suggestions on how to implement these changes. Overall, the comment is mostly helpful, as it provides valuable insights and direction for the authors to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to conduct ablation studies to isolate the impact of specific factors underlying epsilon sampling's strong performance. This feedback is clear and provides a direct action for the authors to take, ensuring that they know exactly what is expected of them. The suggestion is concrete, as it specifies the type of analysis needed and the purpose of the ablation studies. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting ablation studies to isolate the impact of specific factors underlying epsilon sampling's strong performance. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where these studies should be conducted. This lack of grounding makes it difficult for the authors to identify the exact area needing attention. Additionally, the comment lacks specificity regarding which factors should be isolated or how the ablation studies should be conducted. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests conducting ablation studies to isolate the impact of specific factors underlying epsilon sampling's strong performance. However, it does not provide any supporting evidence, reasoning, or examples to justify why these studies are necessary or how they would improve the understanding of the factors contributing to the performance. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting ablation studies to isolate the impact of specific factors underlying epsilon sampling's strong performance. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by conducting additional analyses. By doing so, the authors can gain a deeper understanding of the factors contributing to the performance of their method. However, the comment could be more helpful if it included suggestions on which factors to focus on or how to design the ablation studies. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate the proposed attack against the mode connectivity-based defense proposed in the ICLR paper. While the comment implies that the authors should conduct this evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this evaluation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the ICLR publication \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely evaluating the proposed attack against the mode connectivity-based defense proposed in the ICLR paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the effectiveness of Fine-Tuning in recovering backdoor models, referencing the ICLR publication \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness.\" However, the comment does not provide specific details or evidence from the referenced work to support this claim. It suggests that the authors should evaluate the proposed attack against the mode connectivity-based defense proposed in the ICLR paper, but this suggestion lacks specific guidance or justification. Therefore, the comment is considered borderline verifiable, as it provides a direction for improvement but lacks detailed support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors evaluate the proposed attack against the mode connectivity-based defense proposed in the ICLR paper. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their work by incorporating an additional evaluation. However, the comment could be more helpful if it offered specific guidance on how to conduct this evaluation or what aspects of the defense should be considered. Despite this, the feedback is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors\\' decision not to include the codes during the review process makes their claims less transparent. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue, such as suggesting the inclusion of the codes or explaining the reasoning behind their decision. The comment lacks actionable guidance, leaving the authors uncertain about how to improve the transparency of their claims. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of the authors\\' decision not to include the codes during the review process, which affects the transparency of their claims. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the codes are discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue of transparency but lacks grounding, as it does not explicitly mention which part of the paper is being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' decision not to include the codes during the review process makes their claims less transparent. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the transparency of the authors\\' claims, noting that the decision not to include the codes during the review process affects the clarity of their claims. This feedback is somewhat helpful as it highlights an area where the paper could be improved in terms of transparency and accountability. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as suggesting ways to make the code more accessible or explaining the rationale behind the decision. While it points out a potential weakness, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors validate their proposed approach in Waymax, which provides more traffic scenarios than the current version. This feedback implies that the authors should conduct additional validation experiments using Waymax, which is a specific action for the authors to take. However, the comment does not provide detailed guidance on how to conduct these experiments or what specific aspects to focus on. While the action is implicit, it is concrete because it specifies the need for validation in Waymax and provides a rationale for why it is important. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors validate their proposed approach in Waymax, which provides more traffic scenarios than the current version. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental setup or validation section, but this inference is not direct. The comment is specific in recommending the use of Waymax for validation, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors validate their proposed approach in Waymax, which provides more traffic scenarios than the current version. This claim is somewhat verifiable as it provides a logical reasoning for why additional validation is needed. However, the comment lacks specific examples or references to support the claim that Waymax provides more scenarios, making it somewhat verifiable. The authors would need to infer the significance of Waymax and its potential impact on the validation process. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for the authors to validate their proposed approach in Waymax, which offers more traffic scenarios than the current version. This feedback is actionable and constructive, as it encourages the authors to expand their validation efforts to a more comprehensive platform. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific aspects to focus on. Despite this, the feedback is mostly helpful as it directs the authors to a potential area for improvement and offers a clear direction for enhancing their work. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the technical contribution of the paper, suggesting that the transformer-based TAPG method has been studied in previous works, such as RTD-Net (ICCV2021). It points out that the main difference between RTD-Net and the proposed method lies in the visual features, and that the paper considers 3D pose and action features obtained by Laban Movement Analysis (LMA). However, the reviewer questions whether the addition of these features is significant enough to bring new insights to the community. While the comment identifies a potential issue with the novelty of the contribution, it does not provide explicit guidance on how the authors might address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide more justification for the significance of their technical contribution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the technical contribution of the paper, suggesting that the transformer-based TAPG method has been studied in previous works, such as RTD-Net (ICCV2021). It points out that the main difference between RTD-Net and the proposed method lies in the visual features, and that the paper additionally considers 3D pose and action features obtained by Laban Movement Analysis (LMA). However, the reviewer questions whether the addition of these features is significant enough to bring new insights to the community. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the technical contribution and methodology sections. The comment is specific in detailing what is lacking in the paper, making it fully grounded. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical contribution of the paper is not significant, as the transformer-based TAPG method has been studied in previous works, such as RTD-Net (ICCV2021). The reviewer suggests that the main difference between RTD-Net and the proposed method lies in the visual features, and that the paper additionally considers 3D pose and action features obtained by Laban Movement Analysis (LMA). However, the reviewer questions whether the use of additional features could improve performance, implying that the contribution is not novel. The comment provides some reasoning by referencing previous work, but it lacks specific examples or detailed evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some basis for the claim but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the technical contribution of the paper, suggesting that the transformer-based TAPG method has been studied in previous works, such as RTD-Net (ICCV2021). It points out that the main difference between RTD-Net and the proposed method lies in the visual features, and that the paper additionally considers 3D pose and action features obtained by Laban Movement Analysis (LMA). However, the reviewer questions whether the addition of these features is significant enough to bring new insights to the community, as LMA has been proven effective in dance action recognition. While the comment identifies a potential weakness in the novelty of the contribution, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their draft. The feedback is somewhat helpful as it highlights an area for improvement, but it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the implementation of tree construction requires more experimental comparisons to explore the different design choices of merging nodes among adjacent layers. While the comment implies that the authors should conduct more experiments, it does not provide specific guidance on which comparisons to conduct or how to structure these experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the implementation of tree construction requires more experimental comparisons to explore the different design choices of merging nodes among adjacent layers. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where these comparisons are discussed. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in its suggestion for additional experiments, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the implementation of tree construction requires more experimental comparisons to explore the different design choices of merging nodes among adjacent layers. However, the comment does not provide specific examples or detailed reasoning to support why these comparisons are necessary or how they would benefit the paper. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the implementation of tree construction, suggesting that the different design choices of merging nodes among adjacent layers require more experimental comparisons. This feedback is clear and actionable, as it directs the authors to expand their experimental analysis to provide a more comprehensive understanding of the design choices. However, the comment could be more helpful if it offered specific suggestions on which comparisons to conduct or how to structure these experiments. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that Table 2 in the paper is incomplete and mentions the existence of baselines that outperform it, as reported in the Re-BART paper. It suggests that the paper should report these baselines for completeness, even though their results are slightly weak. This feedback provides a clear and direct action for the authors to take, which is to include the missing baselines in Table 2 and acknowledge their results. The comment is explicit and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and provides a specific issue with the table, namely that it is incomplete because it does not report certain baselines that outperform it. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of these baselines in Table 2 and acknowledgment of their results, even though they are slightly weak. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 2 in the paper is incomplete because it does not report certain baselines that outperform it. The reviewer supports this claim by referencing the Re-BART paper, where these baselines are reported. This provides a clear and specific example of what is missing from the table, making the claim verifiable. The suggestion to include these baselines is logical and actionable, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how these baselines are relevant to the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 2 in the paper, noting that it is incomplete because it does not report certain baselines that outperform it. The reviewer suggests that these baselines are reported in the Re-BART paper and should be included in the table for completeness. This feedback is clear and actionable, as it provides the authors with a concrete step to improve their draft by adding missing information. However, the comment could be more helpful if it offered additional context or suggestions on how to present this information effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the thoroughness of the evaluations on real datasets, specifically questioning why only three scenes are chosen from the HS-ERGB dataset and suggesting that the performance on other sequences should be considered. While the comment implies that the authors should expand their evaluation to include more scenes, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the thoroughness of the evaluations on real datasets, specifically questioning why only three scenes are chosen from the HS-ERGB dataset and suggesting that the performance on other sequences should be considered. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in its request for more thorough evaluations, but without explicit references to sections or specific scenes, the authors may struggle to identify the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the thoroughness of the evaluations on real datasets, specifically questioning why only three scenes are chosen from the HS-ERGB dataset and suggesting that the performance on other sequences should be considered. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the current evaluation is insufficient or how it could be improved. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid point about the thoroughness of the evaluations on real datasets, specifically questioning why only three scenes are chosen from the HS-ERGB dataset and suggesting that the performance on other sequences should be considered. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper\\'s evaluation section. However, the comment lacks specific suggestions or guidance on how to expand the evaluation to include more sequences or how to address the issue of limited scene selection. While it prompts the authors to consider broadening their evaluation, it does not provide actionable steps or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of 44 bits and suggests that there is plenty of room to use more bits. It also questions the interpretation of bit-embeddings, noting that the model is predicting the rank of words but not necessarily their semantic relations. While the comment identifies areas for potential improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The authors are left to infer that they should consider using more bits and exploring the implications of the model's predictions. The lack of concrete steps or detailed suggestions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific concerns about the use of 44 bits and the interpretation of bit-embeddings, suggesting that there is plenty of room to use more bits and questioning the model's ability to predict semantic relations. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the use of 44 bits and the interpretation of bit-embeddings, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the use of 44 bits and suggests that there is plenty of room to use more bits. It also questions the interpretation of bit-embeddings, noting that the model is predicting the rank of words but not necessarily their semantic relations. The reviewer provides logical reasoning by pointing out that the model's power might be the reason for this behavior, but the comment lacks specific examples or references to support the claim about the interpretation of bit-embeddings. This makes the claim somewhat verifiable, as it provides some reasoning but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several concerns about the use of 44 bits and the interpretation of bit-embeddings. It questions the interpretation of the model's predictions, suggesting that the model might be predicting the rank of words rather than their semantic relations. This feedback is somewhat helpful as it identifies a potential issue with the model's interpretation and suggests that the authors should explore this further. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their analysis. To be more helpful, the comment could provide examples of how other models handle similar issues or offer specific recommendations for how the authors might clarify the interpretation of their results. As it stands, the feedback provides some insight but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the practical use of the method, specifically the need for human annotation to provide semantically meaningful information. It notes that the authors mention this limitation in the appendix but do not provide a solution for mitigation. While the comment identifies a gap in the paper, it does not explicitly instruct the authors on how to address this issue or suggest specific steps to mitigate the need for human annotation. The action is implicit and somewhat vague, as the authors need to infer that they should consider providing a solution for mitigation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"method\" and the \"appendix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the method, namely the need for human annotation to provide semantically meaningful information, and points out that the authors mention this limitation in the appendix but do not provide a solution for mitigation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed solution to provide semantically meaningful information requires human annotation, which can be subjective. The reviewer notes that the authors mention this limitation in the appendix but do not provide a solution for mitigation. This claim is somewhat verifiable as it highlights a potential issue with the method and references the appendix for further information. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the practical use of the method, specifically the need for human annotation to provide semantically meaningful information. It points out that the authors mention this limitation in the appendix but do not provide a solution for mitigation. This feedback is somewhat helpful as it highlights a gap in the paper that the authors should address to enhance the practicality of their method. However, the comment could be more helpful if it suggested specific ways to mitigate the need for human annotation or provided examples of alternative approaches. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests two actions for the authors: pretrain a CausalLM using a specific dataset and compare its performance against ObscuraCoder to attribute any improvements to the deobfuscation objective. While the actions are explicit, the comment lacks concrete details on how to implement these tasks, such as which dataset to use or how to compare performance. The authors are left with a general idea of what needs to be done but without specific guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests two actions: pretraining a CausalLM using a specific dataset and comparing its performance against ObscuraCoder to attribute any improvements to the deobfuscation objective. However, it does not specify which part of the paper these actions should be addressed in, making it weakly grounded. The comment is specific in detailing what needs to be done, such as pretraining a CausalLM and comparing performance, but lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests two actions: pretraining a CausalLM using a specific dataset and comparing its performance against ObscuraCoder to attribute any improvements to the deobfuscation objective. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these actions are necessary or how they would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of these suggestions. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides two specific actions for the authors to take: pretrain a CausalLM using a specific dataset and compare its performance against ObscuraCoder to attribute any improvements to the deobfuscation objective. These suggestions are clear and actionable, offering a direct path for the authors to enhance their draft. However, the comment could be more helpful if it provided additional context or rationale for why these actions are necessary or how they might impact the paper\\'s conclusions. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the geometric loss should be added to the reconstruction loss, rather than itself, in the loss equation shown in L264-L266. This is a clear and direct action that the authors can take to correct the mistake. The comment provides concrete guidance on how to implement the correction, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L264-L266,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the addition of the geometric loss to the reconstruction loss in the loss equation. This provides clear guidance on how to address the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the loss equation in L264-L266 has an issue with the geometric loss being included in itself. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the loss equation in the paper, noting that the geometric loss should be added to the reconstruction loss rather than itself. This is a clear and actionable suggestion that can help the authors improve the accuracy and clarity of their work. By addressing this issue, the authors can enhance the robustness and interpretability of their results. However, the comment could be more helpful if it provided additional context or explanation on why this correction is necessary or how it might impact the overall analysis. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method of MLM should be employed in autoregressive language models, which are used more in real-world applications. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to implement this suggestion or what specific steps to follow. The authors are left without any clear direction on how to incorporate this suggestion into their work. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method of MLM should be employed in autoregressive language models, which are used more in real-world applications. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to incorporate MLM in autoregressive language models, but without explicit references to sections or details, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method of MLM should be employed in autoregressive language models, which are more commonly used in real-world applications. However, the comment does not provide any supporting evidence, examples, or references to justify why this is important or how it would benefit the paper. Without additional context or reasoning, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the method of MLM should be employed in autoregressive language models, which are more commonly used in real-world applications. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how to incorporate this suggestion into the paper. The comment does not offer detailed reasoning or examples of how MLM could benefit autoregressive language models, nor does it suggest how the authors might integrate this suggestion into their work. As a result, the comment is somewhat helpful, as it points out a potential area for improvement but does not provide sufficient guidance for the authors to act upon.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors claim the GAN is difficult to optimize and use adversarial gradient updating, but it does not provide a clear explanation of why the proposed idea is better than GAN. Additionally, it notes that the method section lacks discussion on how to avoid the issue of vanishing gradient and model collapsing. While the comment identifies areas for improvement, it does not offer specific guidance on how to address these issues or what aspects of the method should be expanded upon. The actions are implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations and examples to support their claims. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific claims made by the authors regarding the difficulty of optimizing and using adversarial gradient updating with a GAN, as well as the lack of discussion on how to avoid issues like vanishing gradient and model collapsing. However, it does not specify which part of the paper these claims are made in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for more explanation and discussion on these topics. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that the GAN is difficult to optimize and use adversarial gradient updating, suggesting that the proposed idea is not better than GAN. It also notes the lack of discussion on how to avoid issues like vanishing gradient and model collapsing in the method section. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support the claim that the proposed idea is not better than GAN. The lack of specific examples or detailed justification makes the claim somewhat verifiable, as the authors would need to infer the need for more detailed explanations and examples to address the reviewer\\'s concerns.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the claim that the GAN is difficult to optimize and use adversarial gradient updating. It points out that the authors have not provided a clear explanation of why their proposed idea is better than GAN, which is a crucial aspect of the paper. Additionally, the comment highlights the lack of discussion on how to avoid issues like vanishing gradient and model collapsing in the method section. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations and examples to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or what additional information should be included in the method section. Overall, the comment is mostly helpful as it provides valuable insights and guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the design of the ablation study, specifically asking why the ablations are conducted on BART and BART+Longformer instead of the original model, GraphSum. While the comment implies that the authors should reconsider their choice of models for the ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their model selection but may not know exactly how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study\" and specifies the models involved, \"BART and BART+Longformer,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of models for the ablation study, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of models for the ablation study, specifically asking why the ablations are conducted on BART and BART+Longformer instead of the original model, GraphSum. While the comment raises a valid point about the selection of models, it lacks specific reasoning or evidence to support why this choice might be problematic or inappropriate. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered borderline verifiable, as it provides a logical question but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of models for the ablation study, specifically questioning why the ablations are conducted on BART and BART+Longformer instead of the original model, GraphSum. This feedback is valuable as it prompts the authors to reconsider their model selection, which could potentially impact the validity and relevance of the ablation results. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as discussing the potential advantages or disadvantages of using different models. Despite this, the comment is mostly helpful as it directs the authors\\' attention to a critical aspect of their study that requires further consideration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the previous report of SciBERT was removed, which exacerbates a problem in the earlier version where the analyses of the outcomes of the models were cursory and unsupported by deeper analyses. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest how the authors should address this issue or what specific changes should be made to improve the analysis. As a result, the authors are left without any guidance on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the removal of the previous report of SciBERT and the issue of cursory and unsupported analyses of model outcomes in the earlier version. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. The comment also suggests that the current paper does not mention this issue, but it does not provide specific guidance on how to address this lack of mention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the previous report of SciBERT was removed, which exacerbates a problem in the earlier version where the analyses of the outcomes of the models were cursory and unsupported by deeper analyses. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue. The lack of detailed reasoning or evidence makes it challenging for the authors to address the claim effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed information to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the removal of the previous report on SciBERT, which may have contributed to the earlier problem of cursory and unsupported analyses of model outcomes. However, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. The comment also notes that the current paper does not mention this problem, which further highlights the need for action. While the comment raises an important point, it lacks actionable feedback that would help the authors improve their draft. Therefore, it is somewhat helpful, as it provides insight but not comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the clarity of the \"Functional connectivity encoder\" section, specifically questioning the origin of the connectivity graph $\\\\cal{G}_{F}$ and the source of patches and their mixing process. While the comment identifies areas that need clarification, it does not provide explicit guidance on how the authors should address these issues. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations but may not know exactly how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Functional connectivity encoder\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by questioning the origin of the connectivity graph $\\\\cal{G}_{F}$ and the source of patches and their mixing process, providing clear guidance on what needs to be clarified. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the origin of the connectivity graph $\\\\cal{G}_{F}$ and the source of patches and their mixing process, indicating a lack of clarity in the \"Functional connectivity encoder\" section. However, the comment does not provide specific examples or references to support the claim that these aspects are unclear. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the origin of the connectivity graph $\\\\cal{G}_{F}$ and the source of patches and their mixing process in the \"Functional connectivity encoder\" section. This feedback is clear and actionable, as it points out specific areas where the authors need to provide more detailed explanations or clarification. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of how similar concepts have been addressed in other works. Despite this, the feedback is mostly helpful as it directs the authors to a critical area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a longer discussion of related work, particularly in the context of pruning, which is a significant field. While the comment implies that the paper could benefit from such a discussion, it does not explicitly instruct the authors to include it. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion of related work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the Figure 4(b) plot, suggesting that the proposed method does not necessarily result in faster training due to the same number of epochs for all networks. It also mentions the field of pruning and suggests a longer discussion of related work. However, the comment does not specify which part of the paper Figure 4(b) is located in, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its critique of the plot and the need for a longer discussion of related work, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that Figure 4(b) indicates faster training results with the proposed method. It suggests that the claim is far-fetched, given that all networks are trained for the same number of epochs. The reviewer also mentions the field of pruning, implying that the paper could benefit from a longer discussion of related work. While the comment provides some reasoning, it lacks specific examples or references to support the claim that the method does not result in faster training. The lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to further substantiate the claim themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper's argument regarding the Figure 4(b) plot, suggesting that the claim of faster training with the proposed method is not fully substantiated. It points out that all networks are trained for the same number of epochs, which could make the claim far-fetched. The reviewer also suggests that the paper would benefit from a longer discussion of related work in the field of pruning. While the comment provides some insight into areas that need improvement, it lacks specific suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it highlights potential weaknesses but could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific error in the derivative calculation of the Lagrangian, noting that the correct derivative should be -1/2n^{-3/2} rather than 1/2n^{-3/2}. This provides a clear and concrete action for the authors to take, as they are instructed to correct the calculation. The comment is explicit and provides a precise correction, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"derivative of the 'Lagrangian'\" and the specific calculation involving \"n^{-1/2}\", allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the correct calculation for the derivative, providing a clear direction for the authors to make a correction. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the derivative of the Lagrangian is incorrect, specifically stating that the correct derivative should be -1/2n^{-3/2} instead of 1/2n^{-3/2}. The reviewer supports this claim by providing the correct calculation, which is a clear and logical correction. This makes the claim verifiable, as it is based on a specific, correct calculation that can be easily verified by the authors. Therefore, the comment is labeled as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific error in the calculation of the derivative of the Lagrangian, noting that the correct value should be -1/2n^{-3/2} instead of 1/2n^{-3/2}. This is a clear and actionable feedback that the authors can easily address by correcting the calculation. However, the comment does not provide additional context or explanation about why this error occurred or how it might affect the overall understanding or interpretation of the results. While it is helpful in pointing out the mistake, it could be more beneficial if it included suggestions for how to prevent similar errors in the future. Therefore, the comment is rated as somewhat helpful, as it provides a clear and actionable suggestion but lacks depth and context.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper is not clear, particularly in the introduction section, where background information about cognitive models is lacking. It suggests that the authors may need to refine their writing to improve clarity. While the comment identifies an issue, it does not provide explicit guidance on how to address it, such as suggesting specific areas to expand or improve. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the clarity of their writing but are not given concrete steps to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of background information about cognitive models in the introduction. This provides clear guidance on what the authors need to improve to enhance the clarity of their writing. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not clear, particularly in the introduction section, where background information about cognitive models is lacking. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, particularly in the introduction section, where background information about cognitive models is lacking. It suggests that the authors may need to refine their writing to improve clarity. While the comment highlights an area for improvement, it does not provide detailed guidance or examples on how to enhance the clarity of the paper. The feedback is somewhat helpful as it points out a potential weakness but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the performance of DFA and backprop on the NLP task, suggesting that the authors should emphasize this difference more clearly. However, it does not provide explicit instructions or concrete suggestions on how to address this issue. The authors are left to infer that they need to emphasize the performance gap, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"NLP task,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in performance between DFA and backprop on this task and suggests that this issue is not adequately emphasized in the paper. The comment provides clear guidance on what needs to be addressed, namely, the need to emphasize the performance gap between DFA and backprop on the NLP task. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of DFA on the NLP task is significantly behind that of backprop, which is not adequately emphasized in the paper. The comment provides a specific observation about the performance gap and suggests that the abstract gives a misleading impression of DFA\\'s performance. However, the comment lacks detailed evidence or references to support the claim, making it somewhat verifiable. The authors would need to verify the claim themselves by examining the data or references provided to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s presentation of results, particularly regarding the performance of DFA on the NLP task compared to backprop. It points out that the abstract gives an inaccurate impression of DFA\\'s performance, suggesting that it works at near-backprop levels on this task, which is not the case. This feedback is valuable as it highlights a potential misrepresentation in the paper\\'s claims and encourages the authors to clarify or adjust their results to accurately reflect the performance of DFA. However, the comment could be more helpful if it provided suggestions on how to address this issue or improve the presentation of results. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical area needing clarification or correction.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the baseline for dimensional reduction methods in optimal transport estimation is lacking, specifically mentioning SRW and FROT as examples that should be included. This provides a clear and direct action for the authors to take, which is to include these methods as baselines in their analysis. The comment is specific and provides concrete guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the baseline is lacking, especially for the dimensional reduction methods in optimal transport estimation,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that SRW and FROT, as mentioned in the paper, should be included as baselines. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the baseline for dimensional reduction methods in optimal transport estimation is lacking, specifically mentioning SRW and FROT as examples that should be included. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these methods are essential or how they would improve the analysis. Without additional context or explanation, the claim remains somewhat verifiable, as it lacks detailed justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the baseline methods used in the paper, particularly for dimensional reduction methods in optimal transport estimation. It suggests that SRW and FROT, as mentioned in the paper, should be included as baselines. This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance their analysis and improve the robustness of their results. However, the comment could be more helpful if it explained why these methods are important or how they might impact the analysis. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not discuss the advantages and disadvantages of transductive learning. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this omission or what specific aspects of transductive learning should be discussed. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the paper does not discuss the advantages and disadvantages of transductive learning, but it does not specify which part of the paper this omission is in. The authors cannot confidently determine whether it relates to a specific section, figure, or discussion. Additionally, the comment lacks specificity regarding what aspects of transductive learning should be discussed or how the omission affects the paper. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper does not discuss the advantages and disadvantages of transductive learning. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a gap in the paper, specifically noting that the advantages and disadvantages of transductive learning are not discussed. This feedback is somewhat helpful as it points out an area where the paper could be expanded or clarified. However, it lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this omission. Without detailed advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to formally state the invariance of the contractivity. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a formal statement about the invariance of contractivity. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it would be beneficial to have the invariance of the contractivity stated formally. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where this information is discussed. This lack of specificity makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment lacks grounding as it does not explicitly mention a section or part of the paper, making it challenging for the authors to address the feedback effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that it would be beneficial to have the invariance of the contractivity stated formally. However, it does not provide any reasoning, examples, or references to support why this is important or how it would enhance the paper. Without additional context or justification, the claim is not verifiable, as it lacks the necessary information to guide the authors in understanding the significance of this suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that it would be beneficial to formally state the invariance of the contractivity, which could enhance the clarity and rigor of the paper. However, the comment lacks specificity and does not provide detailed guidance on how to achieve this or why it is important. Without further explanation or examples, the authors may find it challenging to understand the exact improvements needed or how to implement them effectively. Therefore, the feedback is somewhat helpful, as it identifies a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the contribution of uncertainty saliency maps, noting that without an application or evaluation, their significance is unclear. It also challenges the assertion that uncertainty/confidence generated from the same mechanism that generated the explanation is more trustworthy than the explanation itself. However, the comment does not provide explicit guidance on how the authors should address these concerns or improve their draft. It lacks concrete suggestions or actionable steps for the authors to take, leaving them without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the potential contribution of uncertainty saliency maps and questions their significance without an application or evaluation. It also challenges the assertion that uncertainty/confidence generated from the same mechanism that generated the explanation is more trustworthy than the explanation itself. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in its critique of the contribution and the trustworthiness of the uncertainty/confidence generated, but without clear grounding, it is difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the significance of the contribution of uncertainty saliency maps without an application or evaluation, and challenges the assertion that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The authors are left without clear guidance on how to address the concerns or improve their draft. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the contribution of uncertainty saliency maps, noting that without an application or evaluation, their significance is unclear. It also challenges the assertion that uncertainty/confidence generated from the same mechanism that generated the explanation is more trustworthy than the explanation itself. This feedback is somewhat helpful as it highlights a critical area for improvement in the paper, specifically regarding the evaluation and application of the proposed method. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. While it points out a potential weakness, it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the importance of using the diffusion model in style transfer, asking what unique benefits it provides compared to other methods. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification for the use of the diffusion model. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the importance of using the diffusion model in style transfer, asking what unique benefits it provides compared to other methods. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for an explanation of the benefits of using the diffusion model, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the importance of using the diffusion model in style transfer, asking what unique benefits it provides compared to other methods. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the diffusion model is essential. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the importance of using the diffusion model in style transfer, specifically asking what unique benefits it provides compared to other methods. This is a valuable point that could prompt the authors to reconsider the rationale behind their choice of method or to provide a more comprehensive discussion of its advantages. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what aspects of the diffusion model should be emphasized. While it identifies a potential area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a discussion or comparison with related work would enhance the understanding of the multi-view approach. While it implies that the authors should include such a discussion or comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion or comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a discussion or comparison with related work would enhance the understanding of the multi-view approach. However, it does not specify which part of the paper this discussion should be included in, such as the \"Related Work\" section or a particular section discussing the methodology. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a potential enhancement but lacks full grounding as it does not pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the multi-view latent attack enhances the model's meta generalizability to some extent, which leads to better performance in the cross-domain setting compared to other adversarial meta-learning methods. The reviewer supports this claim by comparing the multi-view approach to task augmentation meta-learning methods, suggesting that a discussion or comparison in the related work section would enhance understanding. However, the comment lacks specific references or detailed comparisons to specific methods or studies, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a logical reasoning but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for enhancing the paper by suggesting a discussion or comparison with related work. It highlights the potential benefits of including such a section, as it could enhance the understanding of the multi-view approach and its effectiveness in the cross-domain setting. This feedback is actionable and offers a clear direction for the authors to improve their draft, making it mostly helpful. However, it could be more helpful if it included specific references or examples of related work that would be relevant for comparison. Overall, the comment is clear and provides a valuable suggestion for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific omission in the paper, noting that the impact of Age and FaceID features is not studied in the ablation. However, it does not provide any guidance or suggestions on how the authors should address this omission. The comment lacks explicit instructions or concrete steps for the authors to take, leaving them uncertain about how to proceed. As a result, the action is implicit and vague, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions the absence of an analysis of the impact of Age and FaceID features in the ablation, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspects of the impact should be studied or how the analysis should be conducted. This makes the comment specific about the issue but lacks detailed guidance on how to address it. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the impact of Age and FaceID features is not studied in the ablation. However, it does not provide any supporting evidence, reasoning, or references to justify why this omission is significant or problematic. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary justification to guide the authors in addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, noting that the impact of Age and FaceID features is not studied in the ablation. This feedback is clear and actionable, as it points out a gap in the experimental analysis that the authors should address to improve the comprehensiveness of their work. However, the comment could be more helpful if it provided suggestions on how to study the impact or what specific aspects of Age and FaceID features should be considered. Despite this, the feedback is mostly helpful as it directs the authors\\' attention to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to move the detailed discussion from the appendix to the main manuscript, specifically mentioning Table 2 and Fig. 5. It also asks for clarification on the values in Table 2 and Fig. 5, providing clear guidance on what needs to be done. The action is explicit and concrete, as it specifies where the discussion should be placed and what needs to be clarified. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Fig. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for clarification on the values in Table 2 and Fig. 5 and suggests moving the detailed discussion from the appendix to the main manuscript. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the absence of Table 2 and Fig. 5 in the manuscript and asks for clarification on the values in Table 2 and Fig. 5. It also suggests moving the detailed discussion from the appendix to the main manuscript. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claim that these elements are necessary or important for the paper. The suggestion to move the discussion is logical but could be strengthened with more detailed justification. Therefore, the comment is somewhat verifiable, as it provides a clear direction but lacks comprehensive evidence or explanation.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, noting the absence of Table 2 and Fig. 5 in the main text and questioning the values in Table 2. It also suggests moving the detailed discussion from the appendix to the main manuscript, which could improve the clarity and coherence of the paper. While the comment highlights an important oversight, it lacks depth and does not provide detailed guidance on how to address these issues or why they are significant. The feedback is somewhat helpful as it points out a specific area for improvement but could be more comprehensive to be fully helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors should include more results related to LLMs, specifically mentioning llama-3-70B, Mistral-7B, and other models. This feedback provides a clear and concrete action for the authors to take, as it specifies exactly what additional results are expected and why they are important. The comment is explicit and provides specific guidance on how to enhance the paper\\'s experimental results, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction, where the author states the main purpose of the Lorta method. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what additional LLM-related results are expected, such as llama-3-70B, Mistral-7B, and other models. This provides clear guidance on what the authors need to address to improve their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks LLM-related results, specifically mentioning llama-3-70B, Mistral-7B, and other models. The reviewer expects more experiments on these models to demonstrate the efficiency of the Lorta method. However, the comment does not provide specific reasoning or evidence to support why these additional experiments are necessary or how they would enhance the paper\\'s contribution. The lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the importance of these additional experiments themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of LLM-related results in the paper, particularly mentioning models like llama-3-70B and Mistral-7B. It provides a clear and actionable suggestion for the authors to include more experiments on these models to demonstrate the efficiency of the Lorta method. This feedback is valuable as it directs the authors to enhance their experimental results, which could significantly impact the paper\\'s contribution and relevance. However, the comment could be more helpful if it offered additional guidance on how to interpret or analyze these results, such as specific metrics or analysis techniques. Overall, the comment is mostly helpful as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the proposed \"Depth First Search-based Decision Tree\" (DFSDT) technique, noting its similarity to self-consistency + CoT and Tree-of-thoughts. It also questions how DFSDT will perform for other types of LLMs not in the category of LLaMA / GPT / Claude. While the comment identifies potential issues, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their work. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the novelty and applicability of DFSDT, but the comment does not offer specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed \"Depth First Search-based Decision Tree\" (DFSDT) technique and its performance compared to ReAct prompting. It also questions how DFSDT will perform for other types of LLMs not in the category of LLaMA / GPT / Claude. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology or results sections where these techniques are discussed. The comment is specific in detailing what needs to be addressed, such as the novelty and applicability of DFSDT, and how it relates to other techniques. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the proposed \"Depth First Search-based Decision Tree\" (DFSDT) technique, noting its similarity to self-consistency + CoT and Tree-of-thoughts. It also questions how DFSDT will perform for other types of LLMs not in the category of LLaMA / GPT / Claude. While the comment identifies potential issues, it lacks specific examples or references to support the claim that DFSDT is similar to self-consistency + CoT or Tree-of-thoughts. Additionally, it does not provide evidence or reasoning to substantiate the claim about its performance on other LLMs. Therefore, the comment is somewhat verifiable, as it highlights potential issues but lacks detailed justification or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed \"Depth First Search-based Decision Tree\" (DFSDT) technique, noting its similarity to self-consistency + CoT and Tree-of-thoughts. It also questions how DFSDT will perform for other types of LLMs not in the category of LLaMA / GPT / Claude. This feedback is somewhat helpful as it highlights a potential limitation of the proposed technique and raises a relevant question about its applicability. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these concerns or expand their work. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that it is inappropriate to propose an identical method while claiming originality, and it suggests that acknowledging people's contributions in a proper way is important. However, it does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The comment lacks concrete details on what changes should be made or how to acknowledge contributions, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of proposing an identical method while claiming originality, which is specific to the paper\\'s methodology or results section. However, it does not explicitly mention which part of the paper this issue pertains to, such as a specific section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the claim of originality, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that it is inappropriate to propose an identical method while claiming originality. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s methodology or claims, specifically noting that it is inappropriate to propose an identical method while claiming originality. This is a critical observation that highlights a potential ethical concern in the paper\\'s presentation. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or acknowledge contributions more appropriately. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of MMV compared to XDC, asking the authors to explain why MMV outperforms XDC. It also suggests that MMV might be better than XDC due to its backbone architecture. While the comment implies that the authors should provide an explanation or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation or analysis to address the question. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"XDC outperformed its R(2+1)D-18 fully-supervised pertaining baseline, but MMV did not exceed its fully-supervised pertaining baseline.\" This allows the authors to accurately identify the specific parts of the paper being addressed. The comment also specifies the issue by asking the authors to explain why MMV outperforms XDC and whether it is due to a better backbone architecture. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions and observations about the performance of MMV and XDC. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the performance of MMV compared to XDC, suggesting that MMV outperforms XDC despite using a similar fully-supervised baseline. It also asks the authors to explain why this is the case and whether it is due to a better backbone architecture. This feedback is somewhat helpful as it prompts the authors to consider the reasons behind the performance differences and to potentially explore the role of the backbone architecture in shaping the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. To be more helpful, the comment could provide additional insights or examples to support the authors in their exploration. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing is too verbose and hard to follow, and it recommends focusing on a main idea or two with analyses of why they work, rather than a well-engineered system with many functions and details to consider. While the comment provides a clear direction for improvement, it lacks specific guidance on how to achieve this focus or what specific aspects of the paper should be prioritized. The authors are given a general idea of what needs to be done but not concrete steps to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the writing being too verbose and hard to follow, suggesting that it looks like an implementation paper rather than a theoretical or general advancement. It also provides a specific suggestion to focus on a main idea or two with analyses of why they work, rather than a well-engineered system with many functions and details to consider. However, the comment does not explicitly mention which sections or parts of the paper are problematic, making it weakly grounded. The suggestion is specific, but without clear grounding, the authors may struggle to identify the exact areas that need improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the writing is too verbose and hard to follow, suggesting that it resembles an implementation paper rather than a theoretical or general advancement. The reviewer provides a specific suggestion to focus on a main idea or two with analyses of why they work, rather than a well-engineered system with many functions and details to consider. This claim is somewhat verifiable as it provides a logical reasoning for the critique, but it lacks specific examples or detailed justification to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, namely that the writing is too verbose and hard to follow, making it resemble an implementation paper rather than a theoretical or general advancement. The reviewer suggests a specific improvement by recommending that the authors focus on a main idea or two with analyses of why they work, rather than a well-engineered system with many functions and details to consider. This feedback is clear and actionable, providing the authors with a concrete direction for improving the clarity and focus of their paper. However, the comment could be more helpful if it offered additional guidance on how to achieve this focus or what specific aspects of the paper should be prioritized. Overall, the comment is mostly helpful as it effectively points out a significant weakness and provides a constructive suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks code and supplementary documentation, which are crucial for enhancing clarity and reproducibility. It clearly identifies the missing resources and suggests that providing them would be beneficial for readers. This feedback is direct and provides a clear action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of code and supplementary documentation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing (code and documentation) and why it is important for clarity and reproducibility. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks code and supplementary documentation, which are crucial for enhancing clarity and reproducibility. This claim is supported by the logical reasoning that these resources are necessary for understanding and replicating the methodology. However, the comment could be strengthened by providing specific examples or references to similar studies that include such resources. Despite this, the claim is mostly verifiable, as it logically presents a justification for the need of these resources.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, namely the lack of code and supplementary documentation. This feedback is clear and actionable, as it directly points out an area where the paper could be improved to enhance clarity and reproducibility. Providing these resources would be beneficial for readers to understand and replicate the methodology. However, the comment could be more helpful if it offered suggestions on how to present these resources effectively or provided examples of similar studies that include such resources. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should discuss ensembles and uncertainty estimation, particularly in the context of offline RL, where random ensembles (REM) have been found to outperform DQN/naive ensembling. The reviewer also recommends empirically comparing the proposed method to REM. While the comment provides a clear direction for the authors to include this discussion and comparison in their paper, it does not explicitly instruct them to do so. The action is implicit but concrete, as it specifies what needs to be added and how it should be addressed. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ensembles and uncertainty estimation\" and \"offline RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the comparison of random ensembles (REM) with DQN/naive ensembling in the offline setting. This provides clear guidance on what aspects of the paper need to be addressed and expanded upon. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that ensembles and uncertainty estimation have been studied before in the context of offline RL, specifically in the context of discrete Atari games. It references a study where random ensembles (REM) significantly outperformed DQN/naive ensembling in the offline setting. This claim is supported by a reference to an external work, which provides a basis for the assertion. However, the comment could be strengthened by providing more detailed comparisons or examples of how REM outperforms DQN/naive ensembling. Overall, the claim is mostly verifiable due to the reference to an external work, but it could be further substantiated with additional details.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for the authors to discuss ensembles and uncertainty estimation, particularly in the context of offline RL. It references a prior study where random ensembles (REM) were found to outperform DQN/naive ensembling, offering a clear example of a relevant topic that could be incorporated into the paper. The comment also suggests empirically comparing the proposed method to REM, which is a simple way to incorporate value uncertainty in offline RL. This feedback is clear and provides a concrete direction for the authors to enhance their draft, making it mostly helpful. However, it could be more comprehensive by offering additional details or examples of how the comparison could be conducted. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors have combined two methods in a clever way but lack novelty. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of lacking novelty or suggestions for enhancing the novelty of the combined methods. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the second paragraph of the introduction and the proposed methodology, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a subjective opinion on the novelty of the combined methods, suggesting that they lack novelty. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the combined methods lack novelty, based on the author\\'s statements in the second paragraph of the introduction and the proposed methodology. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the assertion. Without additional context or supporting evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the combined methods lack novelty, based on the author\\'s statements in the second paragraph of the introduction and the proposed methodology. However, it does not provide specific examples or detailed reasoning to support this claim, nor does it offer suggestions for how the authors might address this issue. Without actionable feedback or guidance, the comment lacks depth and does not assist the authors in improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the scalability of the proposed approach, suggesting that it may require a different model to be finetuned for each target language. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might improve the scalability of their approach or what specific steps they could take to address this issue. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the scalability of the proposed approach, suggesting that it may require a different model to be finetuned for each target language. However, it does not specify which part of the paper this concern is related to, such as a particular section or model description. This lack of explicit grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the scalability are questionable or how the authors might address these concerns. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the scalability of the proposed approach, suggesting that it may require a different model to be finetuned for each target language. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the scalability of the proposed approach, suggesting that it may require a different model to be finetuned for each target language. This is an important consideration for the authors, as scalability is a key factor in determining the practicality and applicability of their work. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this concern or improve the scalability of their approach. Without detailed feedback or examples, the authors are left with a general understanding of the issue but without clear steps to take. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that providing more details about \"valid words\" in the context of bAbI or question answering would be helpful for readers unfamiliar with these concepts. While the comment explicitly asks for additional information, it does not specify what kind of details should be included or how they should be presented. The authors are left to infer that they need to provide more context, but without concrete guidance on what exactly is missing, the action remains somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq.20,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely providing more details about \"valid words\" in the context of bAbI or question answering. This feedback is clear and actionable, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more details about \"valid words\" in the context of bAbI or question answering would be helpful for readers unfamiliar with these concepts. However, the comment does not provide any supporting evidence, reasoning, or examples to explain why these details are necessary or how they would benefit the reader. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where more details could be beneficial for readers unfamiliar with bAbI or question answering. It suggests that the term \"valid words\" needs clarification, as it may refer to possible answer words for the given story and question. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper by adding more context to help readers understand the concepts. However, the comment could be more helpful if it offered additional guidance on how to provide these details or what specific aspects should be clarified. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the interested-region-based adversarial attacking is not a novel idea and has been proposed earlier by Yao et al. in their work on Trust Region Based Adversarial Attack on Neural Networks at CVPR 2019. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what changes they should make to their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"interested-region-based adversarial attacking,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is being criticized, namely that the idea is not novel and has been proposed earlier by Yao et al. in their work on Trust Region Based Adversarial Attack on Neural Networks at CVPR 2019. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the interested-region-based adversarial attacking is not a novel idea, as it has been proposed earlier by Yao et al. in their work on Trust Region Based Adversarial Attack on Neural Networks at CVPR 2019. This claim is somewhat verifiable as it references a specific work, which provides some evidence for the claim. However, the comment lacks detailed reasoning or explanation of why this earlier work is relevant to the current paper or how it affects the novelty of the proposed method. Providing more context or a comparison with the current work would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out that the interested-region-based adversarial attacking is not a novel idea, as it has been proposed earlier by Yao et al. in their work on Trust Region Based Adversarial Attack on Neural Networks at CVPR 2019. This feedback is somewhat helpful as it identifies a potential issue with the novelty of the proposed method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their work from the prior work. Without actionable advice or constructive feedback, the authors are left with only a general awareness of a potential problem but without clear direction on how to improve their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed methods, which consist of multiple well-known components, may not contribute significantly to the field. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to enhance the novelty or impact of the proposed methods, nor are there suggestions for further exploration or differentiation. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the proposed methods, which consist of multiple well-known components, may not contribute significantly to the field. However, it does not specify which parts of the paper these components are discussed in, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the components are problematic or how they could be improved. Without clear guidance on which parts of the paper need revision, the authors are left without a clear path for action. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed methods, which consist of multiple well-known components, may not contribute significantly to the field. However, the comment lacks specific examples or detailed reasoning to support this claim. Without detailed evidence or references to specific components or their limitations, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the proposed methods, which consist of multiple well-known components, may not contribute significantly to the field. However, it does not provide any specific feedback or suggestions on how the authors might enhance the novelty or impact of their work. Without actionable guidance or constructive criticism, the authors are left without a clear path for improvement. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the test set, specifically the inclusion of multi-turn data and publicly available history conversation data that could still provide some assistance in answering the final question, which may lead to data leakage. However, the comment does not explicitly instruct the authors on how to address this issue or suggest specific actions to mitigate the risk of data leakage. The action is implicit and vague, as the authors are left to infer that they need to take steps to ensure data privacy and security. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a concern about the test set, specifically the inclusion of multi-turn data and publicly available history conversation data, which could still provide some assistance in answering the final question. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential risk of data leakage due to the use of these datasets for training models. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the test set includes multi-turn data and publicly available history conversation, which could still provide some assistance in answering the final question, indicating a risk of data leakage. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the risk or how to address it. Without additional context or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the test set, specifically the inclusion of multi-turn data and publicly available history conversation data, which could still provide some assistance in answering the final question. This observation highlights a potential risk of data leakage in the dataset. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the risk of data leakage. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the application of TTUR in Figure 7 and suggests that a comparison with VSD + TTUR would be more convincing. While the comment implies that the authors should include a comparison with VSD + TTUR, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the application of TTUR in the figure and suggests a comparison with VSD + TTUR to be more convincing. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) and suggests that a comparison with VSD + TTUR would be more convincing. This is a factual statement seeking clarification and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the application of TTUR in Figure 7 and suggests that a comparison with VSD + TTUR would be more convincing. This feedback is clear and actionable, as it prompts the authors to clarify their methodology and provide additional evidence to support their claims. By addressing this point, the authors can enhance the clarity and robustness of their experimental setup. However, the comment could be more helpful if it provided additional context or examples of how the comparison might be conducted. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement and offers a clear path for enhancing their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the theoretical result presented in the paper, questioning the merit of the work given that the authors assume that out-of-distribution (OOD) actions do not exist. It also acknowledges that the authors have addressed limitations and social impact. However, the comment does not provide explicit guidance or suggestions on how the authors might improve their draft to address this issue or clarify the theoretical result. The action is implicit and vague, leaving the authors without clear direction on how to address the concern. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 109,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the theoretical result presented in the paper, given that the authors assume that out-of-distribution (OOD) actions do not exist. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the theoretical result presented in the paper, specifically questioning the merit of the work given that the authors assume that out-of-distribution (OOD) actions do not exist. The comment acknowledges that the authors have addressed limitations and social impact, but it lacks specific reasoning or evidence to support why the assumption of no OOD actions undermines the theoretical result. The claim is somewhat verifiable as it highlights a potential issue but does not provide detailed reasoning or examples to fully substantiate the critique. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the theoretical result presented in the paper, questioning the merit of the work given that the authors assume that out-of-distribution (OOD) actions do not exist. It acknowledges that the authors have addressed limitations and social impact, but it does not provide specific feedback or suggestions on how the authors might address this issue or improve their theoretical result. While the comment identifies a potential weakness, it lacks actionable guidance or detailed feedback to help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper\\'s analysis is shallow and lacks clear takeaways or conclusions. It advises that if the analysis does not enhance the paper\\'s value or clarity, it might be better suited for the appendix. Additionally, it suggests that essential details, such as dataset splitting justifications, should be integrated into the main text. This feedback provides clear and concrete actions for the authors to take, specifying what needs to be improved and where. The explicit nature of the suggestions and the detailed guidance on integration make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"shallow linguistic dataset analysis\" and suggests that it might be better suited for the appendix. It also provides specific feedback by suggesting that essential details, such as dataset splitting justifications, should be integrated into the main text. This level of detail allows the authors to accurately identify the parts of the paper being addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s analysis is \"shallow\" and lacks clear takeaways or conclusions. It suggests that if the analysis does not enhance the paper\\'s value or clarity, it might be better suited for the appendix. The comment also advises that essential details, such as dataset splitting justifications, should be integrated into the main text. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion to move the analysis to the appendix, but it lacks specific examples or references to support the claim about the lack of clear takeaways or conclusions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s analysis, noting that it is shallow and lacks clear takeaways or conclusions. It suggests that if the analysis does not enhance the paper\\'s value or clarity, it might be better suited for the appendix. The comment also provides actionable feedback by recommending that essential details, such as dataset splitting justifications, should be integrated into the main text. This feedback is clear and offers a concrete direction for improvement, making it mostly helpful. However, it could be more helpful if it provided additional guidance on how to integrate these details effectively. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the metric used in Table 1 is not clearly stated and that the experimental details, such as the backbone choice, learning rate, and optimization schedules, are missing. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify the metric and provide more detailed experimental information. The action is implicit and somewhat vague, as the authors need to infer the specific details that need to be added. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"experimental details like backbone choice, learning rate, and optimization schedules,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of the metric used in Table 1 and the inclusion of detailed experimental information. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metric used in Table 1 is not clearly stated and that the experimental details, such as the backbone choice, learning rate, and optimization schedules, are missing. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues or how to address them. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas for improvement in the experimental results, noting that the metric used in Table 1 is not clearly stated and that the experimental details, such as the backbone choice, learning rate, and optimization schedules, are missing. This feedback is clear and actionable, as it directs the authors to provide more detailed information about their experimental setup. However, the comment could be more helpful if it offered suggestions on how to clarify the metric or provided examples of how similar metrics have been presented in other works. Despite this, the feedback is mostly helpful as it highlights important areas for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper, noting that the advantage of POMDPs is not leveraged, specifically the assumption that the decision-maker does not directly observe the target variable Y. The reviewer suggests that the paper should discuss how previous decisions affect the data observable to the decision-maker, especially when a positive decision is given. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue or what specific aspects of the paper should be revised. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the implications of the decision-making process on data observability. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"advantage of POMDPs\" and the assumption that the decision-maker does not directly observe the target variable Y. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on how previous decisions affect the data observable to the decision-maker. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not leverage the advantage of POMDPs, specifically the assumption that the decision-maker does not directly observe the target variable Y. The reviewer supports this claim by pointing out that the paper does not discuss how previous decisions affect the data observable to the decision-maker, especially when a positive decision is given. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of addressing this issue and might find it challenging to understand the exact implications without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by discussing the advantage of POMDPs, specifically the assumption that the decision-maker does not directly observe the target variable Y. The comment highlights a gap in the paper\\'s discussion, noting that the paper does not address how previous decisions affect the data observable to the decision-maker, especially when a positive decision is given. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by incorporating a discussion on this topic. However, the comment could be more helpful if it offered suggestions on how to integrate this discussion into the paper or provided examples of relevant literature or approaches. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the pretraining tokens per sample being extremely small (256) and suggests that it may not be enough for a regular-sized program. It also questions the use of batch size=64 for pretraining. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should consider increasing the pretraining tokens or adjusting the batch size. However, the comment lacks concrete suggestions or detailed instructions on how to implement these changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the pretraining tokens per sample, which are extremely small (256) and suggests that this may not be enough for a regular-sized program. It also questions the use of batch size=64 for pretraining. However, the comment does not specify which part of the paper discusses these tokens or the batch size, making it weakly grounded. The comment is specific in detailing the issue with the pretraining tokens and batch size, but without explicit references to the relevant sections, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the pretraining tokens per sample are extremely small (256) and that using batch size=64 for pretraining is insufficient. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these values are inadequate. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the pretraining process, specifically the small number of tokens per sample (256) and the use of batch size=64 for pretraining. This feedback highlights a potential limitation in the model\\'s capacity and suggests that these values may not be sufficient for a regular-sized program. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending an increase in tokens or batch size. While it points out a potential problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the need for more ablation experiments to help readers understand the proposed method. It specifically questions whether the clustering algorithm can be replaced with other approaches, such as K-Means, and suggests testing the model on different-sized descendant models. While the comment implies that additional experiments are needed, it does not explicitly instruct the authors to conduct these experiments or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for more ablation experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for experiments involving the replacement of the clustering algorithm with other approaches, such as K-Means, and testing the model on different-sized descendant models. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of ablation experiments to understand the proposed method. It suggests that the clustering algorithm could be replaced with other approaches, such as K-Means, and questions how the model performs on different-sized descendant models. While the comment identifies a potential gap in the experimental setup, it lacks specific examples or references to support the claim that additional experiments are necessary. The reasoning is somewhat valid but could be strengthened with more detailed evidence or examples. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental setup of the paper, specifically the lack of ablation experiments to help readers understand the proposed method. It suggests that the clustering algorithm could be replaced with other approaches, such as K-Means, and questions how the model performs on different-sized descendant models. This feedback is clear and actionable, as it provides specific areas for improvement and offers a direction for further exploration. However, the comment could be more helpful if it included examples or detailed guidance on how to conduct these ablation experiments. Overall, the comment is mostly helpful as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the Talking Heads Transformer should be the de-facto baseline for all tasks in the paper, rather than comparing against the vanilla transformer. It also recommends including a comparison of the proposed interaction modules and many-to-many formulation against the Talking Heads Transformer for all tasks presented in the paper. This feedback provides explicit actions for the authors to take, such as including a comparison with the Talking Heads Transformer and making it the baseline for all tasks. The suggestion is clear and concrete, offering a specific direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a comparison of the Talking Heads Transformer as the de-facto baseline for all tasks, rather than comparing against the vanilla transformer. This provides clear guidance on how to improve the paper by including a comparison with the Talking Heads Transformer. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the Talking Heads Transformer should be the de-facto baseline for all tasks in the paper, rather than comparing against the vanilla transformer. The reviewer provides a logical reasoning by pointing out that it is difficult to gauge the benefits of the proposed interaction modules and many-to-many formulation without a comparison to the Talking Heads Transformer. This claim is somewhat verifiable as it provides a clear rationale for the suggestion, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improvement. It highlights the importance of using the Talking Heads Transformer as the de-facto baseline for all tasks in the paper, rather than comparing against the vanilla transformer. This feedback is valuable as it encourages the authors to include a comparison with the Talking Heads Transformer, which would help to better understand the benefits of their proposed interaction modules and many-to-many formulation. The comment is specific and provides a clear direction for enhancing the paper\\'s comparative analysis. Therefore, it is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should check the scenario simulation and benchmark at least speaker identification on datasets like HI-MIA, which is recorded in real-time environments with noise setup and microphone array. While the comment implies that the authors should verify the scenario and include speaker identification benchmarking, it does not provide explicit instructions on how to implement these actions. The authors are left to infer that they need to verify the scenario and conduct benchmarking, but the comment lacks concrete details on how to execute these tasks. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Following 2),\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests checking the scenario simulation and benchmarking at least speaker identification on datasets like HI-MIA, which is recorded in real-time environments with noise setup and microphone array. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should verify the scenario simulation and benchmark at least speaker identification on datasets like HI-MIA, which is recorded in real-time environments with noise setup and microphone array. However, the comment lacks specific reasoning or evidence to support why this is necessary or how it would improve the paper. Without additional context or examples, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should verify the scenario simulation and benchmark at least speaker identification on datasets like HI-MIA, which is recorded in real-time environments with noise setup and microphone array. This feedback is somewhat helpful as it identifies a specific area for improvement, namely verifying the scenario simulation and conducting benchmarking on speaker identification. However, the comment lacks depth and does not provide detailed guidance on how to conduct these verifications or what specific aspects of the scenario should be checked. While it points out a potential area for improvement, the feedback could be more actionable with additional context or suggestions. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific suggestion for reframing the introduction to focus on the loss function and its applications rather than solely on breast cancer. It highlights that the paper's primary contribution is a loss function that can be applied to any semantic segmentation network, and it suggests framing the introduction to emphasize this aspect. While the comment implies a specific action, it does not provide explicit instructions on how to implement this change. The authors are given a clear direction but may need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Introduction\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for reframing the introduction to focus on the loss function and its applications rather than solely on breast cancer. This feedback is detailed and provides a clear direction for improvement, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the introduction focuses on breast cancer but does not provide a detailed justification or evidence to support this claim. It suggests that the paper's primary contribution is a loss function that can be applied to any semantic segmentation network, and that it can be extended to solve other problems in semantic segmentation, such as handling distribution shifts. However, the comment lacks specific examples or references to substantiate the claim that the paper's focus is not on breast cancer. As a result, the claim is not fully verifiable, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment provides a specific and actionable suggestion for reframing the introduction to focus on the loss function and its applications rather than solely on breast cancer. It highlights that the paper's primary contribution is a loss function that can be applied to any semantic segmentation network, and that it can be extended to solve other problems in semantic segmentation, such as handling distribution shifts. This feedback is clear and offers a constructive way for the authors to reframe their introduction, which could improve the clarity and focus of their paper. However, the comment could be more helpful if it provided additional guidance on how to effectively communicate this shift in focus. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to include agreement statistics for the corpus in either section 3.1 or 3.2. This is a clear and direct action that the authors can easily follow, as it specifies the exact location where the statistics should be included. The comment is specific and provides concrete guidance on how to implement the suggested change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly requests the inclusion of agreement statistics for the corpus in either section 3.1 or 3.2. This provides full grounding as the authors can accurately identify the sections being addressed. The comment is also specific because it specifies the exact location where the statistics should be included, making it clear what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for additional information, specifically asking for the inclusion of agreement statistics for the corpus in either section 3.1 or 3.2. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is a normal statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it provides a specific and actionable suggestion for improving the draft. By requesting the inclusion of agreement statistics for the corpus in either section 3.1 or 3.2, the reviewer offers a clear and direct way for the authors to enhance the transparency and comprehensiveness of their work. This feedback is valuable as it guides the authors on how to present their data more effectively, which could significantly impact the clarity and credibility of their findings. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the novelty of the instruction aggregation and the use of LLMs but questions the novelty of the consecutive sub-trajectories and cross-trajectory chaining. It suggests that the use of LLMs is not novel, as existing LLMs are used, and that the use of consecutive sub-trajectories is straightforward. The comment also notes that cross-trajectory chaining has novelty but acknowledges that many of its techniques are inspired by goal-conditioned RL approaches. While the comment identifies areas that could be improved, it does not provide explicit guidance on how to address these issues or suggest specific actions. The authors are left to infer that they should explore ways to differentiate their approach or provide more novelty in their work. Therefore, the comment is somewhat actionable, as it highlights areas for improvement but lacks concrete details on how to achieve them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of the instruction aggregation and the use of LLMs, as well as the use of consecutive sub-trajectories and cross-trajectory chaining. It provides specific feedback on the novelty of cross-trajectory chaining, noting that many of its techniques are inspired by goal-conditioned RL approaches. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The authors can infer that it relates to the sections discussing the methodology or results, but this inference is not direct. The comment is specific in detailing what needs to be addressed regarding novelty and the influence of existing techniques. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the novelty of the instruction aggregation and the use of LLMs, but questions the novelty of the use of consecutive sub-trajectories and cross-trajectory chaining. It suggests that the use of LLMs is not novel, as existing LLMs are used, and that the use of consecutive sub-trajectories is straightforward. The comment also notes that cross-trajectory chaining has novelty but acknowledges that many of its techniques are inspired by goal-conditioned RL approaches, as mentioned in the paper. The comment provides some reasoning by referencing existing works, but it lacks specific examples or detailed justification to fully substantiate the claim about novelty. Therefore, the comment is somewhat verifiable, as it provides some evidence but requires further elaboration to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the novelty of the instruction aggregation and the use of LLMs, but questions the novelty of the use of consecutive sub-trajectories and cross-trajectory chaining. It suggests that the use of LLMs is not novel, as existing LLMs are used, and that the use of consecutive sub-trajectories is straightforward. The comment also notes that cross-trajectory chaining has novelty but acknowledges that many of its techniques are inspired by goal-conditioned RL approaches, as mentioned in the paper. While the comment identifies areas that could be improved, it lacks specific suggestions or guidance on how to address these issues or differentiate the approach from existing works. The feedback is somewhat helpful as it highlights potential weaknesses but does not provide actionable steps for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the rationale behind the use of the identity of the attention map to improve the expressive power of the attention module. It suggests that more discussion is needed to clarify this point. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the discussion should be expanded. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations or discussions but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the rationale behind the use of the identity of the attention map to improve the expressive power of the attention module. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for more discussion on the topic, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the rationale behind the use of the identity of the attention map to improve the expressive power of the attention module. It suggests that more discussion is needed to clarify this point. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the identity mapping might not be the best choice or how it could be improved. Without additional context or examples, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind the use of the identity of the attention map to improve the expressive power of the attention module. It suggests that more discussion is needed to clarify this point. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the discussion should be expanded. The feedback is somewhat helpful as it points out a gap in the paper, but it does not provide actionable steps for the authors to improve their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to explain why they are considering decoder-only transformers. This is a direct and concrete action that the authors can take to improve their draft. The comment provides a clear and specific request, leaving no ambiguity about what needs to be done. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely an explanation for considering decoder-only transformers. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the consideration of decoder-only transformers. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific area where the authors need to provide more explanation. By asking for an explanation of why decoder-only transformers are being considered, the comment prompts the authors to clarify a critical aspect of their work. This feedback is clear and actionable, guiding the authors to enhance the clarity and comprehensibility of their draft. However, the comment could be more helpful if it provided suggestions on how to present this explanation effectively. Overall, the comment is highly helpful as it directs the authors to a crucial area for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of detail in the qualitative analysis, specifically mentioning the absence of proportions of each error category. It also suggests that the contribution could be strengthened by including more fruitful thoughts or speculations about the underlying causes and potential mitigations of the observed issues. While the comment implies that the authors should include these details, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific details and suggestions to address the feedback. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the qualitative analysis, specifically mentioning the absence of proportions of each error category and suggesting that the contribution could be strengthened by including more fruitful thoughts or speculations about the underlying causes and potential mitigations of the observed issues. However, it does not specify which part of the paper discusses the qualitative analysis or where the proportions are mentioned, making it weakly grounded. The comment is specific in suggesting what needs to be addressed, such as including more detailed analysis or speculations about the underlying causes. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the qualitative analysis lacks important details, specifically the proportion of each error category, and suggests that the contribution could be strengthened by including more fruitful thoughts or speculations about the underlying causes and potential mitigations of the observed issues. The reviewer references an external work, \"Language Models Don\\'t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting,\" which provides a basis for the suggestion. However, the comment does not provide detailed reasoning or examples of how these additional insights could be incorporated, leaving the authors with a general idea of what needs to be addressed. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but lacks detailed guidance.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the qualitative analysis, noting the absence of proportions of each error category. It suggests that the contribution could be strengthened by including more fruitful thoughts or speculations about the underlying causes and potential ways to mitigate the observed issues. While the comment provides a clear direction for improvement, it lacks specific guidance on how to incorporate these additional insights or suggestions. The feedback is somewhat helpful as it highlights a gap in the analysis but could be more beneficial with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should attempt to apply Reinforcement Learning, RNNs, Wasserstein GANs with data filled by simple methods to empirically validate that these methods are not suitable for incomplete, small data. This feedback provides a clear and explicit action for the authors to take, which is to conduct an experiment using these methods with a different dataset. The suggestion is concrete and specific, giving the authors a direct path to address the critique. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discuss the limitations of typical MTTP baselines, such as Reinforcement Learning, RNNs, Wasserstein GANs, and their inapplicability to the proposed approach. It also specifies the need for empirical validation by suggesting the authors apply these methods with data filled by simple methods to validate their suitability for incomplete, small data. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors attempt to apply Reinforcement Learning, RNNs, Wasserstein GANs with data filled by simple methods to empirically validate that these methods are not suitable for incomplete, small data. This claim is somewhat verifiable as it provides a logical reasoning for the need to test these methods with different data, but it lacks specific examples or references to support the claim. The suggestion is clear, but the justification could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for the authors to empirically validate the suitability of Reinforcement Learning, RNNs, Wasserstein GANs with data filled by simple methods. This feedback is actionable and offers a clear path for the authors to address the critique by conducting an experiment that could provide valuable insights into the applicability of these methods. By following this suggestion, the authors can strengthen their argument and demonstrate the limitations of the baselines mentioned. However, the comment could be more helpful if it provided additional context or examples of how to implement this validation experiment. Overall, the comment is mostly helpful as it offers a clear and constructive direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of baseline comparison in the paper, specifically mentioning that the G-EVAL method is entirely based on GPT-3.5 and GPT-4 but does not demonstrate their performance using the simplest prompts. The reviewer implies that the authors should include a baseline comparison to enhance the paper\\'s validity. However, the comment does not provide explicit instructions on how to conduct this comparison or what specific aspects to focus on. While the action is implied, it is vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"G-EVAL method\" and \"GPT-3.5 and GPT-4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: a baseline comparison that demonstrates the performance of these models using the simplest prompts. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a baseline comparison, specifically mentioning that the G-EVAL method is entirely based on GPT-3.5 and GPT-4 but does not demonstrate their performance using the simplest prompts. This claim is somewhat verifiable as it highlights a potential gap in the paper\\'s evaluation, but it lacks specific examples or references to support the assertion that a baseline comparison is necessary. The reviewer could provide more detailed reasoning or examples to strengthen the claim, making it more fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of a baseline comparison for the G-EVAL method. It highlights that the method is entirely based on GPT-3.5 and GPT-4, but does not demonstrate their performance using the simplest prompts and does not compare it with the G-EVAL method. This feedback is clear and actionable, as it directs the authors to include a baseline comparison to enhance the validity and robustness of their work. However, the comment could be more helpful if it provided specific suggestions on how to conduct the baseline comparison or what aspects to focus on. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the methodology, specifically the need to compute expected rewards or NE gaps for different perturbations in multiagent environments. It also notes that this requires full knowledge of the game payoffs and the policies of other agents. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to consider the full knowledge of game payoffs and the policies of other agents when computing NE gaps. The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the methodology used to update weights in multiagent environments, specifically mentioning the need to compute expected rewards or NE gaps. It also highlights the requirement for full knowledge of game payoffs and the policies of other agents. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with computing NE gaps and the need for full knowledge of game payoffs and policies. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that computing expected rewards or NE gaps in multiagent environments requires full knowledge of game payoffs and the policies of other agents. The reviewer supports this claim by explaining the process of updating weights and the need for such knowledge. However, the comment lacks specific examples or references to substantiate the claim fully. While the reasoning is logical and clear, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the methodology used to update weights in multiagent environments, specifically highlighting the need to compute expected rewards or NE gaps for different perturbations. It also points out that this requires full knowledge of game payoffs and the policies of other agents, which could be a significant challenge. While the comment provides a clear understanding of the problem, it lacks actionable suggestions or guidance on how the authors might address this issue or improve their methodology. The feedback is somewhat helpful as it highlights a potential weakness but does not offer specific steps for improvement, making it incomplete. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the paper primarily compares the proposed methods with DiffUCO, but it does not provide any explicit or implicit suggestions for improvement or additional analysis. There is no guidance on how the authors might enhance the comparison or address potential limitations in the current comparison. Without any actionable advice or direction, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the paper primarily compares the proposed methods with DiffUCO, but it does not specify which part of the paper this comparison is discussed in. The authors cannot confidently determine whether this comment pertains to a specific section, table, or figure. Additionally, the comment lacks specificity regarding what aspects of the comparison are problematic or how they could be improved. Without explicit references or detailed feedback, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper primarily compares the proposed methods with DiffUCO. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the paper\\'s content or significance. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the paper primarily compares the proposed methods with DiffUCO, which is a specific observation. However, it lacks depth and does not provide any actionable feedback or suggestions for improvement. Without additional context or guidance on how the authors might enhance the comparison or address potential limitations, the comment offers limited value to the authors. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of explicit definition and proof for the equivalence of the local policy product to the globally optimal policy. It points out that the paper is repetitive and superficial in its exposition of the decomposition method, specifically mentioning the need for explicit definitions of local subtasks and their corresponding policies, as well as the relationship between them. However, the comment does not provide specific guidance on how to address these issues or what additional details should be included to improve the paper. The action is implicit and somewhat vague, as the authors know they need to clarify the exposition but may not be entirely sure how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the contribution section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the paper\\'s exposition, particularly the lack of explicit definitions of local subtasks and their corresponding policies, as well as the relationship between them. Additionally, it points out the need for a complete proof of the equivalence between the local policy product and the globally optimal policy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is repetitive and superficial in its exposition of the decomposition method, specifically mentioning the lack of explicit definitions of local subtasks and their corresponding policies, as well as the relationship between them. The comment also suggests that the paper lacks a complete proof of the equivalence between the local policy product and the globally optimal policy. While the comment identifies specific areas for improvement, it does not provide detailed reasoning or references to support the claim that the paper is repetitive or lacks depth. The lack of specific examples or detailed evidence makes the claim somewhat verifiable, as the authors would need to make a concerted effort to address the issues raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s contribution, noting that it is repetitive and superficial in its exposition of the decomposition method. It points out the lack of explicit definitions of local subtasks and their corresponding policies, as well as the relationship between them, and suggests that the paper lacks a complete proof of the equivalence between the local policy product and the globally optimal policy. This feedback is clear and actionable, as it provides specific areas for improvement that could enhance the paper\\'s clarity and rigor. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar concepts have been presented in other works. Overall, the comment is mostly helpful as it directs the authors toward significant improvements in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the performance curve of each algorithm during the training is missing, indicating a gap in the paper\\'s presentation. However, it does not provide explicit guidance on how the authors should address this issue or what specific information should be included. The action is implicit and vague, as the authors are left to infer that they need to include performance curves but without detailed instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"performance curve of each algorithm during the training,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the inclusion of performance curves. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance curve of each algorithm during the training is missing. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting the absence of performance curves for each algorithm during the training. This feedback is clear and actionable, as it directs the authors to include a critical piece of information that could enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it provided suggestions on how to present these performance curves or what specific metrics should be included. Despite this, the comment is mostly helpful as it effectively guides the authors on a meaningful improvement to their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proposed Gaussian kernel-based graph construction method, specifically the computationally expensive nature of computing the full adjacency matrix. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the method. The comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Definition 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the proposed Gaussian kernel-based graph construction method, which requires computing the full adjacency matrix, leading to a high time complexity of O(N^2) for large-scale graphs. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed Gaussian kernel-based graph construction method (Definition 2) requires computing the full adjacency matrix, which is computationally expensive for large-scale graphs with O(N^2) time complexity. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed Gaussian kernel-based graph construction method, specifically the computational complexity of computing the full adjacency matrix. This is a relevant concern for large-scale graphs, as the time complexity of O(N^2) can be prohibitive. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the method. While it highlights a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the authors\\' claims and their experimental results. It suggests that the authors should consider using case (3) instead of case (1) in their analysis, as it achieves better performance for most widths. The reviewer also questions the authors\\' rationale for using case (1) by default, arguing that all sub-networks with different widths should be equally important. While the comment provides a clear suggestion for improvement, it lacks specific guidance on how to implement this change or why case (3) is preferable. The action is explicit but somewhat vague, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 8\" and \"Table 2e,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the authors\\' claims and the results presented in the table, which provides clear guidance on what needs to be addressed. The comment is specific because it details the disagreement with the authors\\' explanation and the need to consider case (3) instead of case (1) in the analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the authors\\' choice of case (1) in their analysis, suggesting that case (3) achieves better performance for most widths. The reviewer questions the authors\\' rationale for using case (1) by default, arguing that all sub-networks with different widths should be equally important. The comment is mostly verifiable as it provides a logical reasoning for the claim, based on the results presented in Table 2e. However, it could be strengthened by referencing specific results or comparisons that support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the authors\\' claims and their experimental results, specifically regarding the choice of case (1) in their analysis. It points out that case (3) achieves better performance for most widths, questioning the authors\\' rationale for using case (1) by default. The comment provides a clear and actionable suggestion for improvement by recommending the use of case (3) instead. This feedback is valuable as it highlights a potential issue with the authors\\' methodology and offers a specific solution to address it. However, the comment could be more helpful if it provided additional context or justification for why case (3) is preferable. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper\\'s main results are general and do not leverage any unique characteristics of tabular data or LLMs, despite claiming to address fine-tuning multiplicity specifically for tabular LLMs. It suggests that the main results are irrelevant to the paper scope. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to align the results with the paper\\'s scope. The action is implicit and somewhat vague, as the authors need to infer that they should focus on results relevant to tabular LLMs, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the paper\\'s claim about addressing fine-tuning multiplicity in tabular LLMs, noting that the main results are general and do not leverage any unique characteristics of tabular data or LLMs. It suggests that the main results are irrelevant to the paper scope. However, the comment does not specify which part of the paper this critique pertains to, making it weakly grounded. The comment is specific in detailing what is missing\u2014the lack of focus on unique tabular or LLM characteristics\u2014but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s main results are general and do not leverage any unique characteristics of tabular data or LLMs, despite claiming to address fine-tuning multiplicity specifically for tabular LLMs. The reviewer suggests that the main results are irrelevant to the paper scope. This claim is somewhat verifiable as it provides a logical reasoning for why the main results are not relevant, but it lacks specific examples or references to support the assertion that the results are general. The authors would need to further explore the claim to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s claims regarding the unique challenges of fine-tuning multiplicity in Tabular LLMs. It points out that while the paper claims to address this specific issue, the main results are general and do not leverage any unique characteristics of tabular data or LLMs. This feedback is clear and actionable, as it highlights a critical gap in the paper\\'s focus and suggests that the authors should reconsider their claims and results to align with the paper\\'s scope. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what unique aspects of tabular data or LLMs should be explored. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggests improvements, but it does not provide explicit instructions or concrete actions for the authors to take. The reviewer questions whether a double summation is needed, but does not specify how this should be implemented or what the implications of this change would be. Similarly, the comment about \"f(.)\" in the line just above equation 3 lacks specific guidance on how to address this issue. The mention of existing works and a request for details on simulating multiple layers versus single-layered clothing also does not provide clear direction for the authors. Overall, the comment is vague and lacks actionable steps, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the summation and the use of PBS to drape garments, as well as suggesting that the authors provide details on simulating multiple layers versus single-layered clothing. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for clarification on the summation and the use of PBS, as well as the need for details on simulating multiple layers. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the summation and the use of PBS to drape garments, suggesting that it might be a double summation. It also questions the use of \"f(.)\" in the line just above equation 3 and references existing works like TailorNet and Patel et al. 2021 that use PBS for garment simulation. The comment requests additional details on simulating multiple layers versus single-layered clothing. While the questions are valid, the comment lacks specific examples or detailed reasoning to fully substantiate the claims. Therefore, the comment is somewhat verifiable, as it provides a basis for the questions but requires further elaboration to be fully justified.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several questions and suggests improvements, providing the authors with opportunities to clarify and enhance their work. It questions the summation in the paper and suggests that it might be a double summation, which could be beneficial for understanding the results. Additionally, it asks for clarification on the use of \"f(.)\" in the line just above equation 3 and references existing works that use PBS for garment simulation. This feedback is somewhat helpful as it prompts the authors to consider additional details and clarifications, but it could be more helpful by providing specific guidance on how to address these issues. Overall, the comment offers some insight but lacks depth and actionable suggestions, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the theoretical analysis, specifically asking for clarification on why the supremum in Definition 1 is expressed as \\gamma(\\frac{B}{\\hat{d}_{\\min}^k})^{\\frac{1}{2}}. It also asks how the proposed GRADE reduces this supremum. While the comment identifies a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definition and its implications. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 1\" and \"supremum,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the theoretical analysis, asking for clarification on why the supremum is expressed as \\gamma(\\frac{B}{\\hat{d}_{\\min}^k})^{\\frac{1}{2}} and how the proposed GRADE reduces this supremum. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the theoretical analysis in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the theoretical analysis in the paper, specifically regarding the definition of the supremum in Definition 1 and how the proposed GRADE reduces it. This feedback is clear and actionable, as it prompts the authors to clarify a point that may be confusing to readers. By addressing this question, the authors can improve the clarity and coherence of their theoretical analysis. However, the comment could be more helpful if it provided additional context or suggestions on how to address the confusion. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include results and analysis on the lengthy dialogue samples, specifically asking whether the performance will drop on these samples. While the comment implies that the authors should conduct such analysis, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors know they need to address this but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including results and analysis on lengthy dialogue samples, specifically asking whether performance will drop on these samples. However, it does not specify which part of the paper this analysis should be included in, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its request for analysis on lengthy dialogue samples, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include results and analysis on the lengthy dialogue samples, specifically asking whether performance will drop on these samples. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would benefit the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include results and analysis on the lengthy dialogue samples, specifically asking whether performance will drop on these samples. This feedback is somewhat helpful as it identifies a potential area for further exploration and analysis, which could enhance the paper\\'s depth and comprehensiveness. However, the comment lacks specific guidance or suggestions on how to conduct this analysis or what specific aspects to focus on. While it points out a potential area for improvement, it does not provide detailed instructions or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the datasets used in the paper should include natural modalities, such as audio and visual, to improve evaluation. While it implies that the authors should consider adding these modalities, it does not provide explicit instructions or guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should include additional modalities. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the datasets used in the paper should include natural modalities, such as audio and visual, to improve evaluation. However, it does not specify which part of the paper discusses the datasets or where this suggestion should be implemented. The authors can infer that it relates to the datasets section, but the comment lacks full grounding as it does not explicitly mention the section. Additionally, while the comment suggests a specific improvement, it does not provide detailed guidance on how to implement this suggestion or what specific modalities should be included. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the datasets used in the paper should include natural modalities, such as audio and visual, to improve evaluation. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this addition would be beneficial. The references to external works, [1], [2], and [3], are included but do not directly support the claim. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the importance of including additional modalities based on the references alone.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the datasets used in the paper should include natural modalities, such as audio and visual, to improve evaluation. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to implement this suggestion. The references to external works, [1], [2], and [3], provide some context but do not offer detailed advice on how to integrate these modalities or what specific aspects of the evaluation should be addressed. The comment is somewhat helpful as it highlights a potential area for improvement, but it could be more beneficial with additional guidance or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a similarity between the oracle-context model and prompt tuning works, specifically mentioning Visual Prompt Tuning and Prompt Learning for Vision-Language Models. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether these works should be discussed or how they might be integrated into the paper. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a similarity between the oracle-context model and prompt tuning works, specifically mentioning Visual Prompt Tuning and Prompt Learning for Vision-Language Models. However, it does not specify which part of the paper this similarity is discussed in, making it weakly grounded. The comment is specific in pointing out the similarity and suggesting that these works should be discussed, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the oracle-context model is similar to prompt tuning works, specifically mentioning Visual Prompt Tuning and Prompt Learning for Vision-Language Models. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the comparison or how it relates to their work. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a similarity between the oracle-context model and prompt tuning works, specifically mentioning Visual Prompt Tuning and Prompt Learning for Vision-Language Models. This is a relevant observation that could be beneficial for the authors to consider, as it may impact the novelty and relevance of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this similarity or incorporate these works into their paper. Without actionable feedback or detailed advice, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of depth in the paper, specifically mentioning that it only discusses the observed phenomenon without exploring how to use the consequences of these observations to design better resilient systems. It suggests a potential approach by asking whether the proposed defense method can be adapted to resemble a hierarchical system, thereby demonstrating the usefulness and significance of the observed results. While the comment implies that the authors should consider this adaptation, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"observed phenomenon\" and the \"research area,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of exploration into how to use the consequences of the observations to design better resilient systems. The comment suggests a potential approach by asking whether the proposed defense method can be adapted to resemble a hierarchical system. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks depth in exploring the consequences of the observed phenomenon and suggests a potential approach to adapt the defense method to resemble a hierarchical system. The comment provides a logical reasoning by pointing out the need for deeper exploration and offers a specific suggestion for improvement. However, it does not provide specific examples or references to support the claim that the current approach lacks depth or the need for adaptation. While the suggestion is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting that it only discusses the observed phenomenon without exploring how to use the consequences of these observations to design better resilient systems. It suggests a potential approach by asking whether the proposed defense method can be adapted to resemble a hierarchical system, thereby demonstrating the usefulness and significance of the observed results. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their research and demonstrating the practical implications of their findings. However, it could be more helpful if it included examples or detailed guidance on how to implement this adaptation. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors are evaluating a form of reliability or trust by looking at what LLMs \"know,\" but no rigorous definitions are provided. However, it does not provide explicit guidance on what specific definitions should be included or how to address this issue. The comment implies that the authors should provide more detailed definitions, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the evaluation of a form of reliability or trust by looking at what LLMs \"know,\" but it does not specify which part of the paper this evaluation is discussed in. The authors cannot confidently determine whether this comment pertains to a specific section, such as the methodology or results, making it weakly grounded. However, the comment is specific in detailing what is missing\u2014the lack of rigorous definitions for this evaluation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors are evaluating a form of reliability or trust by looking at what LLMs \"know\" but do not provide rigorous definitions. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact issue or how to address it. Without concrete evidence or reasoning, the claim is not verifiable, as it does not provide a clear path for improvement. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that the authors are evaluating a form of reliability or trust by looking at what LLMs \"know\" but do not provide rigorous definitions. This feedback highlights a gap in the paper\\'s methodology, which could be addressed by providing more detailed definitions or explanations. However, the comment lacks specific suggestions or guidance on how the authors might improve their approach or what specific definitions should be included. While it points out an area for improvement, it does not offer actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the use of masked self-attention in the Y-Future encoder and why ProbSparse is not preferred. It also questions the impact of this choice on computational efficiency, given the apparent larger forecasting horizons compared to history lengths in experiments from Appendix E.2. While the comment implies that the authors should address these questions, it does not provide explicit instructions or concrete suggestions on how to do so. The authors can infer that they need to provide explanations or comparisons between masked self-attention and ProbSparse, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Y-Future encoder\" and \"ProbSparse,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the questions about the use of masked self-attention and the potential impact on computational efficiency, given the apparent larger forecasting horizons compared to history lengths in experiments from Appendix E.2. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the use of masked self-attention in the Y-Future encoder and why ProbSparse is not preferred. It also questions the impact on computational efficiency, given the apparent larger forecasting horizons compared to history lengths in experiments from Appendix E.2. However, the comment lacks specific examples or references to support these claims or questions. Without detailed reasoning or evidence, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered borderline verifiable, as it provides a starting point for the authors but requires further elaboration to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises important questions about the use of masked self-attention in the Y-Future encoder and why ProbSparse is not preferred. It also questions the impact of these choices on computational efficiency, given the apparent larger forecasting horizons compared to history lengths in experiments from Appendix E.2. This feedback is somewhat helpful as it prompts the authors to consider the rationale behind their choices and the potential implications on computational efficiency. However, the comment could be more helpful if it provided specific suggestions or examples to support the authors in addressing these questions. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the theoretical analysis of why deep layer parameters are more suitable for distillation is lacking. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on what specific aspects of the theoretical analysis should be expanded or improved, nor are there any concrete steps for the authors to take to enhance their draft. As a result, the comment lacks actionability, leaving the authors without a clear understanding of what changes they need to make to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"theoretical analysis of why deep layer parameters are more suitable for distillation,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out the lack of theoretical analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical analysis of why deep layer parameters are more suitable for distillation is lacking. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved: the theoretical analysis of why deep layer parameters are more suitable for distillation. This feedback is clear and actionable, as it points out a gap in the paper that the authors can address to enhance their work. However, the comment could be more helpful if it provided suggestions on how to conduct the theoretical analysis or what specific aspects to focus on. Despite this, the feedback is mostly helpful as it directs the authors to a critical area for improvement, making it deserving of a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that important paper details are in the appendix, indicating that the paper is not self-contained. However, it does not provide explicit guidance on how to address this issue, such as suggesting which details should be integrated into the main text or how to make the paper more self-contained. The action is implicit and vague, leaving the authors to infer that they need to make changes but without specific instructions on what those changes should be. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment points out that important paper details are in the appendix, indicating that the paper is not self-contained. However, it does not specify which details are in the appendix or where they should be integrated into the main text. This lack of specificity makes it difficult for the authors to identify the exact issues and address them effectively. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that important paper details are in the appendix, indicating that the paper is not self-contained. However, it does not provide specific examples or reasoning to support this claim, making it difficult for the authors to understand the exact details or how they might address the issue. The lack of specificity and supporting evidence makes it challenging for the authors to understand and act upon the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that important details are placed in the appendix, making the paper less self-contained. This feedback is clear and actionable, as it highlights a critical weakness that the authors should address to improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided specific suggestions on how to integrate these details into the main text or how to make the paper more self-contained. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the argument that gradient descent-based methods allow scaling to large datasets but questions the authors\\' choice of dataset size. It implies that the authors should consider using larger datasets to further validate their claims. However, it does not provide specific guidance on how to address this issue, such as suggesting a particular dataset size or method for scaling. The action is implicit and somewhat vague, as the authors can infer that they need to consider using larger datasets but are not given concrete steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the argument that gradient descent-based methods allow scaling to large datasets, but questions the authors\\' choice of dataset size, suggesting that 50K points may not be large enough. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where the dataset size is discussed. The authors can infer that it relates to the dataset used in the experiments, but this inference is not direct. The comment is specific in its critique of the dataset size but lacks grounding, as it does not explicitly mention which part of the paper is being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' choice of dataset size, suggesting that 50K points may not be considered large enough. However, the comment does not provide any supporting evidence, reasoning, or references to justify why 50K points might not be considered large enough. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges the argument that gradient descent-based methods allow scaling to large datasets, but questions the authors\\' choice of dataset size, suggesting that 50K points may not be considered large enough. This feedback is somewhat helpful as it highlights an area where the authors might need to further substantiate their claims. However, it lacks specific suggestions or guidance on how the authors might address this issue, such as by providing a rationale for why 50K points are considered small or by suggesting alternative datasets to use. While the comment identifies a potential weakness, it does not offer actionable steps for improvement, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality of the assumptions and questions the feasibility of the method's reliance on \"overloading the library with ASD subroutines\" (assumption 3.2). However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what steps they could take to improve the practicality of their assumptions. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the practicality of the assumptions and questions the feasibility of the method's reliance on \"overloading the library with ASD subroutines\" (assumption 3.2). However, it does not specify which part of the paper this concern is related to, such as a specific section or figure where this assumption is discussed. The authors can infer that it relates to the methodology or assumptions section, but this inference is not direct. The comment is specific in detailing the concern about the practicality of the assumptions, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the practicality of the assumptions and the feasibility of the method's reliance on \"overloading the library with ASD subroutines\" (assumption 3.2). However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the concern. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the critique. Therefore, the comment aligns with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the practicality of the assumptions and questions the feasibility of the method's reliance on \"overloading the library with ASD subroutines\" (assumption 3.2). While it identifies a potential weakness in the paper, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this concern. The comment could be more helpful if it offered examples or alternative approaches to validate the assumptions or provided guidance on how to improve the feasibility of the method. As it stands, the comment provides some insight but lacks depth and actionable advice, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the paper lacks excitement due to the use of a methodology commonly used in data augmentation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the methodology more novel or innovative, nor are there suggestions for alternative approaches or ways to enhance the paper\\'s impact. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks excitement due to the use of a methodology commonly used in data augmentation. However, it does not specify which part of the paper this issue pertains to, such as a particular section or methodology. Without explicit references to sections or specific elements, the authors cannot confidently determine where to address this feedback. Additionally, the comment does not provide specific guidance on how to make the methodology more novel or innovative, nor does it suggest alternative approaches or ways to enhance the paper\\'s impact. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper lacks excitement due to the use of a methodology commonly used in data augmentation. However, it does not provide any specific examples or reasoning to support this claim. Without detailed evidence or references to similar studies or alternative approaches, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper lacks excitement due to the use of a methodology commonly used in data augmentation. However, it does not provide any specific guidance or suggestions on how the authors might enhance the novelty or impact of their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with a claim made in the paper, stating that the results presented in Fig. 4 do not support the authors\\' claim that multi-image IMP significantly improves the quality of LIPs in the cross-domain setting. The reviewer explicitly points out the discrepancy between the results and the authors\\' claims, providing a clear and concrete action for the authors to take. This feedback is explicit and provides a specific area for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4\" and \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is incorrect, namely the claim that multi-image IMP significantly improves the quality of LIPs in the cross-domain setting, as the results presented in Fig. 4 show otherwise. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some statements in the paper are incorrect, specifically mentioning a claim about the performance of multi-image IMP in Fig. 4. The reviewer provides a specific example by pointing out that the results in Fig. 4 do not support the authors\\' claim of significant improvement. This claim is supported by the observation of the results, which provides a clear and concrete basis for the critique. However, the comment could be strengthened by providing additional context or references to similar studies that might support the claim. Overall, the claim is mostly verifiable, as it is based on a specific observation and logical reasoning.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with a claim made in the paper, noting that the results presented in Fig. 4 do not support the authors\\' claim that multi-image IMP significantly improves the quality of LIPs in the cross-domain setting. This is a clear and actionable feedback that prompts the authors to reconsider their claims and potentially revise the results or explanation presented. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue or improve the presentation of the results. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the rank in the VLN Leaderboard is 22-th and that the results of the proposed method are not better than existing methods, such as [1,2,3]. However, it does not provide any explicit or implicit actions for the authors to take. The mention of specific references [1,2,3] suggests that the authors should compare their results with these existing methods, but it does not instruct them on how to do so or what specific aspects to focus on. The comment lacks actionable guidance, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the VLN Leaderboard rank and the specific methods being compared, such as [1,2,3]. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely that the results of the proposed method are not better than existing methods, and it provides references to specific works that demonstrate this comparison. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results of the proposed method are not better than existing methods, such as [1,2,3]. The reviewer supports this claim by referencing specific works, including [1] Zhu F, Zhu Y, Chang X, et al. Vision-language navigation with self-supervised auxiliary reasoning tasks[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 10012-10022, [2] Tan, Hao, Licheng Yu, and Mohit Bansal. \"Learning to navigate unseen environments: Back translation with environmental dropout.\". [3] Ke, Liyiming, et al. \"Tactical rewind: Self-correction via backtracking in vision-and-language navigation.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019. This provides a strong basis for the claim, as it references specific works that demonstrate the performance of existing methods. However, the comment could be further strengthened by discussing why the proposed method does not outperform these existing methods or how it could be improved. Overall, the claim is mostly verifiable, as it is supported by relevant references but lacks detailed justification or analysis.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment highlights a specific issue with the paper, noting that the rank in the VLN Leaderboard is 22-th and that the results of the proposed method are not better than existing methods, such as [1,2,3]. The reviewer provides specific references to existing works, which is helpful in identifying the benchmark against which the proposed method should be evaluated. However, the comment lacks depth and does not offer any suggestions or guidance on how the authors might improve their method or address the issue of not outperforming existing methods. While it points out a problem, it does not provide actionable feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it identifies a weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the discussion in section 2.2 is not convincing regarding how semantic similarity is modeled with the proposed approach. However, it does not provide any specific guidance or suggestions on how the authors might improve the discussion or address this concern. The comment lacks actionable details, such as recommending additional explanations or examples to strengthen the discussion. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the discussion on semantic similarity is not convincing with the proposed approach. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion in section 2.2 is not convincing regarding how semantic similarity is modeled with the proposed approach. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the discussion in section 2.2, noting that it is not convincing in terms of how semantic similarity is modeled with the proposed approach. However, the comment lacks depth and does not provide any specific suggestions or guidance on how the authors might improve the discussion or address this concern. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should discuss the uncertainty in fitted parameter values and provide sensitivity analysis. This feedback is clear and provides a direct action for the authors to take, ensuring that they understand the need for addressing this issue. The comment is specific about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"SEPAI3R3O model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the model, such as the introduction of over 10 parameters and the challenge of estimation from limited real-world observations. The comment further suggests discussing the uncertainty in fitted parameter values and providing sensitivity analysis, providing clear guidance on how the authors can address these concerns. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the SEPAI3R3O model, specifically the introduction of over 10 parameters and the challenge of estimation from limited real-world observations. It suggests that the authors should discuss the uncertainty in fitted parameter values and provide sensitivity analysis. While the comment identifies potential issues, it lacks specific examples or references to support the claim about the difficulty of estimation from limited data. The suggestion to discuss uncertainty and provide sensitivity analysis is logical and reasonable, but the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed SEPAI3R3O model, specifically the introduction of over 10 parameters and the challenge of estimation from limited real-world observations. It suggests that the authors should discuss the uncertainty in fitted parameter values and provide sensitivity analysis. This feedback is clear and actionable, as it provides specific guidance on how the authors can address the limitations of their model. By addressing these concerns, the authors can improve the robustness and reliability of their work. However, the comment could be more helpful if it included examples or references to similar models that have successfully addressed these issues. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the assumption that causal parameters across domains are random samples, suggesting that it may not be a consequence of not having latent confounders in the system. It also points out that the performance of the proposed method and the relative performances of other methods could depend on how the parameters change across domains. The reviewer raises a valid concern about the trustworthiness of the output, given the uncertainty about parameter changes. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific steps they should take to improve their analysis. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their assumptions about causal parameters and explore how they change across domains. However, without concrete steps or examples, the comment lacks actionability. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the assumption that causal parameters across domains are random samples, suggesting that it may not be a consequence of not having latent confounders in the system. It also discusses the performance of the proposed method and the relative performances of other methods, such as MC, IB, and HSIC test, in relation to how parameters change across domains. However, the comment does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in pointing out the potential issue with the assumption and the implications for the results, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the assumption that causal parameters across domains are random samples, suggesting that it may not be a consequence of not having latent confounders in the system. The reviewer also raises concerns about the performance of the proposed method and the relative performances of other methods, such as MC, IB, and HSIC test, in relation to how parameters change across domains. The comment is somewhat verifiable as it provides a logical reasoning for questioning the assumption and highlights the potential implications for the results. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the assumption that causal parameters across domains are random samples, suggesting that it may not be a consequence of not having latent confounders in the system. It also raises concerns about the performance of the proposed method and the relative performances of other methods, such as MC, IB, and HSIC test, in relation to how the parameters change across domains. The reviewer highlights the importance of understanding how parameters change to assess the trustworthiness of the output. While the comment identifies a potential weakness in the assumption and the implications for the results, it lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback is somewhat helpful as it prompts the authors to reconsider their assumptions and consider the impact of parameter changes on the results, but it could be more actionable with additional guidance. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the novelty of the structural optimization method, suggesting that it may not be new. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of novelty or how to clarify the method's novelty in the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the novelty of the structural optimization method, suggesting that it may not be new. However, it does not specify which part of the paper this issue is related to, such as a particular section, figure, or methodology. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in its critique of the novelty, but without clear grounding, it lacks actionable guidance for the authors to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of the structural optimization method, suggesting that it may not be new. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without detailed explanation or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the novelty of the structural optimization method, suggesting that it may not be new. However, it does not provide any specific reasoning or evidence to support this claim, nor does it offer suggestions for how the authors might address this issue or improve the clarity of their narrative. Without actionable feedback or guidance, the comment lacks utility for the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it identifies a potential weakness but does not provide a clear path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proof, noting that the assumption of lambda not being 0.5 may not be correct, as standard mixup can generate mixed samples even with lambda equal to 0.5. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their proof. The action is implicit and vague, as the authors are left to infer that they need to reconsider their assumptions about lambda. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the proof, specifically the assumption that lambda cannot be 0.5, which is relevant to the standard mixup method. The comment further specifies that this assumption may not be correct, given that standard mixup can generate mixed samples even with lambda equal to 0.5. This provides clear guidance on what needs to be addressed in the proof. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof assumption of lambda not being 0.5 may not be correct, as standard mixup can generate mixed samples even with lambda equal to 0.5. This claim is somewhat verifiable as it provides a logical reasoning based on the standard mixup method, which could challenge the assumption. However, the comment lacks specific examples or references to support the claim more robustly, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proof, noting that the assumption of lambda not being 0.5 may not be correct, as standard mixup can generate mixed samples even with lambda equal to 0.5. This is a clear and actionable observation that prompts the authors to reconsider their assumptions and potentially revise their proof. However, the comment could be more helpful if it provided suggestions on how to address this issue or alternative approaches to consider. Despite this, the feedback is mostly helpful as it directs the authors to a critical area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to highlight which set of equations has the same form as the Riccati equation and suggests extracting some inlined math into environments to facilitate looking up symbols. These are clear and concrete actions that the authors can take to improve the draft. The comment provides specific guidance on how to enhance the presentation of equations, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paragraph above Theorem 3.1, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be highlighted and suggests extracting some inlined math into environments to facilitate looking up symbols. This provides clear guidance on how to improve the presentation of equations. Therefore, the comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of requests for clarification and suggestions for improvement. It does not contain any subjective claims, opinions, or judgments that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by requesting that the authors highlight which set of equations has the same form as the Riccati equation and suggesting the extraction of some inlined math into environments to facilitate looking up symbols. This guidance is clear and offers a concrete way for the authors to improve the presentation of their work, making the comment highly helpful. By addressing these points, the authors can enhance the clarity and accessibility of their draft, which is valuable for improving the overall quality of the paper. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit guidance on improving the clarity of the writing by suggesting that certain sections need clearer structure and transitions. It also recommends providing statistical evidence, such as p-values, to clarify subjective terms like \"significant.\" This feedback is clear and direct, giving the authors specific actions to take to enhance the clarity of their draft. The suggestion to provide statistical evidence is concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections, such as \"certain sections,\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the need for clearer structure and transitions, and the need for statistical evidence to clarify subjective terms like \"significant.\" This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that certain sections of the paper could benefit from clearer structure and transitions, and that subjective terms like \"significant\" could be clarified with statistical evidence. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact areas that need improvement. The lack of detailed reasoning or evidence makes it challenging for the authors to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific feedback on the clarity of the writing, suggesting that certain sections could benefit from clearer structure and transitions. It also recommends providing statistical evidence to clarify subjective terms like \"significant,\" which is a clear and actionable suggestion. This feedback is detailed and constructive, offering the authors a concrete path to improve the clarity and rigor of their draft. However, it could be more helpful if it provided examples of how to implement these improvements or suggested specific sections to focus on. Overall, the comment is mostly helpful as it effectively guides the authors in enhancing the clarity and rigor of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, namely the lack of detailed information on how to construct graphs, particularly for non-euclidean datasets. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors can infer that they need to include more detailed information on graph construction, but it is not explicitly stated. The comment is somewhat actionable, as it points out a specific area that needs attention but lacks concrete details on how to implement the suggested improvement.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"detailed information for graph construction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the methodology for defining edges and constructing graphs for non-euclidean datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"the detailed information for graph construction is missing,\" specifically mentioning the need for information on defining edges and constructing graphs for non-euclidean datasets. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, namely the lack of detailed information on how to construct graphs, particularly for non-euclidean datasets. This is a critical point that could impact the clarity and effectiveness of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what additional details should be included. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$ are determined, referencing a specific paper. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should clarify this information in their paper or provide additional details, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$, which are mentioned in the context of a specific paper. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification on how these hyper-parameters are determined, but without explicit references to the paper or the exact section, it is difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$, which are mentioned in the context of a specific paper. This is a relevant question that could help the authors clarify their methodology or provide additional context for readers. However, the comment lacks depth and does not offer suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for clarification, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the visual and textual representations used in each method in Table 4, suggesting that it is unclear whether the end-to-end performance gain is due to the proposed attention model. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information about the visual and textual representations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of information about the visual and textual representations used in each method, which makes it unclear whether the end-to-end performance gain is due to the proposed attention model. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the visual and textual representations used in each method in Table 4, suggesting that it is unclear whether the end-to-end performance gain is due to the proposed attention model. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, specifically regarding the visual and textual representations used in each method in Table 4. It points out that this lack of clarity makes it unclear whether the end-to-end performance gain is due to the proposed attention model. This feedback is somewhat helpful as it highlights an important aspect of the paper that needs clarification, but it does not provide detailed guidance on how to address this issue or suggest specific improvements. The authors are given a direction to focus on but would need to further develop the comment to fully address the concern. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the convergence analysis, including the lack of clear presentation of notations, the absence of a clear justification for the assumption that $\\\\alpha_k$ converges to $\\\\alpha$, and the unclear justification of Eq. (15). While the comment highlights specific areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the notations, provide a more detailed justification for the convergence assumption, and justify Eq. (15). This makes the comment somewhat actionable, as the authors know they need to make improvements but lack specific instructions on how to do so.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues with the convergence analysis, including the lack of clear presentation of notations, the absence of a clear justification for the assumption that $\\\\alpha_k$ converges to $\\\\alpha$, and the unclear justification of Eq. (15). However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for clearer notation and justification for the convergence assumption. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the convergence analysis is unclear, with a lack of clear presentation of notations and assumptions, and that the proof is not clear. It specifically mentions the absence of a clear justification for the assumption that $\\\\alpha_k$ converges to $\\\\alpha$ and the unclear justification of Eq. (15). The comment provides specific examples of what is missing, such as the lack of clear notation and the need for a more detailed justification. However, it does not provide references or detailed reasoning to fully substantiate these claims, making it somewhat verifiable. The authors would need to make a concerted effort to address these issues, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the convergence analysis, noting that the presentation of notations and assumptions is unclear and that the justification for the convergence assumption is missing. It also points out that the proof is not clear and that the justification for Eq. (15) is unclear. This feedback is valuable as it highlights specific areas where the authors need to improve the clarity and rigor of their analysis. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as recommending specific improvements or references to similar works. Overall, the comment is mostly helpful as it directs the authors to specific areas needing attention, but it lacks detailed guidance on how to improve.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the lack of clear organization and illustration of the studied problems, insufficient description of uncertainty calibration, and the need to summarize issues such as small datasets, highly heterogeneous data distribution, and uncertainty calibration. While the comment highlights specific areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to organize and summarize the studied issues, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues with the paper, such as the lack of clear organization and illustration of the studied problems, the insufficient description of uncertainty calibration, and the need to summarize issues like small datasets, highly heterogeneous data distribution, and uncertainty calibration. However, it does not explicitly mention which sections or parts of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as organizing and summarizing the studied issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the studied problems are not well-driven and illustrated, specifically mentioning the insufficient description of uncertainty calibration and the need to organize and summarize issues such as small datasets, highly heterogeneous data distribution, and uncertainty calibration. The comment provides some logical reasoning by suggesting that the lack of organization and insufficient description of uncertainty calibration could be challenging for new readers. However, it lacks specific examples or references to support the claim about the insufficiency of the description of uncertainty calibration. Additionally, while it suggests organizing and summarizing the studied issues, it does not provide detailed guidance on how to achieve this. Therefore, the comment is somewhat verifiable, as it provides some justification but lacks sufficient evidence or specific suggestions for improvement.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, specifically noting that the studied problems are not well-driven and illustrated. It points out that the description of uncertainty calibration is insufficient, which could be confusing for new readers. Additionally, it suggests that the paper should further organize and summarize issues such as small datasets, highly heterogeneous data distribution, and uncertainty calibration. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. For example, it does not provide examples of how to better illustrate the studied problems or offer specific recommendations for organizing and summarizing the content. As a result, the comment is somewhat helpful, as it provides insight into areas that need attention but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not explore the incorporation of PAC-tuning with other fine-tuning techniques such as pruning and data augmentation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this omission or what specific aspects of the paper should be revised to include these explorations. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific omission in the paper, namely the lack of results exploring the incorporation of PAC-tuning with other fine-tuning techniques such as pruning and data augmentation. However, it does not specify which part of the paper this omission pertains to, making it weakly grounded. The comment is specific in detailing what is missing, but without explicit references to sections or figures, the authors may struggle to identify the exact areas that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks results exploring the incorporation of PAC-tuning with other fine-tuning techniques such as pruning and data augmentation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of results exploring the incorporation of PAC-tuning with other fine-tuning techniques such as pruning and data augmentation. This feedback highlights an area where the paper could expand its scope and provide additional insights. However, the comment lacks specific suggestions or guidance on how the authors might address this omission or what specific aspects of the paper should be revised to include these explorations. While it points out a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to validate their experimental analysis on more models, providing a specific reference to the fourth question below. This direct action is clear and concrete, giving the authors a clear path to improve their draft by expanding the experimental analysis. The comment is highly actionable because it provides a specific direction for the authors to follow to enhance the robustness and comprehensiveness of their work.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental analysis\" and provides a specific reference to the \"fourth question below,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to validate the experimental analysis on more models. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental analysis is insufficient and should be validated on more models. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental analysis, noting that it is insufficient and should be validated on more models. It provides a clear and actionable suggestion by referencing the fourth question below, which suggests a potential area for improvement. This feedback is valuable as it directs the authors to a specific area where their work could be strengthened, offering a concrete step for enhancing the robustness and comprehensiveness of their analysis. However, the comment could be more helpful if it provided additional context or examples of how the validation on more models could be achieved. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including the lack of comparison to other methods, the limited scope of the experiments, and the need for more detailed explanations. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to expand their experimental scope, provide more detailed explanations, and compare their method with other methods. The feedback is somewhat actionable as it points out areas for improvement but lacks concrete steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues with the paper, such as the lack of comparison to other methods, the limited scope of experiments, and the need for more detailed explanations. It references specific works, such as [1] and [2], to provide context and examples. However, the comment does not explicitly mention which sections of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for more comprehensive experiments and comparisons with other methods. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method improves over the original initialization, but it does not provide specific evidence or examples to support this claim. The comment references the disadvantages of BN and the limited improvement over baselines in the ImageNet experiments, but it does not elaborate on how these factors affect the overall improvement. The reference to external works, [1] and [2], provides some context but does not fully substantiate the claim. The lack of detailed reasoning or specific examples makes the claim somewhat verifiable, as it requires further elaboration for the authors to fully understand and address the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the lack of comparison to other methods, the limited scope of the experiments, and the need for more detailed explanations. It references specific works, such as [1] and [2], to provide context and examples. While the comment highlights important areas for improvement, it does not offer specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it points out areas for improvement but lacks actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should add a discussion comparing the robustness and immunizability of their proposed method with the method proposed in Yu et al. 2021. While the comment implies that the authors should include this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on this topic. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding a discussion comparing the robustness and immunizability of the proposed method and the method proposed in Yu et al. 2021. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or subsection. The authors might infer that it relates to the results or methodology sections, but this inference is not direct. The comment is specific in suggesting the need for a comparison but lacks grounding as it does not specify where in the paper this addition should be made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should add a discussion comparing the robustness and immunizability of their proposed method with the method proposed in Yu et al. 2021. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should add a discussion comparing the robustness and immunizability of their proposed method with the method proposed in Yu et al. 2021. This feedback is somewhat helpful as it identifies a specific area for improvement, namely the inclusion of a comparison that could enhance the paper\\'s comprehensiveness and relevance. However, the comment lacks depth and does not provide detailed guidance on how to conduct this comparison or what specific aspects to focus on. While it points out a potential area for improvement, the authors would need to infer more detailed guidance to fully address the suggestion. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the proposed algorithm for adaptive top-k decoding and requests clarification. It suggests that the reviewer is open to revising their assessment based on the answers to the questions raised. However, it does not provide explicit guidance on what specific questions need to be addressed or how to address them. The comment also mentions that a plot of time complexity as a function of m would be helpful. While the action is implied, it is vague, as the authors are left to infer what questions need to be answered and how to present the plot of time complexity. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"3), this work proposes an algorithm for adaptive top-k decoding,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the proposed algorithm and requests clarification, as well as suggesting a plot of time complexity as a function of m. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the proposed algorithm for adaptive top-k decoding, suggesting that it may produce \"better\" samples. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment also requests clarification and offers a suggestion for further analysis, such as a plot of time complexity. While it identifies a potential area for improvement, the lack of detailed justification or evidence makes it difficult for the authors to address the claim effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the proposed algorithm for adaptive top-k decoding, suggesting that it may produce \"better\" samples. It also requests clarification and offers a suggestion for further analysis, such as a plot of time complexity as a function of m. While the comment identifies a potential area for improvement and provides a constructive suggestion, it lacks depth and does not offer specific guidance on how to address the questions or improve the paper. The feedback is somewhat helpful as it prompts the authors to consider additional analyses, but it could be more beneficial with more detailed suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity regarding the postprocessing effort mentioned in footnote 2. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify the postprocessing effort, but it lacks concrete instructions or details on how to do so. As a result, the authors are left without a clear understanding of what specific actions are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper, such as a specific section or footnote, is being addressed. It lacks specificity because it does not provide details on what is unclear about the postprocessing effort or how it could be clarified. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the clarity of the postprocessing effort mentioned in footnote 2. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the effort is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a lack of clarity regarding the postprocessing effort mentioned in footnote 2. While it identifies an area that needs clarification, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it highlights a potential area for improvement, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to run their codes for multiple seeds and report the mean. This is a clear and direct action that the authors can easily implement, providing them with a specific step to take in order to improve their draft. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions running the codes for multiple seeds and reporting the mean, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely running the codes for multiple seeds and reporting the mean. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should run their codes for multiple seeds and report the mean. However, it does not provide any reasoning, evidence, or examples to support why this is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is highly actionable as it explicitly instructs the authors to run their codes for multiple seeds and report the mean. This is a clear and direct suggestion that can significantly improve the robustness and generalizability of the results. By following this advice, the authors can address a common issue in empirical studies, ensuring that their findings are more reliable and accurate. However, the comment could be more helpful if it provided additional context or justification for why this step is important or how it might impact the interpretation of the results. Overall, the comment is highly actionable and provides valuable guidance for improving the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup for BCI and IHC4BC in the paper. It specifically mentions that Table 3 lacks results for models like InceptionV3 and ResNet, while Table 2 includes them. While the comment identifies areas that need clarification or explanation, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information about the datasets and experimental setup. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup for BCI and IHC4BC in the paper. It specifically mentions that Table 3 lacks results for models like InceptionV3 and ResNet, while Table 2 includes them. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the inclusion of results for certain models in Tables 2 and 3. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup for BCI and IHC4BC in the paper. It specifically mentions that Table 3 lacks results for models like InceptionV3 and ResNet, while Table 2 includes them. This is a factual observation that highlights a discrepancy in the experimental setup, but it does not contain an opinion, judgment, or suggestion that requires verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the differences between the BCI and IHC4BC datasets and the experimental setup for BCI and IHC4BC in the paper. It specifically points out that Table 3 lacks results for models like InceptionV3 and ResNet, while Table 2 includes them. This feedback is valuable as it highlights a potential inconsistency in the experimental setup, which could impact the validity and comparability of the results. However, the comment could be more helpful if it provided suggestions on how to address this issue or clarified the rationale behind the differences in the datasets and experimental setup. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but lacks detailed guidance on how to resolve it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a more thorough description of the results shown in Figure 4. This feedback is clear and direct, as it specifies the exact part of the paper that needs improvement and what additional information should be included. The action is concrete, as it clearly identifies the need for a more detailed description of the results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a more thorough description of the results shown in Figure 4. This provides clear guidance on what the authors need to improve in their draft. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the results in Figure 4 need a more thorough description. However, it does not provide any specific reasoning or examples to support why this is necessary or how the current description is insufficient. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area for improvement, namely the need for a more thorough description of the results shown in Figure 4. This feedback is clear and actionable, as it directs the authors to provide additional details that can enhance the clarity and comprehensiveness of their results. However, the comment could be more helpful if it offered specific suggestions on what aspects of the results should be elaborated or how the description could be improved. Overall, the comment provides a valuable direction for improvement but lacks depth and detailed guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their work more thoroughly with the relevant literature, specifically mentioning [11]. While it implies that the comparison should be expanded, it does not provide explicit instructions on how to do so or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should expand the comparison with the work in the method section. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the most relevant literature is [11] and recommends comparing with the work more in the method section or in more detail. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its suggestion to compare with the literature, but it lacks grounding as it does not explicitly mention which part of the paper should be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the most relevant literature is [11] and recommends comparing with the work more thoroughly in the method section or in more detail. However, the comment does not provide specific reasoning or examples to support why [11] is considered the most relevant literature or how the comparison should be conducted. Without additional context or evidence, the claim is difficult for the authors to verify and address. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the most relevant literature is [11] and recommends comparing with the work more thoroughly in the method section or in more detail. While it provides a specific reference to a potential relevant work, it lacks depth and does not offer detailed guidance on how to conduct the comparison or what aspects to focus on. The comment identifies a potential area for improvement but does not provide actionable steps or detailed suggestions for the authors to enhance their analysis. Therefore, the feedback is somewhat helpful, as it points out a potential area for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the process of removing words with identical English counterparts in the class label translation and cleaning, suggesting that there may be legitimate shared words between the English and language-specific vocabulary. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve their approach. The comment lacks actionable details, such as recommending specific steps to justify the removal process or suggesting alternative methods for handling shared words. As a result, the authors are left without a clear understanding of how to address the issue, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the process of removing words with identical English counterparts in the class label translation and cleaning, suggesting that there may be legitimate shared words between the English and language-specific vocabulary. However, it does not specify which part of the paper this concern is related to, making it weakly grounded. The comment is specific in detailing the issue with the removal process and referencing a potential source of information, \"Ten Years of BabelNet: A Survey.\" This provides some grounding, but the authors cannot confidently determine the exact part of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the process of removing words with identical English counterparts in the class label translation and cleaning, suggesting that there may be legitimate shared words between the English and language-specific vocabulary. The reviewer supports this claim by referencing a specific work, \"Ten Years of BabelNet: A Survey,\" which discusses the issue of shared words between languages. This reference provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by further elaboration on why this shared vocabulary might be problematic or how it could be addressed in the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the process of removing words with identical English counterparts in the class label translation and cleaning, suggesting that there may be legitimate shared words between the English and language-specific vocabulary. The comment provides a specific reference to a relevant work, \"Ten Years of BabelNet: A Survey,\" which discusses the issue of shared words between languages. This feedback is somewhat helpful as it identifies a potential weakness in the paper's methodology and suggests a potential area for further exploration or clarification. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or improve their approach. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the study should focus on more models to verify the findings. While it implies that the authors should expand their study to include additional models, it does not provide specific guidance on which models to include or how to conduct the additional studies. The action is implicit and somewhat vague, as the authors need to infer that they should expand their study to include more models. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the study focuses on LLaVA and InstructBLIP and draws conclusions for large vision-language models. However, it does not specify which part of the paper this focus is discussed in, making it weakly grounded. The comment is specific in suggesting that the study should include more models to verify the findings, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the study focuses on LLaVA and InstructBLIP and draws conclusions for large vision-language models. However, it does not provide any supporting evidence, reasoning, or references to substantiate why this focus is problematic or inadequate. The comment lacks specificity and does not offer a clear rationale for why expanding the study to include more models would be beneficial. As a result, the claim is not verifiable, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the study focuses on LLaVA and InstructBLIP and draws conclusions for large vision-language models. It recommends expanding the study to include more models to verify the findings. This feedback is somewhat helpful as it identifies a potential limitation in the study\\'s scope and suggests a way to enhance its robustness. However, the comment lacks specific guidance on which models to include or how to conduct the additional studies. To be more helpful, the comment could provide examples of other models that could be studied or offer suggestions on how to effectively expand the study\\'s scope. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the results shown in Figure 7 and Table 3, noting that while the norm shows significant reduction for OpenCLIP in Figure 7, it does not show significant improvement for object localization, which is the main benefit of using register. The reviewer suggests that further explanation or exploration of the reasons behind this discrepancy would be helpful for wide adoption. While the comment implies that the authors should provide an explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation, but it is clear enough to guide the authors in the right direction. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy in the results shown in these figures and suggests that further explanation or exploration of the reasons behind the discrepancy would be beneficial for wide adoption. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a discrepancy between the results shown in Figure 7 and Table 3, noting that while the norm shows significant reduction for OpenCLIP in Figure 7, it does not show significant improvement for object localization, which is the main benefit of using register. The reviewer suggests that further explanation or exploration of the reasons behind this discrepancy would be helpful for wide adoption. However, the comment does not provide specific examples or references to support the claim that the discrepancy is significant or that it affects the main benefit of using register. The lack of detailed evidence or reasoning makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the results presented in Figure 7 and Table 3, noting that while the norm shows significant reduction for OpenCLIP in Figure 7, it does not show significant improvement for object localization, which is the main benefit of using register. The comment suggests that further explanation or exploration of the reasons behind this discrepancy would be helpful for wide adoption. This feedback is somewhat helpful as it points out a potential issue that the authors should address to improve the clarity and impact of their results. However, it could be more helpful if it provided specific suggestions on how to explore or explain the discrepancy. Overall, the comment offers a direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity regarding the use of 3D renders and the GAN objective in Section 3.3. It explicitly asks for more details about how the 3D rendering and the GAN objective are combined. This provides a clear and direct action for the authors to take, which is to provide additional information about the integration of these elements in the paper. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the use of 3D renders and the GAN objective. The comment provides a clear direction for improvement by asking for more details about how the 3D rendering and the GAN objective are combined. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of how the 3D renders are used in conjunction with the GAN objective, specifically mentioning Section 3.3. It highlights the lack of detail on how the latent code z is used to modulate the weights of the rendering network and how the point cloud is used in this stage. The comment is somewhat verifiable as it provides a specific area of concern and seeks clarification, but it lacks detailed reasoning or references to support the claim. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the lack of clarity regarding the use of 3D renders and the GAN objective. It points out that Section 3.3 explains how the latent code z is used to modulate the weights of the rendering network, but it does not provide details on how the 3D rendering and the GAN objective are combined. The comment suggests that more information about this integration would be helpful. This feedback is clear and actionable, as it directs the authors to provide additional details that could enhance the clarity and comprehensibility of their work. However, it could be more helpful if it offered specific suggestions on how to present this information or what aspects to focus on. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the QIF model introduces additional hyperparameters compared to the traditional LIF model, and questions the validity of the parameter insensitivity claim based on the use of simple architectures and datasets. However, it does not provide specific guidance on how the authors should address this issue or what evidence would be more convincing. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the increased complexity of hyperparameters in the QIF model compared to the traditional LIF model, and questions the validity of the parameter insensitivity claim. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the claim and the need for more convincing evidence, but without explicit references to specific sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the validity of the parameter insensitivity claim based on the use of simple architectures and datasets. It does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes it challenging for the authors to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the claim of parameter insensitivity, specifically questioning the validity of this claim based on the use of simple architectures and datasets. It highlights the need for more convincing evidence to support this claim. While the comment points out an area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or provide more robust evidence. The feedback is somewhat helpful as it directs the authors\\' attention to a potential weakness but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the marginal improvements achieved by the proposed method over baselines and suggests that further improvements might be possible with other PLMs. It also suggests discussing the meaningful aspects of the proposed method and experiments in the context of LLMs. While the comment implies that the authors should consider alternative PLMs and discuss the significance of their work, it does not provide explicit instructions or concrete steps on how to address these points. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative PLMs and discuss the significance of their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of marginal improvements over baselines and suggests that further improvements might be achievable with other PLMs. It also mentions specific PLMs, such as RoBERTa and T5, and suggests discussing the meaningful aspects of the proposed method and experiments in the context of LLMs. However, the comment does not explicitly mention which part of the paper this critique pertains to, making it weakly grounded. The comment is specific in suggesting that the authors discuss the significance of their work in the context of LLMs, such as computational costs or real-world scenarios. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the marginal improvements achieved by the proposed method over baselines and suggests that further improvements might be possible with other PLMs. The reviewer questions whether the proposed method is sophisticated enough to achieve such performance and suggests exploring alternative PLMs like RoBERTa and T5. The comment also asks the authors to discuss the significance of their work in the context of LLMs, such as computational costs or real-world scenarios. While the comment provides a logical reasoning for questioning the sophistication of the proposed method, it lacks specific examples or references to support the claim about alternative PLMs. The suggestion to discuss the significance of the work is somewhat verifiable, as it provides a direction for improvement but lacks detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the marginal improvements achieved by the proposed method over baselines and suggests that further improvements might be possible with alternative PLMs. It also encourages the authors to discuss the significance of their work in the context of LLMs, such as computational costs or real-world scenarios. While the comment identifies a potential area for improvement and offers a constructive suggestion, it lacks specific guidance on how to achieve these improvements or what aspects of the proposed method should be discussed. The feedback is somewhat helpful as it provides a direction for improvement but could be more comprehensive with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the explanation of using soft assignment instead of hard assignment in the methodology section. It points out that while the explanation is provided, it lacks clarity on whether the authors have reported an experiment to prove their conjecture. However, the comment does not provide explicit guidance on what specific experiment should be included or how to address the lack of clarity. The action is implicit and vague, leaving the authors to infer that they need to provide more experimental evidence to support their conjecture. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"methodology\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the authors have reported an experiment to prove their conjecture regarding the use of soft assignment instead of hard assignment. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the explanation regarding the use of soft assignment instead of hard assignment in the methodology section. It suggests that while the explanation is provided, it lacks evidence or examples to support the conjecture. However, the comment does not provide specific examples or references to support the claim that an experiment is needed to prove the conjecture. This lack of detailed justification or evidence makes the claim somewhat verifiable, as it highlights a potential gap but does not fully substantiate the need for an experiment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the explanation of using soft assignment instead of hard assignment in the methodology section. It points out that while the explanation is provided, it lacks clarity on whether the authors have reported an experiment to prove their conjecture. This feedback is somewhat helpful as it highlights an area where the authors could improve the clarity and rigor of their work. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending the inclusion of an experimental section or additional evidence. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the methods presented make sense in the cross-silo setting but notes that their applicability is limited to this setting. It suggests that the methods could benefit from generalization to new clients, which is a general federated learning problem. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the generalizability of their methods. The action is implicit and somewhat vague, as the authors can infer that they need to consider generalizing their methods, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the applicability of the methods presented in the paper, specifically noting that they are mostly applicable in the cross-silo setting. It suggests that the methods could benefit from generalization to new clients in a general federated learning problem. However, the comment does not specify which part of the paper discusses the cross-silo setting or the applicability of the methods. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides a general direction for improvement, it lacks specificity and is not grounded. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the methods presented are mostly applicable in the cross-silo setting, as mentioned in the paper, and that their applicability is limited to this setting. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges that the methods presented in the paper are mostly applicable in the cross-silo setting, as mentioned in the paper. It suggests that the applicability is limited to this setting, which could limit its usefulness in general federated learning problems with a larger number of clients. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or improve the generalizability of their methods. While it identifies a potential issue, the feedback lacks actionable advice, making it somewhat helpful. The authors are left with a general understanding of the problem but without clear steps to address it, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the concept of distributional generalization in the context of regression, specifically questioning the phenomenon's surprising nature. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what specific aspects of distributional generalization should be considered. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the concept of distributional generalization in the context of regression, specifically questioning the phenomenon\\'s surprising nature. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment does provide some specificity by suggesting that a reasonably smooth regression model that interpolates the train data would necessarily exhibit distributional generalization in that setting. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the concept of distributional generalization in the context of regression. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the concept of distributional generalization in the context of regression, specifically questioning the phenomenon\\'s surprising nature. It suggests that a reasonably smooth regression model that interpolates the train data would necessarily exhibit distributional generalization in that setting. While the comment identifies a potential area for clarification or discussion, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this question or improve their draft. The feedback is somewhat helpful as it points out a potential gap in understanding, but it could be more actionable and comprehensive to be fully helpful. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the references and baselines are out of date and recommends including more recent research. It also mentions that the authors could easily find relevant results by searching for terms like \"Item Frequencies of Data Streams.\" While the comment implies that the authors should update their references and consider more recent research, it does not provide specific guidance on how to do so or which recent studies to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of outdated references and baselines, suggesting that more recent research should be included. However, it does not specify which parts of the paper these references are in, making it difficult for the authors to pinpoint the exact sections that need updating. Additionally, the comment lacks specificity regarding what recent research should be included or how to conduct the search for relevant studies. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the references and baselines are out of date and suggests that more recent research should be included. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of detailed reasoning or evidence makes the claim unverifiable, as it lacks the necessary support to be actionable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the references and baselines are out of date. It suggests that the authors should consider more recent research to provide a more comprehensive analysis. Additionally, it points out that the authors could easily find relevant results by searching for specific terms. While the comment highlights important areas for improvement, it lacks specific guidance on how to update the references or which recent studies to consider. This limits the comment\\'s helpfulness, as it provides a general direction but does not offer detailed steps for implementation. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the introduction, which focuses on computational challenges of scaling quadratic programs to high-dimensional action spaces, and the experimental analysis in Section 5, which primarily explores action constraints in lower-dimensional spaces. It suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. While the comment identifies a potential area for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should expand their analysis to include high-dimensional action spaces. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction\" and \"Section 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the introduction, which focuses on computational challenges in high-dimensional action spaces, and the experimental analysis in Section 5, which primarily explores action constraints in lower-dimensional spaces. The comment suggests that more in-depth analysis of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would be beneficial. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental analysis in Section 5 primarily explores action constraints in relatively lower-dimensional spaces, while the introduction highlights the computational challenges of scaling quadratic programs to high-dimensional action spaces. The comment suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. This claim is somewhat verifiable as it logically points out a discrepancy between the introduction and the experimental analysis, but it lacks specific examples or references to support the claim. The authors would need to make a logical inference to understand the importance of this discrepancy and how it affects the paper\\'s conclusions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the introduction, which highlights the computational challenges of scaling quadratic programs to high-dimensional action spaces, and the experimental analysis in Section 5, which primarily explores action constraints in lower-dimensional spaces. It suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. This feedback is somewhat helpful as it points out an area where the paper could be expanded to provide a more comprehensive understanding of the system\\'s capabilities. However, the comment lacks specific suggestions or guidance on how to conduct this analysis or what aspects to focus on. To be more helpful, the comment could provide actionable steps for the authors to enhance their analysis and address the identified gap. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the lack of information on the extra computation required to achieve the experimental results. It suggests that the extra performance might be due to the extra parameters or extra computation needed. The reviewer implies that if the model were made to have the same floats, the performance might be similar to the original transformers. While the comment implies that the authors should provide more information about the extra computation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details about the computational requirements, but the comment lacks concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental results and suggests that there is no information on how much extra computation is needed to achieve the good results. It implies that the extra performance might be due to extra parameters or extra computation, and suggests that if the model had the same floats, the performance might be similar to the original transformers. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or table where the results are presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion that the extra performance might be due to extra parameters or computation, but without explicit references to the paper, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental results are good but lacks information on the extra computation required to achieve such results. The reviewer suggests that the extra performance might be due to extra parameters or extra computation, implying that if the model had the same floats, the performance would be similar to the original transformers. The comment provides a logical reasoning and a plausible hypothesis, but it lacks specific examples or references to support the claim. The suggestion is somewhat verifiable, as it provides a reasonable basis for the claim but requires further elaboration to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that there is no information on the extra computation required to achieve the experimental results. It suggests that the extra performance might be due to the extra parameters or extra computation needed. The reviewer implies that if the model had the same floats, the performance might be similar to the original transformers. This feedback is somewhat helpful as it points out a gap in the paper\\'s explanation of the computational requirements, which could be a significant factor in the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or provide more information. To be more helpful, the comment could provide suggestions on how to quantify the extra computation or suggest ways to compare the performance of different models with varying computational requirements. Overall, the comment is somewhat helpful as it highlights an area for improvement but could be more actionable with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation and results are not convincing, as they do not show consistent trends and some improvements are not necessarily statistically significant. However, it does not provide specific guidance on how the authors should address these issues. The comment lacks actionable steps or suggestions for improvement, leaving the authors uncertain about what changes they need to make to enhance the credibility of their results. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the evaluation and results, specifically mentioning that they are not convincing due to inconsistent trends and questionable statistical significance. However, it does not specify which parts of the paper these issues pertain to, such as specific sections, figures, or tables. This makes it difficult for the authors to pinpoint the exact areas that need attention. The comment is specific in identifying issues with the results and evaluation, but it lacks grounding as it does not reference specific sections of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation and results are not convincing due to inconsistent trends and questionable statistical significance. However, it does not provide specific examples or detailed reasoning to support these claims. The comment lacks the necessary evidence or references to substantiate the critique, making it difficult for the authors to understand and address the issues. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the critique.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation and results, noting that they are not convincing due to inconsistent trends and questionable statistical significance. This feedback is valuable as it highlights a critical area that the authors need to address to enhance the credibility of their work. However, the comment lacks specific suggestions or guidance on how to improve the evaluation or results, such as recommending additional analyses or clarifying the statistical methods used. While it points out a significant concern, it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider highlighting the percentage of the error rate that is made up of subjective questions, as determined by human agreement. This feedback provides a clear and concrete action for the authors to take, which is to quantify the subjectivity of their questions. By doing so, the authors can assess whether the subjectivity of their questions is a significant issue and potentially address it. The comment is explicit and provides a specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of subjective questions and suggests that the authors consider highlighting the percentage of the error rate that is made up of subjective questions, as determined by human agreement. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table where the subjective questions are discussed. The comment is weakly grounded because the authors cannot confidently determine the exact part of the paper being addressed, and it is not specific because it lacks details on what needs to be addressed or how to implement the suggestion. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that several questions require subjective answers and proposes a method to quantify the subjectivity of these questions. The reviewer provides a logical reasoning by suggesting that determining the percentage of error rate made up of subjective questions could be useful. However, the comment lacks specific examples or references to support the claim that this method would be problematic. While the suggestion is logical, it could be strengthened with more detailed justification or examples. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but lacks full justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically the subjective nature of some questions. It suggests that the authors consider quantifying the percentage of error rate made up of subjective questions, as determined by human agreement. This feedback is actionable and provides a specific direction for improvement by suggesting a method to assess the subjectivity of the questions. By doing so, the authors can determine whether the subjectivity of their questions is a significant issue and potentially address it. However, the comment could be more helpful if it provided additional guidance on how to implement this suggestion or offered examples of how other studies have addressed similar issues. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from considering additional NLP tasks, such as sentiment classification and named-entity recognition, in addition to the current evaluation on a single dataset. While the comment implies that the authors should consider these tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their evaluation to include more tasks. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks evaluation and considers only a single dataset and limited NLP tasks, specifically mentioning intent recognition. It suggests that the paper would benefit from considering additional NLP tasks, such as sentiment classification and named-entity recognition. However, the comment does not specify which part of the paper discusses the evaluation or which sections should be expanded to include additional tasks. This makes it weakly grounded, as the authors cannot confidently determine which parts of the paper are being addressed. The comment is specific in suggesting additional tasks to consider, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks evaluation and considers only a single dataset and limited NLP tasks, specifically mentioning intent recognition. The comment suggests that the paper would benefit from considering additional NLP tasks, such as sentiment classification and named-entity recognition. However, the comment does not provide specific examples or references to support the claim that these additional tasks would improve the evaluation. While the suggestion is logical, the lack of detailed justification or examples makes the claim somewhat verifiable. The authors would need to infer the importance of these additional tasks and consider them themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that it lacks evaluation and considers only a single dataset and limited NLP tasks. It suggests that the paper would benefit from considering additional NLP tasks, such as sentiment classification and named-entity recognition, to enhance its evaluation. This feedback is clear and actionable, as it provides specific suggestions for improvement that could enhance the paper\\'s rigor and comprehensiveness. However, the comment could be more helpful if it explained why these additional tasks are important or how they would contribute to the paper\\'s overall contribution. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the label for the \"class semantic feature\" in Figure 3 should be changed from \"c\" to \"s.\" This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is highly actionable because it clearly specifies what needs to be changed, making it easy for the authors to implement the suggested change.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the label for the \"class semantic feature\" from \"c\" to \"s.\" This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the label for the \"class semantic feature\" in Figure 3 should be changed from \"c\" to \"s.\" However, the comment does not provide any reasoning, explanation, or evidence to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of the suggestion or how it would improve the clarity of the figure. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the labeling of a feature in Figure 3, suggesting that the label \"c\" should be changed to \"s.\" This feedback is clear and actionable, as it provides a direct and concrete suggestion for improving the clarity and accuracy of the figure. By addressing this issue, the authors can enhance the readability and understanding of their work. However, the comment could be more helpful if it included a rationale or explanation for why the current label is incorrect or misleading. Overall, the comment is mostly helpful as it provides a specific and actionable suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their method with state-of-the-art face swapping algorithms to clarify the distinction between de-identification and face swapping. This feedback provides a clear and explicit action for the authors to take, which is to conduct a comparison that can help differentiate their approach from existing methods. The suggestion is concrete and provides a specific direction for improvement, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the distinction between de-identification and face swapping, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the method proposed in the paper appears to be a form of face swapping and suggests comparing it with state-of-the-art face swapping algorithms. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method proposed in the paper is essentially a form of face swapping, similar to deepfake technology. It suggests that the key difference is that the target face in deepfake technology is a real individual, while in this work, the target face is derived from a 3DMM. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the distinction themselves and might find it challenging to fully understand the basis of the claim without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the distinction between de-identification and face swapping, noting that the method proposed in the paper appears to be a form of face swapping, similar to deepfake technology. It suggests that the key difference is that the target face in deepfake technology is a real individual, while in this work, the target face is derived from a 3DMM. However, the comment does not provide detailed guidance on how the authors might address this issue or suggest specific ways to differentiate their approach from existing methods. While it points out a potential weakness, the feedback lacks actionable suggestions or detailed critique, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results on word embeddings in Tables 1 and 2 are not compelling compared to Gaussian embeddings, the chief baseline from the literature. However, it does not provide any explicit or implicit suggestions on how the authors might improve the results or address this issue. There is no guidance on what specific aspects of the results need improvement or how to improve them. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the experimental results on word embeddings are not compelling compared to Gaussian embeddings, the chief baseline from the literature. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results on word embeddings in Tables 1 and 2 are not compelling compared to Gaussian embeddings, the chief baseline from the literature. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results on word embeddings in Tables 1 and 2, noting that they are not as compelling as the results using Gaussian embeddings, the primary baseline from the literature. This feedback highlights a potential weakness in the paper\\'s experimental design and suggests that the authors might need to reconsider their approach or provide more detailed analysis to strengthen their results. However, the comment lacks specific suggestions or guidance on how to address this issue, such as which aspects of the results need improvement or how to improve them. While it points out a potential area for improvement, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed method does not seem to differ significantly from previous studies mentioned in the paper, except for the task change to text summarization and the reward function change. It acknowledges that the finding that IRL is effective in text summarization is a positive contribution, but questions the significance of this difference. The comment implies that the authors should provide more detailed information or analysis to justify the novelty of their approach. However, it does not explicitly instruct the authors to do so, leaving the action somewhat vague. The authors can infer that they need to provide additional information or analysis to substantiate their contribution, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"methods in the previous studies mentioned in the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method does not differ significantly from previous studies, except for the task change to text summarization and the reward function change. The comment further references specific studies, which provides additional context for the authors to understand the comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method does not differ significantly from previous studies, except for the task change to text summarization and the reward function change. The reviewer references specific studies, such as Shi et al., 2018 and Ghosh et al., 2021, to support this claim. However, the comment lacks detailed analysis or specific examples from the referenced studies to fully substantiate the claim. While the references provide some context, the comment could be strengthened by offering more detailed comparisons or specific examples of how the proposed method differs from the existing literature. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the proposed method, noting that it does not seem to differ significantly from previous studies mentioned in the paper, except for the task change to text summarization and the reward function change. The reviewer references specific studies to support their claim, which provides some context for the authors to understand the comparison. However, the comment lacks detailed feedback or suggestions on how the authors might address this issue or enhance the novelty of their approach. While it points out a potential weakness, it does not offer actionable guidance or specific suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to improve the novelty or how to better integrate the different pieces of the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. However, it does not specify which part of the paper this critique is based on, such as the introduction, methodology, or results sections. Without explicit references to specific sections, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what aspects of the novelty or contribution are lacking. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. However, it does not provide specific feedback or suggestions on how the authors could enhance the novelty or the contribution of the dataset. Without actionable advice or guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks an ablation study related to query embedding, which would provide insights into the significance and impact of this component. This feedback is clear and direct, indicating that the authors should include an ablation study on query embedding. The comment provides a specific action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study\" related to query embedding, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014an ablation study related to query embedding\u2014and why it is important for understanding the significance and impact of this component. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks an ablation study related to query embedding, which would provide insights into the significance and impact of this component. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate why an ablation study is necessary or how it would contribute to the paper. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking: an ablation study related to query embedding. This feedback is clear and actionable, as it points out a gap in the experimental analysis that could provide valuable insights into the significance and impact of the component. By suggesting an ablation study, the reviewer offers a concrete suggestion for improvement that could enhance the paper\\'s depth and rigor. However, the comment could be more helpful if it provided additional guidance on how to conduct such a study or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment expresses a subjective opinion that the contribution is marginal compared to previous works in [1, 2, 3]. However, it does not provide any specific guidance or suggestions on how the authors could improve their contribution or address the comparison to these previous works. The lack of actionable advice or concrete steps for improvement makes it difficult for the authors to know how to respond to this feedback. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the contribution being marginal compared to previous works in [1, 2, 3]. However, it does not specify which part of the paper this comparison is based on, nor does it provide details on what aspects of the contribution are considered marginal. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion that the contribution is marginal compared to previous works in [1, 2, 3]. However, it does not provide any specific references or detailed reasoning to support this claim. Without specific examples or references to previous works, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses an opinion that the contribution is marginal compared to previous works in [1, 2, 3]. However, it does not provide any specific reasoning or examples to support this claim, nor does it offer suggestions for improvement or ways to enhance the contribution. Without actionable feedback or detailed guidance, the authors are left without a clear understanding of what aspects of their work need improvement or how to address the comparison to previous works. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of a question asking the authors to clarify their reasoning behind the loss of performance of w2gm against w2g in the analysis of SWCS. While the comment implies that the authors should provide an explanation, it does not explicitly instruct them to do so or offer guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a response to the question. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the analysis of SWCS,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the loss of performance of w2gm against w2g and seeks clarification on the authors\\' response. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification regarding the loss of performance of w2gm against w2g in the analysis of SWCS. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment consists of a question seeking clarification on the loss of performance of w2gm against w2g in the analysis of SWCS. While it prompts the authors to provide a response, it does not offer any guidance or suggestions on how to address this issue or improve the draft. The comment lacks depth and actionable feedback, making it barely helpful for the authors in terms of improving their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the paper regarding the evaluation of overoptimization. It points out that while the paper discusses overoptimization as a motivation, it does not directly evaluate for overoptimization. The reviewer suggests that the paper should evaluate the tradeoffs of not using early stopping, as current works address the issue with early stopping. Additionally, the reviewer suggests discussing the benefits of not using early stopping. While the comment provides explicit actions for the authors to take, such as evaluating overoptimization and discussing the benefits of not using early stopping, it lacks specific guidance on how to implement these changes. The authors are given a clear direction but may need to infer the details of execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where overoptimization is discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of direct evaluation for overoptimization and the need to discuss the benefits of not using early stopping. The comment provides a clear direction for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not directly evaluate overoptimization, instead focusing on calibration and human evaluation. The reviewer suggests that current works, such as AlignProp, address the overoptimization issue with early stopping. The comment provides a logical reasoning by referencing a specific work, which supports the claim that overoptimization should be evaluated. However, the comment could be strengthened by providing more detailed examples or references to support the claim about early stopping. Overall, the comment is mostly verifiable, as it provides a clear rationale but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the evaluation of overoptimization. It points out that while the paper discusses overoptimization as a motivation, it does not directly evaluate this issue. The reviewer suggests that the paper should evaluate the tradeoffs of not using early stopping, as current works address the overoptimization issue with early stopping. Additionally, the comment suggests discussing the benefits of not using early stopping. This feedback is clear and actionable, providing the authors with specific guidance on how to improve their evaluation and discussion of overoptimization. By addressing these points, the authors can enhance the rigor and comprehensiveness of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed TW model is equivalent to TR by noting that if the core tensor C is represented by a TR, then fusing this TR with the cores G_n can lead to a TR representation equivalent to the former TW model. The reviewer expresses a desire to see this analysis in the paper and a discussion justifying TW over TR. While the comment implies that the authors should include this analysis and discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed TW model\" and the \"TR\" model, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis comparing the TW model to TR and justifying the choice of TW over TR. This provides clear guidance on what the authors need to include in their paper to improve it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed TW model is equivalent to TR by noting that if the core tensor C is represented by a TR, then fusing this TR with the cores G_n can lead to a TR representation equivalent to the former TW model. The reviewer suggests that this analysis and justification should be included in the paper. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the claim, which is not fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential equivalence between the proposed TW model and TR, suggesting that the authors should include an analysis and discussion justifying the choice of TW over TR. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by addressing the equivalence and justifying their model choice. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or what specific aspects of the TW model should be compared to TR. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss the transferability of their toolset, noting that the toolset for the VQA task and the toolset for the reasoning task are not the same. The reviewer suggests that the authors might experiment to create a general toolset for all tasks and observe the results. While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should conduct experiments to create a general toolset. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"toolset\" and the \"VQA task and the reasoning task,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests discussing the transferability of the toolset and provides a suggestion to experiment with creating a general toolset for all tasks. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the transferability of the toolset should be discussed, as the toolset for the VQA task and the toolset for the reasoning task are not the same. The reviewer provides a logical reasoning by pointing out the difference in toolsets and suggests that the authors might experiment with creating a general toolset for all tasks. However, the comment lacks specific examples or references to support the claim that the toolset transferability is an issue. While the suggestion is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the toolset for the VQA task and the toolset for the reasoning task are not the same. It suggests that the authors might experiment with creating a general toolset for all tasks and observe the results. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper by addressing the issue of toolset transferability. However, the comment could be more helpful if it offered additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests evaluating the model's performance using multiple random feature orders to assess the impact of feature order variability without the need for a complex controller. This implies that the authors should consider implementing this baseline to determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. While the suggestion is explicit, it lacks concrete details on how to implement this baseline or what specific metrics should be used to assess the impact. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests evaluating the model's performance using multiple random feature orders to assess the impact of feature order variability without the need for a complex controller. It provides a specific suggestion for a baseline that could help determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The suggestion is specific, as it clearly outlines what needs to be addressed, but it lacks full grounding due to the lack of explicit reference to a specific section. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests evaluating the model's performance using multiple random feature orders to assess the impact of feature order variability without the need for a complex controller. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, which is to determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. However, the comment lacks specific examples or references to support the claim, such as detailed explanations of how this baseline would be implemented or how it would be evaluated. This makes the comment somewhat verifiable, as it provides a reasonable basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It recommends evaluating the model's performance using multiple random feature orders to assess the impact of feature order variability without the need for a complex controller. This suggestion is a valuable addition to the paper, as it offers a baseline approach that could help determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. By implementing this baseline, the authors can gain a deeper understanding of the model's performance and the impact of feature reordering. However, the comment could be more helpful if it included specific guidance on how to implement this baseline or what metrics to use for evaluation. Overall, the comment is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the related work section is severely lacking, specifically mentioning the omission of lexically constrained decoding methods as both related work and baselines for comparison. This provides a clear and direct action for the authors to take, which is to include these references in the related work section. The comment is explicit and provides concrete guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the related work section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the inclusion of lexically constrained decoding methods as both related work and baselines for comparison. This provides clear guidance on what needs to be addressed in the related work section. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related work section is severely lacking, specifically mentioning the omission of lexically constrained decoding methods as both related work and baselines for comparison. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the significance of this omission and how it affects the paper\\'s overall contribution. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the related work section, specifically noting the omission of lexically constrained decoding methods as both related work and baselines for comparison. This feedback is clear and actionable, as it highlights a critical gap in the paper that needs to be addressed. By pointing out the missing references, the comment provides the authors with a specific area to focus on for improvement. However, the comment could be more helpful if it offered suggestions on how to incorporate these references or what specific aspects of lexically constrained decoding methods should be included. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison is not comprehensive due to the absence of important baseline models and datasets. It explicitly mentions two specific models, SimVLM and OFA, as examples of what is missing. However, the comment does not provide any guidance on how the authors should address this issue, such as suggesting which models or datasets should be included or how to improve the comprehensiveness of the comparison. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly what steps to take to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the comprehensiveness of the comparison, mentioning the absence of important baseline models and datasets. It explicitly references two specific models, SimVLM and OFA, which helps the authors identify the parts of the paper being addressed. However, the comment lacks specificity as it does not detail what aspects of the comparison are lacking or how the authors could improve it. Without additional guidance or suggestions, the authors may find it challenging to address the issue effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the comparison is not comprehensive due to the absence of important baseline models and datasets. However, it does not provide specific examples or references to these models or datasets, making it difficult for the authors to understand the exact nature of the issue. Without detailed justification or evidence, the claim lacks verifiability, as it does not provide sufficient support for the authors to address the concern effectively. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the comprehensiveness of the comparison, noting the absence of important baseline models and datasets. It explicitly mentions two specific models, SimVLM and OFA, as examples of what is missing. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve the comprehensiveness of the comparison. While it highlights a critical area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a significant weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the manuscript is framed as a dataset paper but does not present any new data collection or release. It notes that the paper actually presents derivative data, such as 3D pose estimates from existing datasets, which is disappointing for readers who were hoping for a new data source. While the comment identifies a potential issue with the framing of the paper, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the paper. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the nature of their dataset and potentially provide more information about its derivation. However, without concrete steps or examples, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"dataset paper\" framing of the manuscript, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is that it does not present any new data collection or release, but rather presents derivative data from existing datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the manuscript is framed as a dataset paper but does not present any new data collection or release. It further states that the paper actually presents derivative data, such as 3D pose estimates from existing datasets, which is disappointing for readers who were hoping for a new, potentially useful data source. This claim is somewhat verifiable as it provides a logical reasoning for the disappointment, but it lacks specific examples or references to support the assertion that the data is derivative. The authors would need to infer the nature of the data themselves to fully understand the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the framing of the manuscript, noting that it is presented as a dataset paper but does not present any new data collection or release. This is a critical observation, as it misleads readers who were hoping to find a new, potentially useful data source. The comment highlights the disappointment of not having access to new data, which is a crucial aspect of dataset papers. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the paper. While it points out a significant problem, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point criticizes the authors for criticizing L-softmax and A-softmax for requiring an annealing-like training procedure, but it also points out that this method itself has a specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their critique. It lacks actionable details, such as recommending alternative methods or suggesting specific modifications to the training procedure. As a result, the authors are left without a clear understanding of what steps to take to address the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors for criticizing L-softmax and A-softmax for requiring an annealing-like training procedure, but it also points out that this method itself has a specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The authors can infer that it relates to the discussion on training procedures, but they cannot confidently determine the exact section being addressed. The comment is specific in detailing the issue with the critique and the specific learning rate schedule, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors criticize L-softmax and A-softmax for requiring an annealing-like training procedure, but it also points out that this method itself has a specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the authors are criticizing the method for requiring an annealing-like training procedure. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the authors for criticizing L-softmax and A-softmax for requiring an annealing-like training procedure, but it also points out that this method itself has a specific learning rate schedule for experiments on CIFAR and Face Verification. This feedback highlights a potential inconsistency in the authors\\' critique and provides a specific example of the learning rate schedule. However, the comment could be more helpful if it offered suggestions on how the authors might address this inconsistency or improve their critique. While it identifies a relevant issue, the feedback lacks depth and actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the focus of the quantitative and qualitative analysis, suggesting that it should be more focused on the analysis of the results themselves rather than just comparing AE to diffusion. It questions what insights can be gained from the visualizations regarding the crucial elements for detecting a chair, such as the handle, and whether this feature is consistent across a wide range of chairs. The comment implies that the authors should reconsider their analysis approach and provide more detailed insights into the results. However, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to address these concerns. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the focus of the quantitative and qualitative analysis, specifically questioning the emphasis on comparing AE to diffusion and suggesting that the analysis should focus more on the results themselves. It raises questions about what insights can be gained from the visualizations regarding the crucial elements for detecting a chair, such as the handle, and whether this feature is consistent across a wide range of chairs. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the analysis and results sections. The comment is specific in its questioning of the analysis approach and the need for more detailed insights into the results. Therefore, this comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the focus of the quantitative and qualitative analysis, suggesting that it should be more focused on the analysis of the results themselves rather than just comparing AE to diffusion. The reviewer questions what insights can be gained from the visualizations about the crucial elements for detecting a chair, such as the handle, and whether this feature is consistent across a wide range of chairs. The comment is somewhat verifiable as it provides a logical reasoning for the need to reconsider the analysis approach and questions the focus of the analysis. However, it lacks specific examples or references to support the claim that the current analysis is insufficient. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the focus of the quantitative and qualitative analysis, suggesting that it should be more focused on the analysis of the results themselves rather than just comparing AE to diffusion. It raises important questions about what insights can be gained from the visualizations regarding the crucial elements for detecting a chair, such as the handle, and whether this feature is consistent across a wide range of chairs. The comment prompts the authors to reconsider their analysis approach and provides a clear direction for improving the draft. However, it could be more helpful if it offered specific suggestions or examples of how to address these issues. Overall, the comment is somewhat helpful as it provides a valuable critique but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the statement in Section 2.2, suggesting that it should be revised to exclude the word \"at least.\" The reviewer provides a logical explanation of why this change would be appropriate, noting that the worst-case scenario would be x=1, where the ratio would be b/1, and in all other cases (x>1), the ratio would be b/x or eventually b/b=1. However, the comment does not explicitly instruct the authors to make this change or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the suggested change and determine how to incorporate it into their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the beginning of Section 2.2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, suggesting that it should be revised to exclude the word \"at least\" and instead use \"at most.\" The reviewer provides a logical explanation of why this change would be appropriate, which helps the authors understand the rationale behind the suggestion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a logical reasoning and a specific observation about the wording in the paper. It does not contain subjective opinions, judgments, or suggestions that require verification. Instead, it presents a factual observation about the wording in the text, which is not subject to interpretation or validation. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the wording in the beginning of Section 2.2, suggesting that the statement should be revised to exclude the word \"at least\" and instead use \"at most.\" The reviewer provides a logical explanation of why this change would be appropriate, noting that the worst-case scenario would be x=1, where the ratio would be b/1, and in all other cases (x>1), the ratio would be b/x or eventually b/b=1 (as soon as x>b). This feedback is clear and actionable, as it offers a precise correction that can improve the clarity and accuracy of the text. However, it could be more helpful if it included additional context or explanation about why this change is necessary or how it affects the overall understanding of the section. Overall, the comment is mostly helpful, as it provides a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the notation used in Theorem.1, specifically asking about the meaning of D^{alpha}_{x}. The reviewer does not provide any explicit or implicit actions for the authors to take, nor does it suggest any improvements or corrections. Without guidance on how to address the question or clarify the notation, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the meaning of \"D^{alpha}_{x}\" and whether it denotes the derivatives of the probabilistic measure \\mu. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the notation used in Theorem.1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the notation used in Theorem.1, specifically asking about the meaning of D^{alpha}_{x}. This is a clear and actionable feedback that prompts the authors to clarify a potentially confusing aspect of their work. By addressing this question, the authors can improve the clarity and accessibility of their theorem, which is an important aspect of scientific communication. However, the comment could be more helpful if it provided additional context or suggestions on how to clarify the notation. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that there is a missing proper expression for the third face image in Figure 2. This provides a clear and direct action for the authors to take, which is to add the proper expression for the image. The comment is specific and provides a concrete action for the authors to implement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the missing proper expression for the third face image in Figure 2. This provides clear guidance on what needs to be corrected or added. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a missing proper expression for the third face image in Figure 2. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the figure, noting that there is a missing proper expression for the third face image in Figure 2. This is a clear and actionable piece of feedback that the authors can easily address by adding the missing expression. However, the comment lacks depth and does not provide suggestions on how to improve the figure or explain why this expression is important. While it highlights a specific issue, it could be more helpful by offering additional guidance or context. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests including an example created by BERT and comparing it with one created by the proposed model. This is an explicit action that the authors can directly implement by adding this comparison to their draft. The comment provides a clear and concrete suggestion for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a potential addition to the paper, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not provide any reasoning, evidence, or examples to support why this comparison would be beneficial or how it would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including an example created by BERT and comparing it with one created by the proposed model. This feedback is somewhat helpful as it provides a specific suggestion for enhancing the paper by adding a comparison that could help illustrate the performance of the proposed model. However, the comment lacks depth and does not explain why this comparison is important or how it would benefit the paper. Additionally, it does not offer guidance on how to implement this suggestion or what specific aspects of the comparison should be addressed. While it provides a direction for improvement, the feedback could be more comprehensive and actionable with additional details. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the dataset size of Vault and CSN should be the same in order to demonstrate that Vault is better in terms of data quality than CSN. While the comment implies that the authors should make this change, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should adjust the dataset size to achieve the desired comparison. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the code summarization task and the code search task, specifically suggesting that the dataset size of Vault and CSN should be the same to demonstrate that Vault is better in terms of data quality than CSN. However, it does not specify which part of the paper discusses these tasks or where the dataset size is currently being used. This makes it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion about the dataset size, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the dataset size of Vault and CSN should be the same to demonstrate that Vault is better in terms of data quality than CSN. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would demonstrate data quality. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the dataset size of Vault and CSN should be the same in order to demonstrate that Vault is better in terms of data quality than CSN. This feedback is somewhat helpful as it identifies a specific area for improvement, namely ensuring that the dataset sizes are comparable. However, the comment lacks depth and does not provide detailed guidance on how to achieve this comparison or why it is important. Additionally, it does not offer suggestions on how to address any potential issues with dataset size or quality. While the comment provides a clear direction for improvement, it could be more helpful with additional context or suggestions. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific terms that are not explained well in the paper, such as \"action-repeat\" and \"dithering phenomenon.\" It explicitly states that these terms should be explained more carefully and provides examples of their usage in the paper. This feedback is clear and concrete, giving the authors a direct action to take by improving the explanations of these terms. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific terms, \"action-repeat\" and \"dithering phenomenon,\" which allows the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanation for these terms. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some important concepts are not explained well in the paper, specifically mentioning \"action-repeat\" and \"dithering phenomenon.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate why these terms are crucial or how they are not adequately explained. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific terms that are not explained well in the paper, such as \"action-repeat\" and \"dithering phenomenon.\" It highlights the importance of clarifying these concepts, as they are recurring terms throughout the paper. By pointing out these areas of confusion, the comment provides actionable feedback that can help the authors improve the clarity and comprehensibility of their draft. However, the comment could be more helpful if it offered suggestions on how to explain these terms more effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a potential improvement in the methodology by proposing a different approach to handling instructions. It suggests creating an instruction embedding g(f(s)) from state encoding f(s) and passing it directly to the executor, rather than using the generated text. Additionally, it proposes an auxiliary objective to bring the instruction embedding closer to the gold encoding. While the comment provides a clear and concrete action\u2014creating an instruction embedding and modifying the methodology\u2014it lacks specific guidance on how to implement this change or what specific steps to follow. The authors are given a clear direction but may need to infer some details to execute the action. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a potential improvement in the methodology by proposing a different approach to handling instructions. It provides a clear rationale for the change, suggesting that creating an instruction embedding g(f(s)) from state encoding f(s) and passing it directly to the executor could be more effective. The comment also proposes an auxiliary objective to bring the instruction embedding closer to the gold encoding. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in detailing the proposed changes, providing clear guidance on how to implement them. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a potential improvement in the methodology by proposing a different approach to handling instructions. The reviewer provides a logical reasoning for the proposed change, explaining that it avoids discretization in between, which could fail due to a single wrong decoding. The comment is somewhat verifiable as it provides a clear rationale for the suggested change, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the methodology by proposing a different approach to handling instructions. It suggests creating an instruction embedding g(f(s)) from state encoding f(s) and passing it directly to the executor, rather than using the generated text. Additionally, it proposes an auxiliary objective to bring the instruction embedding closer to the gold encoding, which could potentially improve the methodology. The comment is detailed and provides specific guidance on how to implement the suggested changes, making it highly helpful for the authors. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the novelty of the proposed model is not significant, but it does not provide any explicit or implicit suggestions for improvement or action. There is no guidance on how the authors might enhance the novelty or what aspects of the model need to be revised to increase its novelty. Without any actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to address this issue. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment states that the novelty of the proposed model is not significant, but it does not specify which part of the paper discusses the model or where the novelty is lacking. Without explicit references to sections or details, the authors cannot confidently determine which aspects of the paper need to be addressed. Additionally, the comment lacks specificity regarding what aspects of the model are considered unoriginal or lacking in novelty. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the proposed model is not significant. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment states that the novelty of the proposed model is not significant, which is a critical observation that could impact the paper\\'s impact and contribution. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might enhance the novelty or address this issue. Without actionable feedback or detailed insights into what aspects of the model need improvement, the authors are left without a clear path for improvement. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the use of a particular dataset, suggesting that the proportion of each class used for the pool subset may make the dataset easier by removing ambiguity between similar-looking numbers. The reviewer points out that this could affect the accuracy as a measure of quality, as smaller classes may be poorly classified. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their dataset selection. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their dataset selection, but the comment lacks concrete details on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the use of a particular dataset, suggesting that the proportion of each class used for the pool subset may make the dataset easier by removing ambiguity between similar-looking numbers. However, it does not specify which part of the paper discusses the dataset or where this issue is addressed. The authors can infer that it relates to the dataset section, but the comment lacks full grounding. It is specific in detailing the issue with the dataset, such as the removal of ambiguity between numbers, but it does not provide specific suggestions on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proportion of each class used for the pool subset may make the dataset easier by removing ambiguity between similar-looking numbers, which affects the accuracy as a measure of quality. The reviewer provides a logical reasoning by explaining how the dataset's structure could influence the accuracy, suggesting that smaller classes may be poorly classified. However, the comment lacks specific examples or references to support the claim that the dataset's structure affects the accuracy. This makes the claim somewhat verifiable, as it provides a reasonable argument but requires further elaboration to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the use of a particular dataset, suggesting that the proportion of each class used for the pool subset may make the dataset easier by removing ambiguity between similar-looking numbers. This observation is somewhat helpful as it points out a potential issue with the dataset selection that could affect the accuracy as a measure of quality. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their dataset selection. Without actionable advice or detailed feedback, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is rated as somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions and points of clarification, but it does not provide explicit or implicit actions for the authors to take. It suggests that the authors should clarify the \"main\" contribution of their work, which is related to the strategic aspects of prediction. However, it does not specify how the authors should address this issue or what specific aspects of the work need clarification. Additionally, the comment asks about the \"true\" payoff in Table 1 and suggests exploring the work by Vapnik about teaching a learner with side information. While these questions provide some direction, they do not offer concrete steps for the authors to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the paper, such as the contribution of showing the strategic aspects of prediction and the \"true\" payoff in Table 1. It also raises questions about the work by Vapnik and the relationship to the paper\\'s approach. However, the comment does not explicitly mention which section of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the \"main\" contribution and the \"true\" payoff in Table 1. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the main contribution of the paper and suggests exploring the work of Vapnik. However, it does not provide any specific reasoning, evidence, or examples to support these claims. The questions about the \"true\" payoff in Table 1 and the relationship to Vapnik\\'s work are presented as requests for clarification rather than as claims that need verification. Therefore, the comment is considered \"No\" as it does not contain any claims that require verification.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several questions and points of clarification, which can be beneficial for the authors in refining their work. It highlights the need to clarify the \"main\" contribution of the paper and suggests exploring the work of Vapnik regarding teaching a learner with side information. The comment also questions the \"true\" payoff in Table 1 and encourages the authors to consider this aspect further. While the feedback is somewhat helpful in identifying areas for improvement, it lacks specific suggestions or guidance on how to address these issues. Therefore, the comment is rated as somewhat helpful, as it provides some direction but could be more comprehensive with actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should explore another unsupervised domain adaptation (UDA) method based on self-training. While it implies that the authors should consider this approach, it does not provide specific guidance on which method to use or how to integrate it into the existing work. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the proposed method focuses solely on domain-alignment methods and recommends exploring another UDA method based on self-training. However, it does not specify which part of the paper this recommendation pertains to, such as a particular section or methodology. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in recommending a particular approach, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that self-training is a prominent and effective approach within the field of unsupervised domain adaptation (UDA), but the proposed method solely focuses on domain-alignment methods. The comment suggests that the authors should explore another UDA method based on self-training. However, the comment lacks specific examples or references to support the claim that self-training is a more effective approach. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the suggestion without additional guidance.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the proposed method should explore another unsupervised domain adaptation (UDA) method based on self-training. This feedback is clear and actionable, as it provides a concrete direction for the authors to consider an alternative approach that could enhance their work. However, the comment could be more helpful if it offered specific examples or references to other UDA methods that might be suitable for this approach. Despite this, the feedback is mostly helpful as it guides the authors toward a potentially valuable direction for their research.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the reliability diagrams, specifically the accuracy vs confidence plots, and questions whether the observed pathologies are due to dataset pathologies or variance/unpredictability in the proposed methods. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this concern. It lacks specific suggestions or actions for improvement, leaving the authors uncertain about how to proceed. The feedback is vague and lacks actionable details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 1, top,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the reliability diagrams, specifically the accuracy vs confidence plots, and questions whether the observed pathologies are due to dataset pathologies or variance/unpredictability in the proposed methods. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the reliability diagrams, specifically the accuracy vs confidence plots, and questions whether the observed pathologies are due to dataset pathologies or variance/unpredictability in the proposed methods. The comment provides a logical reasoning by pointing out that a perfect system would not exhibit the observed pathologies. However, it lacks specific examples or references to support the claim about pathologies, making it somewhat verifiable. The authors would need to infer the exact nature of the pathologies and determine whether they are due to dataset issues or method variance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the reliability diagrams, specifically the accuracy vs confidence plots, and questions whether the observed pathologies are due to dataset pathologies or variance/unpredictability in the proposed methods. It raises a valid concern about the reliability of the results and prompts the authors to consider whether their methods are robust enough. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or improve their analysis. While it points out a potential problem, it does not provide actionable feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the paper\\'s evaluation of advanced attacks and the detection of backdoors. It points out that the paper does not consider the fine-tuning of a partial subset of the dataset, which could lead to the presence of a backdoor. Additionally, it notes that the paper only focuses on the detection of backdoors and does not discuss state-of-the-art methods for backdoor removal. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should consider advanced attacks and discuss backdoor removal methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"fine-tuning only on a partial subset of D\" and the \"detection of backdoor,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of advanced attacks and the consideration of state-of-the-art methods for backdoor removal. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not evaluate advanced attacks and does not discuss state-of-the-art methods for backdoor removal. The reviewer provides a logical reasoning by explaining that the attacker could fine-tune only on a partial subset of the dataset, which could still lead to the presence of a backdoor. This reasoning is supported by the observation that the paper only focuses on detection and does not consider advanced attacks or backdoor removal methods. However, the comment could be strengthened by providing specific examples or references to relevant literature that discuss these advanced attacks or backdoor removal methods. As it stands, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper\\'s evaluation by pointing out that it does not consider advanced attacks or discuss state-of-the-art methods for backdoor removal. This is a critical oversight, as it limits the paper\\'s applicability and relevance. The comment provides clear and actionable feedback by suggesting that the authors should consider advanced attacks and discuss backdoor removal methods. This feedback is valuable as it directs the authors to enhance the comprehensiveness and practicality of their work. However, the comment could be more helpful if it offered specific examples or references to relevant literature on advanced attacks or backdoor removal methods. Overall, the comment is mostly helpful as it effectively guides the authors toward improving the scope and depth of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the choice of using the original adjacency matrix without exploring the conventional graph convolutional operation. It implies that the authors should provide an explanation or conduct an ablation study to justify this decision. However, the comment does not explicitly instruct the authors to perform these actions, leaving the action somewhat implicit. The authors can infer that they need to address this issue, but the lack of explicit guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the original GCN (Kipf and Welling) and the specific aspect of using the original adjacency matrix without explantation or ablation study. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises a question about the choice of using the original adjacency matrix and suggests an explanation or ablation study to justify this decision. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of using the original adjacency matrix without exploring the conventional graph convolutional operation. It suggests that the authors should provide an explanation or conduct an ablation study to justify this decision. However, the comment lacks specific examples or references to support the claim that the original GCN uses a normalized adjacency matrix with renormalization. Without such evidence or detailed reasoning, the claim is difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides a logical basis for the question but lacks sufficient evidence or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of using the original adjacency matrix without exploring the conventional graph convolutional operation. It suggests that the authors should provide an explanation or conduct an ablation study to justify this decision. This feedback is somewhat helpful as it prompts the authors to consider the implications of their choice and potentially explore alternative approaches. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Overall, the comment offers a valuable direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the absence of a link for WMT\\'14 training corpora, despite the presence of a link for WMT\\'15. This question implies that the authors should provide a link for WMT\\'14 as well. However, the comment does not explicitly instruct the authors to add this link, nor does it provide guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide a link but may not know exactly how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the absence of a link for WMT\\'14 training corpora, despite the presence of a link for WMT\\'15. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where the issue is discussed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in its question about the link\\'s absence, but without explicit grounding, it is difficult for the authors to pinpoint the exact issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for an explanation regarding the absence of a link for WMT\\'14 training corpora, despite the presence of a link for WMT\\'15. This is a factual inquiry and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment raises a question about the absence of a link for WMT\\'14 training corpora, despite the presence of a link for WMT\\'15. This question highlights a potential inconsistency in the paper\\'s presentation, which could be confusing for readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the presentation. While it identifies a potential problem, it lacks actionable feedback or detailed advice, making it somewhat helpful. The authors are given a direction to consider but are not provided with specific steps to take. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors need to provide upper and lower bounds for adaptive matrices A t and B t in order to determine other hyperparameters. This is an explicit action that the authors can directly implement by including these bounds in their paper. The comment is clear and provides concrete guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors need to provide upper and lower bounds for adaptive matrices A t and B t in order to determine other hyperparameters. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for bounds on adaptive matrices, but lacks grounding in terms of where this information should be included. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors need to provide upper and lower bounds for adaptive matrices A t and B t in order to determine other hyperparameters. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these bounds are necessary or how they would impact the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors need to provide additional information, namely the upper and lower bounds for adaptive matrices A t and B t. This feedback is clear and actionable, as it directly suggests a specific improvement that could enhance the clarity and completeness of the paper. By addressing this point, the authors can better guide their readers in understanding the hyperparameter selection process. However, the comment could be more helpful if it provided additional context or examples on how these bounds might impact the results or analysis. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the paper is not particularly high, as most techniques used were proposed and demonstrated before. It also questions the experimental results on the PDBbind dataset. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of novelty or how to improve the experimental results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the paper is not particularly high, as most techniques used were proposed and demonstrated before. It also questions the experimental results on the PDBbind dataset. However, it does not specify which part of the paper this critique pertains to, such as specific sections or results. The authors cannot confidently determine which part of the paper is being addressed, making this comment weakly grounded. The comment is specific in its critique of the novelty and experimental results, but without clear grounding, it is difficult for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the paper is not particularly high, as most techniques used were proposed and demonstrated before. However, it does not provide specific examples or references to support this claim. The mention of the PDBbind dataset is vague and does not offer detailed reasoning or evidence to substantiate the critique. Without specific examples or references, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the novelty of the paper is not particularly high, as most techniques used were proposed and demonstrated before. It also questions the experimental results on the PDBbind dataset. While the comment identifies a potential weakness in the novelty and experimental results, it lacks specificity and actionable suggestions for improvement. It does not provide guidance on how the authors might enhance the novelty or address the concerns about the experimental results. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that adding error bars to the results of comparisons between pairs of models would enhance the presentation by demonstrating that the differences are indeed significant. This feedback is explicit, as it clearly specifies the action needed to improve the draft. However, it does not provide detailed guidance on how to implement this suggestion, such as which statistical method to use or how to present the error bars. While the action is clear, the lack of concrete details on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding error bars to results comparing pairs of models to demonstrate that the differences are significant. However, it does not specify which part of the paper this suggestion pertains to, such as specific figures or sections where these comparisons are presented. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to include error bars, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that adding error bars to results comparing pairs of models would enhance the presentation by demonstrating that the differences are significant. However, the comment does not provide any supporting evidence, reasoning, or references to justify why error bars are necessary or how they would improve the presentation. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that adding error bars to results comparing pairs of models would enhance the presentation by demonstrating that the differences are significant. This feedback is clear and actionable, as it provides a specific suggestion for improving the clarity and robustness of the results. By including error bars, the authors can effectively communicate the magnitude of the differences between models, which is crucial for understanding the significance of their findings. However, the comment could be more helpful if it provided additional guidance on how to determine appropriate error bars or how to present them effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the full state is not defined properly and asks what is included in a full state. This provides a clear and direct action for the authors to take, which is to clarify the definition of a full state in their paper. The comment is specific and provides a concrete action for the authors to implement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 2, line 81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of a full state and what is included in it. This provides clear guidance on what the authors need to clarify or improve in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the definition of a \"full state\" and asks what is included in it. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the definition is unclear or inadequate. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the definition of a \"full state\" in the paper, noting that it is not clearly defined. By asking what is included in a full state, the comment prompts the authors to clarify their terminology and provide more detailed information about their concept. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their paper that could potentially improve its clarity and comprehensibility. However, the comment could be more helpful if it offered suggestions on how to improve the definition or provided examples of what might be included in a full state. Overall, the comment is mostly helpful as it highlights an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the strengths of the empirical study but points out the lack of new proposals for neural architecture encoding. It suggests that a good empirical analysis should not only provide insightful observations or conclusions but also include new initial proposals based on the analysis. While the comment identifies an area for improvement, it does not provide explicit guidance on how to incorporate new proposals or what specific aspects should be considered. The action is implicit and somewhat vague, as the authors can infer that they need to include new proposals but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment acknowledges the strengths of the empirical study and points out the lack of new proposals for neural architecture encoding. However, it does not specify which part of the paper this issue pertains to, such as the results or discussion sections. The authors can infer that it relates to the analysis or conclusions, but this inference is not direct. The comment is specific in its critique of the lack of new proposals, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the strengths of the empirical study but criticizes the lack of new proposals for neural architecture encoding. It suggests that a good empirical analysis should not only provide insightful observations or conclusions but also include new initial proposals based on the analysis. While the comment identifies a gap in the paper, it does not provide specific examples or references to support the claim that the lack of new proposals is a significant issue. The reasoning is somewhat verifiable, as it highlights a potential area for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the strengths of the empirical study but points out a gap in the paper\\'s contribution. It suggests that a good empirical analysis should not only provide insightful observations or conclusions but also include new initial proposals based on the analysis. This feedback highlights an area where the authors could enhance their work by incorporating new proposals or ideas that build upon their empirical findings. However, the comment does not provide specific suggestions or examples on how to incorporate these proposals, which limits its helpfulness. While it identifies a valuable area for improvement, the lack of actionable guidance makes it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly recommends that the paper be evaluated as \"Marginally above the acceptance threshold\" due to its theoretical nature and the lack of empirical results. It also provides specific suggestions for improvement, such as including empirical comparisons with existing algorithms. The comment further details the need for practical usefulness and points out that SGD requires many iterations before convergence, which could impact communication costs. While the comment provides clear actions for the authors to take, such as conducting empirical comparisons and addressing the practical usefulness of the algorithm, it could be more helpful if it included detailed guidance on how to conduct these comparisons or what specific aspects of the algorithm should be evaluated. Overall, the comment is mostly actionable as it provides clear and concrete steps for improvement, but it could be more detailed in its guidance.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors should conduct empirical comparisons with existing algorithms, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue of theoretical nature without empirical results and the need for practical usefulness, providing clear guidance on what needs to be addressed. The comment also includes detailed comments about the lack of definitions for \\Delta_i, \\Delta_{med}, and \\nabla_i, which further enhances the specificity of the feedback. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks empirical comparisons with existing algorithms, which is a theoretical paper. It suggests that theoretical comparison with existing algorithms has been done comprehensively, and it raises an anxiety about the practical usefulness of the algorithm due to the need for many iterations with SGD. The reviewer provides some reasoning by mentioning that communication costs between the master and workers may become larger than with GD. However, the comment lacks specific examples or references to support the claim about the practical usefulness of the algorithm. While the reasoning is logical, it could be strengthened with more detailed evidence or examples. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks specific examples or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable critique of the paper, noting that it is a theoretical paper without empirical results and recommending it be evaluated as \"Marginally above the acceptance threshold.\" It also highlights the need for practical usefulness, particularly in the context of SGD's requirement for many iterations before convergence, which could impact communication costs. The comment further details specific areas for improvement by pointing out the lack of definitions for \\Delta_i, \\Delta_{med}, and \\nabla_i. This feedback is mostly helpful as it identifies key weaknesses and provides clear suggestions for improvement, such as conducting empirical comparisons and addressing the practical usefulness of the algorithm. However, it could be more helpful if it offered additional guidance on how to conduct empirical comparisons or what specific aspects of the algorithm should be evaluated. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed approach performs well in simulations but not in real data, which raises questions about its practical advantage. It implies that including more real data analyses or comparisons could help support the method. While the comment provides a direction for improvement, it does not explicitly instruct the authors to include these analyses or comparisons. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the performance of the proposed approach in simulations and real data, suggesting that the method may not have a practical advantage due to its poor performance in real data. However, it does not specify which part of the paper discusses the approach or where the real data analyses or comparisons should be included. The authors can infer that it relates to the results or discussions sections, but this inference is not as direct as it could be. The comment is specific in suggesting the need for more real data analyses or comparisons, but it lacks full grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed approach performs well in simulations but not in real data, which raises questions about its practical advantage. The comment suggests that including more real data analyses or comparisons could help support the method. However, the comment lacks specific examples or references to support the claim about the performance in real data. Without detailed evidence or comparisons, the claim is difficult for the authors to verify and address. Therefore, the comment is considered borderline verifiable, as it provides a direction for improvement but lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed approach, noting that it performs well in simulations but not in real data. This observation raises questions about the practical advantage of the method. The comment suggests that including more real data analyses or comparisons could help support the method. While the comment highlights an important area for improvement, it lacks specific guidance on how to conduct these analyses or what aspects of the real data should be considered. This limits the comment\\'s usefulness, as it provides a direction for improvement but does not offer detailed guidance. Therefore, the comment is somewhat helpful, as it points out a critical area for enhancement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the authors\\' claims regarding the low discrimination risk and improved fairness of their solution, while also noting the importance of maintaining the underlying data distribution after imputation. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their claims. The feedback lacks actionable steps or concrete details, leaving the authors uncertain about what specific changes or clarifications are needed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the authors\\' claims about the low discrimination risk and improved fairness of their solution, as well as the importance of maintaining the underlying data distribution after imputation. However, it does not specify which part of the paper these claims are made in, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in detailing what needs to be addressed regarding the fairness and data distribution aspects, but it lacks grounding as it does not specify where these issues are discussed in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the authors\\' claims about the low discrimination risk and improved fairness of their solution, suggesting that the underlying data distribution should be maintained after imputation. The comment provides a logical reasoning by pointing out that maintaining the data distribution is crucial for the effectiveness of the models. However, it lacks specific examples or references to support the claim that the solution sacrifices utility. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the authors\\' claims about their solution\\'s low discrimination risk and improved fairness, while also highlighting the importance of maintaining the underlying data distribution after imputation. This feedback is somewhat helpful as it points out a critical aspect of the paper that needs attention, but it lacks specific suggestions or guidance on how the authors might address these concerns or improve their claims. The comment highlights a potential area for further exploration and clarification, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors could exploit ReferIt more by using more of its data before moving on to other datasets. While the suggestion is clear, it lacks specific guidance on how to implement this suggestion or what additional data should be used. The authors are left with a general idea of what to do but without concrete steps or detailed instructions. Therefore, the comment is somewhat actionable, as it provides a direction but lacks the level of detail needed for full actionability.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors could exploit ReferIt more by using more of its data before moving on to other datasets. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this could be implemented. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The suggestion is specific in terms of what could be done, but without clear grounding, it is difficult for the authors to effectively address the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors could exploit ReferIt more by using more of its data before moving on to other datasets. However, the comment lacks specific reasoning or examples to support why this suggestion is beneficial or how it would improve the paper. Without detailed justification or evidence, the claim remains unverifiable, as it does not provide sufficient guidance for the authors to understand and implement the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors could exploit ReferIt more by using more of its data before moving on to other datasets. This feedback is somewhat helpful as it identifies an area for potential improvement, specifically suggesting that the authors could leverage more data from ReferIt. However, the comment lacks depth and does not provide specific guidance on how to implement this suggestion or what additional data could be used. Without detailed instructions or examples, the authors may find it challenging to fully understand and act upon the feedback. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the explanation provided in sections 243-245, specifically regarding the choice of 5*3 and the use of k-NN. It asks for clarification on why 5*3 was chosen over 5*2, as in the case of beta-vae, and why k-NN was used instead of other classifiers. The comment implies that the authors should provide more detailed explanations or examples to address these questions. While the action is implicit, it is clear and specific, as it directs the authors to provide additional information to clarify their explanation. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions sections 243-245, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of why 5*3 was chosen over 5*2 and the use of k-NN instead of other classifiers. The comment provides detailed questions about the choice of 5*3 and the use of k-NN, which helps the authors understand what aspects need clarification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the clarity of the explanation in sections 243-245, specifically questioning the choice of 5*3 over 5*2 and the use of k-NN instead of other classifiers. The reviewer seeks clarification on the reasoning behind these choices, such as the distance metric used and the choice of k. While the comment identifies areas for clarification, it lacks specific examples or references to support the claims. This makes the comment somewhat verifiable, as it provides a general direction for improvement but requires more detailed justification to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas of the paper that are unclear, particularly regarding the choice of 5*3 over 5*2 and the use of k-NN instead of other classifiers. It asks for clarification on the reasoning behind these choices, such as the distance metric used and the choice of k. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations or examples to enhance the clarity and comprehensibility of their work. By addressing these questions, the authors can improve the understanding and robustness of their methodology. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a detailed description of the background of Sharpness-Aware Minimization (SAM). This is a clear and direct action, as it specifies exactly what needs to be added to the paper. The comment is specific, as it identifies the need for a detailed background section, and it provides a concrete direction for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sharpness-Aware Minimization (SAM),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the background of SAM. This provides clear guidance on what the authors need to include in their paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the background of Sharpness-Aware Minimization (SAM) should be described in detail. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate why this background is crucial or how it relates to the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the background of Sharpness-Aware Minimization (SAM) should be described in detail. This feedback is clear and actionable, as it provides a direct and concrete suggestion for enhancing the paper. By addressing this point, the authors can improve the comprehensiveness and depth of their background section, which could enhance the overall understanding and context of their work. However, the comment could be more helpful if it offered additional guidance on how to structure or present this background information. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental setup lacks comprehensive comparisons, particularly between language-assisted and vision-assisted approaches. It provides specific suggestions for improvement, such as incorporating image guidance by utilizing related reference normal images or color-augmentation for the kNN baseline. Additionally, it recommends a thorough examination of both language-based and vision-based assistance to strengthen the evaluation of LAFT\\'s efficacy. These explicit and concrete suggestions provide clear guidance on what the authors should do to enhance their experimental setup. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental setup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as incorporating image guidance and a thorough examination of both language-based and vision-based assistance. This guidance helps the authors understand what aspects of the experimental setup need attention and how to enhance it. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experimental setup lacks comprehensive comparisons, particularly between language-assisted and vision-assisted approaches. It provides a specific example of incorporating image guidance by utilizing related reference normal images and color-augmentation for the kNN baseline. This suggestion is supported by logical reasoning and examples, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed justification or references to similar studies that have demonstrated the value of these approaches. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental setup, specifically the lack of comprehensive comparisons between language-assisted and vision-assisted approaches. It provides specific suggestions for improvement, such as incorporating image guidance by utilizing related reference normal images or color-augmentation for the kNN baseline. These suggestions are actionable and could help the authors enhance the evaluation of their method, particularly by demonstrating the efficacy of language-based and vision-based assistance. However, the comment could be more helpful if it elaborated on why these comparisons are important or how they might impact the overall evaluation. Overall, the comment is mostly helpful as it provides clear and actionable feedback, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of related work, specifically mentioning collective entity linking as a closely related line of work. It suggests that the proposed model is a special case of collective entity linking and implies that the paper should include this work. However, the comment does not provide explicit instructions or concrete guidance on how to incorporate this information into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include related work but are not given specific steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of related work, specifically mentioning \"collective entity linking\" as a closely related line of work. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what is missing\u2014the inclusion of related work\u2014and suggests that the proposed model is a special case of collective entity linking. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed model is a special case of collective entity linking, which is a closely related line of work. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of related work that could provide context and comparison for the proposed model. It specifically mentions collective entity linking as a closely related line of work, suggesting that the proposed model is a special case of this work. However, the comment does not offer specific suggestions or guidance on how the authors might incorporate this information into their paper. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests comparing the effect of truncating the log likelihood function on sensitivity. It also raises a minor comment about the query functions in Algorithm 1, noting that they are the same for all data sources, despite the general framework stating they can be different. The reviewer suggests designing customized query functions for each data source or removing the subscript. While the comment implies that the authors should consider these suggestions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Truncating the log likelihood function\" and \"algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of sensitivity and suggests comparing the effect of truncating the log likelihood function. Additionally, it raises a minor comment about the query functions in Algorithm 1, noting that they are the same for all data sources, despite the general framework stating they can be different. This comment provides specific guidance on how to address the issue of customized query functions for each data source. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests comparing the effect of truncating the log likelihood function on sensitivity. This is a logical suggestion that could provide insight into the impact of the truncation. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The minor comment about the query functions in Algorithm 1 is also somewhat verifiable, as it points out a potential inconsistency but does not provide detailed reasoning or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for further exploration by recommending a comparison of the effect of truncating the log likelihood function on sensitivity. This is a valuable point that could enhance the paper\\'s contribution by offering a new perspective on the impact of truncation. Additionally, the comment raises a minor issue regarding the query functions in Algorithm 1, noting that they are the same for all data sources, despite the general framework stating that they can be different. This feedback is somewhat helpful as it highlights an inconsistency that the authors might want to address. However, the comment could be more helpful if it provided more detailed guidance on how to address this issue or suggested specific ways to customize the query functions. Overall, the comment is mostly helpful as it identifies areas for improvement and offers actionable suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation is limited to a small set of molecules from the MD17 dataset and recommends expanding the evaluation to include a larger and more diverse dataset. This feedback provides a clear and explicit action for the authors to take, which is to broaden the evaluation to include more complex molecules and materials. The suggestion is concrete and specific, giving the authors a direct path to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the evaluation is limited to a small set of molecules from the MD17 dataset and recommends expanding the evaluation to include a larger and more diverse dataset. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in recommending the inclusion of more complex molecules and materials, but without explicit references to sections or figures, the authors may struggle to identify the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluation is limited to a small set of molecules from the MD17 dataset and recommends expanding the evaluation to include a larger and more diverse dataset. However, the comment does not provide specific examples or references to support why this expansion is necessary or how it would enhance the evaluation. Without detailed reasoning or evidence, the claim remains vague, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation, noting that it is limited to a small set of molecules from the MD17 dataset. It suggests expanding the evaluation to include a larger and more diverse dataset, including more complex molecules and materials. This feedback is clear and actionable, providing the authors with a specific direction for improving the evaluation section of their paper. By broadening the dataset, the authors can demonstrate the robustness and generalizability of their method, which is crucial for the credibility of their work. However, the comment could be more helpful if it included specific examples or references to studies that have successfully expanded their evaluations to diverse datasets. Overall, the comment is mostly helpful as it directs the authors to a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is similar to the StreamingLLM paper and points out that the sink tokens in the StreamingLLM paper may correspond to $C_{special}$ and $C_{punct}$. It also mentions that the StreamingLLM paper has recently been uploaded, making it unlikely to compare this paper with it. However, the comment implies that the authors should clarify the differences in their paper. While the action is implicit, it is clear that the authors need to clarify the differences between their work and the StreamingLLM paper. The comment provides a specific area for improvement, but it lacks detailed guidance on how to implement this clarification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the StreamingLLM paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the similarities between the paper and the StreamingLLM paper, and suggests clarifying the differences in the current work. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is similar to the StreamingLLM paper, which sets sink tokens and performs local attention. It suggests that the differences in this paper should be clarified, as the StreamingLLM paper has recently been uploaded. The comment provides some reasoning by mentioning the sink tokens and local attention, but it lacks specific examples or references to the StreamingLLM paper to fully substantiate the claim. This makes the claim somewhat verifiable, as it provides a general idea but requires more detailed evidence or references to fully support the comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential similarity between the paper and the StreamingLLM paper, noting that both papers set sink tokens and perform local attention. It suggests that the differences in this paper should be clarified, given that the StreamingLLM paper has recently been uploaded. While the comment highlights an important area for improvement, it lacks specific guidance on how to clarify the differences or what aspects of the paper need clarification. The feedback is somewhat helpful as it points out a potential issue but does not provide detailed suggestions for addressing it. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a perceived lack of significant improvement in qualitative results compared to ConceptWeaver, which is also capable of handling more than two concepts. However, it does not provide any explicit or implicit actions for the authors to take. The mention of a specific reference, \"ConceptWeaver,\" suggests that the authors should compare their results with those of ConceptWeaver, but this is not a direct instruction. The comment lacks actionable guidance, leaving the authors uncertain about how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ConceptWeaver,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a perceived lack of significant improvement in qualitative results compared to ConceptWeaver, which is capable of handling more than two concepts. This provides clear guidance on what needs to be addressed in terms of qualitative results. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is no significant improvement in qualitative results compared to ConceptWeaver, which is also capable of handling more than two concepts. The reviewer supports this claim by referencing \"ConceptWeaver\" and a specific publication, \"Enabling multi-concept fusion in text-to-image models,\" which provides a basis for comparison. However, the comment lacks detailed analysis or specific examples from the paper to fully substantiate the claim. While the reference provides some context, the comment could be strengthened by offering more detailed comparisons or specific examples from the paper to support the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks comprehensive evidence or justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a perceived lack of significant improvement in qualitative results compared to ConceptWeaver, which is also capable of handling more than two concepts. While it references a specific work, \"ConceptWeaver,\" it does not provide detailed feedback or suggestions on how the authors might address this issue or improve their results. The comment lacks actionable guidance or specific insights into how the authors might enhance their qualitative results. As a result, the feedback is somewhat helpful, as it identifies a potential area for improvement but does not offer concrete steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the problem reduces to subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. However, it does not provide explicit instructions or concrete steps for the authors to follow in implementing this suggestion. The action is implicit and vague, as the authors are left to infer that they should explore matrix completion and subspace clustering as potential solutions. Without detailed guidance or examples, the authors may find it challenging to apply this feedback effectively. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the problem reduces to subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding how the authors should implement the alternating approach between matrix completion and subspace clustering. Without explicit references or detailed guidance, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the problem reduces to subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the problem reduces to subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. While this feedback identifies a potential approach to address the problem, it lacks specificity and does not provide detailed guidance on how to implement this solution or why it might be effective. The comment does not offer actionable steps or examples, leaving the authors with limited direction on how to improve their draft. Therefore, the comment is barely helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the performance of CCKT-Det++ and its reliance on teacher models. It suggests that if the teacher model has limitations or biases, these could affect the performance of CCKT-Det++ and introduce unintended biases. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting specific ways to improve the quality or alignment of the teacher models. The action is implicit and somewhat vague, as the authors can infer that they need to consider the quality and alignment of the teacher models but are not given concrete steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"CCKT-Det++,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the model, namely its reliance on teacher models and the potential impact of teacher model limitations or biases on performance and introducing unintended biases. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a potential issue with the performance of CCKT-Det++ and its reliance on teacher models. It suggests that if the teacher model has limitations or biases, these could affect the performance of CCKT-Det++ and introduce unintended biases. This claim is somewhat verifiable as it logically presents a plausible concern, but it lacks specific examples or references to support the assertion. The authors might need to explore the potential impact of teacher model limitations or biases in more detail to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the performance of CCKT-Det++ and its reliance on teacher models. It highlights the importance of ensuring the quality and alignment of these teacher models to avoid propagating limitations or biases to CCKT-Det++. This feedback is valuable as it points out a critical aspect of the model's performance that the authors may not have considered. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending methods for improving teacher model quality or alignment. Despite this, the comment still offers a clear direction for the authors to consider, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison objects used in the experiment are outdated, and their performance has not significantly improved. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue, such as recommending more recent comparison objects or proposing ways to improve the performance of the existing ones. The comment lacks actionable guidance, leaving the authors uncertain about how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the selection of comparison objects in the experiment, stating that they are outdated and have not shown significant performance improvement. However, it does not specify which part of the paper discusses the comparison experiment or which specific objects are being referred to. This lack of grounding makes it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the comparison objects are outdated or how they could be improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the comparison objects used in the experiment are outdated and have not shown significant performance improvement. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without specific examples or data, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the selection of comparison objects in the experiment, noting that they are outdated and have not shown significant performance improvement. This feedback highlights a potential weakness in the paper\\'s experimental design, which could impact the validity and relevance of the results. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve the experiment. While it points out a critical area for improvement, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point asks a question about how masks are handled in CNN layers (representation block), indicating that the authors need to clarify this aspect of their work. However, it does not provide explicit instructions or suggestions on how to address this question or improve the draft. The action is implicit and vague, as the authors are left to infer that they need to provide more information about masks in their paper. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about how masks are handled in CNN layers (representation block), indicating a lack of clarity in the paper. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs clarification. The comment is specific in its request for clarification on the handling of masks, but it lacks grounding as it does not identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification on how masks are handled in CNN layers (representation block). It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, so it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about how masks are handled in CNN layers (representation block), indicating a potential area for clarification or further explanation in the paper. However, it does not provide any context or guidance on how this information might be relevant to the overall paper or what specific aspects of the handling of masks need to be addressed. While it identifies a potential area for improvement, it lacks depth and actionable suggestions, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the reason for the larger training loss in \"without dropout\" compared to \"with dropout,\" suggesting that activation clipping may be reducing the model capacity. While the comment implies that the authors should provide an explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation but may not be entirely sure how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the reason for the larger training loss in \"without dropout\" compared to \"with dropout,\" suggesting that activation clipping may be reducing the model capacity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the reason for the larger training loss in \"without dropout\" compared to \"with dropout,\" suggesting that activation clipping may be reducing the model capacity. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the reason for the larger training loss in \"without dropout\" compared to \"with dropout,\" suggesting that activation clipping may be reducing the model capacity. This is a relevant and insightful observation that prompts the authors to consider an explanation for this phenomenon. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or explore the relationship between activation clipping and training loss. While it points out an area for further investigation, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by discussing the significance of establishing a large-scale matting dataset, which is not explicitly mentioned in the paper. However, it does not provide explicit guidance on how to incorporate this discussion or what specific aspects of the dataset should be addressed. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on the dataset significance. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could be improved by discussing the significance of establishing a large-scale matting dataset, which is not explicitly mentioned in the paper. However, it does not specify which part of the paper this discussion should be included in, nor does it provide detailed guidance on how to incorporate this suggestion. The authors can infer that it relates to the paper\\'s contributions or methodology sections, but the lack of explicit references or specificity makes it weakly grounded. The comment is specific in suggesting the importance of discussing the dataset, but it lacks grounding in the context of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper\\'s significance is in establishing a large-scale matting dataset, which is not explicitly mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a significant contribution or how it relates to the paper\\'s objectives. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper could be improved by discussing the significance of establishing a large-scale matting dataset, which is not explicitly mentioned in the paper. This feedback is somewhat helpful as it identifies a potential area for improvement and highlights a gap in the paper\\'s discussion. However, the comment lacks specific guidance or suggestions on how to incorporate this discussion or what aspects of the dataset should be addressed. While it points out a potential weakness, it does not provide actionable steps for the authors to improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the number of adversarial examples is too small to demonstrate some distribution. However, it does not provide any explicit or implicit suggestions on how the authors could increase the number of adversarial examples or improve the demonstration of distribution. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the number of adversarial examples is too small to demonstrate some distribution. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table where the adversarial examples are discussed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in identifying the issue with the number of adversarial examples, but without explicit grounding, it is difficult for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of adversarial examples is too small to demonstrate some distribution. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the number of adversarial examples being too small to demonstrate some distribution. This is a relevant observation that could impact the validity of the results. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or improve the demonstration of distribution. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the proposed channel-sparse gradients, suggesting that they may not save time or memory in practice. It also points out that most frameworks only support dense gradients and that zeroing out a particular channel may not alter the computation. The reviewer recommends conducting analysis experiments or \"Qualitative Studies\" with a full set of common corruptions to ensure thoroughness and comparability with other results. While the comment provides a clear suggestion for improvement, it lacks specific guidance on how to conduct these experiments or which corruptions to use. The action is explicit but somewhat vague, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed channel-sparse gradients, noting that they may not save time or memory in practice and that most frameworks only support dense gradients. The comment further provides specific suggestions for improvement, recommending conducting analysis experiments or \"Qualitative Studies\" with a full set of common corruptions to ensure thoroughness and comparability with other results. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed channel-sparse gradients may not save time or memory in practice, as most frameworks only support dense gradients. The reviewer supports this claim by noting that zeroing out a particular channel may not alter the computation performed. The comment also suggests that the analysis experiments or \"Qualitative Studies\" of Section 5.2 are conducted with a subset of common corruptions, which may not generalize to the full set. This provides a logical reasoning for the claim, but it could be strengthened by referencing specific studies or examples that demonstrate the inefficiency of channel-sparse gradients. Overall, the claim is mostly verifiable, as it is supported by logical reasoning and a suggestion for improvement, but it lacks detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed channel-sparse gradients, suggesting that they may not save time or memory in practice. It provides a logical reasoning by noting that most frameworks only support dense gradients and that zeroing out a particular channel may not alter the computation performed. The comment also highlights a limitation in the analysis experiments or \"Qualitative Studies\" of Section 5.2, which are conducted with a subset of common corruptions. This feedback is clear and actionable, as it suggests conducting analysis experiments or \"Qualitative Studies\" with the full set of common corruptions to ensure thoroughness and comparability with other results. This guidance is valuable for the authors to improve their draft, making the comment mostly helpful. However, it could be more comprehensive by providing specific guidance on which corruptions to use or how to conduct the experiments. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the authors\\' claims regarding not considering low rank and suggests that the proof may be related to low rank. It also mentions that the results have been previously explored in other works, indicating that the results may be a simple extension. However, the comment does not provide explicit guidance on how the authors should address these concerns or improve their draft. It lacks actionable steps or suggestions for improvement, leaving the authors uncertain about how to respond to the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific concerns about the paper\\'s claims regarding not considering low rank and the proof\\'s connection to concentration-of-measure. It also mentions specific references to existing results in [39][42][44]. However, the comment does not explicitly mention which part of the paper these concerns are related to, making it weakly grounded. The comment is specific in detailing the issues with the claims and the potential connection to low rank, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claims about not considering low rank and suggests that the proof may be related to low rank. It references specific works ([39][42][44]) to support this claim, providing some evidence that the results are not entirely novel. However, the comment lacks detailed reasoning or specific examples from the referenced works to fully substantiate the claim. While it provides some context, the justification is not comprehensive, making the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the authors\\' claims regarding not considering low rank and suggests that the proof may be related to low rank. It also mentions that the results have been previously explored in other works, indicating that the results may be a simple extension. While the comment identifies potential weaknesses in the claims and suggests that the results may not be as original as claimed, it lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. The feedback is somewhat helpful as it points out potential areas for improvement, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the Limitations section is too concise, which contrasts with the clear and detailed writing style in the main body of the paper. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue. There is no guidance on whether the Limitations section should be expanded, revised, or rewritten to align with the rest of the paper. As a result, the authors are left without any actionable steps to take, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the Limitations section, which is a specific part of the paper. However, it does not specify which part of the Limitations section is too concise, making it weakly grounded. The comment is specific in pointing out the contrast between the clear and detailed writing style in the main body of the paper and the concise nature of the Limitations section. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the Limitations section is too concise, which contrasts with the clear and detailed writing style in the main body of the paper. However, the comment does not provide specific examples or reasoning to support this claim, nor does it offer suggestions for improvement. Without detailed justification or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the Limitations section, noting that it is too concise compared to the clear and detailed writing style in the main body of the paper. This feedback highlights a discrepancy that the authors should address to maintain consistency and coherence in their work. However, the comment does not provide specific suggestions or guidance on how to improve the Limitations section, such as recommending additional details or examples. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the proposed method is weak, as it appears to be a modified version of previous work, PatchCore, with the addition of a denoising process to the memory bank. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or differentiate the method from existing work. Without actionable advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"proposed method\" and \"PatchCore,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issue by pointing out that the novelty of the proposed method is weak, as it appears to be a modified version of PatchCore with the addition of a denoising process to the memory bank. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is weak, as it appears to be a modified version of previous work, PatchCore, with the addition of a denoising process to the memory bank. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a weakness in the novelty of the proposed method, noting that it appears to be a modified version of previous work, PatchCore, with the addition of a denoising process to the memory bank. This feedback highlights a potential issue with the originality of the method, which could impact its perceived value and impact. However, the comment lacks specific suggestions or guidance on how the authors might enhance the novelty or differentiate their method from existing work. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests providing more detailed instructions on how to install and run the software, recommending an extensive version of Table 1 or a similar appendix structure to binpwn. Additionally, it recommends listing all prompts used in the evaluation in the appendix or on GitHub. While the comment provides explicit actions for the authors to take, such as creating an appendix or listing prompts, it does not specify how to implement these actions in detail. The authors know what needs to be done but may need to infer the exact steps to follow. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue with the repository lacking clear instructions on how to install and run the software, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, recommending the inclusion of more detailed instructions in an extensive version of Table 1 or the appendix, similar to binpwn. Additionally, it suggests listing all prompts used in the evaluation in the appendix or on GitHub. This level of detail provides the authors with a clear understanding of what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the repository lacks clear instructions on how to install and run the software, which is a factual observation. However, it does not provide specific examples or detailed reasoning to support this claim, such as which instructions are unclear or how they could be improved. The suggestion to provide more detailed instructions is logical, but without additional context or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the repository, noting that it lacks clear instructions on how to install and run the software. It provides a clear and actionable suggestion by recommending the inclusion of more detailed instructions, such as an extensive version of Table 1 or a similar appendix structure to binpwn. Additionally, it suggests listing all prompts used in the evaluation in the appendix or on GitHub. This feedback is valuable as it directly addresses a critical aspect of the paper, namely the accessibility and usability of the code. By providing specific and detailed guidance, the comment empowers the authors to improve the clarity and practicality of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA, where correct answers are anchored on correct visual content. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should reconsider the importance of the global representation g_v, but it lacks concrete steps or suggestions on how to improve the model or address the discrepancy. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a discrepancy between the model ablation results and the major claim of interpretable VQA. The comment provides a clear critique of the results and suggests that the global representation g_v may be more crucial than other components. However, it does not provide specific suggestions on how to address this issue or improve the model. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the global representation g_v is more crucial than other components in the model ablation results, which slightly contradicts the major claim of interpretable VQA. However, the comment lacks specific evidence or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides a suggestion but lacks sufficient justification or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA, where correct answers are anchored on correct visual content. It points out that the global representation g_v, which opens a \"back door\" for grounded QA, seems more crucial than other components. This feedback highlights an area where the authors may need to reconsider their assumptions and potentially adjust their model or interpretation. However, the comment lacks specific suggestions or guidance on how to address this issue or improve the model. While it provides a valuable insight, it could be more helpful with additional details or actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the notation in section 3 should be revised by avoiding the statement $f^{-1} = g$ and instead using the language of left inverses. This feedback is clear and provides a specific action for the authors to take, ensuring that they know exactly what needs to be changed to improve their draft. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the notation paragraph in sec 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, suggesting that the statement $f^{-1} = g$ should be avoided and replaced with language about left inverses. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation in section 3 should be revised by avoiding the statement $f^{-1} = g$ and using the language of left inverses. The reviewer provides a logical reasoning by explaining that $f$ cannot be an invertible function when $d<D$, as it is defined on a manifold. However, the comment lacks specific examples or references to support the claim that using the language of left inverses would be more appropriate. While the reasoning is clear, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation in section 3, suggesting that the statement $f^{-1} = g$ should be avoided and replaced with language about left inverses. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and accuracy of the notation. By addressing this issue, the authors can enhance the readability and rigor of their paper. However, the comment could be more helpful if it explained why the current notation is problematic or provided additional context on the implications of the suggested change. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the ablation studies on the motion tokenizer should include comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1]. This feedback provides a clear and concrete action for the authors to take, as it specifies the exact comparisons that should be made to enhance the comprehensiveness of the analysis. The suggestion is specific and leaves no ambiguity about what the authors need to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4\" and \"the ablation studies on the motion tokenizer,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], to provide a more comprehensive understanding of the model's relative effectiveness. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ablation studies on the motion tokenizer should include comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1]. This claim is somewhat verifiable as it provides a logical reasoning for why such comparisons would enhance the comprehensiveness of the analysis. However, the comment lacks specific examples or references to MoMask or other relevant works, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It points out that the ablation studies on the motion tokenizer should include comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], to provide a more comprehensive understanding of the model's relative effectiveness. This feedback is clear and constructive, as it directs the authors to a specific area where their work could be enhanced by incorporating additional comparisons. By following this suggestion, the authors can improve the comprehensiveness and rigor of their analysis, making the paper more robust and informative. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the \"primary-secondary\" relationship is mentioned frequently in the paper but that its difference with the concept of nuclearity is unclear and not precisely defined. While the comment identifies a potential area for clarification, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the relationship between primary-secondary and nuclearity. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"primary-secondary\" relationship, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the relationship, noting that it is unclear and not precisely defined in comparison to the concept of nuclearity. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"primary-secondary\" relationship is mentioned frequently but is unclear and not precisely defined in comparison to the concept of nuclearity. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the relationship between the \"primary-secondary\" and nuclearity concepts. It points out that the difference between these concepts is not clearly defined or explained, which could lead to misunderstandings or misinterpretations by readers. This feedback is actionable as it directs the authors to clarify and define these concepts more clearly, ensuring that the paper's message is more precise and understandable. However, the comment could be more helpful if it provided specific suggestions on how to clarify these concepts or examples of how they might be misunderstood. Overall, the comment is mostly helpful as it highlights an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper regarding the effect of mask ratio on different datasets, noting that this could lead to more tuning. It also suggests that the paper lacks an intuitive guide for choosing the mask ratio, which would be helpful. While the comment identifies a specific area for improvement, it does not provide explicit instructions or concrete steps on how to address this issue. The authors are left to infer that they should include an intuitive guide for choosing the mask ratio, but the comment lacks detailed guidance on what this guide should entail. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide specific guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"effect of mask ratio\" and the \"limitations\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of different datasets having different effects on mask ratio and suggests that an intuitive guide for choosing the mask ratio would be helpful. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the effect of mask ratio varies across different datasets, which could lead to more tuning, as mentioned in the limitations section. It also suggests that the paper lacks an intuitive guide for choosing the mask ratio, which would be helpful. The comment provides a logical reasoning for the need for an intuitive guide, but it does not provide specific examples or references to support the claim about the effect of mask ratio on different datasets. This makes the claim somewhat verifiable, as it provides a rationale but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper regarding the effect of mask ratio on different datasets, noting that this could lead to more tuning as mentioned in the limitations section. It also suggests that the paper lacks an intuitive guide for choosing the mask ratio, which would be helpful. This feedback is clear and actionable, as it highlights a specific area where the paper could be improved by providing a more comprehensive discussion of the mask ratio and its impact on different datasets. However, the comment could be more helpful if it offered specific suggestions or examples on how to develop an intuitive guide for choosing the mask ratio. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement and provides a clear direction for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper could benefit from another round of proof-reading, specifically mentioning that certain sections are difficult to follow. This provides a clear and direct action for the authors to take, which is to revise and improve the clarity of the sections in question. The comment is specific about what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from another round of proof-reading, specifically mentioning that certain sections are difficult to follow. However, it does not provide specific examples or references to these sections, making it difficult for the authors to pinpoint exactly where the issues lie. The comment lacks grounding as it does not specify which sections are problematic, making it not grounded. Additionally, it is not specific as it does not provide detailed guidance on what needs to be improved or how to address the issues. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper could benefit from another round of proof-reading, specifically mentioning that certain sections are difficult to follow. However, the comment does not provide any specific examples or detailed reasoning to support why these sections are challenging to understand. Without specific examples or references, the claim lacks sufficient evidence or justification, making it difficult for the authors to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from another round of proof-reading, specifically mentioning that certain sections are difficult to follow. While this feedback identifies a potential issue with the clarity of the paper, it lacks specificity and does not provide any guidance on which sections are problematic or how to improve them. Without detailed feedback or examples, the authors are left without actionable steps to enhance the readability and comprehensibility of their draft. Therefore, the comment is barely helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the manuscript regarding the term \"STG layer\" in Figure 2, noting that it has not been mentioned elsewhere in the paper. The reviewer speculates that it might refer to stochastic gates but does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete instructions or suggestions on how to clarify or correct this discrepancy, leaving the authors uncertain about how to proceed. Since the action is implicit and vague, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of mention of the term \"STG layer\" throughout the manuscript and the reviewer's uncertainty about its reference. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"STG layer\" in Figure 2 has not been mentioned elsewhere in the manuscript, and the reviewer speculates that it might refer to stochastic gates. However, the comment lacks specific references or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript regarding the term \"STG layer\" in Figure 2, noting that it has not been mentioned elsewhere in the paper. The reviewer speculates that it might refer to stochastic gates but does not provide a clear explanation or suggestion for how the authors should address this issue. While the comment highlights a potential inconsistency, it lacks actionable guidance or detailed feedback on how to resolve the issue. As a result, the comment is somewhat helpful, as it points out a potential problem but does not offer a clear path for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed methodology's improvements appear limited in some instances and underperforms compared to the baseline in the cases of FiQA and CONALA. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the methodology or what specific aspects need attention. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of the proposed methodology, specifically mentioning that the improvements appear limited and that it underperforms compared to the baseline in the cases of FiQA and CONALA. However, it does not specify which sections of the paper these results are discussed in, making it weakly grounded. The comment is specific in detailing the issue with the methodology\\'s performance, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed methodology\\'s improvements appear limited and that it underperforms compared to the baseline in the cases of FiQA and CONALA. However, the comment does not provide specific examples, detailed reasoning, or references to support these claims. Without such evidence or justification, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the proposed methodology, noting that the improvements appear limited and that it underperforms compared to the baseline in specific cases, such as FiQA and CONALA. This feedback highlights a potential weakness in the methodology that the authors should address to improve the paper\\'s overall impact. However, the comment lacks specific suggestions or guidance on how to improve the methodology or address the performance issues. While it points out a critical area for improvement, it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparisons with [1] are not clear and questions the contributions and advantages beyond [1]. It specifically mentions the differentially private model personalization and the NeurIPS 2021 conference. However, it does not provide explicit guidance on how the authors should clarify these comparisons or what specific aspects of the paper need improvement. The comment implies that the authors should clarify the contributions and advantages, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Comparisons with [1] are not clear,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the contributions and advantages beyond [1], which provides clear guidance on what needs to be clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of comparisons with [1] and seeks to understand the contributions and advantages beyond [1]. However, it does not provide specific examples or references to support the claim that the comparisons are unclear or that the contributions are not well-explained. The comment lacks detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of comparisons made with [1], which is a differentially private model personalization. It questions the contributions and advantages beyond [1], prompting the authors to clarify these aspects of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the clarity or substance of these comparisons. While it points out a relevant area for improvement, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a well-explained rationale for using the average feature of previous samples to stop the training of the uni-modal branch. This feedback is clear and concrete, as it specifies the exact part of the paper that needs improvement and provides a specific action for the authors to take. The comment also highlights the need for a detailed explanation, ensuring that the authors know exactly what is expected of them to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"re-balancing step method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanation and analysis of the method used to make multi-modal learning less greedy. The comment provides a clear direction for improvement by suggesting that the authors should provide a well-explained rationale for using the average feature of previous samples. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the re-balancing step method, which is used to make multi-modal learning less greedy, is not well described or analyzed in the full text. The reviewer suggests that the authors should provide a well-explained rationale for using the average feature of previous samples to stop the training of the uni-modal branch. This claim is somewhat verifiable as it logically suggests that a detailed explanation is needed, but it lacks specific examples or references to support the claim. The authors would need to make a significant effort to understand the reasoning behind the suggestion, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where the authors need to provide more detailed explanation and analysis. It points out that the re-balancing step method, which is used to make multi-modal learning less greedy, is not well described or analyzed in the full text. The comment suggests that the authors should provide a well-explained rationale for using the average feature of previous samples to stop the training of the uni-modal branch. This feedback is clear and actionable, as it directs the authors to a specific area where they need to improve their explanation and analysis. However, it could be more helpful if it included examples or references to similar methods or techniques that could further enhance the explanation. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the differences and advantages of the \"Reduce\" part compared to EATA and suggests considering the use of entropy instead of energy for identifying harmful OOD instances. While the comment implies that the authors should provide more information or clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details or consider alternative methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the differences and advantages of the \"Reduce\" part compared to EATA and suggests considering the use of entropy instead of energy for identifying harmful OOD instances. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification and additional information. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the differences and advantages of the \"Reduce\" part compared to EATA, and suggests considering the use of entropy instead of energy for identifying harmful OOD instances. This feedback is clear and actionable, as it prompts the authors to provide more detailed information or consider alternative methods. By addressing these questions, the authors can enhance the clarity and robustness of their work. However, the comment could be more helpful if it offered specific examples or references to support the suggestions. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be interesting to compare the proposed method with deterministic control, but it clarifies that this is not necessary for the main claims of the paper. This comment implies that the authors should consider conducting such a comparison if they find it relevant, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider this comparison if they find it valuable. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed method with deterministic control, which is a specific suggestion for improvement. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in its suggestion of a potential comparison, but without explicit references to sections or details, it is difficult for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the proposed method with deterministic control, which is a suggestion for improvement. However, it does not provide any reasoning, evidence, or examples to support why this comparison is necessary or beneficial. The comment lacks specificity and does not offer a clear rationale for the suggestion, making it difficult for the authors to understand the basis of the recommendation. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the proposed method with deterministic control, which could provide insight into the performance of the method. However, it acknowledges that this is not necessary for the main claims of the paper. This feedback is somewhat helpful as it identifies a potential area for improvement but does not provide detailed guidance or suggestions on how to conduct the comparison or what specific aspects to focus on. The authors are given a direction for potential enhancement but lack specific instructions or detailed advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the naming of the 3r column in Table 4, suggesting that it should not be named \"ATE\" and that \"Corr\" might also be \"Cau-Ant.\" While the comment implies that the authors should reconsider the naming of the column, it does not provide explicit instructions or concrete guidance on how to make the necessary changes. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the naming. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4\" and \"3r column,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the naming of the 3r column and suggests that \"Corr\" might also be \"Cau-Ant.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the naming of a column in Table 4. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the naming of a column in Table 4, specifically questioning whether \"ATE\" is the correct label for the 3r column. It suggests that \"Corr\" might also be \"Cau-Ant,\" which could be a typographical error. While the comment identifies a potential issue, it lacks depth and does not provide specific guidance or suggestions on how to address the issue. The feedback is somewhat helpful as it points out a potential inconsistency, but it does not offer actionable steps for the authors to improve their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides two distinct pieces of feedback. The first part notes that the mechanism is not clearly anchored in prior work, even after the experiments section, and suggests that more clarity is needed. It provides a specific example of where the methods section clarifies the methods, implying that more of this clarity should be added. The second part suggests that the figures should be annotated or zoomed in to provide a clearer understanding of the differences in the curves. While the comment implies that the authors should provide more clarity and examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations or examples. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"mechanism\" and the \"experiments section,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the mechanism is not clearly anchored in prior work and suggests that more clarity is needed. Additionally, it provides specific feedback by mentioning the methods section, where the methods are clearly explained, and suggests that more of this clarity should be included. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the mechanism is not clearly anchored in prior work and suggests that more clarity is needed. The reviewer provides a specific example of where the methods section clarifies the methods, implying that more of this clarity should be added. However, the comment lacks detailed reasoning or references to support the claim that the mechanism is not clearly anchored. The suggestion to provide more clarity is somewhat valid but could be strengthened with additional context or examples. Therefore, the comment is somewhat verifiable, as it provides some support but lacks comprehensive evidence or detailed reasoning.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. The first part identifies a potential issue with the clarity of the mechanism, noting that it is not clearly anchored in prior work. It suggests that more clarity is needed, even after the experiments section, and provides an example of where the methods section clarifies the methods. This feedback is actionable and helps the authors understand where they need to improve the clarity of their work. The second part of the comment suggests that the figures should be annotated or zoomed in to provide a clearer understanding of the differences in the curves. This is also a constructive suggestion that can help the authors enhance the clarity and impact of their figures. Overall, the comment is mostly helpful as it provides clear and actionable feedback on improving the clarity and presentation of the work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the limited novelty of the paper, specifically mentioning that the key contribution is the pre-trained mechanism applied to few-shot graph learning. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of limited novelty or suggestions for improving the paper. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a concern about the limited novelty of the paper, specifically mentioning the pre-trained mechanism applied to few-shot graph learning as the key contribution. However, it does not specify which part of the paper this concern is related to, such as a particular section or figure. The authors can infer that it relates to the main contribution or methodology sections, but this inference is not direct. The comment is specific in detailing the issue of limited novelty, but it lacks grounding as it does not explicitly mention a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks novelty, specifically mentioning that the key contribution is the pre-trained mechanism applied to few-shot graph learning. However, the comment does not provide any supporting evidence or reasoning to substantiate this claim. It does not specify how the pre-trained mechanism is not novel or how it has been previously explored, making it difficult for the authors to understand the basis of the critique. Without specific examples or references, the claim remains unverifiable, as it lacks the necessary justification to be actionable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a concern about the limited novelty of the paper, specifically mentioning that the key contribution is the pre-trained mechanism applied to few-shot graph learning. While the comment acknowledges that the main idea seems plausible, it also notes that it feels complicated and lacks excitement. However, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their contribution. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the paper, noting that while it empirically validates which setups and parameters are useful for test time training, it lacks theoretical understanding of why these do not collapse. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they need to provide theoretical insights into the stability of their chosen setups and parameters. Without concrete steps or examples, the authors may find it challenging to implement the suggested improvement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a gap in the paper regarding the lack of theoretical understanding of why certain setups and parameters are useful for test time training. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. The authors can infer that it relates to the empirical validation or theoretical analysis sections, but this inference is not direct. The comment is specific in its critique of the lack of theoretical understanding but lacks grounding as it does not explicitly mention a section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks theoretical understanding of why certain setups and parameters are useful for test time training. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed explanations, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper, noting that while it empirically validates which setups and parameters are useful for test time training, it lacks theoretical understanding of why these do not collapse. This feedback highlights an important area for improvement, as providing theoretical insights could enhance the paper\\'s comprehensiveness and depth. However, the comment does not offer specific suggestions or guidance on how the authors might address this gap, such as recommending particular theoretical frameworks or methods to explore. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the clarity of the visual analysis presented in Section 4.4, specifically questioning whether it pertains to training images or test images. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the context of the visual analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the clarity of the visual analysis presented in Section 4.4, specifically questioning whether it pertains to training images or test images. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in its concern about the clarity of the visual analysis, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of the visual analysis presented in Section 4.4, specifically questioning whether it pertains to training images or test images. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the visual analysis presented in Section 4.4, specifically questioning whether the results pertain to training images or test images. This is a relevant point that could impact the interpretation and validity of the results. However, the comment lacks specific guidance or suggestions on how the authors might clarify this issue or address the confusion. While it highlights an area for improvement, it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests exploring the application of the DEER method to other methods, such as LEM or UnICORNN, to determine whether the same performance can be maintained or if better performance can be achieved. It proposes a potential benefit of training these methods with the DEER method, which could lead to faster training and hyperparameter tuning. While the comment implies that the authors should consider this exploration, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this possibility. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring the application of the DEER method to other methods, such as LEM or UnICORNN, to determine whether the same performance can be maintained or if better performance can be achieved. It proposes a potential benefit of training these methods with the DEER method, which could lead to faster training and hyperparameter tuning. However, the comment does not specify which part of the paper this exploration should be integrated into, nor does it provide detailed guidance on how to implement this suggestion. The authors can infer that it relates to the methodology or results sections, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting an exploration of the DEER method with other methods, but it lacks detailed guidance on how to implement this exploration. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests exploring the application of the DEER method to other methods, such as LEM or UnICORNN, to determine whether the same performance can be maintained or if better performance can be achieved. The comment proposes a potential benefit of training these methods with the DEER method, which could lead to faster training and hyperparameter tuning. However, the comment lacks specific examples or references to support the claim that the DEER method would lead to better performance or faster training. Without detailed evidence or comparisons, the claim remains somewhat verifiable, as it provides a logical hypothesis but lacks concrete support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests an interesting exploration of applying the DEER method to other methods, such as LEM or UnICORNN, to determine whether the same performance can be maintained or if better performance can be achieved. It proposes a potential benefit of training these methods with the DEER method, which could lead to faster training and hyperparameter tuning. This feedback is valuable as it encourages the authors to broaden the impact of their work by considering alternative methods and evaluating their performance. However, the comment could be more helpful if it provided specific guidance on how to implement this exploration or suggested particular aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for further research and potential enhancements to the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the presentation is difficult to follow due to the use of too many notations. However, it does not provide any explicit or implicit suggestions on how the authors could address this issue, such as by simplifying the notation or providing clearer explanations. The comment lacks actionable guidance, leaving the authors uncertain about how to improve the presentation. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the presentation is difficult to follow due to the use of too many notations. However, it does not specify which part of the presentation is affected by this issue or which notations are problematic. Without explicit references to sections, figures, or specific notations, the authors cannot confidently determine where to focus their revisions. The comment is not grounded and lacks specificity, making it difficult for the authors to address the issue effectively. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the presentation is difficult to follow due to the use of too many notations. However, it does not provide any specific examples or reasoning to support this claim, making it challenging for the authors to understand the basis of the critique. Without detailed explanations or references, the authors may find it difficult to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the presentation, namely that it is difficult to follow due to the use of too many notations. However, it does not provide any actionable guidance or suggestions on how the authors might address this issue, such as simplifying the notation or providing clearer explanations. Without such feedback, the authors are left without a clear path for improvement, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include results of GPT-4V, despite the API not being released yet. The reviewer acknowledges that ChatGPT's UI could be used for quick experiments, providing a clear action for the authors to take. This feedback is explicit and provides a concrete direction for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including results of GPT-4V, despite the API not being released yet. It acknowledges that ChatGPT's UI could be used for quick experiments. However, it does not specify which part of the paper should include these results or how they would be integrated. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas that need attention or improvement. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that including results of GPT-4V would be beneficial, despite the API not being released yet. The reviewer acknowledges that ChatGPT's UI could be used for quick experiments. However, the comment lacks specific reasoning or evidence to support why including results of GPT-4V would be valuable or how it would enhance the paper. Without detailed justification or examples, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors include results of GPT-4V, despite the API not being released yet. The reviewer acknowledges that ChatGPT's UI could be used for quick experiments, providing a potential solution to the issue of unavailability. However, the comment lacks depth and does not offer specific guidance on how to incorporate these results or why they are important. While it identifies a potential area for improvement, it does not provide detailed feedback or suggestions for enhancing the paper. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors discuss the implications of their extensive theoretical analysis and compare their results with baselines, specifically mentioning CoPur. While the comment implies that the authors should provide a deeper explanation of their analysis and its significance, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed comparison with baselines. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper provides an extensive theoretical analysis and suggests that the authors discuss the implications of this analysis, particularly in comparison with baselines. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in suggesting that the authors should discuss the meaning of their analysis and compare it with baselines, particularly CoPur. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper provides an extensive theoretical analysis but lacks a discussion of its implications. It specifically mentions the need to discuss the analysis's meaning in comparison with baselines, particularly CoPur. While the comment identifies a potential gap in the paper, it does not provide specific examples or references to support the claim that the analysis is extensive or that CoPur is a relevant baseline. This makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks detailed evidence or reasoning.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, suggesting that the authors should discuss the implications of their extensive theoretical analysis, particularly in comparison with baselines. It highlights the need to explain the significance of the analysis and its comparison with CoPur. While the comment provides a clear direction for improvement, it lacks specific suggestions or examples on how to enhance the discussion. The feedback is somewhat helpful as it points out an area for improvement but does not offer detailed guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues with the evaluation and results: the focus on 3D NVS metrics and the lack of clarity in the evaluation protocol. It explicitly points out that the only metric related to dynamics is keypoint distance, which only assesses motion size but not quality. Additionally, it questions the camera parameters used for generating videos, suggesting that this could affect the keypoint distance. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they should clarify the evaluation protocol and consider metrics beyond keypoint distance. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks concrete instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Result/eval\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the reported metrics, particularly the focus on 3D NVS and the lack of clarity in the evaluation protocol. The comment highlights that the only metric related to dynamics is keypoint distance, which only assesses motion size and not quality. Additionally, it questions the camera parameters used for generating videos, suggesting that this could affect the keypoint distance. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the reported metrics are mostly for 3D NVS and that the only metric related to dynamics is keypoint distance, which only assesses motion size. The reviewer also questions the clarity of the evaluation protocol, specifically inquiring about camera parameters used for generating videos. This claim is somewhat verifiable as it provides a logical reasoning for the critique, but it lacks specific examples or references to support the assertion about the dynamics metric. The lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation and results, noting that the reported metrics are mostly focused on 3D NVS and that the only metric related to dynamics is keypoint distance, which only assesses motion size. This feedback highlights a limitation in the evaluation approach and suggests that the authors should consider metrics beyond keypoint distance to assess motion quality. Additionally, the comment questions the clarity of the evaluation protocol, specifically inquiring about camera parameters used for generating videos. While the comment identifies important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. Therefore, it is somewhat helpful, as it provides insight into potential weaknesses but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the presentation of the two parts of pretraining and regularization appears disjointed and detracts from the coherence of the paper. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should integrate these components more seamlessly, but it lacks concrete suggestions or detailed instructions on how to achieve this integration. As a result, the action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the disjointed presentation of the two parts of pretraining and regularization, suggesting that they appear as incremental additions rather than naturally integrated components. However, it does not specify which parts of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in identifying the issue with the presentation, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the two parts of pretraining and regularization appear as incremental additions rather than naturally integrated components, which detracts from the coherence of the paper. However, the comment does not provide specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification and evidence to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of the two parts of pretraining and regularization, suggesting that they appear as incremental additions rather than naturally integrated components. This observation highlights a potential weakness in the coherence and integration of the paper, which the authors should address to enhance the overall presentation and clarity. However, the comment does not provide detailed guidance or suggestions on how to integrate these components more effectively or improve the coherence of the paper. While it points out a relevant issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the importance of Renyi divergence is not well explained and that it is not clear why it is special for readers unfamiliar with differential privacy. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on what specific aspects of Renyi divergence should be explained or how the authors might improve the explanation. As a result, the comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Renyi divergence,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the importance of Renyi divergence and its relevance to differential privacy. This provides clear guidance on what the authors need to improve, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the importance of Renyi divergence is not well explained and that it is not clear why it is special for readers unfamiliar with differential privacy. However, the comment lacks specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the lack of explanation regarding the importance of Renyi divergence and its relevance to differential privacy. This feedback is clear and actionable, as it highlights a critical aspect of the paper that may confuse readers unfamiliar with the topic. However, the comment could be more helpful if it provided suggestions on how to better explain this concept or offered examples of how it might be addressed. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should prioritize simplicity and clarity over the inclusion of \"mathematical theories.\" However, it does not provide specific guidance on how to achieve this or what aspects of the paper should be simplified or clarified. The action is implicit and vague, as the authors are left to infer that they need to focus on simplicity and clarity but without concrete steps on how to achieve this. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should prioritize simplicity and clarity over the inclusion of \"mathematical theories.\" However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or examples where mathematical theories are included. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The suggestion is specific in terms of what the authors should focus on, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should prioritize simplicity and clarity over the inclusion of \"mathematical theories.\" However, the comment does not provide any reasoning, examples, or references to support why this suggestion is important or how it would improve the paper. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should prioritize simplicity and clarity over the inclusion of \"mathematical theories.\" While it identifies an area for improvement, it lacks specificity and does not provide actionable guidance on how to achieve this goal. The comment does not offer suggestions on which parts of the paper could be simplified or clarified, nor does it provide examples of how mathematical theories might detract from the paper\\'s overall readability. As a result, the feedback is somewhat helpful, as it points out a potential issue but does not provide detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation in the ablation study, specifically mentioning the need for further studies on the impact of the pre-defined threshold \\u03b5. While it identifies an area for improvement, it does not provide explicit guidance on how to conduct these studies or what specific aspects should be explored. The action is implicit and somewhat vague, as the authors can infer that they need to expand their ablation study but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the impact of the pre-defined threshold \\u03b5 and the need for further studies on this aspect. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study in the paper is limited, specifically mentioning the need for further studies on the impact of the pre-defined threshold \\u03b5. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a limitation in the ablation study, specifically mentioning the need for further studies on the impact of the pre-defined threshold \\u03b5. This feedback is somewhat helpful as it points out an area where the authors could expand their analysis and provide more depth to their work. However, the comment lacks specific guidance or suggestions on how to conduct these studies or what aspects should be explored. While it highlights an important area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that only using Rouge-L for evaluation is not reliable, especially for some classification tasks where Rouge-L may not be sensitive enough. However, it does not provide explicit guidance on what alternative evaluation methods should be used or how to address this issue. The action is implicit and vague, as the authors are left to infer that they need to consider alternative evaluation methods but without specific suggestions or concrete steps. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Rouge-L,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with using Rouge-L for evaluation, particularly in classification tasks where it may not be sensitive enough. This provides clear guidance on what needs to be addressed in terms of evaluation methods. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using only Rouge-L for evaluation is not reliable, especially for classification tasks where Rouge-L may not be sensitive enough. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the evaluation method used in the paper, specifically the reliance on Rouge-L for evaluation. It points out that this method may not be sensitive enough for some classification tasks, which could impact the reliability of the evaluation. While the comment highlights a relevant concern, it lacks specific suggestions or alternative evaluation methods that the authors could consider. This limits the comment\\'s helpfulness, as it provides insight but does not offer actionable guidance for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the definitions of variables and the formula (Equation 3), specifically mentioning the absence of \"n_k\" in Equation 3. However, it does not provide any guidance on how the authors should address this issue, such as suggesting corrections or alternative approaches. The comment lacks explicit instructions or concrete details on how to resolve the issue, leaving the authors uncertain about what actions to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 580-588,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definitions of variables not matching the formula (Equation 3) and points out the absence of \"n_k\" in Equation 3. This provides clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the definitions of variables do not match the formula (Equation 3), specifically mentioning the absence of \"n_k\" in Equation 3. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the definitions of variables not matching the formula (Equation 3), particularly the absence of \"n_k\" in Equation 3. This feedback is clear and actionable, as it points out a discrepancy that the authors need to address to ensure the accuracy and consistency of their work. However, the comment could be more helpful if it provided suggestions on how to resolve this issue or offered guidance on how to update the definitions accordingly. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of a single vector for each class in the context of large semantic variances, suggesting that this strategy might conflict with the sample-specific assumption of the paper. It also mentions the absence of key experiments, which implies that the authors should include these experiments to address the issue. However, the comment does not provide explicit instructions or concrete suggestions on how to address these concerns or what specific experiments should be included. The action is implicit and somewhat vague, as the authors need to infer that they should include key experiments and consider the implications of using a single vector for each class. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the use of a single vector for each class in the context of large semantic variances, suggesting that this strategy might conflict with the sample-specific assumption of the paper. It also mentions the absence of key experiments, which implies that the authors should include these experiments to address the issue. However, the comment does not specify which part of the paper this question pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the use of a single vector for each class and the need for key experiments, but without explicit references to the paper, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of a single vector for each class in the context of large semantic variances, suggesting that this strategy might conflict with the sample-specific assumption of the paper. It also mentions the absence of key experiments, implying that the authors should include these experiments to address the issue. However, the comment lacks specific examples or references to support the claim that using a single vector for each class is problematic or that key experiments are missing. Without detailed reasoning or evidence, the claim remains vague, making it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered borderline verifiable, as it provides some indication of a problem but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a critical question about the use of a single vector for each class in the context of large semantic variances, suggesting that this strategy might conflict with the sample-specific assumption of the paper. It also mentions the absence of key experiments, which implies that the authors should include these experiments to address the issue. While the comment identifies a potential weakness in the methodology and highlights a gap in the experimental setup, it lacks specific guidance or suggestions on how to address these concerns. The feedback is somewhat helpful as it points out areas for improvement but does not provide detailed instructions or examples on how to improve the draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a key limitation of the work, specifically the assumption of known number of intent classes during graph construction. It points out that the IntenDD experiments reported in Table 1 may not be comparable to the cited baselines due to this assumption. The reviewer acknowledges that the authors have acknowledged this limitation but suggests that further clarification is needed to determine if the reported SOTA is fair in comparison with baselines. While the comment implies that the authors should clarify the intent discovery experiment setting, it does not provide explicit instructions on how to do so. The action is concrete but somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the IntenDD experiments reported in Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the assumption of known number of intent classes during graph construction and questions the comparability of the IntenDD experiments with the cited baselines. The comment provides a clear direction for improvement by suggesting that further clarification is needed to determine if the reported SOTA is fair in comparison with baselines. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the assumption of known number of intent classes during graph construction, specifically questioning the comparability of the IntenDD experiments reported in Table 1 with the cited baselines. The reviewer acknowledges that the authors have acknowledged this as a limitation but suggests that further clarification is needed to determine if the reported SOTA is fair in comparison with baselines. This claim is somewhat verifiable as it provides a logical reasoning for the need for clarification but lacks specific examples or references to support the assertion about the comparability of the experiments. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a key limitation of the work, specifically the assumption of known number of intent classes during graph construction. It points out that the IntenDD experiments reported in Table 1 may not be comparable to the cited baselines due to this assumption. The reviewer acknowledges that the authors have acknowledged this as a limitation but suggests that further clarification is needed to determine if the reported SOTA is fair in comparison with baselines. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to address it. By suggesting that the authors clarify the intent discovery experiment setting, the comment offers a concrete way for the authors to enhance the robustness and fairness of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the rigorous experimentation in the work but points out the limitations of the results due to the application of d-separation criteria in a known causal graph. It suggests that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which would simplify the problem. The comment provides references to relevant works that discuss the limitations of the approach. While the comment identifies specific issues and suggests improvements, it does not offer explicit guidance on how to address these issues or implement the suggested changes. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment appreciates the rigorous experimentation in the work but points out the limitations of the results due to the application of d-separation criteria in a known causal graph. It also suggests that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which would simplify the problem. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the experimental setup and results. The comment is specific in detailing what needs to be addressed, such as the limitations of the results and the need for additional information. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the rigorous experimentation in the work but questions the significance of the results due to the application of d-separation criteria in a known causal graph. It also suggests that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which would simplify the problem. The comment provides references to relevant works, such as [1] Martin Arjovsky, L\u00e9on Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization and [2] Polina Kirichenko, Pavel Izmailov, and Andrew Gordon Wilson. Last layer re-training is sufficient for robustness to spurious correlations, which supports the claim. The references provide a basis for the critique and suggest areas for improvement, making the claim mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges the rigorous experimentation in the work but points out the limitations of the results due to the application of d-separation criteria in a known causal graph. It suggests that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which would simplify the problem. The comment provides references to relevant works that discuss the limitations of the approach, which could help the authors understand the significance of their results. However, the comment does not offer specific suggestions or guidance on how to address these limitations or improve the work. While it identifies areas for improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the reliance on gradient-based saliency methods to evaluate the importance of feature map channels, suggesting that it may not align with the underlying feature selection mechanisms in the human brain. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what alternative methods they could consider. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider their approach to evaluating feature map channels. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the reliance on gradient-based saliency methods to evaluate the importance of feature map channels, suggesting that it may not align with the underlying feature selection mechanisms in the human brain. However, it does not specify which part of the paper this concern is related to, such as a particular section or methodology. This lack of explicit grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, while the comment highlights a potential issue, it does not provide specific guidance on how to address it or what alternative methods could be considered. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the reliance on gradient-based saliency methods to evaluate the importance of feature map channels, suggesting that it may not align with the underlying feature selection mechanisms in the human brain. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides a logical argument but lacks sufficient justification or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reliance on gradient-based saliency methods to evaluate the importance of feature map channels, suggesting that it may not align with the underlying feature selection mechanisms in the human brain. While the comment highlights a relevant concern, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue or what alternative methods could be considered. The feedback is somewhat helpful as it points out a potential weakness but does not offer detailed guidance or examples to help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper uses Pythia, which is not state-of-the-art (SOTA), but it has the advantage of available checkpoints. However, it does not provide any explicit or implicit suggestions for the authors to consider regarding model choice or whether they should use a more recent or advanced model. The comment lacks actionable guidance or specific recommendations, leaving the authors uncertain about how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the model choice used in the paper, specifically mentioning that Pythia is not state-of-the-art (SOTA) but has the advantage of available checkpoints. However, it does not specify which part of the paper discusses the model choice, making it weakly grounded. The comment is specific in pointing out the issue with the model choice, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that Pythia, while not state-of-the-art (SOTA), has the advantage of available checkpoints. This claim is somewhat verifiable as it provides a logical reasoning for the choice of model, but it lacks specific examples or references to support the assertion that Pythia is not SOTA. The comment could be strengthened by providing more context or comparisons to other models, which would help the authors understand the basis of the claim and how to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The comment identifies a specific issue with the model choice in the paper, noting that Pythia is not state-of-the-art (SOTA) but has the advantage of available checkpoints. While this feedback highlights a potential limitation of the model choice, it does not provide actionable guidance or suggestions for improvement. The authors are informed of a potential weakness but are not given specific advice on how to address it or whether this choice impacts the paper\\'s overall quality. Therefore, the comment is somewhat helpful, as it points out a potential issue but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions and suggests that more information or resources should be provided to challenge the community regarding the image observation version of Franka Kitchen. It also questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning. The comment implies that the task might not be solvable with the provided offline data and suggests exploring alternative data sources. While the comment implies that the authors should provide more information or resources, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional resources or explore alternative data sources. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the image observation version of Franka Kitchen and suggests that more information or resources should be provided to challenge the community. It also questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for additional information or resources, but without clear grounding, it is difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the image observation version of Franka Kitchen and suggests that more information or resources should be provided to challenge the community. It also questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning. The comment seeks clarification on whether the task can be completed solely with the provided offline data and, if not, whether there is an alternative data source that the community can leverage. While the comment raises important questions and prompts the authors to consider alternative perspectives, it lacks specific examples or references to support the claims. This makes the claim somewhat verifiable, as it provides a basis for further exploration but requires more detailed evidence or reasoning to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several questions and suggests that more information or resources should be provided to challenge the community regarding the image observation version of Franka Kitchen. It questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning. The comment also inquires whether the task can be completed solely with the provided offline data and, if not, whether there is an alternative data source that the community can leverage. This feedback is somewhat helpful as it prompts the authors to consider the limitations of their work and potential areas for improvement. However, it lacks specific suggestions or guidance on how to address these questions or provide additional resources. To be more helpful, the comment could provide actionable steps or examples of alternative data sources that the authors could explore. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to provide insight into why the multilingual model is \"noticeably weaker\" on the ET\u2192En and LV\u2192EN evaluations. This is a direct and concrete request, as it clearly specifies what the authors need to address. The action is explicit and the authors know exactly what information is required to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 236,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation of why the multilingual model is \"noticeably weaker\" on the ET\u2192En and LV\u2192EN evaluations. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the reason for the multilingual model's \"noticeably weaker\" performance on specific evaluations. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is a normal statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it raises a specific question about the performance of the multilingual model on certain evaluations. By asking for insight into why the model is \"noticeably weaker\" in these cases, the comment prompts the authors to consider potential factors that could be contributing to this observation. This feedback is actionable and encourages the authors to provide a deeper understanding of their results, which could lead to improvements in the draft. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context for the evaluation. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of the numbers in brackets (1) and (4) in tables #1 and #2. While it implies that the authors should clarify this, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation or clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"tables #1,2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the meaning of the numbers in brackets (1) and (4) in these tables. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the meaning of numbers in brackets (1) and (4) in tables #1 and #2. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the meaning of numbers in brackets (1) and (4) in tables #1 and #2. This is a clear and actionable request for clarification, as it prompts the authors to provide additional information or explanation to enhance the clarity of their tables. By addressing this question, the authors can improve the readability and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what additional context might be beneficial. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the connection between the presented results and the listed limitations, specifically regarding the long-term fairness aspect. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific steps they could take to improve the connection between the results and the limitations. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the connection between the presented results and the listed limitations, specifically regarding the long-term fairness aspect. However, it does not specify which part of the paper this connection is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about how the results connect to the limitations, but it lacks grounding as it does not specify where this connection is discussed in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the connection between the presented results and the listed limitations, specifically regarding the long-term fairness aspect. However, it does not provide any evidence, reasoning, or examples to support the claim that the connection is unclear or lacks clarity. The comment lacks specificity and does not offer a clear path for the authors to address the issue, making it difficult for them to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper regarding the connection between the presented results and the listed limitations, specifically regarding the long-term fairness aspect. It raises a valid point about how the results are connected to the limitations, which is an important consideration for the paper. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue or improve the connection between the results and the limitations. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the low accuracy of 29 percent for table assembly tasks and questions the high Euclidean distance error units in Table 1. It suggests that these errors might be normalized to per datapoint position errors, and questions the reasonableness of an error of 5 cm with HDR-IL. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the normalization of errors and consider the reasonableness of the errors. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the low accuracy of 29 percent for table assembly tasks and questions the high Euclidean distance error units in Table 1. It suggests that these errors might be normalized to per datapoint position errors, and questions the reasonableness of an error of 5 cm with HDR-IL. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the accuracy and error units, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the low accuracy of 29 percent for table assembly tasks and questions the high Euclidean distance error units in Table 1. It suggests that these errors might be normalized to per datapoint position errors, and questions the reasonableness of an error of 5 cm with HDR-IL. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claim that the errors are unreasonably high. The lack of explicit evidence or detailed explanation makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is somewhat verifiable, as it provides some basis for the critique but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the accuracy of 29 percent for table assembly tasks and questions the high Euclidean distance error units in Table 1. It suggests that these errors might be normalized to per datapoint position errors, which could explain the high values. The comment also questions the reasonableness of an error of 5 cm with HDR-IL, providing a clear direction for the authors to investigate and potentially improve their results. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context or references to support the critique. Overall, the comment is somewhat helpful as it highlights a potential area for improvement but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the article provides a fresh perspective but does not reach a conclusion, and it implies that the article suggests existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the article provides a fresh perspective but does not reach a conclusion, and it implies that the article suggests existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the article\\'s conclusion, but it lacks grounding as it does not identify the specific part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the article provides a fresh perspective but does not reach a conclusion, suggesting that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides a general idea but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the article, suggesting that it provides a fresh perspective but does not reach a conclusion. It implies that the article suggests existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. While this feedback highlights a potential weakness in the article\\'s conclusion, it lacks specific guidance or suggestions on how the authors might address this issue or improve their work. The comment provides some insight into a potential area for improvement but does not offer actionable steps for the authors to take. Therefore, it is somewhat helpful, as it points out a potential weakness but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the theoretical results are not surprising and have limited contribution to algorithm design, as the algorithm design is mainly based on a pre-defined labeler's strategy. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific changes could be made to enhance the contribution of the theoretical results. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the theoretical results are not surprising and have limited contribution to algorithm design, as the algorithm design is mainly based on a pre-defined labeler's strategy. However, it does not specify which part of the paper this critique is based on, such as the theoretical results or the algorithm design sections. Without explicit references to specific sections or details, the authors cannot confidently determine where to address this feedback. The comment is specific in its critique of the contribution of the theoretical results, but it lacks grounding as it does not identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical results are not surprising and have limited contribution to algorithm design, as the algorithm design is mainly based on a pre-defined labeler's strategy. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the theoretical results are not surprising and have limited contribution to algorithm design, as the algorithm design is mainly based on a pre-defined labeler's strategy. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or enhance the contribution of their theoretical results. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the article does not provide detailed information on how reverse chain proved to be effective in multi-API planning, and it criticizes the focus on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. However, the comment does not explicitly instruct the authors on what specific details should be included or how to address the issue of focusing on comparison. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed information about the effectiveness of reverse chain in multi-API planning and consider expanding their research contribution beyond comparison. However, without concrete guidance, the authors may struggle to fully understand and implement the suggested improvements. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues related to the article\\'s focus on comparing multiple tools or methods in API calling and planning, which it claims reduces the research contribution. It also mentions the lack of detailed information on how reverse chain proved to be effective in multi-API planning. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the sections discussing the effectiveness of reverse chain or the comparison of multiple tools, but this inference is not direct. The comment is specific in detailing what needs to be addressed, such as the need for more detailed information on the effectiveness of reverse chain and the need to expand the research contribution beyond comparison. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the article focuses on comparing multiple tools or methods in API calling and planning, which reduces its research contribution. However, the comment does not provide specific examples or detailed reasoning to support this claim. The lack of detailed evidence or examples makes it difficult for the authors to understand the basis of the critique and address it effectively. As a result, the claim is unverifiable, as it lacks the necessary support to substantiate the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the article, noting that it focuses too much on comparing multiple tools or methods in API calling and planning, which reduces its research contribution. It also points out that the article lacks detailed information on how reverse chain proved to be effective in multi-API planning. This feedback is somewhat helpful as it highlights areas where the authors could improve their draft, such as providing more detailed information on the effectiveness of reverse chain and expanding their research contribution beyond comparison. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment recommends rejecting the paper due to weaknesses in experimental rigor that cannot be fixed in time, content space, or degree. It also suggests that significant editing is required to address other issues, which seems unrealistic in terms of time and space. However, the comment does not provide explicit guidance on how to address these issues or what specific changes need to be made. The action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment recommends rejecting the paper due to weaknesses in experimental rigor that cannot be fixed in time, content space, or degree. It also suggests that significant editing is required to address other issues, which seems unrealistic in terms of time and space. However, the comment does not specify which specific weaknesses in experimental rigor or which issues with the paper\\'s content or structure are causing these concerns. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point recommends rejecting the paper due to weaknesses in experimental rigor that cannot be fixed in time, content space, or degree. The reviewer supports this claim by stating that significant editing is required to address other issues, which seems unrealistic in terms of time and space. However, the comment lacks specific examples or detailed reasoning to substantiate why these weaknesses are insurmountable or how they impact the paper\\'s overall quality. Without concrete evidence or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks sufficient detail to fully support the recommendation.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment recommends rejecting the paper due to significant issues with experimental rigor that cannot be addressed in time, content space, or degree. It also suggests that significant editing is required to address other issues, which seems unrealistic in terms of time and space. While the comment identifies a critical area of concern, it lacks specificity and actionable suggestions on how to address these issues. The authors are left without clear guidance on how to improve their draft or what specific changes are needed to make the paper more acceptable. Therefore, the comment is barely helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about unfair competition between standalone Medusa and Medusa+ParallelSpec, suggesting that the current setup might be misleading due to the change in draft model architecture. It suggests providing a baseline with only the draft model architecture change to clarify the speedup gain and offers a recommendation to give the modified setting a different name to avoid confusion. While the comment provides a clear direction for improvement by suggesting a baseline and a name change, it does not explicitly instruct the authors to implement these changes. The action is explicit but somewhat vague in terms of execution, as the authors need to determine the exact baseline and name change. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (266-267) and the setup involving Medusa+ParallelSpec, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unfair competition between standalone Medusa and Medusa+ParallelSpec, and it suggests providing a baseline with only the draft model architecture change to clarify the speedup gain. Additionally, it recommends giving the modified setting a different name to avoid confusion regarding the draft model architecture. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about unfair competition between standalone Medusa and Medusa+ParallelSpec, suggesting that the current setup might be misleading due to the change in draft model architecture. It provides a logical reasoning by questioning whether the speedup gain is due to the change in draft model architecture or parallel draft token prediction. The comment suggests providing a baseline with only the draft model architecture change to clarify the speedup gain and recommends giving the modified setting a different name to avoid confusion. While the comment does not provide specific references or examples to support the claim, it offers a clear and actionable suggestion for improvement. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison between standalone Medusa and Medusa+ParallelSpec, suggesting that the current setup might be misleading due to the change in draft model architecture. It provides a clear and actionable suggestion by recommending a baseline with only the draft model architecture change to clarify the speedup gain. Additionally, it recommends giving the modified setting a different name to avoid confusion regarding the draft model architecture. This feedback is valuable as it guides the authors on how to improve the clarity and fairness of their comparison, offering a concrete path for addressing the issue. However, the comment could be more helpful if it provided additional context or examples of how the baseline should be structured or what specific aspects of the draft model architecture should be considered. Overall, the comment is mostly helpful as it provides clear and actionable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of Masked Language Models in the paper and suggests that experiments with autoregressive LMs might not have worked out. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what specific changes they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of Masked Language Models in the paper and suggests that experiments with autoregressive LMs might not have worked out. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the choice of models and the potential alternatives, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the choice of Masked Language Models in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the choice of Masked Language Models in the paper and suggests that experiments with autoregressive LMs might not have worked out. While it identifies a potential area for clarification or improvement, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern. The comment is somewhat helpful as it prompts the authors to consider alternative models, but it could be more beneficial with additional context or suggestions for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: how the map is encoded and the effectiveness of the method on experiments proposed in YNet. While the first question seeks clarification on the encoding process, the second question suggests that the authors should demonstrate the effectiveness of their method on the experiments mentioned. However, the comment does not provide explicit instructions or concrete steps for the authors to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should provide more details about the encoding process and demonstrate the method's effectiveness. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions: how the map is encoded and the effectiveness of the method on experiments proposed in YNet. However, it does not specify which part of the paper these questions pertain to, such as a particular section or figure. This makes it difficult for the authors to identify the exact parts of the paper that need attention. Additionally, while the questions are specific in terms of what is being asked (e.g., the encoding process and the effectiveness on YNet experiments), they lack detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point consists of two questions: \"How is the map encoded?\" and \"The authors should have shown the effectiveness of their method on the experiments proposed in YNet.\" These questions are factual in nature and do not contain subjective claims or opinions that require verification. They are purely requests for clarification or additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions that could help the authors improve their draft. First, it asks for clarification on how the map is encoded, which is a critical aspect of the methodology. This feedback is clear and actionable, as it directs the authors to provide more detailed information about a specific aspect of their work. Second, it suggests that the authors should demonstrate the effectiveness of their method on experiments proposed in YNet, which is a relevant and important consideration for the paper. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or what additional experiments might be needed. Overall, the comment is mostly helpful as it identifies specific areas for improvement and provides some guidance, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the proposed model is not significantly better than the MSA Transformer in terms of r2. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve their model or what specific aspects of the MSA Transformer they should aim to surpass. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment compares the proposed model to the MSA Transformer, specifically mentioning their performance in terms of r2. However, it does not specify which part of the paper discusses the model or its performance, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the model\\'s performance, but it lacks grounding as it does not identify the relevant part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed model is not significantly better than the MSA Transformer in terms of r2. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of this comparison or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment compares the proposed model to the MSA Transformer, stating that the proposed model is not significantly better in terms of r2. However, it does not provide any specific insights or suggestions for improvement, nor does it offer guidance on how the authors might address this issue. Without actionable feedback or constructive criticism, the comment does not help the authors understand what aspects of their model need improvement or how to improve them. Therefore, it is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of mathematical details in the explanation of the hypothesis that large chunks of the final representation of wide DNNs behave like an ensemble of independent measures of the full feature space. It explicitly requests more mathematical details to be included, providing a clear action for the authors to take. The comment is explicit and concrete, as it specifies what additional details are needed and how they can be incorporated. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Top of page 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of mathematical details in the explanation of the hypothesis regarding the behavior of wide DNNs. The comment provides a clear request for more mathematical details, which is essential for understanding the hypothesis. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity and mathematical details of the explanation regarding the hypothesis that large chunks of the final representation of wide DNNs behave like an ensemble of independent measures of the full feature space. The reviewer expresses confusion about the concept and its relevance to the observed scaling, requesting more mathematical details. This claim is somewhat verifiable as it provides a logical basis for the request, but it lacks specific examples or references to support the need for more mathematical details. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where the authors need to provide more mathematical details to support their hypothesis. It highlights the lack of clarity in the explanation of the concept of \"ensemble of independent measures on the full feature space\" and its relevance to the observed scaling. By requesting more mathematical details, the comment provides actionable feedback that can help the authors improve the clarity and rigor of their argument. However, the comment could be more helpful if it offered specific suggestions on how to present these details or what mathematical concepts should be included. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the authors have tried using BlenderBot 2.0 with incorporated knowledge and suggests that incorporating domain ontologies from the SGD dataset could improve dialogs. While the comment implies that the authors should consider this approach, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should explore this possibility. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether the authors have tried using BlenderBot 2.0 with incorporated knowledge and suggests incorporating domain ontologies from the SGD dataset to improve dialogs. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in suggesting a potential improvement by incorporating domain ontologies, but without explicit references to specific sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking whether the authors have tried using BlenderBot 2.0 with incorporated knowledge and suggests that incorporating domain ontologies from the SGD dataset could improve dialogs. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about whether the authors have tried using BlenderBot 2.0 with incorporated knowledge and suggests incorporating domain ontologies from the SGD dataset to improve dialogs. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance or detailed suggestions on how to implement this idea. The comment is somewhat helpful as it prompts the authors to consider a new approach, but it does not offer detailed guidance or examples to support the authors in making improvements. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the number of samples rated by GPT-4 and whether they overlap with the samples used in the human evaluation are not clearly stated. The reviewer assumes that the samples should overlap since the paper calculates Krippendorff $\\\\alpha$. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this. The action is implicit and vague, as the authors are left to infer that they should clarify the overlap of samples. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the calculation of Krippendorff $\\\\alpha$, which provides a clear reference to the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding the number of samples rated by GPT-4 and whether they overlap with the samples used in the human evaluation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the number of samples rated by GPT-4 and whether they overlap with the samples used in the human evaluation are not clearly stated. The reviewer assumes that the samples should overlap since the paper calculates Krippendorff $\\\\alpha$. However, the comment lacks specific examples or detailed reasoning to support this assumption, making it difficult for the authors to understand the basis of the claim. The lack of supporting evidence or references makes the claim borderline verifiable, as it requires further elaboration to be fully understood and actionable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the number of samples rated by GPT-4 and whether they overlap with the samples used in the human evaluation. It assumes that the samples should overlap, as the paper calculates Krippendorff $\\\\alpha$. While the comment highlights an important aspect that needs clarification, it lacks detailed guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential area for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the consistency and accuracy of the paper, specifically questioning the difference between \"arg-wise consistency\" and \"accuracy.\" It suggests that the label annotation agreement should be lower due to low pred-wise consistency. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the clarity of their explanation. The action is implicit and vague, leaving the authors to infer that they need to clarify the distinction between \"arg-wise consistency\" and \"accuracy\" and provide a rationale for the observed consistency and accuracy. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the consistency and accuracy of the paper, specifically questioning the difference between \"arg-wise consistency\" and \"accuracy.\" It suggests that the label annotation agreement should be lower due to low pred-wise consistency. However, the comment does not specify which part of the paper discusses these concepts, making it difficult for the authors to pinpoint the exact section that needs clarification. While the authors might have an idea of where these concepts are discussed, the comment lacks full grounding. It is specific about the issue of consistency and accuracy but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the distinction between \"arg-wise consistency\" and \"accuracy\" and suggests that the label annotation agreement should be lower due to low pred-wise consistency. However, the comment lacks specific examples or references to support the reasoning behind this claim. Without detailed explanations or evidence, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the consistency and accuracy of the paper, specifically questioning the distinction between \"arg-wise consistency\" and \"accuracy.\" It suggests that the label annotation agreement should be lower due to low pred-wise consistency, which is an interesting observation. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify their explanation. While it points out a potential area for improvement, it does not offer actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that providing more details on the neural network parametrization of the reverse process, specifically how position embeddings are provided, could enhance reproducibility. Additionally, it recommends providing the code for the implementation, which is considered a high standard for reproducibility. While the comment implies that the authors should provide more details and code, it does not explicitly instruct them to do so. The actions are concrete, as they specify what needs to be added, but the lack of explicit instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests providing more details on the neural network parametrization of the reverse process, specifically how position embeddings are provided, to enhance reproducibility. It also recommends providing the code for the implementation, which is considered a high standard for reproducibility. However, the comment does not specify which part of the paper these details should be included in, making it weakly grounded. The suggestion to provide code is specific, but the lack of grounding makes it difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing more details on the neural network parametrization of the reverse process, specifically how position embeddings are provided, could enhance reproducibility. It also recommends providing the code for the implementation, which is considered a high standard for reproducibility. The comment provides a logical reasoning for why additional details and code are necessary for reproducibility, but it lacks specific examples or references to support the claim about the importance of providing code. This makes the comment somewhat verifiable, as it provides a clear rationale but requires further elaboration to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors should provide more details on the neural network parametrization of the reverse process, particularly how position embeddings are provided, to enhance reproducibility. It also recommends providing the code for the implementation, which is considered a high standard for reproducibility. This feedback is clear and offers concrete steps for the authors to improve the transparency and reliability of their work. However, the comment could be more helpful if it provided examples of what additional details should be included or how the code should be structured. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement and provides a clear path for enhancing the reproducibility of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a repeated paragraph in the first paragraph of section 3.3. While it identifies the issue, it does not provide any guidance on how to resolve it. The authors are left to infer that they should remove the repeated content, but no specific instructions or suggestions are given. The action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions the first paragraph of section 3.3, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is a repeated paragraph. However, the comment does not provide any additional context or suggestions on how to address this issue, such as suggesting a rephrasing or merging of content. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a repeated paragraph in the first paragraph of section 3.3. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue, namely a repeated paragraph in the first paragraph of section 3.3. This is a clear and actionable observation that the authors can address to improve the clarity and coherence of their draft. However, the comment lacks depth and does not provide suggestions on how to revise or restructure the content to avoid repetition. While it points out a problem, it does not offer detailed guidance on how to resolve it, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reusability and sustainability of synthetic data generated on-the-fly. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific steps they could take to ensure the sustainability and reusability of their synthetic data. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the reusability and sustainability of synthetic data generated on-the-fly, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine whether it relates to a specific section, table, or figure. Additionally, the comment lacks specificity regarding what aspects of the synthetic data generation process should be considered for reusability and sustainability. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the reusability and sustainability of synthetic data generated on-the-fly. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it might impact the paper\\'s findings. Without additional context or examples, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a valid question about the reusability and sustainability of synthetic data generated on-the-fly, which is an important consideration for the paper\\'s findings. However, it lacks specificity and actionable guidance, leaving the authors without clear direction on how to address this concern or what aspects of the synthetic data generation process should be considered for reusability and sustainability. Without detailed feedback or suggestions, the comment provides limited value to the authors in improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two issues with the paper: the lack of examination of alternative RNA structures and the need to consider RNA abundance when building datasets. While the comment identifies specific areas that need attention, it does not provide explicit instructions or concrete steps for the authors to address these issues. The authors are left to infer that they should consider alternative RNA structures and RNA abundance, but the comment lacks detailed guidance on how to implement these improvements. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer concrete steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ProbTransfomer model\" and the issue of RNA folding, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of examination of alternative RNA structures and the need to consider RNA abundance when building datasets. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not examine alternative RNA structures and that they should consider RNA abundance when building datasets. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issues effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two specific areas where the paper could be improved: the lack of examination of alternative RNA structures and the need to consider RNA abundance when building datasets. While it highlights these issues, it does not provide detailed guidance or suggestions on how the authors might address these concerns. The comment points out important aspects that need consideration, but it lacks actionable advice or specific steps for improvement, making it somewhat helpful. The authors are given direction but not enough detail to fully understand how to implement the suggested improvements. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a potential red flag regarding the use of a single entropic regularization coefficient (\\xce\\x94=1200) in the numerical results. It suggests that this might be a weak regularization term, which could lead to sparse couplings and favor the method. The reviewer acknowledges that it is acceptable if the method is not beneficial in strong-regularization regimes. However, they emphasize that this issue needs to be acknowledged in the paper and not swept under the rug. The comment provides a clear and explicit action for the authors to address this issue by acknowledging the potential weakness of the regularization term and its impact on the results. The action is concrete and specific, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the numerical results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of a single entropic regularization coefficient (\\xce\\x94=1200) and suggests that this might be a weak regularization term that results in sparse couplings. The comment further acknowledges that this is acceptable if the method is not beneficial in strong-regularization regimes, but it emphasizes the need for acknowledgment in the paper. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a potential issue with the use of a single entropic regularization coefficient (\\xce\\x94=1200) in the numerical results. The reviewer suggests that this might be a weak regularization term, which could lead to sparse couplings and favor the method. However, the comment does not provide specific evidence or references to support this claim. It lacks detailed reasoning or examples to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of a single entropic regularization coefficient (\\xce\\x94=1200) in the numerical results. It suggests that this might be a weak regularization term, which could lead to sparse couplings and favor the method. The reviewer acknowledges that this is acceptable if the method is not beneficial in strong-regularization regimes. However, they emphasize that this issue needs to be acknowledged in the paper and not swept under the rug. This feedback is clear and actionable, as it prompts the authors to address the potential weakness of their method and its impact on the results. By providing a specific area for improvement and highlighting the importance of acknowledging this issue, the comment offers valuable guidance for the authors to enhance the clarity and robustness of their work. Therefore, it is mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the information provided in Table 1 and the paper regarding the sources used for the analysis. It explicitly states that the Vlachos and Riedel 2014 dataset is mentioned as having no evidence in Table 1, but the paper claims to have collected sources used by journalists. However, the comment does not provide any guidance on how the authors should address this issue or what specific actions they should take to reconcile these statements. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the Vlachos and Riedel 2014 dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy between the information provided in Table 1 and the paper regarding the sources used for the analysis. The comment clearly specifies what needs to be addressed, namely the inconsistency between the information in Table 1 and the paper regarding the sources used for the analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation about the discrepancy between the information provided in Table 1 and the paper regarding the sources used for the analysis. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the information provided in Table 1 and the paper regarding the sources used for the analysis. It points out that the table claims that the Vlachos and Riedel 2014 dataset has no evidence, while the paper states that sources used by journalists were collected. This feedback is somewhat helpful as it highlights a potential inconsistency that the authors should address to ensure the accuracy and completeness of their work. However, the comment lacks specific suggestions on how to resolve this issue or what additional information might be needed. To be more helpful, the comment could provide guidance on how to reconcile these conflicting statements or suggest ways to clarify the sources used in the analysis. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include details about the parameters used for each simulator, such as whether they used the GPU pipeline in IsaacGym or just the CPU pipeline, the substeps for physics simulation, and the number of total vertices in the simulation. This feedback provides clear and concrete actions for the authors to take, ensuring that they know exactly what information to include in their draft. The explicit nature of the request and the detailed guidance make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"parameters for each simulator,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what information is missing, such as the use of the GPU pipeline in IsaacGym, the substeps for physics simulation, and the number of total vertices in the simulation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors include details about the parameters used for each simulator, such as the GPU pipeline in IsaacGym, the substeps for physics simulation, and the number of total vertices in the simulation. While the comment highlights a potential issue with the paper\\'s presentation, it does not provide specific examples or references to support the claim that these details are necessary or how they would impact the overall performance. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of including these details themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors include details about the parameters used for each simulator, such as the GPU pipeline in IsaacGym, the substeps for physics simulation, and the number of total vertices in the simulation. This feedback is clear and actionable, as it provides the authors with a concrete step to enhance the transparency and reproducibility of their work. By addressing this point, the authors can ensure that their results are more robust and replicable, which is valuable guidance for improving the draft. However, the comment could be more helpful if it included suggestions on how to present this information or why it is important for the paper\\'s overall contribution. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern regarding the choice of hyperparameters $s$ and $k$ in the proposed sparse-CL and k-NL method. It notes that these hyperparameters are crucial for the effectiveness of the method but points out that the Supplementary Material only states that $s$ and $k$ are chosen as $5$ based on cross-validation. This implies that the authors should provide more detailed information about the rationale behind the hyperparameter choices, such as the criteria used for selection or the impact on the method's performance. However, the comment does not explicitly instruct the authors to include this information, leaving it somewhat vague. The action is implicit and somewhat vague, as the authors need to infer the specific details to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Supplementary Material A.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of hyperparameters $s$ and $k$ and the impact on the generalizability of the proposed method. The comment provides a clear direction for improvement by suggesting that the authors should provide more detailed information about the rationale behind the hyperparameter choices. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the choice of hyperparameters $s$ and $k$ in the proposed sparse-CL and k-NL method is crucial for its effectiveness but notes that the Supplementary Material only states that these hyperparameters are chosen based on cross-validation. This observation highlights a limitation in the generalizability of the proposed method due to the empirical selection of hyperparameters. The comment provides a logical reasoning by pointing out the importance of these hyperparameters and the potential impact on the method's effectiveness. However, it lacks specific examples or references to support the claim about the impact on generalizability. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but could be strengthened with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the proposed method, specifically the choice of hyperparameters $s$ and $k$ in the sparse-CL and k-NL masking technique. It points out that while these hyperparameters are crucial for the effectiveness of the method, the Supplementary Material only states that they are chosen based on cross-validation, which limits the generalizability of the proposed method. This feedback is valuable as it highlights a potential weakness in the paper that the authors should address to enhance the robustness and applicability of their method. However, the comment could be more helpful if it provided specific suggestions on how to improve the choice of hyperparameters or how to address the issue of generalizability. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors compare the optimization times of their approach with OpenTuner, which adaptively uses different search techniques. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"OpenTuner,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a comparison with OpenTuner, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors compare the optimization times of their approach with OpenTuner, which adaptively uses different search techniques. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors compare the optimization times of their approach with OpenTuner, which adaptively uses different search techniques. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by including a comparison that could enhance the understanding and applicability of the proposed approach. However, the comment could be more helpful if it included specific guidance on how to conduct the comparison or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the novelty of the work, pointing out that many previous works have introduced diffusion models into the anomaly detection area. It specifically mentions several references that have introduced similar ideas, such as [1] [2] [3]. The comment also notes that the work does not introduce any original ideas but instead makes minor adjustments to an existing model by combining popular techniques. While the comment identifies a lack of novelty, it does not provide explicit guidance or suggestions on how the authors could improve the novelty or originality of their work. The action is implicit and somewhat vague, as the authors are left to infer that they need to make their work more original or innovative. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific works, such as [1] [2] [3], which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the work does not introduce any original ideas and only makes minor adjustments to an existing model. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the work lacks novelty, as many previous works have introduced diffusion models into anomaly detection. The reviewer supports this claim by referencing specific works, such as [1] [2] [3], which have introduced similar ideas. However, the comment does not provide detailed reasoning or analysis of why these works are considered more novel or innovative. While the references provide some context, the comment could be strengthened by further elaboration on why the work is not novel. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the novelty of the work, noting that many previous works have introduced diffusion models into the anomaly detection area. It specifically references several references, such as [1] [2] [3], which have introduced similar ideas. The comment also highlights that the work does not introduce any original ideas but instead makes minor adjustments to an existing model by combining popular techniques. While the comment effectively points out a limitation of the work, it lacks actionable suggestions or guidance on how the authors might address this issue or improve the novelty of their contribution. Without specific recommendations or advice on how to enhance the originality or innovation of the work, the comment provides limited value to the authors. Therefore, it is somewhat helpful, as it identifies a weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies two issues: grammar errors and unlabeled axes in Figure 2. While it points out specific errors, such as \"The teacher and the student are jointly trained to make the teacher\u2019s knowledge more friendly to the students called online distillation,\" it does not provide explicit guidance on how to correct these errors or label the axes in Figure 2. The feedback is somewhat actionable as it highlights specific issues but lacks detailed instructions on how to address them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies specific grammar errors, such as \"The teacher and the student are jointly trained to make the teacher\u2019s knowledge more friendly to the students called online distillation\" and \"Our approach achieves better parameter-efficient and student-friendly KD\u2026\", allowing the authors to pinpoint the exact parts of the paper that need correction. Additionally, it points out that Figure 2 lacks axis labels, providing full grounding. The comment is specific in detailing what needs to be corrected, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements about grammar errors and the lack of axis labels in Figure 2. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific grammar errors and points out that Figure 2 lacks axis labels, which are crucial for clarity and understanding. By highlighting these issues, the comment provides actionable feedback that the authors can address to improve the quality and readability of their paper. However, the comment could be more helpful if it offered suggestions on how to correct the grammar errors or provided guidance on how to label the axes in Figure 2. Despite this, the feedback is mostly helpful as it directs the authors to specific areas needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more quantitative error analysis in section 5.2, which is a clear and direct action. It specifies the exact area that needs improvement, providing a concrete direction for the authors to take. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the \"crappy\" error analysis in section 5.2 and the need for more quantitative error analysis. This provides clear guidance on what the authors need to improve, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the error analysis in section 5.2 is \"crappy\" and suggests that more quantitative error analysis would be beneficial. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the error analysis in section 5.2, noting that it is \"crappy\" and suggesting that more quantitative error analysis would be beneficial. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, the comment could be more helpful if it offered specific examples or guidance on how to conduct more quantitative error analysis. Despite this, the comment still provides valuable insights that can help the authors enhance their draft. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider measuring the Proxy-A distance between the distributions in addition to using t-SNE for evaluation. It also points out that Fig. 6c and 6d appear to be the same, prompting the authors to verify if the Proxy-A distance is close. While the comment provides explicit actions\u2014measuring the Proxy-A distance and verifying Fig. 6c and 6d\u2014it does not offer detailed guidance on how to implement these actions. The authors know what needs to be done but may need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 6c, 6d,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed: measuring the Proxy-A distance and verifying whether Fig. 6c and 6d are the same. This level of detail provides the authors with a clear understanding of what needs to be improved. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should consider measuring the Proxy-A distance between the distributions, in addition to using t-SNE for evaluation. The reviewer provides a specific suggestion to address the issue, which is to measure the Proxy-A distance. However, the comment lacks detailed reasoning or examples to fully substantiate why this additional measure is necessary or how it would improve the evaluation. While the suggestion is logical, the lack of detailed justification makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors should consider measuring the Proxy-A distance between the distributions, in addition to using t-SNE for evaluation. It also points out that Fig. 6c and 6d appear to be the same, prompting the authors to verify if the Proxy-A distance is close. This feedback is clear and offers a concrete suggestion for improvement, guiding the authors on how to enhance the evaluation of their results. However, the comment could be more helpful if it provided additional context or examples on why the Proxy-A distance is important or how it relates to the study\\'s objectives. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the rationale behind using cross entropy for the first (P \u00e2\u0080\u0093 floor(t/m)) phrases and suggests exploring the performance of using a reinforcement algorithm for all phrases. While the comment implies that the authors should provide an explanation or comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L216-217,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the rationale behind using cross entropy for the first (P \u00e2\u0080\u0093 floor(t/m)) phrases and suggests exploring the performance of using a reinforcement algorithm for all phrases. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification and comparison. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the rationale behind using cross entropy for the first (P \u00e2\u0080\u0093 floor(t/m)) phrases and suggests exploring the performance of using a reinforcement algorithm for all phrases. This feedback is actionable as it prompts the authors to clarify their methodology and potentially improve their results. However, the comment could be more helpful if it provided specific suggestions or examples of how to address these questions or improve the performance. Despite this, the feedback is mostly helpful as it directs the authors to consider important aspects of their methodology and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific omission in the paper, noting that the proposed cross-modality adaptation has been validated in two previous works but is not discussed in the related work section. This comment explicitly identifies an action for the authors to take, which is to include a discussion of these works in the related work section. The feedback is concrete and provides a clear direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"BEVDepth [1]\" and \"2DPASS [2],\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the omission of discussing these works in the related work section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed cross-modality adaptation has been validated in previous works but is not discussed in the related work section. However, the comment does not provide specific references or details about these previous works, making it difficult for the authors to verify the claim. Without additional context or references, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, noting that the proposed cross-modality adaptation has been validated in previous works but is not discussed in the related work section. This feedback is clear and actionable, as it directs the authors to include a discussion of these works in the relevant section. However, the comment could be more helpful if it provided additional context or examples of how these works could be integrated into the discussion. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Table 1 only presents test loss as a metric for performance degradation and does not include any generation results, such as BLEU scores, to assess the quality of the output. This feedback implies that the authors should include additional metrics to provide a more comprehensive assessment of their results. However, the comment does not explicitly instruct the authors to include these metrics or specify which ones should be used. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what is expected of them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the inclusion of generation results, such as BLEU scores, to assess the quality of the output. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 1 only presents test loss as a metric for performance degradation and does not include any generation results, such as BLEU scores, to assess the quality of the output. This claim is somewhat verifiable as it highlights a specific omission in the paper\\'s evaluation metrics. However, the comment lacks detailed reasoning or examples to fully substantiate why the inclusion of BLEU scores is necessary or how it would enhance the evaluation. Providing more context or examples would strengthen the claim, making it more fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Table 1, noting that it only includes test loss as a metric for performance degradation without including any generation results, such as BLEU scores, to assess the quality of the output. This feedback is clear and actionable, as it points out a gap in the evaluation metrics that the authors should address to provide a more comprehensive assessment of their work. However, the comment could be more helpful if it suggested specific metrics or methods to include in addition to BLEU scores. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical area for improvement, but it could be more detailed to be fully comprehensive.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that including experiments to validate the analysis would be beneficial, particularly for discussions on different regimes. While the comment implies that the authors should consider conducting experiments, it does not explicitly instruct them to do so or provide specific guidance on how to design these experiments. The action is implicit and somewhat vague, as the authors need to infer that they should conduct experiments to validate their analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that including experiments to validate the analysis would be appreciated, particularly for discussions on different regimes. However, it does not specify which part of the paper this suggestion pertains to, such as the sections discussing different regimes or the analysis itself. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The suggestion is specific in terms of what is needed, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including experiments to validate the analysis would be beneficial, particularly for discussions on different regimes. However, the comment does not provide any specific reasoning, examples, or references to support why this is necessary or how it would enhance the paper. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including experiments to validate the analysis would be beneficial, particularly for discussions on different regimes. This feedback is somewhat helpful as it identifies a potential area for improvement by recommending the inclusion of experimental validation to strengthen the paper\\'s claims. However, the comment lacks specific guidance on how to design these experiments or what aspects of the analysis need validation. While it provides a general direction for improvement, it could be more actionable with additional details. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including two naive baselines with only text and a single center frame to provide insights about the benchmark. While the comment implies that the authors should consider adding these baselines, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add these baselines. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including two naive baselines with only text and a single center frame to provide insights about the benchmark. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The suggestion is specific in terms of what additional baselines could be included, but without explicit grounding, it is difficult for the authors to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including two naive baselines with only text and a single center frame to provide insights about the benchmark. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these baselines would be beneficial or how they would contribute to the study. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including two naive baselines with only text and a single center frame to provide insights about the benchmark. This suggestion is a specific and actionable recommendation that could enhance the paper\\'s analysis by offering additional perspectives on the benchmark. However, the comment lacks depth in explaining why these baselines are beneficial or how they might contribute to the study\\'s objectives. While it provides a clear direction for improvement, it could be more helpful if it included more detailed reasoning or examples of how these baselines might be used effectively. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the description of advantage-weighted regression, specifically mentioning the missing explanation of the Q function being w.r.t. \\u03b4, which is crucial for solving the costrained optimization of Eq. 4. This feedback provides a clear and explicit action for the authors to take, which is to clarify the description of the Q function and its relation to \\u03b4. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the description of advantage-weighted regression,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the description, namely the explanation of the Q function being w.r.t. \\u03b4, which is crucial for understanding the costrained optimization of Eq. 4. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of advantage-weighted regression is unclear, specifically mentioning the missing explanation of the Q function being w.r.t. \\u03b4. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the clarity of the preliminaries, particularly regarding the description of advantage-weighted regression. It points out that the Q function is w.r.t. \\u03b4, which is crucial for understanding the costrained optimization of Eq. 4. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their methodology that could impact the readers\\u0027 understanding of the work. However, the comment could be more helpful if it provided additional context or examples to further enhance the authors\\u0027 understanding of the issue. Overall, the comment is mostly helpful as it effectively guides the authors toward improving the clarity of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the overall algorithm is cumbersome and has multiple stages, which is a concern for the proposed method. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to simplify the algorithm or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the overall algorithm of the proposed method, specifically mentioning that it is cumbersome and has multiple stages. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the cumbersomeness and multiple stages of the algorithm, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the overall algorithm is cumbersome and has multiple stages, which is a subjective observation. The comment suggests that this is a drawback compared to existing pruning methods that do not require fine-tuning. However, the comment lacks specific examples or detailed reasoning to support the claim that existing methods are more efficient or effective. Without specific comparisons or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the proposed method, noting that the overall algorithm is cumbersome and has multiple stages. It contrasts this with existing pruning methods that do not require fine-tuning. While the comment highlights an area for improvement, it lacks specific suggestions or guidance on how to address the issue. It does not provide actionable advice or detailed feedback on how to simplify the algorithm or improve its efficiency. As a result, the comment is somewhat helpful, as it points out a potential weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a perceived lack of justification for the advantage of the new quantile function over the existing one. It points out that the paper does not provide supporting data to justify the change from multiplicative factors to an additive term. While the comment identifies an area for improvement, it does not explicitly instruct the authors on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional data or reasoning to justify the change. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"new quantile function (3)\" and compares it to the \"existing function (2),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of justification for the advantage of the new function over the existing one, and it highlights the change from multiplicative factors to an additive term. The comment further specifies that the paper does not present supporting data to justify the reduced sensitivity of the new function. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the advantage of the new quantile function (3) over the existing function (2) is unjustified. It specifically notes that the change from multiplicative factors to an additive term makes the function less sensitive to tail parameters when they are large. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the significance of the change and the potential impact on the results, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out the lack of justification for the advantage of the new quantile function over the existing one. It specifically notes that the change from multiplicative factors to an additive term makes the function less sensitive to tail parameters when they are large, but does not provide supporting data or reasoning to justify this change. This feedback is somewhat helpful as it highlights an area where the authors need to provide more detailed justification or evidence to strengthen their argument. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of how the new function might be beneficial. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete feedback on the confusion surrounding Figure 3 and the low contribution over SWE-Bench. It highlights the authors\\' claim about the new additions of testing fault localization and LLM\\'s capability of discovering issues itself, noting that if a model can fix a bug, it would need to perform fault localization, and that passing a failed unit test to an LLM can be done automatically without needing LLM for issue generation. The comment provides clear guidance on how to improve the contribution section by addressing the confusion and clarifying the contribution over SWE-Bench. The action is explicit and concrete, giving the authors a direct path to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and provides specific feedback on the confusion surrounding the contribution over SWE-Bench. It also specifies the issue with the claim about the new additions of testing fault localization and LLM\\'s capability of discovering issues itself, noting that if a model can fix a bug, it would need to perform fault localization, and that passing a failed unit test to an LLM can be done automatically without needing LLM for issue generation. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity and contribution of Figure 3, specifically questioning the authors\\' claim about the new additions of testing fault localization and LLM\\'s capability of discovering issues itself. The reviewer provides logical reasoning by pointing out that if a model can fix a bug, it would need to perform fault localization, and that passing a failed unit test to an LLM can be done automatically without needing LLM for issue generation. This reasoning is supported by the logical analysis of the claims made by the authors, making the comment mostly verifiable. However, it could be strengthened by providing specific examples or references to support the claims. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the confusion surrounding Figure 3 and the low contribution over SWE-Bench. It highlights the authors\\' claim about the new additions of testing fault localization and LLM\\'s capability of discovering issues itself, noting that if a model can fix a bug, it would need to perform fault localization, and that passing a failed unit test to an LLM automatically does not require LLM for issue generation. This feedback is clear and provides the authors with a concrete understanding of what needs to be improved in their contribution section. By addressing these points, the authors can enhance the clarity and impact of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing aspect in the paper, specifically the lack of key descriptions regarding the selection of topics for the complementary attribute in topic control experiments. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include more detailed descriptions, but it lacks concrete instructions or examples on what specific information is missing or how to incorporate it. As a result, the authors are left with a vague understanding of what needs to be improved, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a missing aspect in the paper regarding the selection of topics for the complementary attribute in topic control experiments. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what is missing, namely the selection process for the complementary attribute, but it does not provide guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of key descriptions in the paper, specifically regarding the selection of topics for the complementary attribute in topic control experiments. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, namely the absence of key descriptions regarding the selection of topics for the complementary attribute in topic control experiments. It highlights a clear gap in the paper that could impact its comprehensiveness and clarity. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific information should be included. While it points out a relevant area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper only presents a single case of real-world manipulation, which is not sufficient to demonstrate the general applicability of the described system identification method for sim-to-real policy deployment. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the case studies or what specific aspects of the method should be improved to enhance its applicability. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of real-world manipulation, specifically mentioning that it is based on a single case. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of convincing evidence for the system identification method to improve sim-to-real policy deployment. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper only presents a single case of real-world manipulation, which is not convincing in demonstrating the general applicability of the system identification method for sim-to-real policy deployment. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides a general observation without sufficient justification or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the real-world manipulation case is limited to a single example. It highlights the need for more convincing evidence to demonstrate the general applicability of the system identification method for sim-to-real policy deployment. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or expand their case studies. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the quality of the ShortcutQA and suggests providing details about how \"answerable\" the distracted texts are. It also requests examples and qualitative results to support the claim. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details and examples. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the quality of the ShortcutQA and suggests providing details about how \"answerable\" the distracted texts are. It also requests examples and qualitative results. However, it does not specify which part of the paper discusses the ShortcutQA, making it weakly grounded. The comment is specific in its request for additional information and examples, providing clear guidance on what the authors need to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a skepticism about the quality of the ShortcutQA, questioning whether it might introduce ambiguity and affect performance. It suggests providing details about how \"answerable\" the distracted texts are and requests examples and qualitative results. While the comment highlights a potential concern, it lacks specific examples or references to support the claim that ambiguity might arise from the ShortcutQA. This makes the claim somewhat verifiable, as it provides a logical basis for the skepticism but requires more detailed evidence or examples to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the quality of the ShortcutQA, questioning whether it might introduce ambiguity and affect performance. It suggests providing details about how \"answerable\" the distracted texts are and requests examples and qualitative results to support the claim. This feedback is somewhat helpful as it identifies a potential weakness in the paper and provides a direction for improvement. However, the comment could be more helpful if it offered specific suggestions or examples of how to address the issue or improve the quality of the ShortcutQA. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more actionable with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be clearer with a forward pointer to the definition of \"deep.\" This implies that the authors should provide a reference or link to the definition of \"deep\" within their paper, making the comment explicit and actionable. The authors know exactly what needs to be done to improve the clarity of their draft, providing a clear and direct action. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that it would be clearer with a forward pointer to the definition of \"deep.\" However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the term \"deep\" is used. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs clarification. Additionally, the comment is not specific about what aspect of the definition needs clarification or how it could be improved. Therefore, this comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that it would be clearer with a forward pointer to the definition of \"deep.\" However, it does not provide any reasoning, evidence, or examples to support why this clarification is necessary or how it would improve the paper. Without additional context or explanation, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that it would be clearer with a forward pointer to the definition of \"deep.\" While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance on how to implement this suggestion or what aspects of the definition might need clarification. Without additional context or examples, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is barely helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the selection of the number of archetypes, k, in the presented framework. It asks if there is a way to perform model selection to identify an appropriate k. While the comment implies that the authors should consider model selection, it does not explicitly instruct them to do so or provide guidance on how to implement this. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"framework\" and the \"number of archetypes, k,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about model selection to identify an appropriate k, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking about the method of model selection to identify an appropriate value for the number of archetypes, k, in the presented framework. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is a normal statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a practical question about the selection of the number of archetypes, k, in the presented framework. It asks if there is a way to perform model selection to identify an appropriate k. This is a relevant point that could help the authors improve their draft by addressing a potential weakness in their methodology. However, the comment lacks depth and does not provide specific suggestions or guidance on how to perform model selection or what criteria to use. While it identifies an area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to clarify the location of Theorem 1 and to separate counting between Assumptions, Lemmas, and Theorems. This feedback provides clear and direct instructions on what the authors need to do to improve their draft. The action is explicit and concrete, as it specifies the exact changes needed to be made. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1\" and \"Assumptions, Lemmas, and Theorems,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the absence of Theorem 1 and the need to separate counting between different types of results. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the location of Theorem 1 and the separation of counting between Assumptions, Lemmas, and Theorems. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific issue with the paper, namely the absence of Theorem 1 and the lack of separation between Assumptions, Lemmas, and Theorems. By pointing out these discrepancies, the comment provides the authors with clear and actionable feedback on how to improve the organization and presentation of their results. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as providing guidance on how to structure the paper or where to place the missing theorem. Overall, the comment is valuable in directing the authors\\' attention to specific areas for improvement, but it could be more comprehensive with additional guidance. Therefore, it is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption that a shorter subsequence within a longer text is necessary and sufficient for performing a target task, specifically questioning its generalizability to long document summarization tasks. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what specific steps they could take to ensure the generalizability of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the assumption that a shorter subsequence within a longer text is necessary and sufficient for performing a target task, specifically questioning its generalizability to long document summarization tasks. However, it does not specify which part of the paper this assumption is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its questioning of the generalizability, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the assumption that a shorter subsequence within a longer text is necessary and sufficient for performing a target task, specifically questioning its generalizability to long document summarization tasks. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the assumption that a shorter subsequence within a longer text is necessary and sufficient for performing a target task, specifically questioning its generalizability to long document summarization tasks. This is an important consideration for the authors, as it highlights a potential limitation in the applicability of their approach. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or test the generalizability of their approach. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the novelty of the proposed method and questions the clarity of certain aspects, such as the generation of multiple graphs and the number of parameters required for different weights on edges. While the comment identifies areas that need clarification, it does not provide explicit guidance on how the authors should address these issues. The feedback is somewhat actionable as it implies that the authors should clarify these points, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific concerns about the novelty of the proposed method and the clarity of certain aspects, such as the generation of multiple graphs and the number of parameters required for different weights on edges. However, it does not specify which lines or sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs clarification, such as the generation of multiple graphs and the number of parameters required for different weights on edges. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the novelty of the proposed method and questions the clarity of certain aspects, such as the generation of multiple graphs and the number of parameters required for different weights on edges. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide evidence or references to substantiate the critique, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not offer sufficient justification or evidence to support the critique. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a concern about the novelty of the proposed method, noting that it seems straightforward and questioning the clarity of certain aspects, such as the generation of multiple graphs and the number of parameters required for different weights on edges. The comment highlights specific areas that need clarification, which is helpful for the authors to address. However, the feedback could be more comprehensive by providing additional details or suggestions on how to improve these areas. Overall, the comment is somewhat helpful as it points out areas for improvement but lacks depth and actionable guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments are limited in scope and recommends expanding the examples to include a more complex manifold. While the comment implies that the authors should include additional examples, it does not provide explicit instructions or concrete steps on how to do so. The authors are left to infer that they need to expand their experimental scope, but the comment lacks specific guidance on which examples to include or how to incorporate them into the existing work. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments\" and \"simulation experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the experiments are limited in scope and suggesting that the authors should include examples of more complex manifolds. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are limited in scope, specifically mentioning the use of a unit sphere, spiral curves, and taxis. The reviewer suggests that it would be beneficial to include examples of more complex manifolds to demonstrate the learning of geometry. While the comment identifies a limitation in the scope of the experiments, it lacks specific examples or references to support the claim that a more complex manifold is necessary. This makes the claim somewhat verifiable, as the authors would need to infer the need for more complex examples themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the experiments, specifically noting that the examples are limited to a unit sphere, spiral curves, and taxis. It suggests that the inclusion of examples of more complex manifolds would be beneficial. This feedback is somewhat helpful as it points out a potential area for improvement, but it lacks specific suggestions on which complex manifolds to consider or how to incorporate them into the existing work. While it highlights a gap in the experimental scope, the comment does not provide detailed guidance on how to address this issue, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific weakness in the current knowledge reliance on a specific template, which lacks naturalness and does not fully utilize the capabilities of LLMs. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the naturalness or how to better utilize LLMs. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific issue of the current knowledge relying on a specific template, which lacks naturalness and does not fully utilize the capabilities of LLMs. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the weakness of relying on a specific template and the need to improve naturalness and utilization of LLMs. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the current knowledge relies on a specific template, which lacks naturalness and does not fully utilize the capabilities of LLMs. This claim is somewhat verifiable as it highlights a specific weakness in the paper, but it lacks detailed reasoning or examples to fully substantiate the claim. The reviewer could provide more specific examples or references to support the claim, such as explaining how the current template limits the naturalness of the knowledge or how it fails to utilize LLMs effectively. As it stands, the comment provides a general observation without detailed evidence or reasoning, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the current knowledge reliance on a specific template, which lacks naturalness and does not fully utilize the capabilities of LLMs. This is a clear and actionable observation that highlights a significant area for improvement in the paper. However, the comment could be more helpful if it provided suggestions on how to address this weakness, such as by suggesting alternative approaches or methods to enhance the naturalness and utilization of LLMs. Despite this, the comment still offers valuable insights that can guide the authors in improving their draft, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the number of baselines used in the study is small, which affects the universality and generality of the results. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue, such as suggesting additional baselines or explaining why the current number is insufficient. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of the number of baselines used in the study, suggesting that it affects the universality and generality of the results. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the number of baselines, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of baselines used in the study is small, which affects the universality and generality of the results. However, the comment does not provide any specific reasoning or examples to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the study, noting that the number of baselines used is small, which could impact the universality and generality of the results. This feedback is somewhat helpful as it highlights an area that the authors might consider expanding or addressing to enhance the robustness of their findings. However, the comment lacks specific suggestions or guidance on how to increase the number of baselines or improve the generalizability of the results. While it points out a relevant issue, it does not provide actionable steps for the authors to take, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the lack of information about the tokenizer training process, including the mixture of corpus size used and the software stack. While it identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include this information but lacks concrete steps or suggestions on how to incorporate it. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the lack of information about the tokenizer training process, including the mixture of corpus size used and the software stack. However, it does not specify which part of the paper this information should be included in, such as a particular section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what is missing, but it lacks full grounding as it does not explicitly mention the sections where this information should be included. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no information about the tokenizer training process, including the mixture of corpus size used and the software stack. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the significance of this omission or how it affects the paper\\'s validity. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of information about the tokenizer training process, including the mixture of corpus size used and the software stack. This is a critical oversight that could impact the validity and reproducibility of the results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional information should be included. While it points out a significant area for improvement, it does not provide actionable steps or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several concerns about the paper, including the complexity of the proposed method and the necessity of certain steps (co-training, positive mining, and alternate optimization). However, it does not provide explicit guidance or suggestions on how the authors might address these issues. The feedback lacks actionable details, such as specific suggestions for improvement or ways to justify the additional complexity. As a result, the authors are left without clear direction on how to address the concerns raised in the comment. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the complexity of the proposed method and questions whether the additional steps (co-training, positive mining, and alternate optimization) are necessary. It references a similar work, [A], which provides context for the comparison. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the necessity of the additional complexity and the results\\' clarity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the complexity of the proposed method and questions whether the additional steps (co-training, positive mining, and alternate optimization) are necessary. It references a similar work, [A], which provides context for the comparison. However, the comment lacks specific examples or detailed reasoning to support the claim that the additional complexity is not justified. The reference to [A] provides some context but does not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it highlights a potential issue but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, specifically questioning the necessity of the additional complexity in the proposed method. It also highlights the good results achieved by the authors but notes that the paper does not fully address the question of whether the additional steps are justified. The comment references a similar work, [A], which provides context for the comparison. While the comment raises important questions, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is somewhat helpful as it points out a potential area for improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the scalability of the proposed approach due to the computational complexity of multi-marginal OT and spline calculations. It suggests that a more comprehensive discussion is needed to address this concern. However, the comment does not provide explicit guidance on how to conduct this discussion or what specific aspects should be covered. The action is implicit and somewhat vague, as the authors can infer that they need to include a discussion on scalability but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"multi-marginal OT and spline calculations,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the computational complexity of these calculations and the potential impact on scalability, which is a critical concern for real-world applications. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the computational complexity of multi-marginal OT and spline calculations may limit the scalability of the proposed approach for large datasets, which could be problematic for real-world applications. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The mention of \"problematic\" suggests that the authors should address this concern, but without further elaboration, the claim remains somewhat vague and lacks sufficient evidence or justification. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides a direction for improvement but requires more detailed support to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the scalability of the proposed approach due to the computational complexity of multi-marginal OT and spline calculations. It suggests that a more comprehensive discussion is required to address this concern, which is important for real-world applications. However, the comment does not provide specific suggestions or guidance on how to conduct this discussion or what aspects should be covered. While it highlights a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the authors\\' claim that non-uniform label noise is not common in practice and the existence of such noise in real-world datasets like Clothing1M. It references a specific work by Kun Yi and Jianxin Wu, which provides evidence of non-uniform label noise in these datasets. The comment implies that the authors should reconsider their claim or provide evidence to support it. However, it does not explicitly instruct the authors to revise their claim or provide additional evidence. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue by providing evidence or revising their claim. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about non-uniform label noise and references specific works, such as Kun Yi and Jianxin Wu\\'s paper, to support the claim. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the authors\\' claim about non-uniform label noise being uncommon in practice. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the authors\\' claim that non-uniform label noise is not common in practice, by referencing specific works that have observed such noise in real-world datasets like Clothing1M. The reviewer provides a reference to a specific paper by Kun Yi and Jianxin Wu, which supports the claim that non-uniform label noise exists. This provides a robust and verifiable basis for the critique, as it directly references a relevant work that contradicts the authors\\' claim. Therefore, the comment is fully verifiable, aligning with a score of 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the authors\\' claim that non-uniform label noise is not common in practice and the existence of such noise in real-world datasets like Clothing1M. It provides specific evidence from a relevant work by Kun Yi and Jianxin Wu, which supports the existence of non-uniform label noise. This feedback is highly helpful as it not only highlights a potential weakness in the authors\\' argument but also offers a clear and actionable suggestion for improvement by referencing a specific study. By addressing this issue, the authors can strengthen their claim and provide a more accurate representation of the prevalence of non-uniform label noise in practice. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the evaluation in Section 6.2 is based on only 10 samples, which could lead to biased findings due to the small scale of the experiment. This feedback provides a clear and direct action for the authors to take, which is to consider increasing the sample size to improve the robustness and generalizability of their results. The comment is specific about the issue and provides a concrete suggestion for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 6.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation, which is based on a limited sample size of only 10 samples. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation in Section 6.2 is based on only 10 samples, which could lead to biased findings due to the small scale of the experiment. However, the comment does not provide specific reasoning or evidence to support why a limited sample size would necessarily lead to biased results. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation in Section 6.2, noting that it is based on only 10 samples. This limited sample size could lead to biased findings due to the small scale of the experiment. While the comment highlights a potential problem, it does not provide detailed guidance or suggestions on how the authors might address this issue, such as recommending a larger sample size or discussing potential implications of the small sample size. The feedback is somewhat helpful as it points out a potential limitation but lacks actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the method is tailored to similar MILP tasks, which could limit its generalizability to significantly different combinatorial optimization problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue experimentally or what specific steps they should consider to improve the generalizability of their method. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the generalizability of the method to significantly different combinatorial optimization problems, which is a specific concern. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential limitation of the method's applicability to different combinatorial optimization problems. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is tailored to similar MILP tasks, which could limit its generalizability to significantly different combinatorial optimization problems. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the method's generalizability to significantly different combinatorial optimization problems, which the paper acknowledges but does not address experimentally. This feedback highlights an area where the authors could improve the paper by providing more experimental evidence or discussing the applicability of their method to a broader range of problems. However, the comment lacks specific suggestions or guidance on how to address this limitation, making it somewhat helpful as it points out a potential weakness but does not fully support the authors in improving their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors attempt to bridge a gap in their baseline description in the Results section, but the reviewer struggles to understand how the baselines work, their relation to InterFair, or whether they are competitive. However, the comment does not provide explicit guidance on how the authors should address these issues. It lacks concrete suggestions or detailed instructions on how to improve the description of the baselines or how to make them more competitive. As a result, the authors are left without clear actions to take, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section \"Results\" and the specific lines \"L256-261,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the reviewer\\'s difficulty in understanding how the baselines work, their relation to InterFair, and whether they are competitive. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors attempt to bridge a gap in their baseline description but struggles to understand how the baselines work, their relation to InterFair, or whether they are competitive. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the reviewer\\'s perspective, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not offer sufficient justification or evidence to support the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the description of the baselines in the Results section, noting that the authors attempt to bridge a gap but lack clarity on how the baselines work, their relation to InterFair, or whether they are competitive. This feedback is somewhat helpful as it points out a potential area for improvement in the paper\\'s presentation of the baselines. However, the comment could be more helpful if it provided specific suggestions or examples on how to improve the clarity and comprehensiveness of the baseline description. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not provide any explicit guidance or suggestions on how the authors should improve this comparison. The comment lacks actionable details, such as recommending specific ways to enhance the comparison or suggesting additional metrics to consider. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of sufficient comparison to other baselines on cycle counting and ZINC. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in identifying the issue with the comparison, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the comparison to other baselines on cycle counting and ZINC. It points out that the comparison is insufficient, which is a critical observation that could impact the validity and reliability of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might improve the comparison or what additional metrics or analyses could be considered. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. This feedback implies that the authors should provide a detailed rationale or evidence to support the effectiveness of the specific mask snippets. However, the comment does not explicitly instruct the authors to do so, leaving the action somewhat vague. The authors are left to infer that they need to provide a detailed explanation, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. However, it does not specify which part of the paper this explanation should be provided in, nor does it provide details on what aspects of the mask snippets are particularly effective or why. This lack of specificity makes it difficult for the authors to identify the exact areas that need attention or improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. This feedback identifies a potential gap in the paper\\'s explanation, which could help the authors provide a more comprehensive understanding of their method. However, the comment lacks specific guidance on how to address this issue or what aspects of the explanation should be included. While it points out a potential area for improvement, it does not offer detailed suggestions or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a perceived limitation in the performance of the SLQ method compared to previous CRD methods, specifically mentioning the F1 score and conductance values. It also notes that SLQ shows worse performance than CRD in Figure 3 and only a small improvement over ACL in Figure 4. While the comment identifies a potential issue with the performance of SLQ, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method. The action is implicit and somewhat vague, as the authors can infer that they need to improve the performance of SLQ, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the performance of the SLQ method compared to the CRD method, noting that SLQ shows worse performance in Figure 3 and only a small improvement over ACL in Figure 4. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of SLQ is limited compared to previous CRD methods, specifically mentioning the F1 score and conductance values. It also provides specific examples from Figures 3 and 4, where SLQ shows worse performance than CRD and only a small improvement over ACL, respectively. These comparisons and references provide a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including more detailed comparisons or additional references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the performance of the SLQ method compared to previous CRD methods, specifically mentioning the F1 score and conductance values. It provides specific examples from Figures 3 and 4, where SLQ shows worse performance than CRD and only a small improvement over ACL, respectively. This feedback is clear and actionable, as it highlights a specific area where the authors need to improve the performance of their method. However, the comment could be more helpful if it offered suggestions on how to address this limitation or provided additional context on why the CRD method is considered more competitive. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly encourages the authors to add more baselines to perform robust performance comparisons. This feedback is clear and provides a direct action for the authors to take, which is to expand their selection of baselines. The comment also specifies the need for more robust comparisons, giving the authors a specific direction for improvement. Therefore, the action is explicit and concrete, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the selection of baselines, specifically noting that the authors have limited themselves to naive/old models. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to add more baselines for robust performance comparisons, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the selection of baselines is limited to naive/old models, suggesting that more robust performance comparisons could be achieved by adding additional baselines. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of detailed reasoning or evidence makes the claim borderline verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is classified as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s selection of baselines, noting that the authors have limited themselves to naive/old models. It encourages the authors to add more baselines to perform robust performance comparisons. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting the inclusion of additional baselines. However, the comment could be more helpful if it offered specific examples of other models that could be considered or provided guidance on how to select and evaluate these baselines. Despite this, the comment is mostly helpful as it directs the authors to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors either justify their choice of target structure or provide additional experiments demonstrating the method's adaptability to different target structures. This feedback is clear and provides a concrete action for the authors to take, ensuring that they know exactly what steps to take to improve their draft. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"the choice of target structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the justification for the choice of only one target structure and the need for additional experiments to demonstrate adaptability. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of only one target structure for evaluation and suggests that additional experiments are needed to demonstrate the method's adaptability to different target structures. This claim is somewhat verifiable as it provides a logical reasoning for the need to expand the evaluation, but it lacks specific examples or references to support the argument. The authors would need to further develop the rationale to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the choice of target structure in Table 2 and suggests that the authors either justify this choice or provide additional experiments demonstrating the method's adaptability to different target structures. This feedback is clear and actionable, as it provides a concrete direction for the authors to address the issue of limited generalizability. By addressing this point, the authors can enhance the robustness and applicability of their method. However, the comment could be more helpful if it offered specific suggestions on how to justify the choice or conduct the additional experiments. Overall, the comment is mostly helpful as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the paper\\'s scope, noting that it focuses primarily on the knapsack problem and neglects more realistic scenarios like medical diagnosis. It suggests that exploring applications in critical areas like healthcare could significantly enhance the paper\\'s impact and relevance. While the comment implies that the authors should broaden their scope, it does not provide explicit instructions or concrete steps on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should expand their application scope. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"research primarily concentrates on the knapsack problem,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the paper should explore applications in more realistic scenarios, such as medical diagnosis, to enhance its impact and relevance. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the research focuses primarily on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. This critique suggests that broadening the application scope would significantly enhance the paper\\'s impact and relevance. However, the comment lacks specific examples or references to support the claim that medical diagnosis is a more realistic scenario. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is somewhat verifiable, as it provides a logical argument but lacks sufficient evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the paper's scope, noting that it primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. It suggests that exploring applications in critical areas like healthcare could significantly enhance the paper's impact and relevance. This feedback is clear and actionable, as it directs the authors to broaden their scope and consider applications in areas with greater practical significance. However, the comment could be more helpful if it provided specific examples or references to support the claim that medical diagnosis is a more relevant and impactful area. Overall, the comment is mostly helpful as it guides the authors toward a more meaningful and relevant application of their research.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the method\\'s claimed improvement in robustness and sensitivity, specifically mentioning that the new method appears noisier in two domains and is equally noisy as the competitors in the rest. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve the method. The comment lacks actionable details, such as recommending specific steps to improve robustness or sensitivity or suggesting ways to reduce noise. As a result, the authors are left without a clear understanding of what changes they should make to address the concerns raised. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the method does not seem to improve on robustness and sensitivity as claimed in the motivation section, and it compares the method to competitors in terms of noise. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method does not improve robustness and sensitivity as claimed in the motivation section. It provides a specific comparison with the noise levels in Figure 3, suggesting that the new method is noisier in two domains and equally noisy as the competitors in the rest. This claim is somewhat verifiable as it provides a comparison with the noise levels, but it lacks detailed reasoning or references to support the claim that the method does not improve robustness and sensitivity. The authors would need to further explore the data or provide additional evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the method\\'s claimed improvement in robustness and sensitivity, specifically questioning whether the method actually delivers on these promises. It provides a specific comparison with the noise levels in Figure 3, suggesting that the new method is noisier in two domains and equally noisy as the competitors in the rest. This feedback is somewhat helpful as it points out a potential weakness in the methodology, but it lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue. To be more helpful, the comment could provide additional insights or recommendations for improving the robustness and sensitivity of the method. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the conclusion of the paper, specifically asking whether it holds against more sophisticated or aggressive removal methods. While this question implies that the authors should consider the applicability of their conclusion to more advanced or aggressive methods, it does not provide explicit guidance on how to address this issue or what specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to consider the applicability of their conclusion, but the comment lacks concrete details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the conclusion to more sophisticated or aggressive removal methods. However, it does not specify which part of the paper this conclusion is drawn from, nor does it provide details on what specific aspects of the conclusion need to be tested or how the authors should address this question. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts of the paper need to be revised. The comment is not grounded and lacks specificity, making it difficult for the authors to understand and act upon the feedback. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the applicability of the conclusion to more sophisticated or aggressive removal methods. However, it does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the applicability of the conclusion to more sophisticated or aggressive removal methods. This is a valuable point as it prompts the authors to consider the robustness of their findings in the face of more advanced techniques. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what aspects of their conclusion might be challenged by more aggressive methods. While it identifies a potential area for improvement, it does not provide actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper introduces explainable AI in the introduction but does not explain the definition of interpretability or the difference between these two concepts. It also notes that the authors do not provide any work in this line. While the comment identifies specific areas where the paper is lacking, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the definitions and provide examples of work in this area, but the comment lacks concrete steps or suggestions on how to implement these improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of explanation regarding the definitions of interpretability and the difference between explainable AI and interpretable methods. The comment also highlights the absence of work in this line, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper introduces \"explainable AI\" in the introduction but does not explain the definition of interpretability or the difference between these two concepts. It also notes that the authors do not provide any work in this line. The comment provides some logical reasoning by pointing out the discrepancy between the introduction and the paper\\'s focus on interpretable methods. However, it lacks specific examples or references to support the claim that the definitions are unclear or that the work is missing. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the issues raised.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that the introduction of \"explainable AI\" is not consistent with the paper\\'s focus on interpretable methods. It highlights the lack of explanation regarding the definitions of interpretability and the difference between these two concepts, as well as the absence of work in this line. This feedback is clear and actionable, as it directs the authors to clarify these important distinctions and provide examples of work in the field. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided references to relevant literature. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the clarity and depth of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point asks a question about the training data for the probes in the compositionality and transitivity experiments. While it does not explicitly instruct the authors to provide this information, it implies that the authors should include this detail in their paper. The action is implicit but concrete, as the authors know exactly what information is missing and how to address it. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the training data for the probes in the compositionality and transitivity experiments. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for information about the training data, but without explicit grounding, it is difficult for the authors to pinpoint the exact location of the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for information about the training data for the probes in the compositionality and transitivity experiments. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the training data for the probes in the compositionality and transitivity experiments. This is a clear and actionable request for information that the authors should address to improve the transparency and reproducibility of their work. By providing this detail, the authors can ensure that their experiments are fully understood and replicable by others. However, the comment could be more helpful if it offered suggestions on how to present this information or provided additional context on why this detail is important. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors need to clarify what is meant by \"not only the complete captions but also parts thereof,\" and questions the convincingness of the argument around why filling in the blanks is difficult. The reviewer suggests that there are ways to perform bi-directional beam search for fill-in-the-blank applications, providing a reference (C). While the comment identifies areas that need clarification and suggests an alternative approach, it does not explicitly instruct the authors on how to address these issues or provide detailed guidance on how to implement the suggested method. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L133-134,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the meaning of \"not only the complete captions but also parts thereof,\" and questions the convincingness of the argument around filling in the blanks. The reviewer provides a suggestion to consider bi-directional beam search, which is relevant but not directly applicable to the current issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the argument regarding the difficulty of filling in the blanks, suggesting that the reasoning is unconvincing. The reviewer provides a reference to a method (C) that could be used for bi-directional beam search, which is a logical suggestion. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that the argument is unconvincing. While the reference provides a basis for the claim, the comment could be strengthened with more detailed justification or examples. Therefore, the comment is somewhat verifiable, as it provides a starting point but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, noting that the argument around the difficulty of filling in the blanks is unconvincing. It suggests that the authors clarify what is meant by \"not only the complete captions but also parts thereof,\" and provides a reference to a method (C) that could be used for bi-directional beam search. This feedback is clear and actionable, as it directs the authors to address a specific issue and offers a potential solution. However, the comment could be more helpful if it provided more detailed guidance on how to improve the argument or clarified the relevance of the reference to the current discussion. Overall, the comment is mostly helpful as it effectively points out a weakness and offers a constructive suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of reverse KL for training flows and questions the realism of assuming differentiability of the function $g$. It also mentions that the reverse KL is mode-seeking and suggests that it may be a limitation for rare event sampling. The reviewer provides specific references to recent work on normalizing flows, such as [3], which could help the authors address this issue. However, the comment does not explicitly instruct the authors to comment on these aspects or provide guidance on how to address the limitations. While the action is implicit, it is concrete because it specifies the need for a comment on differentiability and the mode-seeking nature of the reverse KL. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the use of reverse KL for training flows and raises concerns about the assumption of differentiability of the function $g$. It also mentions the mode-seeking nature of the reverse KL and its potential limitations for rare event sampling. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology or results sections where the training process is described. The comment is specific in detailing the concerns about the use of reverse KL and its potential limitations, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the use of reverse KL for training flows and questions the realism of assuming differentiability of the function $g$. It also mentions that the reverse KL is known to be mode-seeking and suggests that it may be a limitation for rare event sampling. The reviewer provides references to recent work on normalizing flows, such as [3], to address this issue. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claims about the limitations of reverse KL. While it provides some evidence, the lack of detailed justification makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the use of reverse KL for training flows, specifically questioning the realism of assuming differentiability of the function $g$. It also points out that the reverse KL is known to be mode-seeking, which could be a limitation for rare event sampling. The reviewer provides references to recent work on normalizing flows, such as [3], to address this issue. This feedback is clear and actionable, as it highlights a specific concern and suggests ways for the authors to improve their work. However, it could be more helpful if it included more detailed guidance on how to address the limitations or potential solutions. Overall, the comment is mostly helpful as it provides valuable insights and direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the annotations in the visual event detection stage of the ViStruct Suite might contain noise due to their reliance on an off-the-shelf semantic role labeling system. It implies that a detailed analysis of the curated dataset is necessary. However, the comment does not provide explicit guidance on how to conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a detailed analysis of the dataset. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ViStruct Suite\" and the \"visual event detection stage,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the annotations in the visual event detection stage, noting that they might contain noise due to their reliance on an off-the-shelf semantic role labeling system. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that annotations in the visual event detection stage of the ViStruct Suite might contain noise due to their reliance on an off-the-shelf semantic role labeling system. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not offer sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the annotations in the visual event detection stage of the ViStruct Suite, noting that they might contain noise due to their reliance on an off-the-shelf semantic role labeling system. This is a relevant observation that could impact the accuracy and reliability of the dataset used for evaluation. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as recommending alternative approaches or methods for noise reduction. While it points out a potential problem, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the model implementation should be better justified, specifically mentioning the stopping rule with n consecutive identical samples as being arbitrary and noting the lack of discussion on sensitivity with regard to n. However, it does not provide explicit guidance on how to justify the model implementation or what specific aspects should be addressed. The feedback is vague and lacks concrete steps for the authors to take, leaving them without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"stopping rule with n consecutive identical samples,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the justification of the stopping rule and the sensitivity with regard to n. This provides clear guidance on what aspects of the model implementation need improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model implementation should be better justified, specifically questioning the stopping rule with n consecutive identical samples and the lack of discussion on sensitivity with regard to n. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these aspects are problematic or how they could be improved. Without additional context or examples, the claim remains vague and lacks verifiability, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the justification of the model implementation, particularly the stopping rule with n consecutive identical samples and the lack of discussion on sensitivity with regard to n. This feedback is clear and actionable, as it points out a gap in the paper that needs to be addressed. However, the comment could be more helpful if it provided suggestions on how to better justify the stopping rule or how to discuss sensitivity in the context of the model implementation. Despite this, the comment still offers valuable insights that can guide the authors in improving their draft, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two main issues: the lack of time complexity analysis and running time reporting for the proposed algorithms, and the absence of a comparison with state-of-the-art algorithms regarding search time. While the comment identifies these gaps, it does not provide explicit instructions on how to address them. The authors are left to infer that they should include time complexity analysis and running time results, as well as conduct a comparison with existing methods. The suggestion to explore the impact on search time is implicit and lacks concrete guidance on how to conduct this analysis. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues related to the lack of time complexity analysis and running time results for the proposed algorithms, as well as the absence of a comparison with state-of-the-art algorithms regarding search time. It provides specific guidance on what needs to be addressed, such as the need for time complexity analysis and running time results. However, it does not explicitly mention which section of the paper these issues are discussed, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks time complexity analysis and running time results, as well as a comparison with state-of-the-art algorithms regarding search time. The reviewer provides a logical reasoning by pointing out the importance of time complexity analysis and running time results, especially given the NP-hard nature of the problem. However, the comment does not provide specific examples or references to support the claim about the lack of comparison with state-of-the-art algorithms. This makes the claim somewhat verifiable, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two significant issues with the paper: the lack of time complexity analysis and running time results for the proposed algorithms, and the absence of a comparison with state-of-the-art algorithms regarding search time. It provides a clear and actionable suggestion by recommending the inclusion of time complexity analysis and running time results, as well as a comparison with existing methods to assess the impact on search time. This feedback is valuable as it guides the authors on how to enhance the comprehensiveness and rigor of their work. However, the comment could be more helpful if it offered specific suggestions on how to conduct the comparison or what metrics to use. Overall, the comment is mostly helpful as it effectively directs the authors to address important gaps in their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of quality control or manual evaluation on the data collected through an automatic model-based approach. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the authors should implement additional quality control measures, perform manual evaluations, or clarify the data collection process. As a result, the comment lacks actionable details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of quality control or manual evaluation on the data collected through an automatic model-based approach. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the data is discussed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in identifying the issue of lacking quality control or manual evaluation, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no quality control or manual evaluation on the data collected through an automatic model-based approach. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the significance of this issue or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting the lack of quality control or manual evaluation on the data collected through an automatic model-based approach. This is a critical observation that could impact the validity and reliability of the results. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue, such as recommending additional quality control measures or manual evaluations. Without actionable feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is somewhat helpful, as it highlights a critical area for improvement but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests comparing a confidence interval from a small development set with the Frechet bound. While it provides a specific suggestion for an additional analysis, it does not explicitly instruct the authors to perform this comparison or explain how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of a small set of labeled data for most tasks, including the reliance on a small development set for hyperparameter tuning in snorkel. It suggests comparing a confidence interval from a small dev set with the Frechet bound. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the discussion of data and hyperparameter tuning. The suggestion is specific, as it provides a clear direction for an additional analysis. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing a confidence interval from a small development set with the Frechet bound. While it provides a logical reasoning for this comparison, it lacks specific examples or references to support the claim that this comparison would be interesting or beneficial. The suggestion is somewhat verifiable, as it provides a rationale but requires more detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting a comparison between a confidence interval from a small development set and the Frechet bound. This is a valuable suggestion that could enhance the paper\\'s analysis and provide insights into the performance of the model. However, the comment lacks specific guidance on how to implement this comparison or what aspects of the analysis should be considered. While it points out a potentially interesting direction, it does not offer detailed instructions or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is only applicable to problems with low dimensional input spaces, specifically mentioning that the largest dimensionality in the experiments is 3. It further explains this limitation due to the curse of dimensionality caused by the use of a finite set of points that cover the region of interest in the surrogate modeling of the shape constraint. While the comment identifies a limitation, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methodology. The action is implicit and somewhat vague, as the authors can infer that they need to consider dimensionality issues but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the method is only applicable to problems with low dimensional input spaces, due to the curse of dimensionality caused by the use of a finite set of points that cover the region of interest in the surrogate modeling of the shape constraint. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is only applicable to problems with low dimensional input spaces, specifically mentioning that the largest dimensionality in the experiments is 3. This is due to the curse of dimensionality caused by the use of a finite set of points that cover the region of interest in the surrogate modeling of the shape constraint. The comment provides a logical reasoning for the limitation, which is based on a common understanding of the curse of dimensionality. However, it lacks specific references or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable explanation but could benefit from more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the proposed method, noting that it is only applicable to problems with low dimensional input spaces. This is a critical observation, as it highlights a potential limitation in the applicability of the method. The comment further explains the issue by referencing the curse of dimensionality, which is a well-known concept in machine learning and data analysis. However, the comment could be more helpful if it provided suggestions on how the authors might address this limitation or expand their method to accommodate higher dimensional input spaces. While it points out a significant issue, the feedback lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the results of the methods presented in Tables 1 and 2 are within their standard deviations, which casts doubt on the claim that the presented method is significantly better than others. However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to support the claim. The comment lacks actionable details, such as suggesting alternative analyses or methods to demonstrate superiority, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the results, namely that they are within their standard deviations, which casts doubt on the claim of significant superiority. This provides clear guidance on what needs to be addressed to support the claim. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results of the methods presented in Tables 1 and 2 are within their standard deviations, which casts doubt on the claim that the presented method is significantly better than others. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the assertion, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not offer sufficient justification or evidence to support the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results presented in Tables 1 and 2, noting that the methods' results are within their standard deviations. This observation raises a concern about the claim of significant superiority over other methods. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the presentation of their results to better support their claims. Without actionable feedback or additional context, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the complexity of generating synthetic tabular data due to factors such as multiple entries in a table being associated with the same entity, leading to additional relationships. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"synthetic tabular data\" and provides specific examples of factors that make it non-trivial, such as multiple entries in a table being associated with the same entity. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issues with generating synthetic tabular data, providing a detailed explanation of the challenges. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that generating synthetic tabular data is non-trivial due to factors such as multiple entries in a table being associated with the same entity, resulting in additional relationships. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this claim and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific challenge in generating synthetic tabular data, noting that it can be non-trivial due to factors such as multiple entries in a table being associated with the same entity, leading to additional relationships. While the comment highlights a potential issue, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this challenge. Without specific recommendations or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the paper\\'s focus on the AmbiQT benchmark, suggesting that an overemphasis on this specific benchmark without broader context or validation on other datasets could lead to questions about its applicability and relevance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure broader applicability. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their validation efforts beyond the AmbiQT benchmark. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the creation of the AmbiQT benchmark, suggesting that an overemphasis on this specific benchmark without broader context or validation on other datasets could lead to questions about its applicability and relevance. However, it does not specify which part of the paper discusses the AmbiQT benchmark, making it weakly grounded. The comment is specific in its concern about the potential overemphasis and the need for broader validation, but without explicit references to specific sections, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the overemphasis on the AmbiQT benchmark and its potential impact on the applicability and relevance of the work. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s focus on the AmbiQT benchmark, suggesting that an overemphasis on this specific benchmark without broader context or validation on other datasets could lead to questions about its applicability and relevance to other scenarios. This feedback is valuable as it highlights a potential weakness in the paper\\'s validation approach, which could impact its generalizability. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional datasets or context to strengthen the paper\\'s applicability. While it points out a relevant concern, the comment could be more helpful with actionable advice. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of annotation training details and guidelines, as well as the lack of information about the tool used. While it identifies specific areas that need attention, it does not provide explicit instructions or concrete steps for the authors to take. The comment implies that the authors should include these details, but it lacks actionable guidance on how to do so. The authors can infer that they need to provide more information about annotation training and the tool, but the lack of specific guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the absence of annotation training details and guidelines, as well as the lack of information about the tool used. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what is missing, such as the need for training details and information about the tool. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the absence of annotation training details and guidelines is important, as professional translators often face issues with non-standard tasks. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the claim. The lack of detailed reasoning or evidence makes the claim unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of annotation training details and guidelines, as well as the lack of information about the tool used. This is a critical observation, as professional translators often struggle with non-standard tasks. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues. While it highlights important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the bold-faced font for EX/NORB and the statistical significance of the difference between 0.59+/-0.12 and 0.58+/-0.11. While these questions imply that the authors should reconsider the presentation of these values, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the presentation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the bold-faced font for EX/NORB and the statistical significance of the difference between 0.59+/-0.12 and 0.58+/-0.11. This provides clear guidance on what needs to be addressed in the table, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions about the presentation of data in Table 1, specifically whether the bold-faced font for EX/NORB is appropriate and whether the difference between 0.59+/-0.12 and 0.58+/-0.11 is statistically significant. These questions are factual and do not express an opinion or claim that requires justification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises specific questions about the presentation of data in Table 1, particularly questioning the bold-faced font for EX/NORB and the statistical significance of the difference between 0.59+/-0.12 and 0.58+/-0.11. This feedback is somewhat helpful as it prompts the authors to reconsider the presentation of their data, potentially leading to a clearer and more accurate representation. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered guidance on how to determine statistical significance. Overall, the comment is somewhat helpful as it directs the authors\\' attention to specific areas for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the metric used for the video level supervision experiment, specifically inquiring whether it is based on tracklet-based metrics. While the comment identifies a potential gap in the paper, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the metric used. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the metric used in the video level supervision experiment, specifically inquiring whether it is based on tracklet-based metrics. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the experiment is described. This makes it difficult for the authors to pinpoint the exact part of the paper that needs clarification. While the authors might have an idea of where the experiment is discussed, the comment lacks full grounding. It is specific in its inquiry about the metric used, but without explicit references, it is weakly grounded. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the metric used in the video level supervision experiment. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the metric used in the video level supervision experiment, noting that it does not appear to be based on tracklet-based metrics as mentioned in the paper. This feedback is clear and actionable, as it prompts the authors to clarify or provide additional information about the metric used in the experiment. However, the comment could be more helpful if it suggested ways to address this issue or provided additional context on why tracklet-based metrics might be relevant. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the effect of \"person blocking\" on the models, specifically asking for an explanation or comment on this phenomenon. While the comment implies that the authors should provide an explanation or comment, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a response to the question. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the effect of \"person blocking\" on the models, specifically asking for an explanation or comment on this phenomenon. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for an explanation or comment, providing clear guidance on what the authors need to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the effect of \"person blocking\" on the models, suggesting that it might be due to models learning person-related features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the effect of \"person blocking\" on the models, suggesting that it might be due to models learning person-related features. This prompts the authors to consider whether this phenomenon is undesirable and to provide a comment on it. While the comment identifies a potential issue and prompts the authors to consider it, it lacks depth and does not offer specific suggestions or guidance on how to address this issue. The feedback is somewhat helpful as it points out a potential area for improvement but could be more actionable with additional details. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the authors have tried the combination of TF-IDF and dense retrieval for evidence sentence extraction. While it implies that the authors should consider this approach, it does not provide explicit instructions or guidance on how to implement it or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should explore this combination. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"TF-IDF and dense retrieval,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about whether the authors have tried a particular combination for evidence sentence extraction, providing clear guidance on what aspect needs clarification or exploration. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking whether the authors have tried a specific combination of TF-IDF and dense retrieval for evidence sentence extraction. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about whether the authors have tried a specific combination of TF-IDF and dense retrieval for evidence sentence extraction. While it is a relevant question that could prompt the authors to consider a potential improvement, it lacks depth and does not provide any guidance or suggestions on how to implement this approach or what specific aspects to focus on. The comment is somewhat helpful as it prompts the authors to consider a potential improvement but does not offer actionable advice or detailed feedback. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should mention or provide examples of instances where time-series prediction did not perform well, specifically referencing the COVID-19 dataset. It also asks for examples of countries where the predictions were not great and how their trajectories related to the top eigenvectors of the Laplacian. While the comment provides a clear direction for the authors to include examples or case studies, it does not explicitly instruct them to do so. The action is implicit but concrete, as it specifies what additional information should be included. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the paper should mention or provide examples of instances where time-series prediction did not perform well, specifically referencing the COVID-19 dataset. It also asks for examples of countries where the predictions were not great and how their trajectories related to the top eigenvectors of the Laplacian. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the time-series prediction aspect of the work. The suggestion to provide examples is specific, making the comment mostly grounded. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should mention or provide examples of instances where time-series prediction did not perform well, specifically referencing the COVID-19 dataset. The reviewer provides a specific example of the UK and Russia being highly correlated, despite not being neighboring countries, as evidence that the prediction did not perform well. However, the comment lacks detailed reasoning or references to support why this example is relevant or how it relates to the paper\\'s focus. While the suggestion is somewhat verifiable, it could be strengthened with additional context or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending that the paper mention or provide examples of instances where time-series prediction did not perform well, specifically referencing the COVID-19 dataset. It also asks for examples of countries where the predictions were not great and how their trajectories related to the top eigenvectors of the Laplacian. This feedback is clear and actionable, as it directs the authors to include additional context and examples that could enhance the paper\\'s analysis and discussion. By addressing these points, the authors can improve the comprehensiveness and depth of their work. However, the comment could be more helpful if it provided additional guidance on how to incorporate these examples or examples of other countries with similar issues. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the claims of proposing a \"learning framework\" seem overblown, as it is not a new framework but a modified loss and architecture. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue or improve their claims. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the claims of proposing a \"learning framework\" as overblown, suggesting that it is not a new framework but a modified loss and architecture. However, it does not specify which part of the paper these claims are made in, leaving the authors to infer that it relates to the introduction or discussion sections. The comment is specific in detailing what is considered overblown, but it lacks grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the claims of proposing a \"learning framework\" are overblown, as it is not a new framework but a modified loss and architecture. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the claims of proposing a \"learning framework\" as overblown, suggesting that it is not a new framework but a modified loss and architecture. While the comment identifies a potential issue with the authors\\' claims, it lacks specificity and does not provide actionable guidance or suggestions for improvement. The authors are left without clear direction on how to address this critique or improve their claims. Therefore, the comment is barely helpful, as it points out a weakness but does not offer constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential limitation in the customization of learned prompts for individual transformer-based architectures, such as CLIP and DINOv2, and suggests that this specificity may limit cross-model generalization. It recommends exploring ways to design prompts with more universal features or optimizing them independently of model architecture to enhance broader applicability. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the customization of learned prompts for individual transformer-based architectures, such as CLIP and DINOv2, and suggests that this specificity may limit cross-model generalization. It recommends exploring ways to design prompts with more universal features or optimizing them independently of model architecture to enhance broader applicability. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion of prompt customization or the broader applicability of the work. The comment is specific in its suggestion to explore universal features or independent optimization, providing clear guidance on how to address the issue. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the specificity of customized learned prompts for individual transformer-based architectures, such as CLIP and DINOv2, which may limit cross-model generalization. The comment suggests that exploring ways to design prompts with more universal features or optimizing them independently of model architecture could enhance broader applicability. While the comment identifies a potential limitation, it lacks specific examples or references to support the claim that this specificity limits cross-model generalization. The suggestion to explore universal features or independent optimization is logical but requires further elaboration to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the concern but lacks detailed evidence or references to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the customization of learned prompts for individual transformer-based architectures, such as CLIP and DINOv2, which may limit cross-model generalization. It suggests that exploring ways to design prompts with more universal features or optimizing them independently of model architecture could enhance broader applicability. This feedback is clear and actionable, as it points out a specific area for improvement and provides a direction for addressing the issue. However, the comment could be more helpful if it offered specific suggestions or examples of how to implement these changes. Overall, the comment is mostly helpful as it provides valuable insights and guidance for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the absence of baselines in the paper and suggests that the model architecture used appears outdated. It explicitly recommends evaluating the current methodology against contemporary time-series forecasting architectures, specifically mentioning the \"Time-Series Library\" repository as a potential source of advanced models. This feedback provides a clear and concrete action for the authors to take, which is to include comparisons with other models to demonstrate the effectiveness and novelty of their methodology. The suggestion is explicit and provides specific guidance on how to enhance the paper, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the absence of baselines in the paper and suggests that the model architecture used appears outdated. It provides specific suggestions for potential baselines, such as those available in the \"Time-Series Library\" repository. This feedback is clear and provides a concrete direction for improvement, making the comment fully grounded as it explicitly mentions the \"Time-Series Library\" repository. The comment is also specific, as it details what needs to be addressed regarding the model architecture and baselines. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the absence of baselines in the paper and suggests that the model architecture used appears outdated. It provides a specific suggestion to evaluate the current methodology against contemporary time-series forecasting architectures, such as those available in the \"Time-Series Library\" repository. This claim is somewhat verifiable as it logically argues that the absence of baselines and the use of outdated techniques may impact the novelty and effectiveness of the methodology. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the absence of baselines in the paper, which raises questions about the novelty and effectiveness of the methodology. It suggests that the model architecture used appears outdated and recommends evaluating the current methodology against contemporary time-series forecasting architectures. The comment provides a specific suggestion to consider potential baselines, such as those available in the \"Time-Series Library\" repository. This feedback is clear and actionable, offering the authors a concrete direction for improving their draft by including comparisons with other models. However, the comment could be more helpful if it provided additional guidance on how to select or interpret these baselines. Overall, the comment is mostly helpful as it effectively highlights a critical area for improvement and offers a specific suggestion for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include at least one strong baseline in one of the tasks, even though it is primarily a theoretical work. This feedback implies that the authors should consider adding a more robust baseline to enhance the comparative analysis. However, the comment does not specify which task or how to implement this suggestion, leaving the authors with a general idea of what to do but without concrete guidance on execution. The action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include at least one strong baseline in one of the tasks, despite being primarily a theoretical work. However, it does not specify which tasks or sections of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for a stronger baseline, but without explicit references to sections or tasks, the authors may struggle to identify the exact areas that need improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks a strong baseline in one of the tasks, despite being primarily a theoretical work. However, the comment does not provide any specific reasoning or examples to support why a stronger baseline is necessary or how it would enhance the paper. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that it lacks a strong baseline in one of the tasks, despite being primarily a theoretical work. This feedback is somewhat helpful as it highlights an area where the paper could be strengthened, namely by including a more robust baseline for comparison. However, the comment does not provide specific suggestions on which tasks would benefit from a stronger baseline or how to incorporate it into the paper. While it offers a direction for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to more clearly compare their proposed method to the two prior works mentioned, and to include them in the tables of experimental results. This feedback provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The suggestion is concrete and specific, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the proposed method\" and \"the two prior works cited by the authors [3, 5].\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, the need for a more detailed comparison of the proposed method with the prior works and their inclusion in the tables of experimental results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is similar to two prior works mentioned by the authors. However, it does not provide specific details or examples of how the proposed method is similar to these prior works, nor does it offer any comparisons or references to support the claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the proposed method is similar to two prior works mentioned by the authors. It suggests that the paper should more clearly compare the proposed method to these prior works and include them in the tables of experimental results. This feedback is clear and actionable, providing the authors with a direct and specific direction for improvement. By addressing this issue, the authors can enhance the novelty and comprehensiveness of their work. However, the comment could be more helpful if it included examples or detailed guidance on how to effectively compare the methods. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors\\' claim about the lack of visualization systems for interpretable reinforcement learning is unclear because the broader goals identified are not specified. However, it does not provide any guidance on how the authors should clarify or address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors without a clear path forward. As a result, the action is implicit and vague, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim about the lack of visualization systems for interpretable reinforcement learning, specifically mentioning that the broader goals identified are not specified. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what the broader goals are. This lack of specificity makes it difficult for the authors to identify the exact part of the paper that needs attention. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that there is a lack of visualization systems for interpretable reinforcement learning that effectively address the broader goals identified. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific claim made in the paper regarding the lack of visualization systems for interpretable reinforcement learning that effectively address broader goals. However, it points out that the broader goals themselves are not clearly defined, making it difficult for the authors to evaluate the claim. While the comment highlights an area for improvement, it does not provide actionable guidance or suggestions on how the authors might clarify or address this issue. Without specific advice or examples, the feedback is somewhat helpful, as it directs the authors to a potential area for improvement but lacks depth and actionable steps. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the independence of AAL and SLS and questions whether applying them separately would still provide a stable improvement. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The comment lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the independence of AAL and SLS and questions whether applying them separately would still provide a stable improvement. However, it does not specify which part of the paper this concern is related to, such as a specific section, table, or figure. The authors can infer that it relates to the discussion or results sections, but this inference is not direct. The comment is specific in its concern about the independence and stability of the methods, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the independence and stability of the AAL and SLS methods, suggesting that applying them separately might not provide significant improvements. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the independence and stability of the AAL and SLS methods, suggesting that applying them separately might not provide significant improvements. However, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this concern or improve their draft. Without detailed guidance or examples, the comment does not offer much value to the authors in terms of improving their work. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments are limited to only one task (sentiment classification) and one dataset (SST2), which limits the depth of insights that can be gained. It recommends exploring the effects on different tasks or utilizing multiple datasets for the same task to gain deeper insights. While the comment implies that the authors should expand their experiments, it does not provide explicit instructions on how to do so. The action is concrete but somewhat vague, as the authors know they need to explore different tasks and datasets but may not be entirely sure how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"limited task and dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the experiments are limited to only one task (sentiment classification) and one dataset (SST2), and recommends exploring the effects on different tasks or utilizing multiple datasets for the same task. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are limited to only one task (sentiment classification) and one dataset (SST2), which limits the depth of insights gained. The comment suggests that exploring the effects on different tasks or utilizing multiple datasets for the same task would be beneficial. While the claim is logical and provides a reasonable suggestion, it lacks specific examples or references to support the claim. This makes the comment somewhat verifiable, as it provides a reasonable basis but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s experimental setup, noting that the experiments are limited to only one task (sentiment classification) and one dataset (SST2). It suggests that exploring the effects on different tasks or utilizing multiple datasets for the same task would enhance the depth of insights gained. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experiments and improve the depth of their analysis. However, it could be more helpful if it offered specific suggestions on how to implement these changes or what additional tasks or datasets might be relevant. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the experimental design, specifically whether the heat equation, damped wave, and Navier-Stokes are simulated or based on real-world data. It suggests that simulated data would be easier to fit, but it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or improve their experimental design. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the experimental design, specifically whether the heat equation, damped wave, and Navier-Stokes are simulated or based on real-world data. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the nature of the simulated data and its potential impact on fitting, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the experimental design, specifically whether the heat equation, damped wave, and Navier-Stokes are simulated or based on real-world data. The comment suggests that simulated data would be easier to fit, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the experimental design, specifically whether the heat equation, damped wave, and Navier-Stokes are simulated or based on real-world data. It suggests that simulated data would be easier to fit, which could be a valid point for consideration. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or improve their experimental design. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the study lacks a dedicated image quality metric for evaluating the performance of image generation models. It specifically recommends the inclusion of inter-class or intra-class Frechet Inception Distance (FID) as a quantitative assessment. While the comment provides a clear and concrete action\u2014the addition of a specific metric\u2014it does not explain why this metric is necessary or how it would enhance the evaluation. The authors are given a direct and specific action to take, but the rationale for why this is necessary is missing, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of a dedicated image quality metric for evaluating the performance of image generation models. This allows the authors to accurately identify the part of the paper being addressed, which is the evaluation section. The comment is also specific because it suggests the inclusion of inter-class or intra-class Frechet Inception Distance (FID) as a quantitative assessment, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the study lacks a dedicated image quality metric for evaluating the performance of image generation models. The reviewer provides a specific recommendation, namely the inclusion of inter-class or intra-class Frechet Inception Distance (FID) as a quantitative assessment. This claim is somewhat verifiable as it logically suggests that including such a metric would enhance the comprehensiveness of the evaluation and comparison between different models. However, the comment lacks detailed justification or examples of how this metric would improve the evaluation, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the study, specifically the absence of a dedicated image quality metric for evaluating the performance of image generation models. It provides a specific suggestion for improvement by recommending the inclusion of inter-class or intra-class Frechet Inception Distance (FID) as a quantitative assessment. This feedback is clear and actionable, as it offers a concrete way for the authors to enhance the comprehensiveness and robustness of their evaluation. However, the comment could be more helpful if it explained why FID is a particularly relevant or useful metric for this context. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a clear path for enhancing their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the proposed mechanism can be used in vision transformers, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this question or what specific steps they should consider. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of a proposed mechanism to vision transformers, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine the exact part being addressed. Additionally, the comment lacks specificity regarding what aspect of the mechanism needs to be considered for vision transformers. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking whether the proposed mechanism can be used in vision transformers. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of a proposed mechanism to vision transformers, which could prompt the authors to consider expanding their work to include this application. However, the comment lacks depth and does not provide any specific suggestions or guidance on how the authors might address this question or what aspects of the mechanism would be relevant for vision transformers. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the superiority of the precision of IMLE compared to the proposed Adaptive IMLE and inquires if the authors have applied the method to different domains. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a response to these questions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the superiority of the precision of IMLE compared to the proposed Adaptive IMLE and inquires if the authors have applied the method to different domains. However, it does not specify which part of the paper these questions pertain to, such as a particular section or table where the comparison is discussed. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its inquiry about the comparison and application of the method, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the superiority of the precision of IMLE compared to the proposed Adaptive IMLE and inquires if the authors have applied the method to different domains. While it suggests that the proposed method could be applied to any few-shot synthesis problem, it does not provide specific evidence or references to support the claim that IMLE is superior. The comment lacks detailed reasoning or examples to substantiate the claim, making it somewhat verifiable. The authors would need to provide additional evidence or reasoning to fully address the question. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the superiority of the precision of IMLE compared to the proposed Adaptive IMLE and inquires if the authors have applied the method to different domains. It highlights a potential gap in the paper\\'s discussion and suggests that the authors should address these questions to provide a more comprehensive understanding of their work. While the comment identifies a relevant area for improvement, it lacks specific suggestions or guidance on how the authors might address these questions or apply the method to different domains. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not offer actionable steps for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the necessity of all the modules in the experimental results. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should reconsider the necessity of the modules, but it lacks concrete steps or suggestions on how to do so. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the necessity of all the modules in the experimental results, but it does not specify which part of the paper this concern pertains to. The authors cannot confidently determine which section or figure is being addressed, making the comment weakly grounded. However, the comment is specific in its concern about the necessity of the modules, providing some level of detail. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of all the modules in the experimental results. However, it does not provide any specific reasoning or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the necessity of all the modules in the experimental results, which is a valid point that could lead to a more focused and streamlined experimental design. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or which modules might be redundant. Without actionable advice or detailed feedback, the authors are left with a general concern but without clear direction on how to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not provide sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider a larger number of layers, such as 32 or 64, to explore how the network behaves with more layers. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments to address the issue of oversmoothing. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors consider a larger number of layers, such as 32 or 64, to explore how the network behaves with more layers. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the network architecture or experimental design, but the lack of explicit reference makes it weakly grounded. The comment is specific in suggesting the need for additional experiments with larger layers, but without detailed guidance on how to implement this suggestion, it remains somewhat specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors consider a larger number of layers, such as 32 or 64, to explore how the network behaves with more layers. However, the comment lacks specific reasoning or evidence to support why this is necessary or how it would address the issue of oversmoothing. Without detailed justification or examples, the claim remains vague and difficult for the authors to understand and act upon. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors consider a larger number of layers, such as 32 or 64, to explore how the network behaves with more layers. This is a valuable suggestion as it could help the authors understand the impact of additional layers on the network's performance. However, the comment lacks specific guidance on how to implement this suggestion or what specific aspects of the network behavior should be examined. While it identifies a potential area for improvement, it does not provide detailed instructions or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to perform significance tests to ensure the reliability of their experimental results. This is a clear and direct action that the authors can take to address the issue of the limited improvement of MT over ST. The comment provides a specific suggestion for improving the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the improvement of MT over ST, suggesting that the authors should perform significance tests to ensure the reliability of their experimental results. However, it does not specify which part of the paper discusses the improvement of MT over ST, making it weakly grounded. The comment is specific in its suggestion to perform significance tests, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvement of MT over ST is limited and suggests that the authors should perform significance tests to ensure the reliability of their experimental results. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides a general idea but lacks the necessary detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the limited improvement of MT over ST, and suggests that the authors should perform significance tests to ensure the reliability of their experimental results. This feedback is clear and actionable, as it provides a direct suggestion for improving the paper by addressing a potential weakness in the experimental design. However, the comment could be more helpful if it included specific guidance on how to perform these tests or what criteria to use for assessing reliability. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the model-agnostic claim made by the authors, pointing out that the proposed framework is evaluated only under different GCN architectures. The reviewer questions how it would perform on different GNN blocks, specifically mentioning GAT, GraphSAGE, GIN, Geniepath, and others that employ LSTM-like aggregation. This feedback implies that the authors should consider evaluating their framework on a broader range of models to substantiate its model-agnostic claim. While the comment implies that the authors should expand their evaluation, it does not explicitly instruct them to do so. Therefore, the action is implicit but somewhat actionable, as the authors can infer the need to expand their evaluation but may not know exactly how to do so.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 5\" and \"the node and graph classification models,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the evaluation of the proposed framework on different GNN blocks, particularly those that employ LSTM-like aggregation. This provides clear guidance on what the authors need to address to strengthen their claim of model agnosticity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim of model-agnosticism made by the authors, suggesting that the framework is only evaluated under different GCN architectures. The reviewer raises a valid concern by pointing out that the framework has not been tested on other GNN blocks, such as GAT, GraphSAGE, GIN, Geniepath, and others that employ LSTM-like aggregation. This feedback is somewhat verifiable as it logically challenges the claim but lacks specific examples or references to support the argument. The authors would need to address this concern by providing evidence or examples of how the framework performs on these alternative GNN blocks. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s claim of model-agnosticism, noting that the proposed framework is evaluated only on different GCN architectures. It raises a relevant question about how the framework would perform on different GNN blocks, specifically mentioning GAT, GraphSAGE, GIN, Geniepath, and others that employ LSTM-like aggregation. This feedback is valuable as it prompts the authors to consider a broader range of models to substantiate their claim of model-agnosticism. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what additional experiments could be conducted. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical area for improvement, but it lacks detailed guidance on execution.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the method's complexity and suggests that an error analysis should be included to address potential issues with individual components, such as GPT-4o. While the comment implies that the authors should consider conducting an error analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an error analysis to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the complexity of the method and suggests an error analysis to address potential issues with individual components, such as GPT-4o. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its request for an error analysis but lacks grounding in terms of identifying the exact section or part of the paper that needs this analysis. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the complexity of the method and suggests that an error analysis should be conducted to address potential issues with individual components, such as GPT-4o. However, the comment lacks specific examples or detailed reasoning to support why an error analysis is necessary or how it would address the concern. Without concrete evidence or references, the claim is difficult for the authors to understand and act upon. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the method's complexity and suggests that an error analysis should be conducted to address potential issues with individual components, such as GPT-4o. This feedback is somewhat helpful as it highlights a specific area for improvement and provides a direction for the authors to consider. However, the comment lacks depth and does not offer specific guidance on how to conduct the error analysis or what specific aspects to focus on. To be more helpful, the comment could provide examples of potential errors or suggest ways to evaluate the robustness of the method. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality of the reversible version due to its higher computational cost during training, which is acknowledged by the paper. It suggests that the authors should include perplexity/BLEU scores of a NF-Rev{GRU, LSTM} to verify the necessity of the gating mechanism. While the comment implies that the authors should include these scores, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors know they need to include these scores but may not be entirely sure how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the computational cost during training, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the practicality of the approach due to the higher computational cost. Additionally, it suggests including perplexity/BLEU scores to verify the necessity of the gating mechanism. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the practicality of the reversible version due to its higher computational cost during training, which is acknowledged by the paper. The comment suggests that the authors should include perplexity/BLEU scores to verify the necessity of the gating mechanism. While the claim about the practicality is based on a logical observation, it lacks specific examples or references to support the claim about the computational cost. The suggestion to include perplexity/BLEU scores is a logical request, but it does not provide detailed evidence or reasoning to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the practicality of the reversible version due to its higher computational cost during training, which is acknowledged by the paper. It suggests that the authors should include perplexity/BLEU scores to verify the necessity of the gating mechanism. This feedback is somewhat helpful as it points out a specific area for improvement and provides a suggestion for how to address it. However, the comment could be more helpful if it offered additional guidance on how to interpret or analyze these scores, or if it provided examples of how other studies have addressed similar concerns. Overall, the comment provides some insight but lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that an error analysis should be included to understand the limitations of SetCSE in certain scenarios. This provides a clear and direct action for the authors to take, indicating that they should include an error analysis in their draft. The comment is specific and provides a concrete suggestion on how to improve the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of an error analysis, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included, namely an error analysis to understand the limitations of SetCSE in certain scenarios. This provides clear guidance on what the authors need to address in their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that an error analysis should be included to understand the limitations of SetCSE in certain scenarios. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why an error analysis is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the inclusion of an error analysis to understand the limitations of SetCSE in certain scenarios. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\\'s comprehensiveness and depth. By addressing this point, the authors can significantly improve the understanding and applicability of their work. However, the comment could be more helpful if it offered additional guidance on how to conduct the error analysis or what specific scenarios should be considered. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about measuring tool-knowledge by prompting and suggests that it might not be sufficient. It proposes an alternative approach, such as unintentional fine-tuning or using other prompts to elicit the model\\'s ability to use a tool. While the comment implies that the authors should consider these alternatives, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about measuring tool-knowledge by prompting and suggests that it might not be sufficient. It proposes an alternative approach, such as unintentional fine-tuning or using other prompts to elicit the model\\'s ability to use a tool. However, the comment does not specify which part of the paper this concern is related to, making it weakly grounded. The suggestion is specific in terms of the alternative approach, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the effectiveness of measuring tool-knowledge by prompting, suggesting that it might not be sufficient. The reviewer proposes an alternative approach, such as unintentional fine-tuning or using other prompts to elicit the model\\'s ability to use a tool. However, the comment lacks specific examples or detailed reasoning to support the claim that prompting might not be sufficient. The suggestion is somewhat verifiable, as it provides a logical basis for the critique but requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the effectiveness of measuring tool-knowledge by prompting, suggesting that it might not be sufficient. It proposes an alternative approach, such as unintentional fine-tuning or using other prompts to elicit the model\\'s ability to use a tool. While the comment identifies a potential weakness in the methodology and offers a suggestion for improvement, it lacks specific guidance on how to implement the alternative approach or examples of how it might be effective. The feedback is somewhat helpful as it points out a potential issue and provides a direction for improvement, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a critique of the experimental results, suggesting that the improvement of HA3C over the baseline algorithms on MuJoCo control tasks is marginal. It also points out that the benefit of HA3C relies on the structure of the problem, specifically the causal relationship based on the current state. The reviewer suggests that the authors should find other tasks or even artificial tasks to demonstrate the effectiveness of HA3C. While the comment implies that the authors should explore alternative tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative tasks to demonstrate the effectiveness of HA3C. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental results and the specific improvement of HA3C over the baseline algorithms on MuJoCo control tasks. It also provides specific feedback by suggesting that the benefit of HA3C relies on the structure of the problem and that MuJoCo tasks may not be the best environment for HA3C. The comment further recommends finding other tasks or even artificial tasks to demonstrate the effectiveness of HA3C. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the improvement of HA3C over the baseline algorithms on MuJoCo control tasks is marginal, suggesting that this does not indicate ineffectiveness. The reviewer provides a logical reasoning by explaining that the benefit of HA3C relies on the structure of the problem, specifically the causal relationship based on the current state, which can be complex. The reviewer also suggests that MuJoCo tasks may not be the best environment for HA3C and recommends finding other tasks or even artificial tasks to demonstrate the effectiveness of HA3C. This reasoning is supported by the claim that the current results may not accurately reflect the capabilities of HA3C. However, the comment could be strengthened by providing specific examples or references to other tasks or artificial tasks that would better demonstrate HA3C\\'s effectiveness. Overall, the claim is mostly verifiable, as it provides a logical reasoning and a clear suggestion for improvement, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the experimental results, suggesting that the improvement of HA3C over the baseline algorithms on MuJoCo control tasks is marginal and may not accurately reflect the effectiveness of HA3C. It offers a logical explanation for this observation, noting that the benefit of HA3C relies on the structure of the problem, specifically the causal relationship based on the current state. The reviewer also suggests that MuJoCo tasks may not be the best environment for HA3C and recommends exploring other tasks or even artificial tasks to demonstrate the effectiveness of HA3C. This feedback is highly valuable as it not only identifies a potential limitation in the current experimental setup but also provides actionable advice for improving the paper. By suggesting alternative tasks, the authors can better demonstrate the capabilities of HA3C and strengthen their results. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should focus on the insights derived from the data to deepen the understanding of LLM capabilities, rather than solely reporting aggregate numbers. It implies that the authors should present key takeaways or insights that are generalizable and hold broader significance for the community. While the comment does not explicitly instruct the authors to include these insights, it provides a clear direction for improvement. The action is implicit but concrete, as it specifies what the authors need to include to enhance the paper. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"key contributions\" and \"insights derived from the data,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what the authors need to focus on: presenting key insights or takeaways from the experiments that are generalizable and hold broader significance for the community. This provides clear guidance on what the authors should address to improve their paper. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not fully address the insights derived from the data, specifically the key contributions, and suggests that the authors should focus on presenting key insights or takeaways that are generalizable and hold broader significance for the community. The comment provides a logical reasoning by pointing out the importance of addressing the insights derived from the data, which is a common expectation in research papers. However, it lacks specific examples or references to support the claim that the paper does not fully address this aspect. This makes the claim somewhat verifiable, as it provides a clear direction for improvement but lacks detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting that the novelty does not lie in the dataset itself but rather in the insights derived from the data. It suggests that the paper should focus on presenting these insights and takeaways, which are generalizable and hold broader significance for the community. While the comment highlights an important area for improvement, it does not provide specific suggestions or examples of what these insights might be. This limits the comment\\'s helpfulness, as it points out a critical need for improvement but lacks actionable guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the statement in Section 3.1 claiming that GANs are the de facto choice for vocoders is false and ignores other active and important works in the community. It provides a specific example of alternative vocoders, such as WaveNet, WaveRnn, and diffusion-based approaches. This feedback is clear and concrete, as it identifies the issue and suggests specific alternatives that the authors should consider. The action is explicit and leaves no ambiguity, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that GANs are the de facto choice for vocoders, pointing out that this statement ignores a large array of active and important works in the community. The comment provides a list of alternative vocoders, such as WaveNet, WaveRnn, and diffusion-based approaches, which are examples of specific works that should be considered. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that GANs are the de facto choice for vocoders, arguing that it ignores a large array of active and important works in the community. The reviewer provides specific examples of alternative vocoders, such as WaveNet, WaveRnn, and diffusion-based approaches, which are widely used and recognized in the field. This provides a clear and logical reasoning for why the claim is false and offers a more accurate representation of the state of the field. Therefore, the comment is fully verifiable, as it presents a well-supported argument with specific examples.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a false claim in Section 3.1 regarding the de facto choice of GANs for vocoders, which ignores a large array of active and important works in the community. It provides a specific critique by mentioning alternative vocoders, such as WaveNet, WaveRnn, and diffusion-based approaches, that are widely recognized and used in the field. This feedback is clear and actionable, as it directs the authors to revise their statement to accurately reflect the state of the field. By offering specific examples, the comment provides the authors with a concrete path to improve their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of explanation or empirical justification for certain design choices, specifically mentioning the choice of token similarity metric. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the design choices need further explanation or justification. The feedback is vague and lacks concrete steps for the authors to take, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the approach and its design choices, specifically mentioning the choice of token similarity metric. However, it does not specify which part of the paper discusses these design choices, making it weakly grounded. The comment is specific in identifying the issue of lack of explanation or empirical justification for the design choices, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the approach is straightforward and sensible but contains design choices that are not fully explained or empirically justified, specifically mentioning the choice of token similarity metric. However, the comment does not provide specific examples or detailed reasoning to support the claim about the lack of explanation or justification. This makes it difficult for the authors to understand the exact nature of the issue and how to address it. As a result, the claim is somewhat verifiable, as it highlights a potential problem but lacks the necessary evidence or detailed reasoning to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the approach, noting that while it is straightforward and sensible, it contains design choices that are not fully explained or empirically justified. It mentions the choice of token similarity metric as an example. This feedback is somewhat helpful as it points out a potential weakness in the paper, but it lacks specific guidance or suggestions on how the authors might address this issue. The comment highlights a critical area for improvement but does not provide actionable steps or detailed advice, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific inconsistencies in the notation, such as the absence of j on the right-hand side (RHS) of Equation (6) and the presence of T and W on the left-hand side (LHS) of Equation (4). While the comment points out these inconsistencies, it does not provide explicit guidance on how to address them. The authors are left to infer that they should correct these inconsistencies, but the comment lacks concrete details on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific equations, Equation (4) and Equation (6), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the inconsistencies in the notation, such as the absence of j on the right-hand side (RHS) of Equation (6) and the presence of T and W on the left-hand side (LHS) of Equation (4). This provides clear guidance on what needs to be addressed in these equations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements about inconsistencies in the notation, specifically mentioning Equation (4) and Equation (6). It does not contain any subjective opinions, judgments, or suggestions that require verification. The claims are purely factual, making the classification \"No\" appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific inconsistencies in the notation, particularly in Equation (4) and Equation (6). By pointing out these inconsistencies, the comment provides the authors with clear and actionable feedback on areas that need correction. However, the comment could be more helpful if it offered suggestions on how to address these inconsistencies or provided examples of how to correct them. Despite this, the feedback is still valuable as it directs the authors\\' attention to specific areas needing improvement, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the evaluation of the proposed approach. It points out that the number of models constructed during evaluations is insufficient, and that there is a lack of evaluation regarding the distortion of the image after warping. Additionally, it notes the absence of a discussion on potential countermeasures against the proposed approach. While the comment highlights specific areas that need improvement, it does not provide explicit guidance on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors can infer that they need to expand their evaluation and include a discussion on countermeasures, but the comment does not offer detailed instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"evaluation\" and \"less than 20 models constructed during the evaluations,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing in the evaluation, such as the lack of evaluation regarding the distortion of the image after warping and the absence of a discussion on potential countermeasures against the proposed approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation is insufficient, as it involves constructing less than 20 models during the evaluations, which is not enough to demonstrate the effectiveness of the approach. The comment also notes the lack of evaluation regarding the distortion of the image after warping and the absence of a discussion on potential countermeasures against the proposed approach. While the comment identifies specific areas for improvement, it lacks detailed justification or examples to fully substantiate the claim. The authors would need to infer the need for more comprehensive evaluation and discussion, making the comment somewhat verifiable. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several critical areas for improvement in the evaluation section of the paper. It points out that the number of models constructed during evaluations is insufficient to demonstrate the effectiveness of the approach, and it highlights the lack of evaluation regarding the distortion of the image after warping. Additionally, it notes the absence of a discussion on potential countermeasures against the proposed approach. While the comment provides clear and actionable feedback on areas that need attention, it could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how other studies have addressed similar concerns. Overall, the comment is mostly helpful as it directs the authors\\' attention to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the categorization of discourse particles or discourse + imported vocab in Table A3, suggesting that if the latter, they should be placed in separate tables. It also suggests that glosses would be helpful. While the comment implies that the authors should consider separating these categories, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should separate the categories and provide glosses. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table A3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the categorization of discourse particles or discourse + imported vocab, suggesting that if the latter, they should be placed in separate tables and that glosses would be helpful. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the categorization of discourse particles or discourse + imported vocab in Table A3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the categorization of discourse particles or discourse + imported vocab in Table A3, suggesting that if the latter, they should be placed in separate tables. It also suggests that glosses would be helpful. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of the data in the table. However, it could be more helpful if it offered additional guidance on how to implement these changes or provided examples of how glosses might be used effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about the idea behind formula (4) and questions the need for the maximum over all possible pieces for unoccupied squares. However, it does not provide any explicit or implicit suggestions for how the authors might clarify or address this issue. The comment lacks actionable guidance, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"formula (4),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the rationale behind the maximum over all possible pieces for unoccupied squares. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the rationale behind formula (4) and specifically inquires about the need for the maximum over all possible pieces for unoccupied squares. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about the idea behind formula (4) and questions the need for the maximum over all possible pieces for unoccupied squares. While it identifies a potential area of confusion, it lacks specificity and does not provide any actionable guidance or suggestions for improvement. The comment does not offer insight into how the authors might clarify or address this issue, leaving them without a clear path forward. Therefore, the feedback is not helpful as it does not provide meaningful direction for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the experiments lack a comparison to state-of-the-art subset selection methods, which is a clear and direct action for the authors to take. This feedback provides a specific area for improvement, indicating that the authors should include such comparisons in their experiments. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be done to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the experiments, namely the lack of comparison to state-of-the-art subset selection methods. However, it does not specify which part of the paper this issue pertains to, such as which experiments or sections are missing the comparison. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what is missing, but without explicit references or clear guidance, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments lack a comparison to state-of-the-art subset selection methods. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of comparison to state-of-the-art subset selection methods. This feedback is clear and actionable, as it directs the authors to include such comparisons in their experiments. By addressing this gap, the authors can enhance the rigor and relevance of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the paper is vague and suggests that the primary components should be more concise. It mentions specific elements that have been integrated from previous works, such as SCL, Aligned, and CLNN. However, the comment does not provide explicit guidance on how to improve the clarity or concision of the novelty statement. It lacks concrete suggestions on how to enhance the novelty or what specific aspects need to be clarified. As a result, the authors are left without clear direction on how to address this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the paper, suggesting that it is somewhat vague and needs to be more concise. It mentions specific components that integrate effective elements from previous works, such as SCL, Aligned, and CLNN. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The suggestion to clarify the novelty is specific, but without explicit references to sections or elements, the authors may struggle to identify the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the paper is vague and suggests that the primary components integrate effective elements from previous works, such as SCL, Aligned, and CLNN. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or detailed explanations of how these elements are integrated or how they contribute to the novelty of the paper. This lack of supporting evidence makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique and potentially conduct further research to understand the critique fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the paper, suggesting that it is somewhat vague and needs to be more concise. It mentions specific components that integrate effective elements from previous works, such as SCL, Aligned, and CLNN, among others. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the clarity or concision of the novelty statement. While it points out a potential weakness, it does not offer actionable feedback or detailed advice for the authors to address this issue. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not provide comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. This feedback implies that the authors should include such benchmarks in their paper to make the user simulator more usable and accessible to the community. While the action is implicit, it is concrete because it specifies a specific improvement that the authors should make. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests using evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where these benchmarks could be included. The authors can infer that it relates to the evaluation or results section, but this inference is not direct. The comment is specific in suggesting the inclusion of evaluation benchmarks, but it lacks full grounding as it does not explicitly mention a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should use evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is important or how it would benefit the community. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should use evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, specifically the use of benchmarks to evaluate the performance of smaller models. However, the comment lacks specific guidance on how to implement this suggestion or what specific benchmarks should be used. While it points out a potential enhancement, it does not provide detailed instructions or examples, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the impact of open-set detectors on the performance of the proposed method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of the impact should be explored. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the impact of open-set detectors on the performance of the proposed method. However, it does not specify which part of the paper this question pertains to, such as a particular section, figure, or table. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the impact should be explored or how it could be addressed. As a result, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the impact of open-set detectors on the performance of the proposed method. However, it does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the impact of open-set detectors on the performance of the proposed method. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this question or what aspects of the impact should be explored. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific issues: a missing explanation of the symbol \"(*)\" in Table 1 and a potential inconsistency in Table 5 regarding the setting \"from-scratch.\" The reviewer asks for clarification on the meaning of \"from-scratch\" and whether it implies random initialization or pre-training on a text corpus. While the comment identifies specific areas that need clarification or correction, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify the explanation of the symbol and the setting in Table 5. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the missing explanation of the symbol \"(*)\" in Table 1 and the potential inconsistency in Table 5 regarding the setting \"from-scratch.\" The comment provides detailed guidance on what needs to be clarified or corrected, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two claims: (1) the absence of an explanation for the symbol \"(*)\" in Table 1 and (2) a potential inconsistency in Table 5 regarding the setting \"from-scratch.\" The first claim is somewhat verifiable as it points out a specific issue that requires clarification, but it lacks detailed explanation or examples of what the symbol \"(*)\" might represent. The second claim is more verifiable as it references a specific table and provides a clear question about the meaning of \"from-scratch\" and whether it implies random initialization or pre-training. However, the comment could be strengthened by providing more context or examples to fully support the claims. Overall, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues in the paper, namely the absence of an explanation for the symbol \"(*)\" in Table 1 and a potential inconsistency in Table 5 regarding the setting \"from-scratch.\" It provides clear and actionable feedback by asking the authors to clarify the meaning of the symbol and the setting, which are crucial for understanding the paper\\'s methodology and results. By addressing these issues, the authors can improve the clarity and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context or examples to guide the authors. Overall, the comment is mostly helpful, as it effectively directs the authors\\' attention to important areas for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the results presented in Table 1, suggesting that the observed increase in transferability with higher noise intensity might not be as expected. It raises a concern about the potential activation of different neurons to reduce confidence in source samples, which could lead to increased misclassification. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their results. The authors are left to infer that they should provide additional analysis or explanation to support their findings. As a result, the comment is somewhat actionable, as it identifies a potential issue but lacks concrete details on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the results presented in Table 1, suggesting that the observed increase in transferability with higher noise intensity might not be as expected. The comment further speculates on the potential activation of different neurons and its impact on misclassification, providing a clear rationale for the concern. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the results presented in Table 1, suggesting that the observed increase in transferability with higher noise intensity might not be as expected. The reviewer raises a concern about the potential activation of different neurons to reduce confidence in source samples, which could lead to increased misclassification. However, the comment lacks specific evidence or references to support this claim, making it somewhat verifiable. The authors would need to provide additional analysis or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the results presented in Table 1, suggesting that the observed increase in transferability with higher noise intensity might not be as expected. It raises a concern about the potential activation of different neurons to reduce confidence in source samples, which could lead to increased misclassification. While the comment identifies a potential weakness in the results, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback is somewhat helpful as it prompts the authors to reconsider their findings, but it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests adding ablation studies with importance weighting or rejection to understand their effects better. It also points out that the fonts in the figures are too small to read and highlights an issue with the ChopperCommand results in Figure 6(a). However, the comment does not provide explicit instructions on how to conduct these studies or address the issues with the figures. While it suggests improvements, the lack of concrete guidance makes it somewhat actionable. The authors can infer that they need to conduct ablation studies and address the font size issue, but the comment lacks detailed guidance on how to implement these changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 6 (a)\" and \"ChopperCommand results,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests adding ablation studies with importance weighting or rejection to understand their effects better and points out issues with the font size in the figures. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that adding ablation studies with importance weighting or rejection would help understand their effects better. However, it does not provide any evidence or reasoning to support why these studies are necessary or how they would improve the understanding of the effects. The comment also mentions issues with the font size in the figures and the ChopperCommand results in Figure 6(a), but it does not provide specific examples or detailed explanations to substantiate these claims. As a result, the comment lacks sufficient justification and is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides several pieces of feedback that can help the authors improve their draft. It suggests adding ablation studies with importance weighting or rejection to better understand the effects of the proposed method. This is a clear and actionable suggestion that can enhance the paper\\'s comprehensiveness and depth. Additionally, the comment points out issues with the font size in the figures, which can be improved for readability. However, the comment could be more helpful if it provided specific guidance on how to conduct these ablation studies or addressed the issues with the ChopperCommand results in Figure 6(a). Overall, the comment is mostly helpful as it offers valuable suggestions for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific issues with the technical clarity of the paper: the lack of explanation of the main learning framework, Equantion (18), and the need for clarification on how to implement the balancing term and penalty term. While the comment explicitly states these areas of concern, it does not provide explicit instructions or concrete guidance on how to address them. The authors are left with a general understanding of what needs to be clarified but without specific steps on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the main learning framework, Equantion (18), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with technical clarity, particularly the lack of explanation of the balancing term and penalty term. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical clarity is weak, specifically mentioning the lack of explanation for the main learning framework, Equantion (18). It also questions how to implement the balancing term and penalty term. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the technical clarity of the paper, specifically mentioning the lack of explanation for the main learning framework, Equantion (18). It also questions how to implement the balancing term and penalty term, which are crucial components of the technical framework. This feedback is clear and actionable, as it highlights specific areas where the authors need to provide more detailed explanations and guidance. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar frameworks have been explained in the literature. Overall, the comment is mostly helpful as it directs the authors to critical areas needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the decision boundary generation process, specifically noting that the projection results and Voronoi tessellations appear to be fixed across multiple rounds. It suggests that the authors clarify how these fixed tessellations capture the model's behavior and question the use of 2D projections to represent high-dimensional decision boundaries. While the comment implies that the authors should address these concerns by clarifying the decision boundary generation process, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their methodology. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the figures, the projection results, and the Voronoi tesselation results,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issue by pointing out that the fixed tessellations with updated predictions may not accurately capture the model's behavior and questions the use of 2D projections to represent high-dimensional decision boundaries. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the decision boundary generation process, specifically questioning the fixed tessellations and the use of 2D projections to represent high-dimensional decision boundaries. The comment provides a logical reasoning by pointing out that the projection results and decision boundaries should be updated as feature vectors update during training. It also highlights the potential issue with using 2D projections, which could lead to significant variations in results based on the chosen projection method and parameters. This provides a clear and well-supported claim, as it identifies specific areas of concern and offers a rationale for why these issues need to be addressed. Therefore, the comment is fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a critical issue with the decision boundary generation process, specifically noting that the projection results and Voronoi tessellations appear to be fixed across multiple rounds. It highlights the need to clarify how these fixed tessellations capture the model's behavior, especially considering that feature vectors update during training. Additionally, the comment questions the use of 2D projections to represent high-dimensional decision boundaries, noting that results can vary significantly based on the chosen projection method and parameters. This feedback is clear and actionable, providing the authors with specific areas to address in their draft to improve the accuracy and robustness of their results. By addressing these concerns, the authors can enhance the credibility and reliability of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of an ablation study and a comparison to methods in the past decade. While it identifies specific areas that could be improved, it does not provide explicit guidance on how to conduct these studies or what specific aspects to include in the comparison. The authors are left with a general understanding of what is missing but without concrete steps to address it. The action is implicit and somewhat vague, as it lacks detailed instructions on how to implement the suggested improvements. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the absence of an ablation study and a comparison to methods in the past decade. However, it does not specify which part of the paper these omissions are found in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, while the comment identifies specific areas for improvement, it lacks specificity in detailing what aspects of the ablation study or comparison should be included. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that there is no ablation study and no comparison to methods in the past decade. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific areas where the paper could be improved: the absence of an ablation study and a comparison to methods in the past decade. While it highlights these gaps, it does not provide any detailed guidance or suggestions on how to address them. The comment points out the need for additional analysis, but it lacks actionable advice or specific recommendations for improvement. This limits the comment\\'s usefulness to the authors, as it does not offer a clear path forward for enhancing their draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include more theoretical results on more complicated models, specifically mentioning SVC. While the comment implies that the authors should expand their theoretical results, it does not provide specific guidance on how to achieve this or which models should be included. The action is implicit and somewhat vague, as the authors need to infer that they should expand their theoretical results but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include more theoretical results on more complicated models, specifically mentioning SVC. However, it does not specify which part of the paper this suggestion pertains to, such as sections or figures where these results could be included. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to include more theoretical results, but without explicit grounding, it is difficult for the authors to pinpoint the exact areas that need improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include more theoretical results on more complicated models, specifically mentioning SVC. However, the comment does not provide any reasoning, examples, or references to support why this is necessary or how it would enhance the paper. Without additional context or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should include more theoretical results on more complicated models, specifically mentioning SVC. This feedback is somewhat helpful as it identifies a potential area for expansion and improvement in the theoretical aspects of the paper. However, the comment lacks specific guidance or suggestions on how to incorporate these additional results or which models should be considered. While it points out a potential gap, it does not provide actionable steps for the authors to address this issue. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more ablation studies should be provided, particularly to demonstrate the necessity of the proposed DA Inversion. It also points out that the existing results in Figure 11 are insufficient to demonstrate the necessity. While the comment implies that additional studies are needed, it does not explicitly instruct the authors to conduct these studies or specify which aspects should be addressed. The action is implicit and somewhat vague, as the authors can infer that more studies are needed but may not know exactly what kind of studies or how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more ablation studies should be provided, particularly to demonstrate the necessity of the proposed DA Inversion. It references Figure 11, which provides some existing results, but the reviewer believes these results are insufficient to demonstrate the necessity. However, the comment does not specify which parts of the paper should include these additional studies or how they should be structured. While the authors can infer that the results in Figure 11 are being questioned, the comment lacks specific guidance on what additional studies should be conducted or how they should be presented. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, and it is not specific in terms of what needs to be addressed. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that more ablation studies are needed to demonstrate the necessity of the proposed DA Inversion, particularly in light of the existing results in Figure 11. However, the comment does not provide specific examples or detailed reasoning to support why the existing results are insufficient or how additional studies would address this concern. Without specific examples or references, the claim lacks sufficient justification, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that more ablation studies should be provided, particularly to demonstrate the necessity of the proposed DA Inversion. It references Figure 11, which provides existing results, but notes that these results are insufficient to demonstrate the necessity. This feedback is clear and actionable, as it highlights a gap in the paper that the authors can address by conducting additional studies or providing more detailed analyses. However, the comment could be more helpful if it provided specific suggestions on what types of ablation studies would be most beneficial or how to structure them. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a clear rationale for why it is necessary.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should present a clear ablation on the clustering in the second phase of training, specifically questioning its necessity when a linear regressor is learned on top of the discovered keypoints for evaluation. This feedback provides a direct and concrete action for the authors to take, which is to conduct an ablation study to clarify the role of clustering in their method. The comment also specifies the section (3.3) where this analysis should be presented, making it clear and actionable for the authors to implement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the clustering in the second phase of training and the necessity of this step when a linear regressor is learned on top of the discovered keypoints for evaluation. This provides clear guidance on what the authors need to address in order to improve their paper. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of clustering in the second phase of training, suggesting that it may not be required if a linear regressor is learned on top of the discovered keypoints for evaluation. The comment provides a logical reasoning by pointing out that learning a linear regressor does not necessarily require clustering. However, it lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further explore the rationale behind the claim to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the necessity of clustering in the second phase of training, particularly when a linear regressor is learned on top of the discovered keypoints for evaluation. It suggests that a clear ablation on this aspect should be presented, which would help clarify the role of clustering in the method. This feedback is actionable and provides a clear direction for the authors to improve their draft by conducting an ablation study or further explaining the rationale behind the clustering step. However, the comment could be more helpful if it included specific suggestions on how to conduct the ablation or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification and provides a concrete action for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the figures, specifically Fig2a, where the forgetting curve appears less drastic compared to class incremental. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to the figures. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to a specific figure, \"Fig2a,\" allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspect of the figure is problematic or how it relates to the issue of forgetting. The comment lacks specificity in detailing the issue or suggesting improvements, making it weakly grounded but specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the forgetting curve in Fig2a is less drastic than in class incremental, suggesting that the results may be misleading. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the forgetting curve in a specific figure, Fig2a, suggesting that it may not be as drastic as in class incremental. This observation could be a significant concern for the authors, as it may indicate a discrepancy in the results or a limitation in the methodology. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should highlight the data-dependent nature of their approximation results, specifically mentioning that it is data dependent on the covariance spectrum. While the comment implies that the authors should include this information in the abstract, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in the abstract. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should highlight the data-dependent nature of their approximation results, specifically mentioning that it is data dependent on the covariance spectrum. However, it does not specify which part of the paper this suggestion pertains to, such as the abstract or a particular section. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting the need to highlight the data-dependent nature, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should highlight the data-dependent nature of their approximation results, specifically mentioning that it is data dependent on the covariance spectrum. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is important or how it affects the results. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should highlight the data-dependent nature of their approximation results, specifically mentioning that it is data dependent on the covariance spectrum. This feedback is somewhat helpful as it identifies a potential area for improvement by emphasizing the importance of transparency regarding the dependence on data. However, the comment lacks specific guidance on how to highlight this aspect or what specific changes should be made to the abstract or results sections. While it points out a potential weakness, it does not provide detailed suggestions for addressing it, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of RMSD in Figure 3, specifically asking whether it refers to the RMSD between a docking pose and the ground truth from PDB or between docking poses obtained with different methods to quantify consensus. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the meaning of RMSD. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified regarding the meaning of RMSD, namely whether it refers to the RMSD between a docking pose and the ground truth from PDB or between docking poses obtained with different methods to quantify consensus. This provides clear guidance on what the authors need to address in order to improve the clarity of their paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification regarding the meaning of RMSD in Figure 3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of RMSD in Figure 3, specifically asking whether it refers to the RMSD between a docking pose and the ground truth from PDB or between docking poses obtained with different methods to quantify consensus. This feedback is somewhat helpful as it identifies a potential area of confusion in the paper that could be clarified for readers. However, the comment lacks depth and does not provide specific suggestions or guidance on how to clarify the meaning of RMSD. While it points out a potential issue, it does not offer actionable advice or detailed guidance, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It explicitly asks the authors to address the question of whether there could be a smooth regret scaling without phase transitions while still maintaining the proven bounds. This feedback is explicit and provides a clear direction for the authors to improve their draft by elaborating on the necessity of phase transitions. The action is concrete, as it specifies exactly what needs to be addressed, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"actual regret scaling\" compared to the asymptotic bounds, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a more thorough treatment of the necessity of phase transitions in the actual regret scaling. The comment provides a clear direction for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the necessity of phase transitions in the \"actual regret scaling\" compared to asymptotic bounds. It suggests that the authors should provide a more thorough treatment of this topic, implying that the current treatment is insufficient. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of supporting evidence or examples makes it difficult for the authors to understand the basis of the suggestion and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides a direction for improvement but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper regarding the necessity of phase transitions in the \"actual regret scaling\" compared to asymptotic bounds. It suggests that the authors should provide a more thorough treatment of this topic, which could involve answering the question of whether a smooth regret scaling without phase transitions could still maintain the proven bounds. This feedback is clear and actionable, as it directs the authors to expand their analysis to address a critical aspect of their work. However, the comment could be more helpful if it provided specific suggestions or examples of how to approach this treatment. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of comparisons to previous robust RL methods, specifically mentioning RARL, despite these methods being cited. It suggests that if GAD or EG already include these prior works, the authors should be explicit about it. While the comment implies that the authors should include these comparisons or explicitly mention the inclusion of prior works, it does not provide explicit instructions on how to do so. The action is clear but somewhat vague, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"RARL\" and \"GAD\" or \"EG,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the comparison to previous robust RL methods, and suggests that if these methods are included, the authors should be explicit about it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that comparisons to previous robust RL methods, specifically mentioned as RARL, are missing despite being cited. The comment suggests that if GAD or EG already include these prior works, the authors should be explicit about it. However, the comment lacks specific examples or references to support the claim that these comparisons are missing or necessary. Without additional context or evidence, the claim is difficult for the authors to verify and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper regarding the absence of comparisons to previous robust RL methods, specifically mentioning RARL. It suggests that if GAD or EG already include these prior works, the authors should be explicit about it. This feedback is somewhat helpful as it points out a potential area for improvement and provides a clear direction for the authors to address. However, the comment could be more helpful if it offered specific suggestions on how to incorporate these comparisons or how to present them effectively. Overall, the comment provides a valuable insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more details about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. While the comment explicitly states what needs to be added, it does not provide specific guidance on how to present these details or what information should be included. The action is clear but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more details are needed about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. However, it does not specify which part of the paper these details are missing in, nor does it provide examples or detailed guidance on what information should be included. This makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific about what needs to be addressed but lacks grounding, as it does not specify where in the paper these details are currently lacking. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details are needed about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. However, it does not provide any specific reasoning, examples, or references to support why these details are necessary or how they would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper lacks details about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. While it identifies specific areas that need more information, it does not provide detailed guidance or examples on what kind of information would be beneficial or how to present it effectively. The comment highlights a potential gap in the paper\\'s explanation, but without actionable suggestions or examples, it offers limited assistance to the authors in improving their draft. Therefore, the comment is somewhat helpful, as it points out a need for more detail but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relationship between HIS and the negative inverse of mean response time. While it identifies an area of confusion, it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks actionable advice or suggestions for improvement, leaving the authors uncertain about how to respond to the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the relationship between HIS and the negative inverse of mean response time, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine the exact part being addressed. Additionally, the comment lacks specificity as it does not provide details on what aspect of the relationship is unclear or how it should be clarified. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification regarding the relationship between HIS and the negative inverse of mean response time. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the relationship between HIS and the negative inverse of mean response time, which could be a significant point of confusion for readers. However, it does not provide any guidance or suggestions on how the authors might address this issue or clarify their explanation. Without actionable feedback or context, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it identifies a potential area for clarification but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the choice of sparse representation learning method and the omission of FTA as a baseline in the experiments. It suggests that a rigorous comparison is necessary, particularly in the context of a supervised learning setting. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should provide a rationale for their method choice and include FTA as a baseline in their experiments. The feedback is somewhat actionable as it highlights specific areas that need attention, but it lacks detailed guidance on how to implement these changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"particular sparse representation learning method\" and \"experiments part,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issues by questioning the choice of sparse representation learning method and suggesting that FTA should be compared as a baseline. The comment is specific in detailing what needs to be addressed, such as the rationale for the method choice and the omission of FTA in a RL setting. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the choice of sparse representation learning method and the omission of FTA as a baseline in the experiments. It suggests that a rigorous comparison is necessary, particularly in the context of a supervised learning setting. The comment provides a logical reasoning for why a comparison is necessary and highlights specific areas that need attention. However, it lacks specific examples or references to support the claim that a rigorous comparison is necessary. This makes the comment somewhat verifiable, as it provides a clear rationale but requires further elaboration to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas for improvement by questioning the choice of sparse representation learning method and suggesting that FTA should be included as a baseline in the experiments. It highlights the need for a rigorous comparison, particularly in the context of a supervised learning setting. While the comment provides valuable insights into potential weaknesses and areas for improvement, it could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how other studies have conducted rigorous comparisons. Overall, the comment is mostly helpful as it directs the authors\\' attention to important aspects of their work that need further exploration and clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue on page 4, line 154, where the authors describe a particular choice of shift and scaling and claim it as \"more appropriate,\" but do not explain why. The reviewer implies that the authors should provide a rationale or explanation for this choice to make the paper more comprehensible. However, the comment does not explicitly instruct the authors to include this explanation, leaving it somewhat vague. While the action is implied, the authors can infer that they need to provide a rationale, but the lack of concrete guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p.4, l.154,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the description of a choice of shift and scaling, noting that the authors claim it is more appropriate but do not explain why. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors make a particular choice of shift and scaling but do not explain why. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper where the authors claim a particular choice of shift and scaling as \"more appropriate\" but do not provide an explanation for this choice. This feedback highlights a gap in the paper\\'s justification, which could lead to confusion or misunderstanding by readers. However, the comment does not offer suggestions or guidance on how the authors might address this issue or provide a rationale for their choice. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the use of \"partial inference of GFlowNets\" in the title and \"partial inference\" elsewhere should be revised. This provides a clear and direct action for the authors to take, indicating that they should revise the title and potentially other parts of the paper to clarify the terminology. The comment is specific and provides concrete guidance on what changes need to be made, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the use of \"partial inference of GFlowNets\" in the title and \"partial inference\" elsewhere. However, it does not specify which sections of the paper these issues are mentioned in, making it weakly grounded. The comment is specific in suggesting that the terminology should be revised, but without explicit references to the title or sections, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests revising the use of \"partial inference of GFlowNets\" in the title and \"partial inference\" elsewhere. However, it does not provide any reasoning, examples, or references to support why this change is necessary or how it would improve the clarity or accuracy of the paper. Without additional context or justification, the claim remains unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of terminology in the paper, particularly the use of \"partial inference of GFlowNets\" in the title and \"partial inference\" elsewhere. It suggests that this terminology should be revised, which is a clear and actionable piece of feedback. However, the comment lacks depth and does not provide further explanation or suggestions on how to revise the terminology or why it is problematic. While it points out a potential issue, it could be more helpful if it included additional guidance or examples to help the authors improve their draft. Therefore, the comment is somewhat helpful, as it provides a clear direction but lacks comprehensive support.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper only measures BERTscore to illustrate the similarity of the newly generated text, but it suggests that there are other matrices that could measure the stealthiness of the generated content. However, it does not provide explicit guidance on which matrices should be used or how to incorporate them into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should consider additional metrics and provide more detailed explanations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, namely that it only measures BERTscore to illustrate the similarity of the newly generated text. However, it suggests that there are other matrices that could measure the stealthiness of the generated content, which are not discussed in the paper. While the comment identifies a specific area of concern, it does not explicitly mention which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in suggesting the inclusion of additional metrics, but without explicit references to sections, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper only measures BERTscore to illustrate the similarity of the newly generated text, which is a subjective critique. However, the comment does not provide any supporting evidence, reasoning, or references to justify why other matrices should be used to measure the stealthiness of the generated content. Without specific examples or detailed explanations, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it only measures BERTscore to illustrate the similarity of the newly generated text. However, it suggests that there are other matrices that could measure the stealthiness of the generated content, which are not discussed in the paper. This feedback is somewhat helpful as it points out a potential gap in the paper\\'s analysis and suggests an area for further exploration. However, the comment lacks specific suggestions or guidance on which matrices to consider or how to incorporate them into the paper. To be more helpful, the comment could provide examples of alternative matrices or offer suggestions on how to integrate these into the analysis. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the need to clearly highlight the issues with existing estimators, the lack of basic notation definition, and the need for clarity about the heuristic nature of the algorithm. However, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they need to clarify the issues and provide more details, but without specific guidance on what aspects need clarification or how to improve the clarity. As a result, the comment is somewhat actionable, as it highlights areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several issues with the paper, including the need to clearly highlight the issues with existing estimators, the lack of basic notation definition, and the need for clarity about the heuristic nature of the algorithm. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need to clarify the issues with existing estimators and the heuristic nature of the algorithm. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several issues with the paper, including the need to clearly highlight the issues with existing estimators, the lack of basic notation definition, and the need for clarity about the heuristic nature of the algorithm. The reviewer provides some reasoning by mentioning specific aspects that need clarification, such as the dimensionality \"p\" and the unit ball \"S p,\" the outer product \"v) \\u00f4 2,\" and the constant \"d 2.\" However, the comment lacks specific references or detailed explanations to fully substantiate the claims, making it somewhat verifiable. The authors would need to infer and investigate the issues themselves, which could be challenging without more detailed guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the need to clearly highlight the issues with existing estimators and the lack of basic notation definition. It also points out that the clarity about the heuristic nature of the algorithm is unclear. While the comment provides some insight into areas that need improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are left to infer that they need to clarify and provide more details, but without detailed instructions or examples, the feedback is somewhat helpful. It highlights areas for improvement but does not fully support the authors in making those improvements. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims novelty in the perceptual loss functions for PSR, but does not specify which parts are new. It suggests that the authors might elaborate on this aspect to provide more clarity. While the comment implies that the authors should clarify the novelty of the perceptual loss functions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the novelty of the perceptual loss functions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors claim that \"three perceptual loss functions for PSR, two of which are new,\" providing the authors with clear guidance on where to focus their attention. It is also specific because it points out that the neural network and loss functions used are not entirely novel in the field of medical imaging, and it suggests that the authors should elaborate on which parts of the loss functions are new. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the novelty of the perceptual loss functions for PSR, suggesting that they are not entirely novel in the field of medical imaging. The comment provides a logical reasoning by pointing out that the neural network and loss functions used are not unheard of, which implies that the novelty of the perceptual loss functions might be overstated. However, the comment lacks specific examples or references to support the claim that these functions are not novel. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim of novelty regarding the perceptual loss functions for PSR. It points out that the neural network and loss functions used are not entirely novel in the field of medical imaging, which could undermine the paper\\'s contribution. The comment suggests that the authors might elaborate on which parts of the loss functions are new, providing a clear and actionable suggestion for improvement. This feedback is valuable as it directs the authors to clarify an important aspect of their work, ensuring that their claims are substantiated and accurate. However, the comment could be more helpful if it offered specific examples or guidance on how to elaborate on the novelty of the perceptual loss functions. Overall, the comment is mostly helpful as it effectively guides the authors toward a more robust and accurate presentation of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two issues with the experimental results: (1) the lack of significant improvement in real-life datasets and (2) the inadequacy of the comparison on the ZINC dataset, specifically mentioning Table 5 in [1]. However, it does not provide explicit guidance on how the authors should address these issues or what specific improvements should be made. The feedback lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental results, specifically mentioning the lack of significant improvement in real-life datasets and the inadequacy of the comparison on the ZINC dataset, referencing Table 5 in [1]. This provides full grounding as it clearly identifies the part of the paper being addressed, allowing the authors to accurately pinpoint the sections that need attention. The comment is also specific in detailing what needs to be addressed, such as the need for significant improvement and the inadequacy of the comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results, as in many GNN papers, do not exhibit significant improvement in real-life datasets. It also criticizes the comparison on the ZINC dataset, specifically mentioning Table 5 in [1]. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or references makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experimental results, noting that they do not exhibit significant improvement in real-life datasets. It also critiques the comparison on the ZINC dataset, specifically mentioning Table 5 in [1]. This feedback is valuable as it highlights a key area for improvement in the paper, which is the lack of practical significance in the experimental results. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these issues. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks detailed guidance on how to achieve it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential convincingness of the SLM's performance compared to larger models due to the limited availability of data. However, it also provides examples from various experiments, such as Figure 3 (b) and BSM models, where larger models perform better than smaller ones. While the comment highlights a potential issue, it does not explicitly instruct the authors to address this concern or suggest specific actions to improve the draft. The feedback is implicit and lacks concrete guidance, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the performance of the SLM compared to larger models, specifically mentioning Figure 3 (b) and BSM models. This provides some grounding by referencing specific parts of the paper, such as Figure 3 and BSM models. However, the comment does not specify what aspect of the SLM's performance is problematic or how it could be improved, leaving the authors to infer the issue. The lack of specificity regarding the exact problem or suggestion for improvement makes the comment weakly grounded but specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the SLM may be convincing if it performs better than larger models due to limited data availability. However, the comment supports this claim by referencing specific experiments, such as Figure 3 (b) and BSM models, where larger models perform better than smaller ones. This provides a logical reasoning and specific examples to support the claim, making it mostly verifiable. The authors can understand the basis of the claim and the need for further investigation. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the potential convincingness of the SLM's performance compared to larger models due to the limited availability of data. However, it also provides examples from various experiments, such as Figure 3 (b) and BSM models, where larger models perform better than smaller ones. This feedback is somewhat helpful as it identifies a potential weakness in the paper's argument but lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their draft. The comment provides some insight but does not fully support the authors in improving their work, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out inconsistencies in the notation, specifically mentioning that the notation in Figures 2 and 3 does not match the notation in Algorithm 1 and changes again on Page 4 and Figure 4. While the comment identifies a specific issue with notation consistency, it does not provide explicit guidance on how to address this inconsistency. The authors are left to infer that they need to review and standardize the notation, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figures 2 & 3\" and \"Alg 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of inconsistent notation, particularly with \"nu,\" which is a clear and specific point. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation is inconsistent, particularly with \"nu,\" and provides examples by referencing Figures 2 and 3 and Algorithm 1. However, the comment lacks specific examples or detailed reasoning to support the claim of inconsistency, making it difficult for the authors to understand the exact issue and address it. The lack of detailed evidence or references makes the claim somewhat verifiable, as the authors would need to infer the issue and potentially conduct additional research to fully understand and resolve it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation used in the paper, particularly regarding the inconsistency between Figures 2 and 3 and Algorithm 1. It points out that the notation changes again on Page 4 and Figure 4, which is a clear and actionable observation. However, the comment could be more helpful if it provided suggestions on how to standardize the notation or address the inconsistencies. While it highlights an important area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more experiments should be conducted in challenging tasks, specifically mentioning dexterous manipulations in Adroit. While it implies that the authors should conduct additional experiments, it does not provide specific guidance on which tasks or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more experiments in challenging tasks, but the comment lacks concrete details on what those tasks should be or how to implement them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments in challenging tasks, specifically mentioning dexterous manipulations in Adroit. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental evaluation, but the lack of explicit reference makes it weakly grounded. The comment is specific in suggesting the need for more experiments in challenging tasks, but without detailed guidance on which tasks or how to implement them, it remains under-specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experiments should be conducted in challenging tasks, specifically mentioning dexterous manipulations in Adroit. However, the comment lacks specific examples or detailed reasoning to support why these tasks are considered challenging or how conducting experiments in them would validate the proposed method. Without additional context or evidence, the claim is difficult for the authors to understand and address effectively. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient justification or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that more experiments should be conducted in challenging tasks, specifically mentioning dexterous manipulations in Adroit. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting that the authors conduct experiments in more challenging environments. However, the comment lacks specific guidance on which tasks or how to conduct these experiments, leaving the authors with a general suggestion that requires further exploration. While it points out a potential area for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the fairness of the summary of previous works in the introduction, specifically questioning the assumption that some papers only assume linearly separable data. It also points out a potential assumption in the paper that the feature direction of each arbitrary training sample could act as a perfect linear classifier. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns. It lacks actionable details, such as recommending specific changes or clarifications to the text. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the fairness of the summary of previous works and questioning the assumption that some papers only assume linearly separable data. The comment further raises a question about the assumption that the feature direction of each arbitrary training sample could act as a perfect linear classifier, suggesting that it might refer to orthogonally separable data. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the fairness of the summary of previous works in the introduction, specifically mentioning Williams et al. (2019), Lyu et al. (2021), Boursier et al. (2022), and Wang & Ma (2023). The reviewer points out that some of these papers only assume linearly separable data, while the paper's assumption about the feature direction of each arbitrary training sample acting as a perfect linear classifier is even stronger. The reviewer also suggests that this assumption might be related to the concept of orthogonally separable data. However, the comment lacks specific references or detailed reasoning to support the claim that the summary is unfair or inaccurate. The lack of detailed justification makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires further elaboration to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the summary of previous works in the introduction, specifically questioning the assumption that some papers only assume linearly separable data. It also raises a concern about the assumption that the feature direction of each arbitrary training sample could act as a perfect linear classifier, suggesting that this might be an even stronger assumption. The comment prompts the authors to reconsider the fairness and accuracy of their summary, which could lead to a more comprehensive and accurate representation of the literature reviewed. However, the comment lacks specific suggestions or guidance on how to address these concerns, such as recommending specific changes or clarifications to the text. While it points out important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the paper\\'s per-sample weight tuning method, which relies on the influence function. However, it notes that the explanation of the influence function is only valid when the upweight is very close to 0. The reviewer suggests that if the weights are far away from 0 during training iterations, the influence function might not accurately reflect each sample\\'s influence, leading to unreliable weight production. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve their method. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their method when weights are far from 0. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"per-sample weight tuning method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the method, which relies on the influence function and its applicability when the upweight is close to 0. The comment further explains the potential problem with the influence function when the weights are far from 0, suggesting that the weights produced might be unreliable. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s per-sample weight tuning method relies on the influence function, which is only valid when the upweight is very close to 0. The reviewer explains that if the weights are far away from 0 during training iterations, the influence function might not accurately reflect each sample\\'s influence, leading to unreliable weight production. This claim is somewhat verifiable as it provides a logical reasoning based on the assumption that the upweight is close to 0. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s per-sample weight tuning method, which relies on the influence function. It points out that the explanation of the influence function is only valid when the upweight is very close to 0. If the weights are far away from 0 during training iterations, the influence function might not accurately reflect each sample\\'s influence, leading to unreliable weight production. This feedback is clear and actionable, as it highlights a specific weakness in the methodology and suggests a potential solution by recommending that the authors reconsider their method when weights are far from 0. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested alternative approaches. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the use of centering in partial shapes and scenes, suggesting that it may not be well-defined. It also raises a concern about the authors\\' experiment with missing points, noting that this is an augmentation and not representative of general training scenarios. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the implications of centering in partial shapes and scenes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of centering in partial shapes and scenes, suggesting that it may not be well-defined. It also raises a concern about the authors\\' experiment with missing points, noting that this is an augmentation and not representative of general training scenarios. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the use of centering in partial shapes and scenes and the need for addressing this issue, but without explicit references to specific sections, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the use of centering in partial shapes and scenes, suggesting that it may not be well-defined. It also questions the authors\\' experiment with missing points, noting that this is an augmentation and not representative of general training scenarios. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed evidence or references makes the claim somewhat verifiable, as it provides some insight but requires further elaboration for full understanding. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of centering in partial shapes and scenes, suggesting that it may not be well-defined. It also raises a concern about the authors\\' experiment with missing points, noting that this is an augmentation and not representative of general training scenarios. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors should address these issues. It does not provide actionable steps or examples of how to improve the paper, leaving the authors with a general understanding of the problem but without clear direction on how to resolve it. Therefore, the comment is somewhat helpful, as it points out a potential weakness but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should try to ensemble models trained with the proposed negative augmentations and without them to determine whether this could improve performance. This is an explicit and concrete action for the authors to take, as it provides a clear direction for experimentation. The comment also references a similar approach in [1], which further guides the authors on what to expect and how to implement the suggested experiment. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the proposed method of learning less about texture semantics by adding negative samples that share texture semantic with the anchor images. It suggests trying to ensemble models trained with the proposed negative augmentations and without them to determine whether this could improve performance. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors might have an idea of where this suggestion fits, it is not explicitly grounded. The comment is specific in suggesting the need for an ensemble experiment, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper proposes learning less about texture semantics by adding negative samples that share texture semantics with the anchor images. However, it provides a rationale by referencing a similar approach in [1] and suggests trying to ensemble models trained with and without the proposed negative augmentations to determine if this could improve performance. This provides a logical reasoning and a reference to a similar work, making the claim mostly verifiable. The authors would need to conduct the suggested experiment to fully verify the claim, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s approach, suggesting that the proposed method of learning less about texture semantics by adding negative samples that share texture semantic with the anchor images may not be optimal. It provides a specific suggestion to try ensemble models trained with and without the proposed negative augmentations to determine whether this could improve performance. This feedback is actionable and constructive, as it offers a clear direction for the authors to explore and potentially enhance their method. However, the comment could be more helpful if it included additional details or examples of how to implement the ensemble experiment. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the sample efficiency of a particular equation and suggests that the authors ensure that the variable \"D i\" sufficiently goes through all possible transition probabilities. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation or analysis of the sample efficiency. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific parts of the paper, including the partitioning method and the sample efficiency of a particular equation. It raises a question about whether \"D i\" sufficiently goes through all possible transition probabilities, which is relevant to the analysis presented in the paper. However, the comment does not explicitly mention which section or figure this discussion is based on, making it weakly grounded. The authors can infer that it relates to the analysis on pages 5 and 6, but this inference is not as direct as it could be. The comment is specific in its question about the sample efficiency and the use of \"D i,\" providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question about the sample efficiency of a particular equation and a request for clarification on whether \"D i\" sufficiently goes through all possible transition probabilities. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the sample efficiency of a particular equation and suggests that the authors ensure that \"D i\" sufficiently goes through all possible transition probabilities. This feedback is somewhat helpful as it prompts the authors to clarify their analysis and provide a more detailed explanation of their results. However, the comment lacks specific guidance or suggestions on how to address the issue, such as recommending additional experiments or analyses. While it points out a potential area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the authors form clusters for tokens in Figure 1, specifically mentioning that it is unclear from Section 3. This comment implies that the authors should clarify this aspect of their methodology, which is an explicit action. However, it does not provide specific guidance on how to address this issue or what additional details should be included. The action is clear but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the methodology for forming clusters for tokens in Figure 1, which is currently unclear in Section 3. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about how the authors form clusters for tokens in Figure 1, specifically mentioning that it is unclear from Section 3. This is a factual request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the methodology used to form clusters for tokens in Figure 1, noting that it is unclear from Section 3. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their work that could impact the understanding and interpretation of their results. By addressing this issue, the authors can improve the clarity and comprehensibility of their paper. However, the comment could be more helpful if it provided suggestions on how to clarify this aspect or offered additional context. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the SimNPO method, noting that it introduces two additional hyperparameters that must be manually adjusted to achieve optimal performance. This complexity and time cost are seen as limiting the potential application of the method for large language models in real-world settings. While the comment identifies a problem, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the method. The authors are left to infer that they need to consider simplifying the method or reducing the complexity of the hyperparameters. Therefore, the comment is somewhat actionable, as it identifies a problem but lacks concrete details on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SimNPO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the method, which introduces two additional hyperparameters that significantly increase complexity and time cost, limiting its potential application in real-world settings. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that SimNPO introduces two additional hyperparameters that must be manually adjusted, significantly increasing the complexity and time cost of experiments. This limits the potential application of the method for large language models in real-world settings. The comment provides a logical reasoning by highlighting the impact of these additional hyperparameters on the practicality of the method. However, it lacks specific examples or references to support the claim about the impact on real-world applications. This makes the claim somewhat verifiable, as it provides a reasonable argument but requires further elaboration to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the SimNPO method, noting that it introduces two additional hyperparameters that must be manually adjusted to achieve optimal performance. This complexity and time cost are seen as limiting the potential application of the method for large language models in real-world settings. While the comment highlights a critical problem, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the method. The feedback is somewhat helpful as it points out a significant limitation but lacks actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the work places too much emphasis on affordance prompting, which is overengineered, as evidenced by the Pick&place example. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the paper. The comment lacks actionable details, such as suggesting alternative approaches or methods to better demonstrate the advantages of affordance prompting. As a result, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the focus on affordance prompting, suggesting that it is overengineered and lacks demonstration of its advantages. However, it does not specify which part of the paper this critique pertains to, such as a particular section or example. The authors can infer that it relates to the discussion of affordance prompting, but the lack of explicit mention makes it weakly grounded. The comment is specific in detailing the issue with the Pick&place example, which shows the advantage of affordance prompting, but it does not provide further guidance on how to address this issue or what specific changes should be made. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work places too much emphasis on affordance prompting, which is overengineered, as evidenced by the Pick&place example. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s focus on affordance prompting, suggesting that it is overengineered and lacks demonstration of its advantages. It specifically points out the example of the Pick&place task, which does not effectively showcase the benefits of affordance prompting. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the demonstration of affordance prompting. While it highlights a potential weakness, the feedback lacks actionable details, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that ablation studies are needed to demonstrate the necessity of all parts of the proposed algorithmic pipeline. While the comment implies that the authors should conduct these studies, it does not provide explicit instructions on how to conduct them or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct ablation studies to address the concern. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that ablation studies are needed to demonstrate the necessity of all parts of the proposed algorithmic pipeline. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for ablation studies to demonstrate the necessity of the proposed methodology, but without explicit references to sections or elements of the paper, the authors may struggle to identify the exact areas that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that ablation studies are needed to demonstrate the necessity of all parts of the proposed algorithmic pipeline. However, the comment does not provide specific reasoning or examples to support why ablation studies are necessary or how they would address the concern about the necessity of the proposed methodology. Without detailed justification or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that ablation studies are needed to demonstrate the necessity of all parts of the proposed algorithmic pipeline. This feedback is somewhat helpful as it identifies a potential weakness in the paper\\'s justification for the proposed methodology. However, the comment lacks specific guidance on which parts of the pipeline should be tested or how to conduct these studies effectively. While it highlights an area for improvement, the lack of detailed instructions or examples makes it somewhat helpful, as the authors can infer the need for ablation studies but may not have a clear understanding of how to implement them. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the necessity of the instruction-tuning stage, questioning whether the performance improvement could be attributed to the additional training and tuning costs. It implies that the authors should provide evidence or analysis to demonstrate the necessity of this stage. However, the comment does not explicitly instruct the authors to conduct such an analysis or provide specific guidance on how to address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional evidence or analysis to support their conclusion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the conclusion about the necessity of the instruction-tuning stage, specifically questioning whether the performance improvement can be attributed to the additional training and tuning costs. However, it does not specify which part of the paper this conclusion is discussed in, making it weakly grounded. The comment is specific in questioning the necessity of the instruction-tuning stage and suggesting that performance improvements could come from the additional training cost. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of the instruction-tuning stage and suggests that the performance improvement could be attributed to the additional training and tuning costs. The comment provides a logical reasoning by comparing the costs of instruction-tuning with those of task-specific fine-tuning. However, it lacks specific examples or references to support the claim that the performance improvement could come from the additional training cost. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid point about the necessity of the instruction-tuning stage, questioning whether the performance improvement can be attributed solely to this stage. It suggests that the additional training and tuning costs of the instruction-tuning stage might be a concern, and it prompts the authors to consider whether the performance improvement could come from the additional training cost. This feedback is somewhat helpful as it encourages the authors to reconsider the justification for the instruction-tuning stage and provides a direction for further exploration. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this concern or how to demonstrate the necessity of the instruction-tuning stage. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the outdated evaluation setup, specifically mentioning the release dates of Llama-1 and Mistral-v0.1 and the advancements in current models. It suggests testing the approach on a more challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST or any other instruction fine-tuning dataset. While the comment implies that the authors should update their evaluation setup, it does not provide explicit instructions on how to do so or which specific datasets to use. The action is clear but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation setup, specifically mentioning the release dates of Llama-1 and Mistral-v0.1 and the current models Llama-3, Llama-3.1, Qwen-2.5, and gemma-2. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need to update the evaluation setup to include more challenging and representative fine-tuning datasets, such as instruction tuning on Alpaca/OASST or other instruction fine-tuning datasets. This provides clear guidance on how to improve the evaluation setup. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation setup is outdated and suggests testing the approach on a more challenging and representative fine-tuning setup. The comment provides some justification by mentioning the release dates of Llama-1 and Mistral-v0.1 and the advancements in current models. However, it lacks specific examples or references to support the claim that the current models are significantly better or more challenging. The suggestion to test on a more representative dataset is vague without detailed guidance on which datasets to use. Therefore, the comment is somewhat verifiable, as it provides some support but lacks comprehensive evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the outdated evaluation setup, noting that the models used in the study are no longer current and have been surpassed by more advanced models. It suggests testing the approach on a more challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST or other instruction fine-tuning datasets. This feedback is clear and actionable, providing the authors with a specific direction for improving their evaluation setup and ensuring that their results are more relevant and up-to-date. However, the comment could be more helpful if it included specific examples of how these datasets might be used or how the authors might select them. Overall, the comment is mostly helpful as it effectively guides the authors on how to enhance their study.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of logical coherence in the second section, which results in disorganized content. However, it does not provide specific guidance on how the authors should address this issue. The comment lacks explicit instructions or concrete suggestions on how to improve the logical coherence or organization of the content. Without actionable advice or detailed steps, the authors are left without a clear understanding of what changes to make. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the second section of the paper, where related works are presented. However, it does not specify which part of the section is disorganized or lacks logical coherence, making it difficult for the authors to pinpoint the exact issue. The comment is specific in identifying the issue of disorganization and lack of logical coherence, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the second section lacks logical coherence, resulting in disorganized content. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some indication of a problem but lacks sufficient detail for the authors to effectively improve their draft.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the second section of the paper, noting that while many related works are presented, the lack of logical coherence results in disorganized content. This feedback is somewhat helpful as it points out a potential weakness in the organization and coherence of the content. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending a particular structure or approach to improve the logical flow. Without actionable advice, the authors may find it challenging to make meaningful improvements to their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to mention the language they focus on to retrieve Reddit posts. This is a clear and direct action that the authors can easily implement by adding a sentence or a note in their draft. The comment is specific and provides a concrete action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Reddit posts,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the language used to retrieve Reddit posts. This provides clear guidance on what the authors need to include in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the language used to retrieve Reddit posts. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area where the authors need to provide more information. By asking for clarification on the language used to retrieve Reddit posts, the comment highlights a potential gap in the paper that could be addressed to enhance its clarity and completeness. However, the comment lacks depth and does not offer suggestions or guidance on how to improve the draft, limiting its usefulness. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks comparisons with recent works, specifically mentioning [1]. While it identifies a gap in the literature review, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include comparisons with recent works, but it does not specify which works or how to incorporate them. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons with recent works but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of comparisons with recent works, such as [1], allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of comparisons with recent works. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons with recent works, specifically mentioning [1]. However, it does not provide any supporting evidence, reasoning, or examples to substantiate why this is a significant issue or how it affects the paper\\'s contribution. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by noting the lack of comparisons with recent works, such as [1]. This feedback is clear and actionable, as it highlights a gap in the literature review that the authors should address to enhance the paper\\'s comprehensiveness and relevance. However, the comment could be more helpful if it provided additional guidance on how to incorporate these comparisons or suggested specific works to consider. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether TSG (likely a specific technique or method) would work in diffusion models that do not embed class labels into timestep, such as UViT. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or suggestions on how to address this question or incorporate TSG into such models. The action is implicit and somewhat vague, as the authors need to infer that they should explore the applicability of TSG in these models. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of TSG in diffusion models that do not embed class labels into timestep, specifically mentioning UViT as an example. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the applicability of TSG in these models, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about the applicability of TSG in diffusion models that do not embed class labels into timestep, specifically mentioning UViT as an example. However, it does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of TSG in diffusion models that do not embed class labels into timestep, specifically mentioning UViT as an example. This is a relevant point that could prompt the authors to consider the broader applicability of their technique in different contexts. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this question or explore the applicability of TSG in these models. While it identifies a potential area for improvement, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to release their training code, dialogue dataset, and model checkpoints through anonymous repositories in the paper submission. This provides a clear and direct action for the authors to take, ensuring that the claims in the paper can be reproduced by reviewers. The comment is specific and concrete, giving the authors a clear path to improve the transparency and reproducibility of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of limited reproducibility, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the problem by highlighting the need for the authors to release their training code, dialogue dataset, and model checkpoints through anonymous repositories in the paper submission. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the reproducibility of the paper is limited due to the lack of release of training code, dialogue dataset, and model checkpoints. The reviewer suggests that the authors should release these materials through anonymous repositories in the paper submission to enable reviewers to verify the claims and try out the model themselves. This claim is somewhat verifiable as it provides a logical reasoning for the need to reproduce the work, but it lacks specific examples or references to support the claim. The suggestion to release the materials is clear, but the justification could be strengthened with additional details or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the reproducibility of the paper due to the lack of release of training code, dialogue dataset, and model checkpoints. It provides a clear and actionable suggestion by encouraging the authors to release these materials through anonymous repositories in the paper submission. This feedback is valuable as it empowers the authors to improve the transparency and verifiability of their work, enabling reviewers to reproduce and verify the claims made in the paper. However, the comment could be more helpful if it included specific examples or guidance on how to effectively present these materials in the paper. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the main result of the paper is somewhat obvious, as it involves gradient boosting, which is known to minimize objectives in functional space. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their work. There is no guidance on whether the authors should provide additional context, clarify their approach, or explore alternative methods. As a result, the comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the main result of the paper is somewhat obvious, as it involves gradient boosting, which is known to minimize objectives in functional space. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspect of the main result is considered obvious or how it could be improved. Without explicit references or detailed suggestions, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main result of the paper is \"somewhat obvious\" because it involves gradient boosting, which is known to minimize objectives in functional space. However, the comment lacks specific reasoning or examples to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the main result of the paper is somewhat obvious, as it involves gradient boosting, which is known to minimize objectives in functional space. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or constructive criticism, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the contribution of the work is insufficiently expressed and that the details provided are inadequate. It also mentions the lack of related work mentioned and the absence of appropriate analysis. However, the comment does not provide explicit guidance on how the authors should address these issues, such as suggesting specific areas for improvement or additional analyses that should be included. The feedback is vague and lacks concrete steps for the authors to take, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the contribution of the work, specifically mentioning that it is insufficiently expressed and that the details provided are inadequate. It also notes the lack of related work mentioned and appropriate analysis. However, the comment does not specify which sections or parts of the paper are lacking in contribution or detail, making it weakly grounded. The authors can infer that it relates to the sections discussing the model and its contributions, but this inference is not direct. The comment is specific in detailing what is missing, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contribution of the work is insufficiently expressed and that the details provided are inadequate. It also criticizes the lack of related work mentioned and appropriate analysis. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed reasoning or evidence makes the claim borderline verifiable, as it requires further elaboration to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, namely that the contribution of the work is insufficiently expressed and the details provided are inadequate. It points out the lack of related work mentioned and the absence of appropriate analysis, which are crucial elements for a comprehensive paper. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the clarity and depth of their work. While it highlights areas for improvement, the feedback lacks actionable advice, making it somewhat helpful. The authors are given a direction for improvement but not a clear path forward, which limits the utility of the comment. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify what \"training steps\" refer to in Figure 2b, as the x-axis is labeled \"item.\" It also suggests that Figure 2a should be given with iterations or training steps as the x-axis. These actions are clear and concrete, providing specific guidance on how to improve the clarity of the figures. The authors know exactly what changes to make to enhance the readability and understanding of their results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2a\" and \"Figure 2b,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the meaning of \"training steps\" and the label \"item\" on the x-axis in Figure 2b. The comment provides detailed guidance on how to improve the clarity of the figures, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the \"training steps\" in Figure 2b and suggests that Figure 2a should be given with iterations or training steps as the x-axis. However, the comment does not provide any specific reasoning or examples to support why the current labeling is unclear or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the figures, noting that the \"training steps\" in Figure 2b are not clearly defined and that Figure 2a should be given with iterations or training steps as the x-axis. This feedback is clear and actionable, as it provides the authors with a concrete direction for improving the clarity of their figures. By addressing this issue, the authors can enhance the readability and understanding of their results. However, the comment could be more helpful if it offered suggestions on how to label the x-axis or provided examples of how similar figures have been labeled in similar studies. Overall, the comment is mostly helpful as it effectively guides the authors on how to improve the clarity of their figures.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the use of different cost metrics (flops, latency, and 1/FPS) for different hardware, suggesting that using the same cost for different devices would be more appropriate. While the comment implies that the authors should consider using a different cost metric, it does not provide explicit guidance on which metric to use or how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their cost metric choices. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the use of different cost metrics (flops, latency, and 1/FPS) for different hardware, suggesting that using the same cost for different devices would be more appropriate. However, it does not specify which part of the paper this critique pertains to, such as a particular section or table where these cost metrics are discussed. The authors can infer that it relates to the discussion of cost metrics, but this inference is not direct. The comment is specific in its suggestion to use the same cost metric, but it lacks grounding as it does not identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of different cost metrics (flops, latency, and 1/FPS) for different hardware, suggesting that using the same cost for different devices would be more appropriate. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or examples, the claim remains vague and lacks verifiability, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the use of different cost metrics (flops, latency, and 1/FPS) for different hardware, suggesting that using the same cost for different devices would be more appropriate. While the comment identifies a potential issue with the methodology, it lacks specificity and does not provide detailed guidance or examples on how the authors might address this concern. The feedback is somewhat helpful as it points out a potential weakness but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the maximum iterations used in the experiments and whether these iterations might significantly slow down the training speed. While it implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"two-dimention Wasserstein distance\" and the \"Sinkhorn algorithm,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by questioning the maximum iterations used in the experiments and whether these iterations might significantly slow down the training speed. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the maximum iterations used in the experiments and whether these iterations might significantly slow down the training speed. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the maximum iterations used in the experiments and whether these iterations might significantly slow down the training speed. This is a relevant point that could impact the performance and efficiency of the proposed method. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve their experiments. While it identifies a potential concern, it does not offer actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a major weakness in the paper's soundness, specifically regarding the teacher policy and its distribution matching. It suggests that the paper lacks theoretical results to support the soundness of the approach and questions whether the student policy can still perform correct distribution matching. The reviewer implies that the method appears more like a heuristic than a theoretically sound approach. While the comment highlights a critical area for improvement, it does not provide explicit guidance on how to address this issue or what specific theoretical results should be included. The action is implicit and somewhat vague, as the authors need to infer that they should include theoretical results to strengthen their approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"soundness\" of the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the distribution matching between the student policy's state action visiting distribution and the expert's distribution, and whether the student policy can still perform correct distribution matching. The comment further suggests that the method appears more like a heuristic than a theoretically sound approach, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks theoretical soundness due to the teacher policy's distribution matching approach. The reviewer questions whether the student policy can still perform correct distribution matching and suggests that the method appears more like a heuristic than a theoretically sound approach. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims, making it somewhat verifiable. The authors would need to infer the need for theoretical results and the potential issues with the approach, rather than having clear evidence or guidance to address these points. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper\\'s soundness, specifically regarding the distribution matching approach used by the teacher policy. It questions whether the student policy can still perform correct distribution matching and suggests that the method appears more like a heuristic than a theoretically sound approach. This feedback is valuable as it highlights a critical area for improvement and provides a clear direction for the authors to address. However, the comment could be more helpful if it offered specific suggestions or examples of how to improve the theoretical foundation of the approach. Overall, the comment is mostly helpful as it provides actionable guidance for enhancing the soundness of the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the proposed method in Table 3 does not perform well in some classes and suggests that reasons should be analyzed and discussed. This provides a clear and direct action for the authors to take, which is to analyze and discuss the reasons for the performance issues. The comment is specific and provides concrete guidance on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the performance issues in some classes and the need to analyze and discuss the reasons for these issues. This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method in Table 3 does not perform well in some classes and suggests that reasons should be analyzed and discussed. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed method in Table 3, noting that it does not perform well in some classes. It suggests that the reasons for this performance should be analyzed and discussed. While the comment highlights a potential weakness, it does not provide detailed guidance or examples on how to address this issue or what specific aspects of the method need to be analyzed. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of rigor in the experimental design, specifically mentioning that MTT should test on unseen tasks and that the experimental results could be further discussed or explained. It provides a clear direction for improvement by suggesting that the authors should test on unseen tasks and explain the variation of model behavior under different datasets/settings. This feedback is explicit and concrete, giving the authors a specific action to take to enhance the rigor and comprehensiveness of their experimental design. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"MTT\" and \"experimental settings,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as testing on unseen tasks and discussing the variation of model behavior under different datasets/settings. This provides clear guidance on how to improve the rigor and comprehensiveness of the experimental design. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some experimental settings are not rigorously designed, specifically mentioning MTT and the need for testing on unseen tasks. It also suggests that the experimental results could be further discussed or explained, such as the variation of model behavior under different datasets/settings. While the comment identifies a potential issue with the experimental design, it lacks specific examples or references to support the claim that the experimental settings are not rigorous. This makes the claim somewhat verifiable, as the authors would need to infer the specific aspects that need improvement based on the general suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental design, noting that some settings are not rigorously designed, such as MTT testing on unseen tasks. It also suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets/settings. This feedback is clear and actionable, providing the authors with a concrete direction for improving the rigor and comprehensiveness of their experimental design. By addressing these points, the authors can enhance the credibility and robustness of their results. However, the comment could be more helpful if it offered specific suggestions on how to test on unseen tasks or how to discuss the results in more detail. Overall, the comment is mostly helpful, as it provides valuable insights for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the randomization of data collection for the five layouts, suggesting that the data may not have been collected randomly and that this could lead to learning effects across the different layouts. While the comment implies that the authors should address this issue by ensuring randomization, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should ensure randomization. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the randomization of data collection for five layouts, suggesting that the data may not have been collected randomly and that this could lead to learning effects across the different layouts. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table where the data collection is described. The authors can infer that it relates to the experimental setup or results, but the lack of explicit mention makes it weakly grounded. The comment is specific in its concern about the randomization of data collection, which is important for the authors to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the randomization of data collection for five layouts, suggesting that the data may not have been collected randomly and that this could lead to learning effects across the different layouts. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the data was not randomized. Without such evidence, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the randomization of data collection for five layouts, suggesting that the data may not have been collected randomly and that this could lead to learning effects across the different layouts. This is an important point that could impact the validity and reliability of the results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as recommending a specific method for randomization or discussing potential implications. While it identifies a significant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the relevance of node ordering in the context of random atom ordering in a specific point of the composition space. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific changes they should make to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the relevance of node ordering in the context of random atom ordering in a specific point of the composition space. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its questioning of the relevance of node ordering, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the relevance of node ordering in the context of random atom ordering in a specific point of the composition space. However, it does not provide any reasoning, evidence, or examples to support why node ordering should not play a role in this context. Without additional information or justification, the claim remains unverifiable, as it lacks sufficient support to guide the authors in improving their draft. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment questions the relevance of node ordering in the context of random atom ordering in a specific point of the composition space. However, it does not provide any reasoning or explanation as to why node ordering might not be relevant or how it could be addressed. Without further context or guidance, the authors are left without actionable feedback or suggestions on how to improve their draft. As a result, the comment is barely helpful, as it identifies a potential issue but lacks depth and specificity in its critique. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the novelty of the work is diminished by the previous work [5], which also presents a dexterous manipulation benchmark with musculoskeletal hands. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue, such as by differentiating their work or providing additional context. The lack of actionable advice makes it difficult for the authors to know how to respond to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment references a previous work [5] that also presents a dexterous manipulation benchmark with musculoskeletal hands, which detracts from the novelty of the current work. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. The authors can infer that it relates to the introduction or discussion sections, but this inference is not direct. The comment is specific in detailing the issue of novelty being diminished, but it lacks grounding as it does not specify where in the paper this issue is discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the work is diminished by previous work that also presents a dexterous manipulation benchmark with musculoskeletal hands. However, the comment does not provide any specific references or details about the previous work or how it detracts from the current work. Without specific examples or comparisons, the claim lacks sufficient evidence or justification to be fully verifiable. The authors would need to conduct additional research to understand the implications and address the issue effectively. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the work, suggesting that it is diminished by previous work that also presents a dexterous manipulation benchmark with musculoskeletal hands. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their work from the previous studies. Without actionable advice or detailed feedback, the authors are left without a clear path forward to enhance the novelty or impact of their work. Therefore, the comment is barely helpful, as it points out a potential weakness but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the selection process of datasets and the splitting procedure, suggesting that these aspects should be made more explicit. It provides examples of how similar work has addressed these issues, such as OpenML100 and OpenML CC-18 for classification and the OpenML Benchmarking Suites. Additionally, it mentions the need for more detailed information on the selection of the splitting procedure and split ratios. While the comment implies that the authors should provide more detailed information about their dataset selection and splitting process, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the selection process of datasets and the splitting procedure, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for more clarity regarding the selection process and the splitting procedure, providing examples of how similar work has addressed these issues. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of the dataset selection process and the splitting procedure, suggesting that these aspects are not detailed enough. It provides examples of how similar work has addressed these issues, such as OpenML100 and OpenML CC-18 for classification, and references specific publications. This provides a logical basis for the claim, but the comment could be strengthened by including more detailed examples or references to further substantiate the critique. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of clarity regarding the selection process of datasets and the splitting procedure. It highlights that these aspects are crucial to the paper\\'s contribution and suggests that the authors should provide more detailed information about the datasets used and the selection process. The comment also references specific examples from other works, such as OpenML100 and OpenML CC-18 for classification, to guide the authors on how to improve their explanation. This feedback is clear and actionable, offering a concrete direction for the authors to enhance the clarity and transparency of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include a baseline comparison with an unconditional diffusion model that has been refined using the suggested architectural changes. It also suggests comparing the proposed method to conventional baselines under the same computational constraints. The comment provides clear guidance on what the authors should add to their ablation study, making it highly actionable. The authors know exactly what changes to make to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study\" and the specific issue of a lack of comparison with a baseline. It also specifies what is missing, namely the inclusion of a baseline comparison with an unconditional diffusion model that has been refined using the suggested architectural changes, followed by either consistency distillation or progressive distillation. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study lacks a critical comparison by not including a baseline with an unconditional diffusion model refined using the suggested architectural changes. The comment suggests that the authors should compare their proposed method to conventional baselines under the same computational constraints. This claim is somewhat verifiable as it provides a logical reasoning for why the baseline comparison is necessary and suggests a specific approach to include it. However, the comment lacks specific examples or references to support the claim fully, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the ablation study, noting the absence of a baseline comparison with an unconditional diffusion model refined using the suggested architectural changes. It suggests that the authors should include such a comparison to determine if the proposed method would outperform conventional baselines under the same computational constraints. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their ablation study. By addressing this suggestion, the authors can significantly improve the robustness and comparability of their results. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the tasks in the paper are based on grasping and that the difficulties are too homogeneous. It provides a specific recommendation to refer to projects like [1] and [2] to design more tasks. While the comment implies that the authors should explore additional tasks, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should explore additional tasks. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the tasks in the paper are based on grasping and that the difficulties are too homogeneous. It provides a specific recommendation to refer to projects like [1] and [2] to design more tasks. However, the comment does not explicitly mention which part of the paper discusses these tasks or the difficulties, making it weakly grounded. The suggestion to refer to external projects is specific, but without full grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the tasks in the paper are based on grasping and that the difficulties are too homogeneous. It provides a specific recommendation to refer to external projects like [1] and [2] to design more tasks. However, the comment lacks detailed reasoning or examples to support why the tasks are homogeneous or how the suggested projects could address this issue. Without specific examples or detailed justification, the claim is somewhat verifiable, as it provides a direction but lacks sufficient evidence or explanation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that all the tasks seem to be based on grasping and that the difficulties are too homogeneous. It provides a specific recommendation by suggesting that the authors refer to external projects like [1] and [2] to design more tasks. This feedback is clear and actionable, as it offers a concrete direction for the authors to explore additional tasks and diversify the difficulties presented. However, the comment could be more helpful if it provided more detailed guidance on how to incorporate these projects or why they might be relevant. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and offers a path for enhancing their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an issue with the comparison in Table 2, specifically noting that the training data for LEPA is likely larger than the \"Without Plan/Without Self-Reflection\" settings. The reviewer provides a reference to a specific line in the paper (lines 349-360) and suggests that the settings are not aligned. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the comparison. While the action is implied, it is vague and lacks concrete details on how to implement the suggested correction. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"lines 349-360,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, noting that the training data for LEPA is likely larger than the \"Without Plan/Without Self-Reflection\" settings. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison in Table 2 is unfair because the training data for LEPA is likely larger than the \"Without Plan/Without Self-Reflection\" settings, based on a reference to lines 349-360. However, the comment lacks specific evidence or detailed reasoning to support this claim, such as data or references to specific experiments. Without additional context or detailed explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides a basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison in Table 2, noting that the training data for LEPA is likely larger than the \"Without Plan/Without Self-Reflection\" settings. This is a clear and actionable observation that could help the authors improve the accuracy and fairness of their comparisons. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as recommending a method for aligning the settings or suggesting ways to adjust the comparison methodology. Despite this, the feedback is mostly helpful as it directs the authors\\' attention to a critical area that needs improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider using datasets from the GLUE benchmark, specifically mentioning tasks like QQP, to compute similarity between sentence pairs. It also recommends showing results on real-world diversity datasets. While the comment implies that the authors should include these datasets in their experiments, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors need to infer the exact steps to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the synthetic datasets used in the experiments and suggests using datasets from the GLUE benchmark, specifically mentioning tasks like QQP. It also recommends showing results on real-world diversity datasets. This provides clear guidance on what aspects of the paper need attention, making it easy for the authors to identify the parts that need improvement. The comment is specific in suggesting the use of real datasets and providing examples of tasks from the GLUE benchmark. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should use real datasets, specifically mentioning the GLUE benchmark tasks like QQP, to compute similarity between sentence pairs. It also recommends showing results on real-world diversity datasets. While the comment provides a logical reasoning for why real datasets could be beneficial, it lacks specific examples or references to support the claim that using synthetic datasets is insufficient. The suggestion is somewhat verifiable, as it provides a clear direction for improvement but could be strengthened with more detailed evidence or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper, noting that the authors have only experimented with synthetic datasets and have not shown results with real datasets. It suggests using datasets from the GLUE benchmark, specifically mentioning tasks like QQP, to compute similarity between sentence pairs. Additionally, it recommends showing results on real-world diversity datasets. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance their experimental setup and broaden the scope of their analysis. By addressing these points, the authors can significantly improve the comprehensiveness and relevance of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add details on how to solve the optimization in the main paper. This is a clear and direct action, providing the authors with a specific task to undertake. The comment also highlights the importance of this information, making it easier for the authors to understand the need for this addition. Therefore, the action is explicit and concrete, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to add details on how to solve the optimization in the main paper. This allows the authors to accurately identify the part of the paper being addressed, making it fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the optimization details, and highlights their importance in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should add details on how to solve the optimization in the main paper. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is important or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, namely the absence of details on how to solve the optimization problem. This is an important piece of information that the authors should include to provide a more comprehensive understanding of their work. However, the comment does not offer suggestions or guidance on how to address this gap, leaving the authors without actionable steps to improve their draft. While it highlights a critical area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is rated as somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks why LLaVA-series and Qwen-VL are not included in the evaluation, suggesting that their inclusion would provide a more comprehensive comparison across different LVLM architectures and training approaches. This feedback is clear and provides a direct action for the authors to take, which is to include these models in their evaluation. The comment is specific and provides concrete guidance on what needs to be done to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"LLaVA-series\" and \"Qwen-VL,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of these models in the evaluation for a more comprehensive comparison. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the exclusion of LLaVA-series and Qwen-VL from the evaluation, suggesting that their inclusion would provide a more comprehensive comparison across different LVLM architectures and training approaches. However, the comment does not provide any specific reasoning or evidence to support why these models are commonly adopted or why their inclusion would be beneficial. Without additional context or examples, the claim remains somewhat verifiable, as it lacks detailed justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific omission in the evaluation, noting the absence of LLaVA-series and Qwen-VL models. It suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. This feedback is clear and actionable, as it directs the authors to include relevant models in their evaluation, which could enhance the comprehensiveness and relevance of their study. However, the comment could be more helpful if it provided additional context or justification for why these models are important or how their inclusion would impact the study\\'s conclusions. Overall, the comment is mostly helpful, as it effectively guides the authors on how to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include captions or descriptions for figures and tables, as well as datasets with OCR (Optical Character Recognition) capabilities. While the comment implies that these additions are necessary, it does not provide explicit instructions on how to implement them or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include captions or descriptions for figures and tables, as well as datasets with OCR capabilities. However, it does not specify which part of the paper these additions should be included in, such as specific sections or tables. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas that need attention. Additionally, the comment is not specific about what kind of captions or descriptions should be included or how OCR datasets should be incorporated. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should include captions or descriptions for figures and tables, as well as datasets with OCR capabilities. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these additions are necessary or how they would enhance the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include captions or descriptions for figures and tables, as well as datasets with OCR capabilities. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on what kind of captions or descriptions should be included or how to incorporate OCR datasets. The comment is somewhat helpful as it points out a potential enhancement but does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between Assumption 3.1 and Equation 7, noting that the loss of TKD is assumed to be less than IYOR in Assumption 3.1 but is reported as greater than IYOR in Equation 7. However, the comment does not provide explicit guidance on how the authors should address this discrepancy or suggest specific actions to reconcile the differences. The authors are left to infer that they need to resolve this inconsistency, but without concrete instructions or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption 3.1\" and \"eqn.7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the assumptions and the equations, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a discrepancy between Assumption 3.1 and Equation 7, specifically regarding the loss of TKD. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy between Assumption 3.1 and Equation 7 regarding the loss of TKD. It points out that Assumption 3.1 assumes the loss of TKD to be less than IYOR, while Equation 7 reports the opposite. This feedback is somewhat helpful as it highlights a potential inconsistency in the paper that the authors should address. However, the comment lacks depth and does not provide specific suggestions or guidance on how to reconcile this discrepancy or address the issue. To be more helpful, the comment could offer suggestions on how to resolve the inconsistency or clarify the assumptions and equations. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that question 3, mentioned earlier in the paper, is not clear about whether it indicates other limitations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should clarify this question or address the issue of unclear limitations. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper discusses question 3 or the limitations mentioned in the previous comment. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine what aspect of the paper is being addressed. Additionally, the comment lacks specificity as it does not provide details on what is unclear about question 3 or the limitations mentioned. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the clarity of question 3, which is mentioned earlier in the paper. However, it does not provide any specific reasoning or evidence to support why the question is unclear or how it relates to other limitations mentioned. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the clarity of question 3, which is mentioned earlier in the paper. It highlights that the question may not be clear about whether it indicates other limitations. However, the comment does not provide any specific guidance or suggestions on how the authors might clarify this issue or address the potential confusion. Without actionable feedback or detailed advice, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective for probing. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific changes they should consider. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective for probing. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this choice is discussed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in its question about the choice of using last-layer hidden states, but without full grounding, it is difficult for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective for probing. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective for probing. This is a valid point that could prompt the authors to reconsider their choice of features or to provide a justification for their selection. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or what alternative approaches might be considered. While it identifies a potential weakness, it does not provide actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks a clear motivation for the use cases, specifically mentioning the first question. It also criticizes the decision to use GUE to determine modeling choices, arguing that it may lead to models optimized for a narrow set of tasks presented in GUE, with limited generalizability. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should provide a more detailed motivation for their use cases and consider broader generalizability. The feedback is somewhat actionable as it highlights specific areas needing attention, but it lacks concrete steps for improvement.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first question\" and \"GUE,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of motivation for the use cases and the potential arbitrariness of using GUE to determine modeling choices. The comment further explains the concern about the generalizability of the learned representations, providing a clear rationale for the critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is poorly motivated in terms of use cases and that the decision to use GUE to determine modeling choices is arbitrary and potentially incongruous. The reviewer supports this claim by referencing the first question and suggesting that the representations learned using these modeling decisions will be optimized for the relatively narrow set of tasks presented in GUE, with limited generalizability. This reasoning is logical and provides a clear justification for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the argument further. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper\\'s motivation, specifically the lack of clear use cases and the arbitrary nature of the decision-making process for modeling choices. It points out that using GUE to determine modeling decisions may lead to models optimized for a narrow set of tasks within GUE, with limited generalizability. This feedback is valuable as it highlights a key area where the paper could be improved by providing a more robust justification for the use cases and modeling choices. However, the comment could be more helpful if it offered specific suggestions or examples of how the authors might address these issues. Overall, the comment is mostly helpful as it directs the authors\\' attention to a crucial aspect of their work that requires further development.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper is clunky due to significant grammar and spelling errors, and it suggests that a major editing pass is needed. This provides a clear and direct action for the authors to take, which is to revise and edit the paper to improve its readability. The comment also specifies the issue clearly, making it easy for the authors to understand and implement the suggested action. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the issue of clunkiness due to grammar and spelling errors, which provides full grounding as it allows the authors to identify the specific part of the paper being addressed. It also specifies the issue by suggesting a major editing pass is needed, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is clunky due to significant grammar and spelling errors, suggesting that it needs a major editing pass. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the exact nature of the issues or how to address them. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, namely that it is clunky due to significant grammar and spelling errors. This feedback is clear and actionable, as it directly points out a problem that needs to be addressed. However, the comment lacks specific examples or suggestions on how to improve the grammar and spelling errors, which would make it more helpful. While it highlights a critical area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is somewhat helpful, as it provides a general direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the consistency of the SITE estimator and its assumptions as a valid estimator of the causal effect. It also questions the loss function being only defined over minibatches and whether this oddball objective function could cause issues. While the comment identifies potential issues, it does not provide explicit guidance or suggestions on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify these aspects of their work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the consistency of the SITE estimator and its assumptions as a valid estimator of the causal effect. It also questions the loss function being only defined over minibatches and whether this oddball objective function could cause issues. However, the comment does not specify which part of the paper these questions pertain to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the questions about the estimator and the loss function, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the consistency of the SITE estimator and its assumptions as a valid estimator of the causal effect. It also questions the loss function being only defined over minibatches and whether this oddball objective function could cause issues. While the comment identifies potential concerns, it lacks specific examples or references to support the claims. The reasoning is somewhat logical but lacks detailed evidence or references to fully substantiate the claims. Therefore, the comment is somewhat verifiable, as it provides a basis for the authors to explore these issues but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the consistency and assumptions of the SITE estimator, particularly regarding its validity as an estimator of the causal effect. It questions the loss function being defined only over minibatches and whether this oddball objective function could cause issues. While the comment identifies potential weaknesses and areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these concerns. The feedback is somewhat helpful as it prompts the authors to consider these aspects of their work, but it lacks actionable advice or detailed guidance. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the ability of Object-level Interaction Segmentation (OIS) to handle interactive segmentation for multiple objects simultaneously, particularly in the context of Object-level Understanding, which relies on Mask Guidance from previous interactions. The reviewer suggests that OIS may struggle to shift focus to a new target if the target object changes between clicks due to constraints from the previous mask. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the practical utility of their method. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider this issue and potentially explore ways to improve their method. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Object-level Interaction Segmentation (OIS)\" and \"Object-level Understanding,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out a potential limitation in the method's practical utility due to constraints from previous masks. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the practical utility of Object-level Interaction Segmentation (OIS) due to its limitations in handling interactive segmentation for multiple objects simultaneously. The reviewer supports this claim by referencing the Object-level Understanding method, which relies on Mask Guidance from previous interactions. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a logical basis for the concern, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the practical utility of the Object-level Interaction Segmentation (OIS) method, particularly when handling interactive segmentation for multiple objects simultaneously. It raises a concern about the method's ability to shift focus to a new target object due to constraints from the previous mask. This feedback is valuable as it highlights a potential weakness in the methodology that the authors should consider and address. However, the comment could be more helpful if it provided specific suggestions or examples on how the authors might address this limitation or improve the method's practical utility. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a critical area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption that anomalies would be aligned with concepts, questioning the realism of this assumption. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what specific changes could be made to improve the assumption. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the assumption that anomalies would be aligned with concepts, questioning the realism of this assumption. However, it does not specify which part of the paper this assumption is made in, nor does it provide detailed guidance on how the authors might address this concern. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is specific in its critique of the assumption but lacks grounding, making it difficult for the authors to effectively respond. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the realism of the assumption that anomalies would be aligned with concepts, suggesting that this assumption may not be valid given the nature of anomaly detection systems. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the assumption that anomalies would be aligned with concepts, questioning the realism of this assumption. It highlights the potential limitations of this assumption, particularly in scenarios where the type of anomalies is unknown. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve their approach. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful. The authors are given insight into a potential issue but are not provided with clear steps to resolve it, limiting the comment\\'s utility. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include a discussion on the current limitations and challenges of HLOP and the experimental design, as well as a discussion on the potential downsides of HLOP and limitations of the evaluation process. This feedback provides clear and concrete actions for the authors to take, specifying exactly what needs to be added to the paper. The comment is explicit and provides detailed guidance on how to enhance the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"current limitations/challenges of HLOP and the experimental design,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be added, namely a discussion on the potential downsides of HLOP and limitations of the evaluation process. This provides clear guidance on what the authors need to address to improve their draft. Therefore, the comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is \"almost no discussion on the current limitations/challenges of HLOP and the experimental design,\" which makes it difficult to assess the tradeoffs between using HLOP versus other approaches. The reviewer suggests that the authors should include a discussion on the potential downsides of HLOP and limitations of the evaluation process. This claim is somewhat verifiable as it highlights a gap in the paper\\'s discussion, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to make a significant effort to address this feedback effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of discussion on the current limitations and challenges of HLOP and the experimental design. It suggests that the authors should include a discussion on the potential downsides of HLOP and limitations of the evaluation process. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by addressing these critical aspects. By addressing these points, the authors can improve the comprehensiveness and depth of their analysis, which is valuable for the reviewer. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should evaluate the effectiveness of their proposed gating scheme on recently released language models, such as FlanT5 and Llama, in addition to GPT-2. This feedback provides a clear and explicit action for the authors to take, which is to expand their evaluation to include these additional models. The suggestion is concrete, as it specifies the exact models to be evaluated and the rationale for doing so. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should evaluate the effectiveness of their proposed gating scheme on recently released language models, such as FlanT5 and Llama, in addition to GPT-2. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in detailing the need for evaluating these additional models, but without explicit references to specific sections or parts of the paper, the authors may struggle to pinpoint where this evaluation should be integrated. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should evaluate the effectiveness of their proposed gating scheme on recently released language models, such as FlanT5 and Llama, in addition to GPT-2. This claim is somewhat verifiable as it provides a logical reasoning for expanding the evaluation to include these additional models. However, the comment lacks specific examples or references to these models, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for the authors to expand their evaluation of the proposed gating scheme by including recently released language models, such as FlanT5 and Llama, in addition to GPT-2. This feedback is clear and constructive, as it identifies a gap in the current evaluation and offers a concrete way to enhance the contribution of the work. By addressing this suggestion, the authors can significantly improve the comprehensiveness and impact of their study. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should cite and compare recent works that are highly correlated with their proposed method. It provides a specific example of a work that might be relevant, \"Differential Treatment for Stuff and Things: A Simple Unsupervised Domain Adaptation Method for Semantic Segmentation - Wang et al. cvpr2020.\" This feedback is explicit and provides a clear action for the authors to take, which is to include this reference and compare it to their work. The suggestion is concrete and provides a specific direction for improvement, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should cite and compare recent works that are highly correlated with their proposed method. It provides a specific example of a work that might be relevant, \"Differential Treatment for Stuff and Things: A Simple Unsupervised Domain Adaptation Method for Semantic Segmentation - Wang et al. cvpr2020.\" This reference is clear, allowing the authors to identify the specific part of the paper that needs attention. However, the comment lacks specificity regarding what aspects of the proposed method should be compared or how the comparison should be conducted. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the authors should cite and compare recent works that are highly correlated with their proposed method. The reviewer provides a specific example of a work that might be relevant, \"Differential Treatment for Stuff and Things: A Simple Unsupervised Domain Adaptation Method for Semantic Segmentation - Wang et al. cvpr2020.\" This reference is a clear example of a work that could be relevant to the authors\\' method, providing a logical basis for the suggestion. However, the comment lacks detailed justification or specific examples of how this comparison would enhance the paper. Therefore, the claim is somewhat verifiable, as it provides a starting point but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should cite and compare recent works that are highly correlated with their proposed method. It provides a specific example of a work that might be relevant, \"Differential Treatment for Stuff and Things: A Simple Unsupervised Domain Adaptation Method for Semantic Segmentation - Wang et al. cvpr2020.\" This feedback is clear and actionable, as it directs the authors to include a relevant reference and compare it to their work. By doing so, the authors can enhance the context and depth of their analysis, which could lead to a more comprehensive understanding and evaluation of their method. However, the comment could be more helpful if it provided additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should add more detail about the way UNKs are handled by the neural decoder or, at least, provide a citation to the dictionary-based replacement strategy being used. This feedback is explicit, as it clearly instructs the authors to either add more detail or provide a citation. The action is concrete, as it specifies exactly what the authors need to do to address the comment. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should add more detail about the way UNKs are handled by the neural decoder or provide a citation to the dictionary-based replacement strategy being used. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for additional information or a citation, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide more detail about the way UNKs are handled by the neural decoder or at least cite the dictionary-based replacement strategy being used. However, the comment does not provide any specific reasoning or evidence to support why this additional information is necessary or how it would enhance the paper. Without detailed justification or references, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide more detail about the way UNKs are handled by the neural decoder or, at least, add a citation to the dictionary-based replacement strategy being used. This feedback is somewhat helpful as it identifies a potential gap in the paper\\'s explanation of the neural decoder handling of UNKs. However, the comment lacks specific guidance on how to address this issue or what additional details would be beneficial. While it points out a potential area for improvement, it does not provide detailed suggestions or examples of what could be included to enhance the paper. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their SOTA code summarization methods with other methods that use pre-trained models. While the comment implies that the authors should include this comparison in their experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing SOTA code summarization methods, specifically those that use pre-trained models, with the current experiments. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting the inclusion of this comparison, but without explicit references to sections or specific experiments, the authors may struggle to identify where to integrate this feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should compare their SOTA code summarization methods with other methods that use pre-trained models. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should compare their SOTA code summarization methods with other methods that use pre-trained models. This feedback is somewhat helpful as it identifies a potential area for improvement in the experiments, specifically by including comparisons with other state-of-the-art methods. However, the comment lacks specific guidance on how to implement this comparison or what aspects to focus on. While it provides a direction for improvement, it does not offer detailed instructions or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the results in Table 3, specifically asking for an explanation of why AttendOut has lower variance than Scheduled Bernoulli and requesting the statistical significance value when comparing the two methods. While the comment implies that the authors should provide an explanation or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation or statistical analysis to address the questions raised. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the results in Table 3, specifically asking for an explanation of why AttendOut has lower variance than Scheduled Bernoulli and requesting the statistical significance value when comparing the two methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification and additional information about the results in Table 3. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the results in Table 3, specifically questioning the reason for the lower variance of AttendOut compared to Scheduled Bernoulli and requesting the statistical significance value when comparing the two methods. This feedback is valuable as it prompts the authors to clarify their findings and provide additional context, which could enhance the understanding and interpretation of their results. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided guidance on how to present the information more effectively. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the prediction lengths in the experimental results do not reflect the setting of \"long-term,\" and recommends following the same settings as the original dataset. This feedback provides a clear and explicit action for the authors to take, which is to adjust the prediction lengths to match those used in the original dataset. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"prediction lengths,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the mismatch between the \"long-term\" setting and the prediction lengths. This provides clear guidance on how to improve the paper. Therefore, the comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prediction lengths in the experimental results do not reflect the setting of \"long-term,\" suggesting that the current settings are too short. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental results, specifically noting that the prediction lengths used in the experiments do not align with the setting of \"long-term.\" It suggests following the same settings as the original dataset, which are {96, 192, 336, 720}. This feedback is clear and actionable, providing the authors with a specific and concrete suggestion for improving the experimental design. By addressing this issue, the authors can enhance the credibility and relevance of their results. However, the comment could be more helpful if it explained why the current settings are inappropriate for a \"long-term\" forecasting setting. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an issue with the difference between confidence and accuracy for one sample when using it in Equation. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or improve their draft. There is no guidance on whether the authors should clarify this difference, provide examples, or suggest a resolution. As a result, the comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the confidence and the accuracy for one sample\" and \"using it in Eq.\", allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the difference between confidence and accuracy for one sample, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the difference between confidence and accuracy for one sample is not reasonable when using it in Equation. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the difference between confidence and accuracy for one sample when using it in Equation. This is a clear and actionable observation that can help the authors improve the accuracy and reliability of their results. However, the comment lacks depth and does not provide suggestions on how to address this issue or improve the explanation in the paper. While it points out a potential problem, it does not offer detailed guidance or examples, making it somewhat helpful. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the method's ability to account for shifts in the data distribution when calculating the divergence between a sample and the data. It poses a question about whether there is a way to adapt the method to account for these shifts. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should consider adapting the method to account for shifts in the data distribution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the method's ability to account for shifts in the data distribution when calculating the divergence between a sample and the data. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the method and suggesting a way to adapt it to account for shifts in the data distribution. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the method's ability to account for shifts in the data distribution when calculating the divergence between a sample and the data. The comment suggests that the approach may fail when the sample is shifted from the data distribution. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it requires further elaboration to be fully understood and actionable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the method's ability to account for shifts in the data distribution when calculating the divergence between a sample and the data. It raises a valid concern about the robustness of the method in such scenarios and suggests that the authors consider adapting it to account for these shifts. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the replacement of words in a given context, specifically questioning whether it is better to replace a single word or the entire phrase. The reviewer suggests that replacing the whole phrase might be more coherent. While the comment implies that the authors should consider this approach, it does not provide explicit instructions or concrete guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their approach to word replacement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 076-079,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the replacement of words in a given context and suggests that it might lead to incoherent text. The comment provides a clear direction for improvement by suggesting that it might be better to replace the whole phrase instead of independent words. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification regarding the replacement of words in a given context. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the replacement of words in a given context, questioning whether it is better to replace individual words or phrases. It suggests that replacing the whole phrase might be more coherent. While the comment identifies a potential issue with the text, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential problem but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be desirable to include runtime comparison of different deep learning-based methods. While this comment implies that the authors should include such a comparison, it does not provide explicit instructions or concrete details on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should include runtime comparisons but are not given specific guidance on how to conduct them or what aspects to focus on. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including runtime comparisons of different deep learning-based methods, but it does not specify which part of the paper should include this information. The authors cannot confidently determine whether this suggestion relates to a specific section, table, or figure. Additionally, the comment lacks specificity regarding what aspects of the runtime comparisons should be included or how they should be presented. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that runtime comparisons of different deep learning-based methods would be desirable. However, it does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or beneficial. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that runtime comparisons of different deep learning-based methods would be desirable. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to conduct these comparisons or what aspects to focus on. The feedback is somewhat helpful as it points out a potential enhancement but does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should explore and compare ECG-specific architectures using SSL or transformer-based architectures to significantly improve the current ECG encoder. While the comment implies that the authors should consider these architectures, it does not provide explicit instructions on how to implement or integrate them into the existing framework. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the MEIT framework, specifically the ECG encoder, modality alignment, and LLM backbone. It suggests exploring and comparing ECG-specific architectures using SSL or transformer-based architectures to improve the current ECG encoder. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the ECG encoder or the framework as a whole. The comment is specific in suggesting the need for exploring and comparing different architectures, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the ECG encoder in the MEIT framework could be improved by exploring and comparing ECG-specific architectures using SSL or transformer-based architectures. While the comment provides a logical reasoning for the need to improve the ECG encoder, it lacks specific examples or references to support the claim that these architectures would significantly improve the current ECG encoder. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and implement the suggested improvements. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the MEIT framework, specifically the ECG encoder. It suggests that the current ECG encoder, which uses only several 1-D CNN layers and average pooling, could be significantly improved by exploring and comparing ECG-specific architectures using SSL or transformer-based architectures. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their work. However, the comment could be more helpful if it included specific examples or references to such architectures, which would guide the authors in implementing these improvements. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for enhancement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rephrase the abstract to accurately reflect the focus of the paper, which is a model-agnostic explainability technique for deep neural networks. This feedback provides a clear and concrete action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is highly actionable because it specifies the exact change needed in the abstract and provides a clear direction for the authors to follow.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inaccurate suggestion of a defense methodology and the need to rephrase the abstract to reflect the correct focus on model-agnostic explainability. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract inaccurately suggests a defense methodology is proposed, when in fact, the paper presents a model-agnostic explainability technique for deep neural networks. The reviewer provides a clear and specific reasoning for the claim, which is that the abstract does not accurately reflect the content of the paper. This makes the claim verifiable, as it is supported by a logical and precise explanation. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, noting that it inaccurately suggests a defense methodology is proposed when the paper actually presents a model-agnostic explainability technique for deep neural networks. It provides a clear and actionable suggestion to rephrase the abstract to accurately reflect the content of the paper. This feedback is valuable as it guides the authors to correct an inaccuracy in their abstract, ensuring that their work is presented accurately and effectively. However, the comment could be more helpful if it offered additional guidance on how to rephrase the abstract or provided examples of alternative wordings. Overall, the comment is mostly helpful, as it effectively directs the authors to a specific area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of comparison to recent methods that propose new activation functions for INRs, specifically mentioning FINER [1], Incode [2], and SL2A-INR [3]. While the comment implies that the authors should include these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these comparisons. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"compares its method with earlier methods,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out the lack of comparisons to recent methods, such as FINER [1], Incode [2], and SL2A-INR [3], which propose new activation functions for INRs. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons to recent methods that propose new activation functions for INRs, specifically mentioning FINER [1], Incode [2], and SL2A-INR [3]. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate why these comparisons are necessary or how they would enhance the paper. Without additional context or justification, the claim remains somewhat verifiable, as it lacks the necessary support to fully justify the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by including comparisons to recent methods that propose new activation functions for INRs. It mentions specific methods, such as FINER [1], Incode [2], and SL2A-INR [3], which could provide valuable insights into the advancements made in this area. While the comment highlights a clear gap in the paper, it lacks detailed guidance on how to incorporate these comparisons or why they are important. This limits the comment\\'s helpfulness, as it provides a direction for improvement but does not offer actionable steps. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation setting can be improved by challenging the value of research on length extrapolation, as long as the models are finetuned. However, it does not provide explicit guidance on how to improve the evaluation setting or what specific changes should be made. The comment lacks actionable details, such as suggesting specific modifications or examples of how to enhance the evaluation setting. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the evaluation setting can be improved by challenging the value of research on length extrapolation, as long as the models are finetuned. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the evaluation or methodology sections, but this inference is not direct. The comment is specific in suggesting an improvement but lacks grounding as it does not explicitly mention a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a straightforward method, such as the one mentioned in the external reference, works well in practice and challenges the value of research on length extrapolation. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim that the method challenges the value of research. As a result, the claim is not fully verifiable, as it relies on an external reference without further elaboration or justification. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the evaluation setting can be improved by challenging the value of research on length extrapolation, as long as the models are finetuned. It highlights a potential weakness in the current research approach and provides a direction for improvement. However, the comment lacks specific suggestions or guidance on how to implement this improvement or what specific aspects of the evaluation setting need to be challenged. While it identifies an area for potential enhancement, the feedback is somewhat helpful as it points out a potential weakness but does not offer actionable steps for the authors to address it. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the training and testing environments in Section 2.4, specifically asking which environment is the training one and which are the testing ones. It also suggests that cross-validation testing would be preferable to demonstrate the robustness of the results better. While the comment implies that the authors should clarify this information and potentially perform cross-validation testing, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the environments and consider cross-validation testing. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the training and testing environments, asking for clarification on which environment is the training one and which are the testing ones. It also suggests cross-validation testing as a way to demonstrate the robustness of the results better. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the training and testing environments in Section 2.4, specifically asking which environment is the training one and which are the testing ones. It also suggests that cross-validation testing would be preferable to demonstrate the robustness of the results better. While the comment identifies a potential issue with the experimental setup, it lacks specific examples or references to support the claim that cross-validation is necessary. The suggestion is logical and reasonable, but the lack of detailed justification or examples makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental setup in Section 2.4, specifically questioning the training and testing environments. It raises a concern about the clarity of which environment is the training one and which are the testing ones, and suggests that cross-validation testing would be preferable to demonstrate the robustness of the results better. While the comment highlights a potential weakness in the paper, it does not provide specific suggestions or guidance on how to address this issue or improve the experimental setup. The feedback is somewhat helpful as it points out a potential area for improvement but lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of comparison to demonstrate the improvement in generation quality due to refinement during inference. It suggests that while the statistic of the number of refinements is informative, it does not necessarily indicate an improvement. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific comparisons should be included. The action is implicit and somewhat vague, as the authors can infer that they need to include comparisons to demonstrate improvement, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of a comparison to demonstrate the improvement in generation quality due to refinement during inference. It suggests that while the statistic of the number of refinements is informative, it does not necessarily indicate an improvement. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or table where the comparison should be included. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to include comparisons, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of comparison to demonstrate the improvement in generation quality due to refinement during inference. The reviewer suggests that while the statistic of the number of refinements is informative, it does not necessarily indicate an improvement. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim borderline verifiable, as it requires further elaboration to be fully understood and actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the lack of a comparison to demonstrate the improvement in generation quality due to refinement during inference. It acknowledges the inclusion of a statistic on the number of refinements but points out that this alone does not necessarily indicate an improvement. The comment provides a clear and actionable suggestion for the authors to include comparisons to show the impact of refinement on generation quality. However, it could be more helpful if it offered specific examples or guidance on how to structure these comparisons. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: \"something missing (threshold?)\" regarding a specific section and \"did you do this partitions randomly?\" regarding the methodology. While these questions imply that the authors should clarify or provide additional information, they do not explicitly instruct the authors to do so. The feedback is somewhat actionable as it implies that the authors should address these questions, but it lacks concrete guidance on how to implement the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it addresses, such as a specific section, table, or figure. It lacks specificity because it does not provide detailed guidance on what is missing or what needs to be clarified. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of two questions: \"something missing (threshold?)\" regarding a specific section and \"did you do this partitions randomly?\" regarding the methodology. These questions are factual in nature and do not contain subjective opinions, judgments, or suggestions that require verification. They are purely inquiring and do not require justification or evidence. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment consists of two questions, one regarding a specific section (336 \"with... PMI\") and the other about the methodology (371). While these questions are relevant and could prompt the authors to clarify or provide additional information, the comment lacks depth and does not offer specific suggestions or guidance on how to address these issues. The questions are somewhat helpful as they point out potential areas for improvement, but they do not provide actionable feedback or detailed guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: \"How long will the MDP take?\" and \"Could you provide the training time comparison of MDP and ImageNet pretraining + individual dataset fine-turning?\" These questions are explicit and seek specific information that the authors need to provide. The first question asks for an estimation of the time required for the MDP, while the second question seeks a comparison of the training time between MDP and ImageNet pretraining with individual dataset fine-turning. While the questions are clear, they do not provide explicit guidance on how to address them or what specific information should be included in the response. However, the authors can infer that they need to provide an estimation or comparison to satisfy the reviewer. Therefore, the comment is somewhat actionable, as it identifies specific areas that need attention but lacks detailed guidance on how to implement the suggested improvements.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions regarding the time required for the MDP and the training time comparison between MDP and ImageNet pretraining + individual dataset fine-turning. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions themselves are specific, as they ask for specific comparisons and estimations. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions seeking information about the time required for the MDP and the training time comparison between MDP and ImageNet pretraining + individual dataset fine-turning. These questions are factual in nature and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions that are relevant to the paper\\'s content. The first question seeks an estimation of the time required for the MDP, while the second question asks for a comparison of the training time between MDP and ImageNet pretraining with individual dataset fine-turning. These questions are clear and specific, providing the authors with actionable steps to address potential concerns or gaps in their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects of the comparison should be highlighted. Overall, the comment is mostly helpful as it directs the authors\\' attention to important aspects of their work that need further clarification or elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a claim made by the authors regarding the advantages of G-PDE over other methods, specifically mentioning that it is an incremental improvement upon GraphCON. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest how the authors should address this claim or clarify their reasoning. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"G-PDE\" and \"GraphCON,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what the comment is about: the claim that G-PDE is an incremental improvement upon GraphCON, and it notes that the static encoder is substituted by SNN. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim made by the authors that G-PDE is intentionally designed to leverage the advantages of both spike ODE and graph ODE. The reviewer suggests that G-PDE is an incremental improvement upon GraphCON, where the static encoder is substituted by SNN. This claim is somewhat verifiable as it provides a logical reasoning for the comparison between G-PDE and GraphCON, but it lacks specific references or detailed evidence to fully substantiate the claim. The authors would need to provide more detailed information or references to fully support their claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential misrepresentation in the authors\\' claims about the design of G-PDE. It points out that G-PDE is an incremental improvement upon GraphCON, where the static encoder is substituted by SNN. This feedback is somewhat helpful as it highlights a potential inconsistency in the authors\\' claims, which could be clarified or addressed in the paper. However, the comment lacks specific suggestions or guidance on how the authors might clarify or correct this issue, limiting its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed method does not significantly outperform Jiang et al. in certain metrics, specifically mentioning Penetration(Dep), CR, and Sim-Disp(Mean). It provides specific numerical comparisons, such as Ours(100.00%) only outperforming Jiang et al.(99.97%) by 0.03% in Penetration(Dep) and Ours(1.74) being worse than Jiang et al.(1.52) in Sim-Disp(Mean). This feedback is explicit and provides concrete details on where the proposed method falls short compared to Jiang et al. The authors know exactly what aspects need improvement, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific metrics, such as Penetration(Dep), CR, and Sim-Disp(Mean), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that the proposed method does not significantly outperform Jiang et al. in these metrics. The comment provides numerical comparisons to support the claim, making it clear and actionable. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method does not significantly outperform Jiang et al. in certain metrics, providing specific numerical comparisons to support the claim. This is a factual statement that does not require an opinion or judgment, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment highlights a significant issue with the proposed method, noting that it does not significantly outperform Jiang et al. in certain metrics. It provides specific numerical comparisons, such as Penetration(Dep), CR, and Sim-Disp(Mean), to illustrate the extent of the performance gap. This feedback is clear and actionable, as it identifies areas where the proposed method falls short and offers concrete evidence to support the claim. By addressing these points, the authors can improve the comparative analysis and potentially enhance the overall impact of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of comparison or mention of related work in the context of \"vFSAD,\" which refers to OOD detection in time-series data. It also points out that the \"Policy\" and \"Evaluation tasks\" subtitles are not descriptive and seemingly unrelated to the actual content. While the comment highlights areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should include comparisons with relevant work and make the subtitles more descriptive, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"vFSAD\" and \"Policy\" and \"Evaluation tasks,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison or mention of related work in the context of \"vFSAD\" and the unrelatedness of the \"Policy\" and \"Evaluation tasks\" subtitles to the actual content. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"vFSAD\" refers to OOD detection in time-series data, which is a specific claim. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. The mention of \"Kaur et al.\" is not sufficient to establish the claim, as it does not provide context or explanation for why this reference is relevant. Additionally, the comment suggests that the \"Policy\" and \"Evaluation tasks\" subtitles are not descriptive and unrelated to the content, but it does not provide further elaboration or examples to support this claim. Therefore, the comment is considered unverifiable due to the lack of detailed justification or evidence.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of comparison or mention of related work in the context of \"vFSAD,\" which refers to OOD detection in time-series data. It also points out that the subtitles \"Policy\" and \"Evaluation tasks\" are not descriptive and seemingly unrelated to the actual content. This feedback is clear and actionable, as it provides the authors with specific areas to address in order to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it suggested specific ways to compare with or mention related work or provided examples of how to make the subtitles more descriptive. Overall, the comment is mostly helpful as it directs the authors toward meaningful improvements, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include an ablation study that investigates the effect of memory size on their model. This provides a clear and direct action for the authors to take, ensuring that they understand exactly what needs to be done to improve their draft. The comment is specific and provides concrete guidance on how to implement the suggested change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for an ablation study to investigate the effect of memory size, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the ambiguity of memory size and the need for an ablation study to justify the memory size selection. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the effect of memory size is ambiguous and suggests adding an ablation study to investigate the effect of memory size. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the memory size is ambiguous or how an ablation study would address this issue. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of ambiguity in the paper, namely the effect of memory size on the model. It suggests that an ablation study should be added to investigate this effect and provide justification for the memory size selection. This feedback is clear and actionable, as it directs the authors to include a specific analysis that could improve the clarity and robustness of their work. However, the comment could be more helpful if it provided additional guidance on how to design and conduct the ablation study. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the paper regarding the abbreviation \"GNN\" and its full definition \"Graph Neural Network (GNN)\". While the comment identifies a specific issue with the organization and timing of the definition, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should either provide the full definition earlier or ensure consistency in the use of abbreviations throughout the paper. The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 1\" and \"Section 2, at the end of page 2,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistency in the abbreviation \"GNN\" and its full definition \"Graph Neural Network (GNN)\". Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abbreviation \"GNN\" appears at the end of page 1 but is not defined until much later in Section 2, at the end of page 2. This is a factual observation that does not require any subjective interpretation or judgment. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization and timing of the definition of the abbreviation \"GNN\" and its full definition \"Graph Neural Network (GNN)\". This is a clear and actionable feedback that can help the authors improve the clarity and consistency of their paper. By pointing out this inconsistency, the comment provides the authors with a concrete step to address it, ensuring that readers can easily understand the terminology used throughout the paper. However, the comment could be more helpful if it offered suggestions on how to improve the organization or timing of the definition. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the performance of the baseline methods on the DAVIS dataset is low compared to state-of-the-art results, specifically mentioning a J mean of 65.6% on 2019-val by [1]. It also notes that the proposed loss function may not be effective on top-performing methods. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or suggestions for improvement. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the DAVIS dataset and the specific performance of the baseline methods compared to state-of-the-art results, providing clear context for the authors. It also references a specific work, [1], which further grounds the comment. The comment is specific because it points out the low performance of the baseline methods and the potential ineffectiveness of the proposed loss function on top-performing methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of the baseline methods on the DAVIS dataset is low compared to state-of-the-art results, specifically mentioning a J mean of 65.6% on 2019-val by [1]. The reviewer also notes that the proposed loss function may not be effective on top-performing methods. However, the comment lacks specific references or detailed reasoning to support these claims. The mention of [1] provides a reference to a specific work, but without further explanation or analysis, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of the baseline methods on the DAVIS dataset, noting that it is low compared to state-of-the-art results. It also highlights the potential ineffectiveness of the proposed loss function on top-performing methods. This feedback is valuable as it points out a specific area where the paper may need improvement, providing the authors with a clear direction for enhancing their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how other methods have improved their performance on the DAVIS dataset. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical area needing improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the results for the proposed two-step decoding method, specifically asking if the results in Table 1 are obtained with or without the two-step method. It also inquires about the performance of the two-step method without, and if it is worse. While the comment implies that the authors should clarify these results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about the results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the results for the proposed two-step decoding method, specifically asking if the results in Table 1 are obtained with or without the two-step method. It also inquires about the performance of the two-step method without, and if it is worse. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or table. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the results and their comparison, but without full grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions and requests for clarification regarding the results presented in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the results for the proposed two-step decoding method, asking if the results in Table 1 are obtained with or without the two-step method. It also inquires about the performance of the two-step method without, and if it is worse. This feedback is clear and actionable, as it prompts the authors to clarify their results and provide more detailed information about the method's performance. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to increase the font size in the figures to improve readability. This feedback is clear and provides a direct action for the authors to take, ensuring that they know exactly what needs to be done to address the issue. The comment is specific and provides concrete guidance, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"font size in the figures,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely increasing the font size to improve readability. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the font size in the figures, suggesting that it is too small and needs to be increased for better readability. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is a factual statement that requires no verification.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it provides a specific and actionable suggestion to improve the readability of the figures by increasing the font size. This feedback is clear and direct, allowing the authors to easily identify and address the issue. By addressing the font size, the authors can enhance the clarity and accessibility of their figures, which is an important aspect of scientific communication. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments only consider synthetic problems, suggesting that the authors should consider real-world problems as well. However, it does not provide explicit guidance on how to incorporate real-world problems or which specific ones to consider. The action is implicit and somewhat vague, as the authors need to infer that they should include real-world problems in their experiments. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments only consider synthetic problems, but it does not specify which part of the paper this critique pertains to, such as the experimental section or methodology. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what aspects of the synthetic problems should be addressed or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experiments only consider synthetic problems, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential limitation in the experiments, noting that they only consider synthetic problems. This observation highlights an area where the paper could be strengthened by incorporating real-world problems. However, the comment lacks specificity and does not provide guidance on how to address this issue or what real-world problems should be considered. While it identifies a potential weakness, the feedback is incomplete and does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors should compare their natural language explanation (NLE) tool with other NLE interpretability tools. This provides a clear and direct action for the authors to take, ensuring that they are aware of the need to expand their comparisons to include other NLE baselines. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"NLE baselines\" and the \"feature attribution type of explanations,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors should compare their NLE tool with other NLE interpretability tools. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should compare their natural language explanation (NLE) tool with other NLE interpretability tools. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would enhance the paper. Without additional context or examples, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should compare their natural language explanation (NLE) tool with other NLE interpretability tools. This feedback is clear and actionable, as it provides a direct suggestion for expanding the comparative analysis in the paper. By including this comparison, the authors can enhance the comprehensiveness and relevance of their evaluation. However, the comment could be more helpful if it provided specific examples or references to other NLE interpretability tools that the authors might consider. Overall, the comment is mostly helpful as it directs the authors to a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the use of data points in Equation (5), noting that only one pertinent positive data point is used, while many other data points that satisfy Equations (1) and (2) are not included. It suggests that these data points contribute equally to Equation (3) but have different perturbation directions. The comment implies that the authors should include an exhaustive test over the diversity of these data points in Equation (5). While the action is implicit, it is clear that the authors need to expand their data analysis to include these additional data points. The comment provides a concrete direction for improvement, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. (5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the use of only one pertinent positive data point in Eq. (5) and suggests that many other data points that satisfy Equations (1) and (2) should be included. The comment provides a clear rationale for why this inclusion is necessary and how it would enhance the analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that only one pertinent positive data point is used in Equation (5), while many other data points that satisfy Equations (1) and (2) are not included. The reviewer suggests that these data points contribute equally to Equation (3) but have different perturbation directions. The comment provides a logical reasoning for why the inclusion of these additional data points would be beneficial, but it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as it provides a clear rationale but requires further elaboration to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s analysis, noting that only one pertinent positive data point is used in Equation (5) while many other data points that satisfy Equations (1) and (2) are not included. It suggests that these additional data points contribute equally to Equation (3) but have different perturbation directions. The comment highlights a potential gap in the analysis and provides a clear direction for improvement by suggesting an exhaustive test over the diversity of these data points. This feedback is actionable and offers a concrete way for the authors to enhance their analysis and presentation. However, it could be more helpful if it included specific examples or guidance on how to implement this suggestion. Overall, the comment is mostly helpful as it effectively points out a weakness and provides a constructive suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a comparison of the document augmentation method with existing supervised retrievers, such as InPars-V2 and Promptagator. The reviewer implies that this comparison would be beneficial to understand the potential impact of document augmentation on the final retriever model. However, the comment does not explicitly instruct the authors to conduct this comparison or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the results section, specifically mentioning the comparison without using supervision data and the exclusion of InPars-V2 and Promptagator. It suggests including a comparison with existing supervised retrievers to understand the potential impact of document augmentation on the final retriever model. However, the comment does not specify which part of the results section this comparison should be included, nor does it provide detailed guidance on how to conduct this comparison. While the authors can infer that the results section is being addressed, the lack of specificity makes it weakly grounded. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the results are compared fully without using supervision data and suggests including a comparison with existing supervised retrievers to understand the potential impact of document augmentation on the final retriever model. The reviewer provides a logical reasoning by suggesting that augmented queries or documents could add additional performance boost to the final retriever model. However, the comment lacks specific examples or references to support the claim, such as mentioning specific supervised retrievers or providing detailed reasoning on how document augmentation could enhance performance. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the authors include a comparison of the document augmentation method with existing supervised retrievers. This feedback is valuable as it encourages the authors to explore the impact of document augmentation on the final retriever model, especially considering that the authors already have training signals from supervised retrievers. The comment provides a clear and actionable suggestion for enhancing the paper by offering a specific direction for further investigation. However, it could be more helpful if it included specific examples or guidance on how to conduct this comparison. Overall, the comment is mostly helpful as it offers a constructive suggestion that can significantly enhance the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the cache hierarchy is not discussed, specifically mentioning the order in which the three dimensions are applied, shared data, and how the individual levels are constructed and their details. It also notes that the hierarchy claim contradicts the lack of discussion on how the levels are applied together, as they are independent from each other in their memory benefits. While the comment identifies a gap in the discussion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to discuss the cache hierarchy and its application, but the comment does not specify how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the cache hierarchy, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the cache hierarchy discussion, noting that it is not discussed in terms of the order in which the three dimensions are applied, shared data, and how the individual levels are constructed and their details. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the cache hierarchy is not discussed, specifically mentioning the order in which the three dimensions are applied, shared data, and how the individual levels are constructed and their details. The reviewer also notes that the hierarchy claim contradicts the lack of discussion on how the levels are applied together, as they are independent from each other in their memory benefits. This claim is somewhat verifiable as it highlights a gap in the discussion but lacks specific examples or references to support the assertion that the hierarchy claim contradicts the lack of application discussion. The authors would need to further explore the issue to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting that the cache hierarchy is not discussed in detail. It points out that the order in which the three dimensions are applied, shared data, and how the individual levels are constructed and their details are discussed, but not how they are applied together. This feedback is clear and actionable, as it highlights a critical area where the authors need to provide more information and context to support their claims. By addressing this issue, the authors can enhance the clarity and coherence of their paper. However, the comment could be more helpful if it offered specific suggestions on how to address this gap or provided examples of how similar discussions have been handled in other works. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the authors managed to prevent the out-of-memory (OOM) issue during pretraining, given that Figure 2 suggests that forward propagation occurs three times before backpropagation. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete suggestions on how to manage GPU memory. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation or solution to this issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the GPU memory management during pretraining, suggesting that the authors need to address the issue of out-of-memory (OOM) during pretraining. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about GPU memory management during pretraining, specifically regarding the number of forward propagations before backpropagation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about GPU memory management during pretraining, specifically regarding the number of forward propagations before backpropagation. This is a clear and actionable point that prompts the authors to clarify their approach to managing GPU memory, which is crucial for addressing the issue of out-of-memory (OOM) during pretraining. By asking for clarification, the comment provides the authors with a direct path to improving their draft. However, it could be more helpful if it offered suggestions on how to manage GPU memory more effectively or provided examples of similar approaches. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rewrite and improve the abstract, suggesting that it is not well written and difficult to understand the contributions. This feedback provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to enhance the clarity of their abstract. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Abstract\" and provides a specific issue with it, namely that it is not well written and difficult to understand the contributions. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly recommends rewriting and improving the abstract to enhance its clarity. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract is not well written and difficult to understand the contributions. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks specificity and does not offer guidance on how to improve the abstract, making it challenging for the authors to understand the exact issues and address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, noting that it is not well written and difficult to understand the contributions. It provides a clear and actionable suggestion to rewrite and improve the abstract, which is a crucial part of the paper. This feedback is valuable as it directs the authors to a specific area that needs attention and offers a concrete way to enhance the clarity and effectiveness of their abstract. However, the comment could be more helpful if it provided additional guidance on how to improve the abstract, such as suggesting specific language or structure changes. Overall, the comment is mostly helpful as it effectively guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that ADE is a dataset for image parsing and notes that it may be biased among different scenes, potentially favoring the performance of the proposed method. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this potential bias or whether it should be considered in their analysis. As a result, the comment lacks actionability, leaving the authors without a clear path forward.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ADE,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the dataset, noting that it may be biased among different scenes and favor the performance of the proposed method. This provides clear guidance on what needs to be addressed regarding the dataset used in the study. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that ADE, a dataset for image parsing, may be biased among different scenes and favor the performance of the proposed method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset used in the study, noting that ADE, a dataset for image parsing, may be biased among different scenes and favor the performance of the proposed method. This is a relevant observation that could impact the validity and generalizability of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or mitigate its impact on their analysis. While it points out a potential problem, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of two matrices in section 2.1.2 and suggests that the authors might explain why two matrices are used. It also points out that many matrices are not used in the following text. While the comment implies that the authors should clarify the purpose of using two matrices, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation or clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.1.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the use of two matrices and suggests that the authors explain why two matrices are used. Additionally, it points out that many matrices are not used in the following text, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the use of two matrices in section 2.1.2. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the use of two matrices in section 2.1.2, suggesting that the authors might explain why two matrices are used. It also points out that many matrices are not used in the following text. While the comment identifies a potential issue with the clarity of the paper, it lacks specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it prompts the authors to clarify the purpose of using two matrices, but it could be more beneficial with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors do not understand the statement about the semantics of the upsampled feature map being stronger than the original one. However, it does not provide any explicit or implicit suggestions for clarification or improvement. Without guidance on how to address this issue, the authors are left without a clear action to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the end of Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement about the semantics of the upsampled feature map being stronger than the original one, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the statement about the semantics of the upsampled feature map being stronger than the original one. However, it does not provide any reasoning, evidence, or examples to support or challenge this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a lack of clarity regarding the statement about the semantics of the upsampled feature map being stronger than the original one. This feedback is somewhat helpful as it identifies a specific area where the authors need to clarify their explanation. However, it does not provide any suggestions or guidance on how to improve the clarity or what aspects of the statement are unclear. While it highlights an area for improvement, the comment lacks depth and actionable advice, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should clarify the differences between their method and other methods used to predict user personality, such as the reference to a specific paper. While the comment implies that the authors should provide a comparison, it does not explicitly instruct them to do so or offer guidance on how to structure this comparison. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison but are not given specific details on how to execute this task. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should clarify the differences between their method and other methods used to predict user personality, such as a reference to a specific paper. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a comparison with other methods, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should clarify the differences between their method and other methods used to predict user personality, such as a reference to a specific paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate why these differences need to be clarified. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should clarify the differences between their method and other methods used to predict user personality, such as a reference to a specific paper. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a comparison with other methods. However, the comment lacks specific guidance on how to structure this comparison or what aspects to focus on. While it provides a direction for improvement, it does not offer detailed suggestions or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the clarity of the rationale behind the choice of tuning parameters in LoRA, specifically the basis and coordinate selection. It questions the theoretical basis for this choice and suggests that the authors should consider alternative approaches. However, the comment does not provide explicit guidance on how to address these concerns or what specific changes should be made. It lacks actionable steps or detailed suggestions, leaving the authors uncertain about how to improve their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the clarity of the rationale behind the choice of tuning parameters in LoRA, specifically the basis and coordinate selection. It questions the theoretical basis for this choice and suggests that the authors should consider alternative approaches. However, the comment does not specify which part of the paper discusses these tuning parameters, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this discussion is located, the comment lacks full grounding. It is specific in questioning the theoretical basis and suggesting alternative approaches, but it does not provide detailed guidance on how to address these concerns. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the theoretical basis of the tuning parameters in LoRA, specifically the choice of basis and coordinate selection. The reviewer questions why these choices would accelerate convergence, as theoretically, they should cover the same $X$ space. The comment also suggests that constant step size is sufficient but that step size tuning is still needed for the experiments. While the comment identifies a potential issue with the theoretical basis of the tuning parameters, it lacks specific examples or references to support the claim that the current tuning parameters are inappropriate. This makes the claim somewhat verifiable, as it provides a logical basis for questioning the choice of tuning parameters but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the theoretical basis of the tuning parameters in LoRA, specifically the choice of basis and coordinate selection. It questions why these choices would accelerate convergence, as theoretically, they should cover the same $X$ space. The reviewer also suggests that constant step size is sufficient but that step size tuning is still needed for the experiments. While the comment highlights a potential weakness in the theoretical foundation of the work, it lacks specific suggestions or guidance on how the authors might address this issue or improve their explanation. The feedback is somewhat helpful as it points out a potential area for improvement but does not provide actionable steps or detailed advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct more ablation studies or analyses on problems other than the shortest path problem, which is closely related to the experimental environments. This feedback implies that the authors should expand their analysis to include a broader range of problems, which would enhance the credibility and generalizability of their findings. However, the comment does not provide specific guidance on which problems to focus on or how to conduct these analyses. While the action is implicit, it is clear that the authors need to broaden their analysis, but the lack of concrete details makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"most experimental environments\" and \"the design of architecture (PathGNN),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests conducting more ablation studies or analyses on problems other than the shortest path problem, which is closely related to the experimental environments. This provides clear guidance on what the authors need to address to enhance the credibility and generalizability of their findings. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experimental environments are closely related to the shortest path problem, which is addressed by the design of the architecture (PathGNN). The comment recommends conducting more ablation studies or analyses on problems other than the shortest path problem to enhance the credibility and generalizability of the findings. While the comment provides a logical reasoning for why this is necessary, it lacks specific examples or references to support the claim that other problems are more relevant. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that most experimental environments are closely related to the shortest path problem, which is addressed by the design of the architecture (PathGNN). It suggests that conducting more ablation studies or analyses on problems other than the shortest path problem would enhance the credibility and generalizability of the findings. This feedback is clear and actionable, as it provides a concrete suggestion for expanding the analysis to include a broader range of problems. However, it could be more helpful if it included specific examples or suggestions of which problems to focus on. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include more recent models, especially in multilingual settings or other languages beyond English, when comparing ControlSpeech with baselines. While the comment implies that the authors should expand their comparison to include additional models, it does not provide specific guidance on which models to include or how to integrate them into the existing comparison. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include more recent models, especially in multilingual settings or other languages beyond English, when comparing ControlSpeech with baselines. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the comparison section, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting the inclusion of more recent models, but without detailed guidance on which models to include or how to integrate them, it remains somewhat specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include more recent models, especially in multilingual settings or other languages beyond English, when comparing ControlSpeech with baselines. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these additional models are necessary or how they would enhance the comparison. Without such evidence or justification, the claim remains vague and lacks verifiability. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should include more recent models, especially in multilingual settings or other languages beyond English, when comparing ControlSpeech with baselines. This feedback is somewhat helpful as it identifies a potential area for improvement by expanding the comparison to include more relevant models. However, the comment lacks specific guidance on which models to include or how to integrate them into the existing comparison. While it points out a potential gap in the paper, it does not provide detailed suggestions or examples to help the authors address this issue effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of visualization for the learned context token, which shows the difference of context tokens of different groups. It also notes that the paper is simple and effective but lacks novelty and analysis for insight into the approach. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to visualize the context token or what specific insights should be analyzed. The action is implicit and somewhat vague, as the authors can infer that they need to include visualization and analysis but are not given specific steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of visualization for the learned context token, which shows the difference of context tokens of different groups. It also notes that the paper is simple and effective but lacks novelty and analysis for insight into the approach. However, the comment does not specify which part of the paper should include visualization or analysis, nor does it provide detailed guidance on how to address these issues. While the authors can infer that the visualization and analysis sections might be relevant, the comment lacks specificity and grounding, making it difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper is \"simple and effective\" but lacks novelty and analysis for insight into the approach. The comment suggests that the lack of visualization for the learned context token, which shows the difference of context tokens of different groups, contributes to this limitation. However, the comment does not provide specific examples or references to support the claim that the paper is lacking in novelty or analysis. The reasoning is somewhat vague, leaving the authors to infer the need for more detailed analysis or visualization. Therefore, the comment is somewhat verifiable, as it provides a general direction for improvement but lacks specific evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of visualization for the learned context token, which shows the difference of context tokens of different groups. It also notes that the paper is simple and effective but lacks novelty and analysis for insight into the approach. This feedback is somewhat helpful as it highlights a gap in the paper\\'s visualization and analysis, providing the authors with a clear direction for enhancing the draft. However, the comment could be more helpful if it offered specific suggestions on how to visualize the context token or what insights should be analyzed to enhance the novelty and depth of the paper. Overall, the comment provides some guidance but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental section should include results for other models besides MetaOptNet to emphasize the generality of the method and demonstrate its ability to improve several baseline models. This feedback provides a clear and explicit action for the authors to take, which is to include results for additional models. The comment also specifies the importance of these results to strengthen the paper. However, it does not provide detailed guidance on which models should be included or how to present these results effectively. While the action is clear, the lack of specific instructions on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for results on other models besides MetaOptNet to emphasize the generality of the method and demonstrate its ability to improve several baseline models. This provides clear guidance on what the authors should do to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experimental section lacks robustness and generalizability due to the limited comparison to other models besides MetaOptNet. The comment provides a logical reasoning by emphasizing the importance of demonstrating the method's effectiveness on multiple models to enhance its generality and credibility. However, the comment does not provide specific examples or references to support the claim that the current results are insufficient. This makes the claim somewhat verifiable, as the authors would need to infer the need for broader comparisons themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern with the experimental section, specifically the limited comparison to other models besides MetaOptNet. It suggests that reporting results for these additional models would enhance the generality of the method and demonstrate its ability to improve several baseline models. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by expanding the experimental section. However, the comment could be more helpful if it offered suggestions on which models to include or how to effectively present these results. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their experimental section.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper should include a more extensive comparison by including well-established methods like FTML[1] and LFW[2]. This provides a clear and direct action for the authors to take, as it specifies exactly what additional comparisons are needed to enhance the evaluation of their proposed method. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a more extensive comparison by including well-established methods like FTML[1] and LFW[2]. However, it does not specify which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors can infer that it relates to the evaluation or comparison sections, but this inference is not as direct as it could be. The comment is specific in suggesting the inclusion of additional methods for comparison, but it lacks full grounding as it does not explicitly mention the sections where these changes should be made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparison by including well-established methods like FTML[1] and LFW[2]. This claim is somewhat verifiable as it provides a logical reasoning for why broader comparisons would enhance the evaluation of the proposed method. However, the comment lacks specific examples or references to these methods, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically the lack of a more extensive comparison with well-established methods like FTML[1] and LFW[2]. This feedback is clear and actionable, as it suggests that broadening the comparison would provide a more comprehensive evaluation of the proposed method's strengths and weaknesses. By suggesting specific methods to include, the comment offers a concrete direction for improvement, making it highly helpful. However, it could be more beneficial if it provided additional guidance on how to interpret or analyze these comparisons. Overall, the comment is highly helpful as it effectively guides the authors on how to enhance their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the proposed CRF variants underperform the hierarchical transformers (HiTRF) in both the main dataset and the dataset discussed in Appendix D. It suggests that the focus of the paper should be downgraded due to this performance gap. Additionally, it points out that location embeddings seem to provide additional information on the main dataset but not in the extra dataset (Appendix D). The comment implies that the authors should discuss this observation in the paper. However, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to address the issues. The actions are implicit and somewhat vague, leaving the authors with a general idea of what needs to be improved but without detailed guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed CRF variants\" and \"hierarchical transformers (HiTRF)\" in the main dataset and the \"dataset discussed in Appendix D,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the CRF variants underperform the hierarchical transformers and that location embeddings seem to provide additional information on the main dataset but not in the extra dataset. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed CRF variants underperform the hierarchical transformers (HiTRF) in both the main dataset and the dataset discussed in Appendix D. It also notes that location embeddings seem to provide additional information on the main dataset but not in the extra dataset (Appendix D). This provides some evidence for the claim, as it suggests that the CRF variants may not be as effective as expected. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to conduct their own analysis or provide additional evidence to fully verify the claim. Therefore, the comment is somewhat verifiable, as it provides some support but requires further elaboration.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the performance of the proposed CRF variants compared to hierarchical transformers (HiTRF), both in the main dataset and the dataset discussed in Appendix D. It highlights that location embeddings seem to provide additional information on the main dataset but not in the extra dataset (Appendix D), which suggests that they may be useful for specific types of datasets only. The comment also points out that the focus of the paper should be downgraded due to this performance gap. However, it does not provide specific suggestions or guidance on how the authors might address these issues or discuss the implications of the findings. While the comment identifies important areas for improvement, it lacks actionable advice, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the impact of the training-testing inconsistency is not clear. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects of the training-testing inconsistency need clarification. Without guidance on how to improve the clarity or what aspects to focus on, the authors are left without actionable steps to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper discusses the training-testing inconsistency. Without specific references to sections, figures, or other elements, the authors cannot confidently determine where this issue is addressed. Additionally, the comment lacks specificity as it does not provide details on what aspects of the training-testing inconsistency are unclear or how they impact the paper. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the impact of the training-testing inconsistency is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area of concern regarding the clarity of the impact of the training-testing inconsistency. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what aspects of the training-testing inconsistency need clarification. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the unclear condition for y membership and claims that are not adequately supported. However, it does not provide explicit guidance on how to address these issues. The comment implies that the condition should be clarified, but it does not specify what exactly needs to be clarified or how to improve the claims. Additionally, it does not offer suggestions on how to better support the claims or provide examples of what should be included. As a result, the authors are left with a vague understanding of what needs to be done to improve their draft, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the condition for y membership and claims that are not adequately supported. It provides some level of detail by mentioning the sets S and the second line after Eq., which allows the authors to identify the parts of the paper being addressed. However, the comment lacks specificity in terms of what needs to be clarified regarding the condition for y membership or how to better support the claims. Without explicit guidance or examples, the authors may find it challenging to address these issues effectively. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the condition for y membership is unclear and that some claims are not adequately supported. However, it does not provide specific examples or detailed reasoning to support these claims. The lack of supporting evidence or examples makes it difficult for the authors to understand and address the issues raised. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues: the unclear condition for y membership and claims that are not adequately supported. It mentions that the sets S are disjoint, as defined above, which could be a source of confusion regarding the condition for y membership. Additionally, it points out that some claims are not backed up, without further elaboration on which claims are lacking support. While the comment highlights areas that need clarification and improvement, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it directs the authors\\' attention to specific areas needing attention, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that certain key references that are highly related are not compared or explained. However, it does not provide specific guidance on which references should be compared or how they should be explained. The action is implicit and vague, as the authors are left to infer that they need to address this issue but without clear instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the comparison of key references that are highly related but not compared or explained. However, it does not specify which references are being referred to, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. The comment is specific in identifying the issue of missing comparisons, but it lacks grounding as it does not specify the exact references or sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that certain key references that are highly related are not compared or explained. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand which references are being referred to. Without concrete evidence or examples, the claim lacks verifiability, as it does not allow the authors to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that certain key references that are highly related are not compared or explained. This feedback is clear and actionable, as it points out a specific area where the authors need to provide more detail or analysis. However, the comment could be more helpful if it suggested specific references or examples that should be compared or explained. Despite this, the feedback is somewhat helpful as it directs the authors to a critical area needing improvement, providing them with a clear direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a concern with the analysis of SCL in section 5.2, specifically regarding the few-shot ability. It points out that the paper claims a more regularized representation space by SCL may result in better generalization ability in few-shot scenarios, but the results in Figure 7(c) and (d) do not meet the authors\\' expectations. The comment suggests that the authors should check if COCO-LM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. While the comment implies that the authors should investigate this further, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.2\" and \"Figure 7(c) and (d),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the analysis of SCL regarding few-shot ability, pointing out that the results in Figure 7(c) and (d) do not meet the authors\\' expectations and suggesting that the authors investigate the benefits of COCO-LM for sentence retrieval tasks. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of SCL in section 5.2 regarding few-shot ability is not convincing. It suggests that the paper\\'s claim about a more regularized representation space by SCL leading to better generalization ability in few-shot scenarios is not supported by the results in Figure 7(c) and (d), where COCO-LM achieves more improvements with fewer labels and the improvements gradually disappear with more labels. The reviewer also suggests that the authors should investigate whether COCO-LM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. The comment provides a logical reasoning and specific examples to support the claim, making it mostly verifiable. However, it could be strengthened by referencing specific results or studies that demonstrate the expected behavior of SCL in few-shot scenarios. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the analysis of SCL in section 5.2, regarding the few-shot ability. It points out that the paper\\'s claim about a more regularized representation space by SCL leading to better generalization ability in few-shot scenarios is not supported by the results in Figure 7(c) and (d), where COCO-LM achieves more improvements with fewer labels and the improvements gradually disappear with more labels. The comment also suggests that the authors should investigate whether COCO-LM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. This feedback is clear and actionable, as it directs the authors to reconsider their claims and provides a specific area for further exploration. However, it could be more helpful if it offered suggestions on how to address the identified issues or provided additional context on why the results are not convincing. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that conducting more experiments on other LLMs would demonstrate the generalization of the proposed framework. While this point implies that the authors should conduct additional experiments, it does not provide specific guidance on which LLMs to focus on or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more experiments but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments on other LLMs to demonstrate the generalization of the proposed framework. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of generalization. Without explicit references to sections or specific elements, the authors cannot confidently determine the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what additional experiments should be conducted or how they would demonstrate the generalization of the framework. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests conducting more experiments on other LLMs to demonstrate the generalization of the proposed framework. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting more experiments on other LLMs to demonstrate the generalization of the proposed framework. While this is a valid suggestion, it lacks specificity and does not provide detailed guidance on which LLMs to focus on or how to conduct these additional experiments. The comment could be more helpful if it included examples of other LLMs or suggested specific experiments to conduct. As it stands, the feedback provides a general direction but does not offer actionable steps for improvement, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors need to clarify what is meant by \"short\" and \"long\" videos to determine the downsample layers. It also recommends an apple-apple comparison of SOTA VLM/Video-LLM outputs for the qualitative examples added. While the comment provides a clear action for the authors to take, it does not specify how to conduct the apple-apple comparison or what specific qualitative examples should be included. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified regarding the terms \"short\" and \"long\" videos and suggests an apple-apple comparison of SOTA VLM/Video-LLM outputs for qualitative examples. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors need to clarify what is meant by \"short\" and \"long\" videos to determine the downsample layers. It also recommends an apple-apple comparison of SOTA VLM/Video-LLM outputs for the qualitative examples added. While the comment provides a logical suggestion for improving clarity, it lacks specific examples or references to support the claim that an apple-apple comparison is necessary. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and implement the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors clarify what is meant by \"short\" and \"long\" videos to determine the downsample layers. It also recommends an apple-apple comparison of SOTA VLM/Video-LLM outputs for the qualitative examples added, which could help the authors better understand and contextualize their work. This feedback is clear and provides a concrete direction for improvement, making it mostly helpful. However, it could be more helpful if it included specific examples or guidance on how to conduct the apple-apple comparison. Overall, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation in the efficiency of the method, specifically the time taken to generate multiple objects, depending on the number of objects. It suggests that this could be a significant issue, especially for scenes with a high number of objects or complex interactions. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the efficiency of their method. The action is implicit and somewhat vague, as the authors can infer that they need to consider the efficiency aspect but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the paper discusses the time taken to generate multiple objects, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the potential limitation in terms of efficiency, especially for scenes with a high number of objects or complex interactions. This provides clear guidance on what needs to be addressed in terms of efficiency. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that generating multiple objects takes longer, depending on the number of objects, indicating a potential limitation in terms of efficiency. This is a factual observation based on the paper\\'s content. However, the comment lacks specific examples or detailed reasoning to support the claim that this limitation is significant or how it affects the overall performance of the method. Without additional context or evidence, the claim remains somewhat verifiable, as it provides a general observation but lacks depth and specificity. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the efficiency of the method, specifically the time taken to generate multiple objects, depending on the number of objects. It suggests that this could be a significant issue, especially for scenes with a high number of objects or complex interactions. While the comment highlights an important aspect of the paper, it lacks specific suggestions or guidance on how the authors might address this limitation or improve the efficiency of their method. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the technical contribution is thin and recommends that the authors focus on finding additional applications and evaluating the approach more deeply. It also suggests that tasks would help to find additional properties of the representation that could be emphasized in future versions, increasing the manuscript's value. While the comment provides a clear direction for the authors to take, it lacks specific guidance on how to find additional applications or what specific tasks to evaluate. The action is explicit but somewhat vague, as the authors know they need to explore additional applications but may not be entirely sure how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"technical contribution\" and the \"interpolative decomposition used,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the algorithm proposed may be considered incremental and recommends focusing on finding additional applications and evaluating the approach more deeply. The comment provides specific guidance on how to enhance the manuscript by suggesting tasks that could help find additional properties of the representation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical contribution is \"thin\" and suggests that the algorithm proposed may be considered incremental due to the use of interpolative decomposition. The reviewer recommends focusing on finding additional applications and evaluating the approach more deeply to enhance the manuscript's value. While the comment provides a logical reasoning for the need to explore additional applications, it lacks specific examples or references to support the claim that the algorithm is incremental. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the technical contribution of the paper, suggesting that the algorithm proposed may be considered incremental due to the use of interpolative decomposition. It recommends that the authors focus on finding additional applications and evaluating the approach more deeply to enhance the manuscript's value. This feedback is clear and actionable, providing specific guidance on how the authors can improve their work by exploring additional applications and evaluating the approach. However, the comment could be more helpful if it offered specific examples or suggestions for these additional applications or tasks. Overall, the comment is mostly helpful as it directs the authors toward a meaningful area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for information about the neural network library used for implementing the system, noting the lack of details on the implementation. This is a clear and direct request, providing the authors with a specific action to take by requesting more information about the implementation. The comment is specific and provides a concrete action for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly asks for information about the neural network library used for implementing the system, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what information is missing, namely details on the implementation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for information about the neural network library used for implementing the system. It does not express an opinion, judgment, or suggestion that requires verification. It is a factual inquiry seeking clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors could provide more detailed information, namely the neural network library used for implementing the system. This feedback is clear and actionable, as it directs the authors to include specific details about the implementation, which could enhance the transparency and reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific areas where the descriptions are unclear, such as undefined math notations and missing details in figure illustrations. It provides a direct reference to the reviewer\\'s questions, which offers a clear path for the authors to follow in order to improve their draft. By specifying the exact issues and providing a reference to additional questions, the comment offers concrete guidance on what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment identifies specific areas where the descriptions are unclear, such as undefined math notations and missing details in figure illustrations. It provides a reference to additional questions, which allows the authors to pinpoint the exact parts of the paper that need clarification. However, the comment does not specify which sections or figures are affected by these issues, making it weakly grounded. The specificity of the comment is high, as it clearly identifies what needs to be addressed, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some descriptions are unclear, specifically mentioning undefined math notations and missing details in figure illustrations. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issues. Without detailed examples or references, the claim lacks verifiability, as it does not provide sufficient evidence or justification for the authors to address the issues effectively. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas where the descriptions are unclear, such as undefined math notations and missing details in figure illustrations. It provides a direct reference to additional questions, which offers the authors a clear path for improvement. By highlighting these specific issues, the comment offers actionable feedback that can help the authors enhance the clarity and comprehensibility of their draft. However, the comment could be more helpful if it provided more detailed guidance on how to address these issues or suggested specific improvements. Overall, the comment is mostly helpful as it directs the authors\\' attention to specific areas needing clarification, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should mention the meaning of the notation \\nu in the text, in addition to its explanation in Algorithm 1. This is a clear and direct action that the authors can easily implement by adding a brief explanation in the text. The comment provides concrete guidance on what needs to be done to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the meaning of the notation \\nu in the text. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the explanation of notation \\nu in Algorithm 1 is insufficient, as it is not mentioned in the text. However, the comment does not provide any reasoning or evidence to support why this omission is problematic or how it affects the understanding of the paper. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the explanation of notation \\nu in Algorithm 1 is provided but not mentioned in the text itself. This feedback is clear and actionable, as it directs the authors to include the meaning of \\nu in the text to ensure consistency and clarity. By addressing this point, the authors can improve the readability and comprehensibility of their draft. However, the comment could be more helpful if it provided additional context or examples of how the notation is used in the algorithm. Overall, the comment is mostly helpful as it effectively guides the authors toward a specific improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises an interesting finding from appendix A.4, where using noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9. It questions whether the model is underfit due to the accuracy of the pseudo-labels, suggesting that the noise robust loss might not be effective in this case. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their model. It lacks actionable details, such as recommending specific modifications or experiments to test the robustness of the noise robust loss. As a result, the authors are left without a clear path forward, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"appendix A.4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance difference between using noise robust loss on pseudo-labels and positive learning from Eq 9, and it raises an interesting point about the potential benefits of using noise robust loss with pseudo-labels. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises an interesting observation about the performance difference between using noise robust loss on pseudo-labels and positive learning from Eq 9. It questions whether the model is underfit due to the accuracy of the pseudo-labels, suggesting that the noise robust loss might not be effective in this case. The comment provides a logical reasoning and an observation that could be further explored, but it lacks specific examples or references to support the claim. This makes the comment somewhat verifiable, as it provides a basis for the claim but requires additional evidence or explanation to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises an interesting observation about the performance difference between using noise robust loss on pseudo-labels and positive learning from Eq 9. It questions whether the model is underfit due to the accuracy of the pseudo-labels, suggesting that the noise robust loss might not be effective in this case. This feedback prompts the authors to consider the potential implications of their model's accuracy on the robustness of the loss function. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their model. While it provides a valuable insight, it could be more helpful with additional actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the claim made in the paper regarding the impact of an additional exponential on runtime. It expresses confusion about why this would significantly increase runtime, suggesting that the authors should clarify this point. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the explanation. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detail or clarification regarding the runtime impact. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim about the impact of an additional exponential on runtime, indicating that the authors need to clarify this point. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim about the impact of an additional exponential on runtime, expressing confusion about why this would significantly increase runtime. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or the reviewer\\'s perspective. This lack of justification makes the claim unverifiable, as it does not offer sufficient evidence or explanation to support the critique. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the claim about the impact of an additional exponential on runtime, expressing confusion about why this would significantly increase runtime. It highlights a potential weakness in the argument and prompts the authors to clarify or provide more evidence to support their claim. While the comment identifies a specific area of concern, it lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their explanation. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide actionable feedback for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the lack of comparison with related works, specifically mentioning \"Rubi\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies.\" It questions the improvements to the proposed methods and suggests that the experiments are insufficient compared to state-of-the-art (SOTA) methods. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific improvements should be made. It lacks actionable details, such as recommending specific comparisons or improvements to the experimental setup. As a result, the authors are left without clear direction on how to address the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Rubi\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the improvements to the proposed methods and suggests a comparison with related works, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the lack of comparison with related works, specifically mentioning \"Rubi\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies.\" It questions the improvements to the proposed methods and suggests that the experiments are insufficient compared to state-of-the-art (SOTA) methods. However, the comment lacks specific examples or detailed reasoning to support why these comparisons are necessary or how the proposed methods could be improved. The lack of detailed justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically questioning the lack of comparison with related works, such as \"Rubi\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies.\" It highlights the potential inadequacy of the experiments compared to state-of-the-art (SOTA) methods. While the comment raises an important point about the need for comparisons, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their experiments. The feedback is somewhat helpful as it points out a critical area for improvement, but it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed method enhances performance, but it is not surprising because it introduces more learnable parameters, including the temperature. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes could be made to improve the surprise factor. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the experiments show the proposed method enhances performance, but it is not surprising because it introduces more learnable parameters, including the temperature. However, it does not specify which part of the paper this observation is based on, such as specific experiments or sections where the temperature is introduced. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. Additionally, the comment lacks specificity in terms of what aspects of the introduction of learnable parameters are problematic or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed method enhances performance but is not surprising because it introduces more learnable parameters, including the temperature. However, the comment lacks specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the proposed method enhances performance but is not surprising due to the introduction of more learnable parameters, including the temperature. While it points out a potential limitation in the novelty of the approach, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the surprise factor. The comment lacks actionable feedback or detailed advice, leaving the authors without a clear path forward. Therefore, it is barely helpful, as it identifies a potential weakness but does not offer concrete steps for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the inspiration from neuroscience research seems unnecessary to the main processing pipeline of the main work, making it distracting. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to improve the focus of the work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the inspiration from neuroscience research seems unnecessary to the main processing pipeline of the main work, making it distracting. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. The authors might infer that it relates to the introduction or discussion sections, but this inference is not direct. The comment is specific in its critique of the unnecessary inspiration, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the inspiration from neuroscience research seems unnecessary to the main processing pipeline of the main work, making it distracting. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the inspiration from neuroscience research seems unnecessary to the main processing pipeline of the work, making it distracting. While it identifies a potential issue with the paper\\'s focus, it lacks specificity and does not provide actionable feedback or suggestions on how to address this concern. The comment does not offer guidance on how to improve the focus or clarify the relevance of the neuroscience inspiration to the main work. As a result, the feedback is not particularly helpful, as it does not provide the authors with clear steps to enhance their draft. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to add information about the source dataset in the caption of Table 3, noting that the image and table captions should contain all necessary information about the experiment. This feedback is clear and provides a direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of information about the source dataset in the caption. This provides clear guidance on how to improve the paper. Therefore, the comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the caption of Table 3 is unclear about the source dataset used. It suggests adding information about the dataset in the caption to avoid the reader having to search for it in the main text. While the comment highlights a specific issue, it lacks detailed reasoning or references to support why this information is crucial or how it would enhance the clarity of the paper. The suggestion is somewhat verifiable, as it provides a clear direction for improvement but could benefit from more detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of information in Table 3, noting that the caption does not provide sufficient information about the source dataset used. It suggests that the image and table captions should contain all necessary information about the experiment, making it easier for the reader to understand the context and avoid searching for details in the main text. This feedback is clear and actionable, providing the authors with a direct and concrete way to improve the clarity and accessibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information in the caption or provided examples of how similar studies might present their datasets. Overall, the comment is mostly helpful, as it effectively guides the authors on how to enhance the clarity and comprehensibility of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the lack of explicit description of the specific architectures used in the paper, particularly the value network, policy networks, and uncertainty-aware networks. This feedback implies that the authors should provide more detailed descriptions of these architectures to enable readers to replicate and evaluate the applicability of the approach. However, the comment does not explicitly instruct the authors to add these descriptions or specify how they should be presented. While the action is implied, it is not as concrete as it could be, as the authors may not know exactly how to implement the suggested changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the lack of explicit description of specific architectures used in the paper, particularly the value network, policy networks, and uncertainty-aware networks. This provides a clear indication of what is missing in the paper, allowing the authors to identify the relevant sections that need attention. However, the comment does not specify which sections or parts of the paper should include this information, making it weakly grounded. The comment is specific in detailing what is missing, but it lacks full grounding because it does not pinpoint the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks explicit descriptions of the specific architectures used, particularly the value network, policy networks, and uncertainty-aware networks. This claim is somewhat verifiable as it highlights a gap in the paper\\'s description, which could make it difficult for readers to replicate or evaluate the approach. However, the comment does not provide specific examples or references to similar works that might include such descriptions, which would strengthen the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of explicit descriptions of the specific architectures used, particularly the value network, policy networks, and uncertainty-aware networks. This is a critical oversight, as it makes it difficult for readers to replicate and evaluate the applicability of the approach presented in the paper. The comment highlights a crucial area for improvement, providing a clear and actionable suggestion for the authors to enhance the clarity and reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to present these architectures or provided examples of how similar architectures have been described in other works. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out several assumptions that may render EMCTS inapplicable to real complex problems. It specifically mentions that the transition model P is assumed to be true, that Theorem 1 requires $Q^{\\pi}$ to be linear, and that learned models are assumed to be consistent. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address these assumptions or what specific changes should be made to improve the applicability of EMCTS. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific assumptions made in the paper, such as the assumption that the transition model P is true and the requirement for $Q^{\\pi}$ to be linear in Theorem 1. It also mentions that learned models are assumed to be consistent, which may not be reasonable in many cases. However, the comment does not specify which part of the paper these assumptions are discussed in, making it weakly grounded. The comment is specific in detailing the assumptions that may render EMCTS inapplicable to real complex problems. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some assumptions in the paper may render EMCTS inapplicable to real complex problems. It specifically mentions that the transition model P is assumed to be true, that Theorem 1 requires $Q^{\\pi}$ to be linear, and that learned models are assumed to be consistent. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the exact nature of the assumptions and their implications. Without detailed reasoning or evidence, the claim is not fully verifiable, as it relies heavily on the reader to infer the significance of the assumptions. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific assumptions made in the paper that may render EMCTS inapplicable to real complex problems. It points out that the transition model P is assumed to be true, that Theorem 1 requires $Q^{\\pi}$ to be linear, and that learned models are assumed to be consistent. These assumptions are considered not reasonable in many cases, as they may not hold true in practical scenarios. However, the comment does not provide actionable feedback or suggestions on how the authors might address these issues or improve their work. It lacks depth and specificity, leaving the authors without clear guidance on how to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that explicitness (E) and size (S) may be highly related to the given dataset, and that the different capacity requirements in the third paragraph may be due to input modality differences. It also proposes that evaluating disentanglement should provide enough capacity and training time, which is powerful enough to achieve the DCI evaluation. If the capacity of probing needs to be evaluated, the comment suggests considering the training time, cost, and learning rate as they may influence the final value of DCI. While the comment provides a clear direction for the authors to consider the relationship between explicitness, size, and capacity requirements, it does not explicitly instruct them on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"3rd paragraph,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion about the relationship between explicitness (E) and size (S) and the capacity requirements, as well as the need to evaluate the capacity of probing and its potential influence on the final value of DCI. The comment offers a detailed analysis of the dataset and its capacity requirements, providing specific guidance on how to address these issues. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the relationship between explicitness (E) and size (S) and the capacity requirements in the third paragraph, suggesting that these may be highly related to the given dataset. The comment also provides a logical reasoning by explaining that the different capacity requirements could be due to input modality differences. The reviewer suggests that evaluating disentanglement should provide enough capacity and training time, which is powerful enough to achieve the DCI evaluation. However, the comment lacks specific examples or references to support the claim about the influence of input modality differences on capacity requirements. While the reasoning is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed analysis of the relationship between explicitness (E) and size (S) and the capacity requirements in the third paragraph, suggesting that these may be highly related to the given dataset. It also offers a logical explanation for the different capacity requirements, attributing them to input modality differences. The comment further suggests that evaluating disentanglement should provide enough capacity and training time, which is powerful enough to achieve the DCI evaluation. If the capacity of probing needs to be evaluated, the comment advises considering the training time, cost, and learning rate, as they may influence the final value of DCI. This feedback is clear and actionable, providing the authors with specific insights and suggestions on how to improve their draft. By addressing these points, the authors can enhance the clarity and robustness of their evaluation. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper title does not need to include abbreviations. This provides a clear and direct action for the authors to take, ensuring that the title is concise and informative without including unnecessary abbreviations. The comment is specific and provides a concrete action for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper title, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of abbreviations in the title. This provides clear guidance on what the authors should change to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper title does not need to include abbreviations. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is the case. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and direct suggestion regarding the paper title, stating that it does not need to include abbreviations. This feedback is actionable and specific, as it offers a concrete way for the authors to improve the clarity and simplicity of their title. By removing unnecessary abbreviations, the authors can enhance the readability and accessibility of their paper, making the comment highly helpful. However, it could be more helpful if it provided additional guidance on how to choose an appropriate title or suggested specific abbreviations to remove. Overall, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors mention the ability of the discriminator to transfer to other tasks and domains without further training, as well as its effectiveness with limited data. Additionally, the reviewer suggests that the authors mention the observation at L400, where the discriminator can be small, as a significant insight. While the comment implies specific actions, such as mentioning these points and highlighting the significance of the observation, it does not provide explicit instructions on how to implement these suggestions. The action is concrete but somewhat vague, as the authors need to infer the exact details of how to incorporate these points into their draft. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors mention the ability of the discriminator to transfer to other tasks and domains without further training, as well as its effectiveness with limited data. It also mentions the observation at L400, where the discriminator can be small, as a significant insight. However, the comment does not specify which part of the paper these observations should be discussed in, nor does it provide detailed guidance on how to incorporate these points into the draft. While the authors can infer that the comments relate to the discriminator section, the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting the importance of these observations, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the discriminator can transfer to other tasks and domains without further training and that it can be effectively trained with limited data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand the basis of these claims or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors mention the ability of the discriminator to transfer to other tasks and domains without further training, as well as its effectiveness with limited data. It also highlights the observation at L400, where the discriminator can be small, as a significant insight. While the comment provides some valuable insights and suggestions, it lacks depth and does not offer specific guidance on how to incorporate these points into the draft. The authors are given a general direction but are not provided with detailed instructions or examples on how to effectively implement these suggestions. Therefore, the comment is somewhat helpful, as it provides some actionable feedback but could be more comprehensive to be fully helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add the \"SOTA GNN-QE\" as a baseline, which is the closest work in terms of components to their approach. This action is clear and concrete, as it specifies exactly what needs to be done to improve the draft. The comment also provides a rationale for why this baseline should be included, making it easy for the authors to understand and implement the suggested change. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"SOTA GNN-QE,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the SOTA GNN-QE as a baseline. This provides clear guidance on what the authors need to add to their work. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the current SOTA GNN-QE is omitted from the baselines, despite being the closest work in terms of components to the approach being discussed. This claim is somewhat verifiable as it provides a logical reasoning for why the baseline should be included, but it lacks specific examples or references to support the claim. The authors would need to infer the relevance of the SOTA GNN-QE to their work and understand the importance of including it as a baseline. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, noting that the current SOTA GNN-QE is not included as a baseline, despite being the closest work in terms of components to the approach being discussed. This feedback is clear and actionable, as it directly instructs the authors to include the SOTA GNN-QE as a baseline for comparison. By addressing this omission, the authors can enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided additional context or justification for why the SOTA GNN-QE is important to include. Overall, the comment is mostly helpful, as it effectively guides the authors in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the potential limitations of the pretraining data in allowing GPT-2 to understand language, and questions the reasonableness of the setting. It suggests that the authors should address these concerns to prove the validity of their findings. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these concerns or what specific actions the authors should take. The feedback is somewhat actionable as it highlights areas that need attention, but it lacks concrete steps for improvement.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the potential limitations of the pretraining data in allowing GPT-2 to understand language, and questions the reasonableness of the setting. It suggests that the authors should address these concerns to prove the validity of their findings. However, the comment does not specify which part of the paper these concerns are related to, making it weakly grounded. The comment is specific in detailing the concerns and what needs to be addressed, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the potential limitations of the pretraining data in allowing GPT-2 to understand language, questioning the reasonableness of the setting. It suggests that facts may have been learned in GPT-2 before training. The comment is somewhat verifiable as it provides a logical reasoning for questioning the validity of the findings, but it lacks specific examples, references, or detailed evidence to fully substantiate the claim. The authors would need to address these concerns to strengthen their argument, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper regarding the role of pretraining data in allowing GPT-2 to understand language. It questions the reasonableness of the setting and suggests that facts may have been learned in GPT-2 before training. While the comment highlights an interesting area for consideration, it does not provide specific guidance or suggestions on how the authors might address these concerns or improve their work. The feedback is somewhat helpful as it points out a potential weakness but lacks actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific areas where the proposed method is not thoroughly explained, such as the computation of some terms in (4) and the optimization algorithm for calculating $p(x_k|d)$. It provides a clear and explicit action for the authors to take, which is to explain these missing details. The comment also suggests a criterion for what should be excluded from detailed explanation, which is when the idea is extremely obvious. This feedback is concrete and provides a clear direction for the authors to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the computation of some terms in (4)\" and \"the optimization algorithm for calculating $p(x_k|d)$,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be explained, such as the computation of terms and the optimization algorithm, and suggests a criterion for what should be excluded from detailed explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not thoroughly explained, specifically mentioning the missing computation of some terms in (4) and the optimization algorithm for calculating $p(x_k|d)$. The reviewer provides a logical reasoning by suggesting that if the method is expressed using math formulas, every term should be clearly explained except for cases where it is extremely obvious. This reasoning is somewhat verifiable as it provides a general guideline for what should be included in the explanation, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas where the proposed method is not thoroughly explained, such as the computation of some terms in (4) and the optimization algorithm for calculating $p(x_k|d)$. It provides a clear and actionable suggestion for the authors to clarify these missing details, which is crucial for ensuring the method's comprehensibility and reproducibility. The comment also offers a criterion for what should be excluded from detailed explanation, which is helpful in guiding the authors on what aspects to prioritize. However, the comment could be more helpful if it provided examples or additional guidance on how to clarify these points. Overall, the feedback is mostly helpful as it directs the authors to improve the clarity and completeness of their methodology section.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the implementation details for the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments are not provided. It also points out that the lack of implementation details makes it difficult to assess the fairness of comparisons with existing methods and even between $RAMP_{KL}$ and $RAMP_{W}$. The comment clearly identifies the need for a thorough description of the implementation details to address these issues. The action is explicit and concrete, as it specifies exactly what needs to be added to the paper to improve its reproducibility and fairness assessment. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly details what is missing, namely the implementation details and the lack of fairness assessment, which are crucial for reproducibility and assessing the significance of the experimental results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of implementation details and discretization used in the state coverage metric makes it difficult to assess the fairness of comparisons with existing methods and even between $RAMP_{KL}$ and $RAMP_{W}$. This claim is somewhat verifiable as it provides a logical reasoning for the need to include implementation details, but it lacks specific examples or references to support the assertion about the impact on fairness assessment. The comment could be strengthened by providing more detailed examples or references to similar studies that have addressed these issues. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper, noting that the implementation details for the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments are not provided. This lack of detail makes it difficult to reproduce or assess the fairness of comparisons with existing methods, as well as comparisons between $RAMP_{KL}$ and $RAMP_{W}$. The comment is clear and actionable, providing the authors with a specific and critical feedback on the need for a thorough description of the implementation details to address these issues. This guidance is valuable for improving the reproducibility and comprehensiveness of the experiments, which is essential for the overall contribution of the paper. Therefore, the comment is highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the use of a mixture of experts (MoE) for a task is not unusual, given its extensive application in various tasks such as general LLM, summarization, and machine translation. However, it also notes that the application of MoE in text detection is relatively new but not groundbreaking in terms of its fundamental idea. While the comment acknowledges the novelty of the application, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their work. The lack of actionable advice or concrete steps makes the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the concept of employing a mixture of experts (MoE) for a task, specifically noting its application in various tasks such as general LLM, summarization, and machine translation. It also acknowledges that the application of MoE in text detection is relatively new but not groundbreaking in terms of its fundamental idea. However, the comment does not specify which part of the paper discusses this concept or where it should be addressed. This lack of grounding and specificity makes it difficult for the authors to identify the exact area needing revision. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the concept of employing a mixture of experts (MoE) for a task is not unusual, given its extensive application in various tasks such as general LLM, summarization, and machine translation. The reviewer also acknowledges that the application of MoE in text detection is relatively new but not groundbreaking in terms of its fundamental idea. This claim is somewhat verifiable as it provides a rationale for the commonality of MoE applications, but it lacks specific examples or references to support the assertion that the concept is not groundbreaking. The authors might benefit from more detailed reasoning or references to substantiate the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the concept of employing a mixture of experts (MoE) for a task is not unusual, given its extensive application in various tasks such as general LLM, summarization, and machine translation. It also notes that the application of MoE in text detection is relatively new but not groundbreaking in terms of its fundamental idea. While the comment provides some context about the applicability of MoE, it lacks specific suggestions or actionable feedback for the authors to improve their draft. The authors are informed of the general applicability of MoE but are not guided on how to enhance their work or address potential weaknesses. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors make a claim about SpaceTGN achieving significant performance improvement but do not provide a statistical analysis to support this claim of significance. This feedback explicitly identifies the need for statistical analysis to substantiate the claim. However, it does not provide specific guidance on how to conduct the analysis or what statistical methods should be used. While the action is clear\u2014to include a statistical analysis\u2014the comment lacks concrete details on how to implement it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SpaceTGN\" and \"performance improvement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a statistical analysis to support the claim of significance. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors make a claim about SpaceTGN achieving significant performance improvement but do not provide a statistical analysis to support this claim of significance. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of a statistical analysis to support the claim of significant performance improvement made by the authors. This is a critical point as it undermines the credibility of the authors\\' claims. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending specific statistical methods or analyses to be used. While it highlights a significant gap in the paper, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential source of confusion regarding the excerpting versus reproducing of certain scores. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify this confusion or what specific changes should be made to address it. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential source of confusion regarding the excerpting versus reproducing of certain scores. However, it does not specify which part of the paper this confusion relates to, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment lacks specificity regarding the issue and does not provide any grounding by referencing specific sections or elements of the paper. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the excerpting versus reproducing of certain scores may cause confusion. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential source of confusion regarding the excerpting versus reproducing of certain scores, which could lead to misunderstandings in the paper. However, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might clarify this issue or address the confusion. Without detailed feedback or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it points out a potential issue but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more insight into how consistency models achieve novelty compared to previous generative models. It highlights a weakness and points out that this is also listed as a question in the paper. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of the novelty of consistency models. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"consistency models\" and \"generative models,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the novelty of the method and how consistency models differ from previous generative models. The comment highlights a weakness and provides a question for the authors to consider, making it clear and specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is \"somewhat simply applying consistency models in place of other generative models for learning target distributions,\" suggesting a lack of novelty. The reviewer supports this claim by pointing out that consistency models are a recent trend, implying that the method does not introduce significant innovation. However, the comment lacks specific examples or references to support the claim about the novelty of consistency models compared to previous generative models. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires more detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that the method is somewhat simple in its application of consistency models in place of other generative models for learning target distributions. It suggests that the authors should provide more insight into how consistency models achieve novelty compared to previous generative models. This feedback is clear and actionable, as it prompts the authors to address a specific area of concern and provide a deeper understanding of the method's novelty. However, the comment could be more helpful if it offered specific suggestions or examples of how the authors might address this issue. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation metric in Table 2 only uses MSE, which does not accurately reflect the accuracy of nowcasting. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether they should consider alternative metrics or how to incorporate them into the evaluation. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the evaluation metric only uses MSE, which does not accurately reflect the accuracy of nowcasting. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation metric in Table 2 only uses MSE, which does not accurately reflect the accuracy of nowcasting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why MSE is insufficient for evaluating nowcasting accuracy. Without additional context or examples, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation metric used in Table 2, noting that MSE alone does not accurately reflect the accuracy of nowcasting. This feedback is clear and actionable, as it highlights a gap in the evaluation methodology that the authors can address to improve the accuracy of their results. However, the comment could be more helpful if it suggested alternative metrics or methods for evaluating nowcasting accuracy. Despite this, the feedback provides valuable insights that can guide the authors in enhancing their draft. Therefore, the comment is rated as mostly helpful, consistent with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the benefit of FFA-LoRA on differential privacy (DP) is not well supported by empirical evaluation, specifically noting that the performance gap remains the same across various privacy budgets $\\\\epsilon$. The reviewer suggests that this empirical result suggests that the impact of DP noise is the same on both the vanilla LoRA and the proposed FFA-LoRA. While the comment identifies a gap in the empirical evaluation, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more comprehensive empirical evaluations to support their claims. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FFA-LoRA\" and \"differential privacy (DP)\" and provides specific details about the performance gap between the vanilla LoRA and the proposed FFA-LoRA across various privacy budgets $\\\\epsilon$. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the empirical evaluation, noting that the performance gap remains the same across different privacy budgets. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the benefit of FFA-LoRA on differential privacy (DP) is not well supported by empirical evaluation. It suggests that the performance gap remains the same across various privacy budgets $\\\\epsilon$, including $\\\\epsilon = 0$. This claim is somewhat verifiable as it provides a logical reasoning based on the empirical result, which suggests that the impact of DP noise is the same on both the vanilla LoRA and the proposed FFA-LoRA. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s empirical evaluation, noting that the benefit of FFA-LoRA on differential privacy (DP) is not well supported by the results. It points out that the performance gap remains the same across various privacy budgets $\\\\epsilon$, including $\\\\epsilon = 0$, suggesting that the impact of DP noise is the same on both the vanilla LoRA and the proposed FFA-LoRA. This feedback is clear and actionable, as it directs the authors to provide more comprehensive empirical evaluations to substantiate their claims. However, the comment could be more helpful if it offered suggestions on how to conduct these evaluations or what specific metrics to use. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should add Cap-CapNE-ClipNE-EA and Cap-CapNE-ClipNE-NE-EA according to the overview model of ENGINE. It also recommends providing more detailed analysis of the ablation results. This feedback is clear and provides specific actions for the authors to take, such as adding specific components and conducting more detailed analysis. The explicit nature of the suggestions and the concrete details on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study of ENGINE\" and suggests adding specific components, \"Cap-CapNE-ClipNE-EA\" and \"Cap-CapNE-ClipNE-NE-EA,\" according to the overview model of ENGINE. It also recommends providing more detailed analysis of the ablation results. This level of detail allows the authors to accurately identify the part of the paper being addressed. The comment is specific because it clearly specifies what needs to be added and why, providing clear guidance on how to improve the ablation study. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ablation study of ENGINE is incomplete and recommends adding specific components, \"Cap-CapNE-ClipNE-EA\" and \"Cap-CapNE-ClipNE-NE-EA,\" according to the overview model of ENGINE. The comment also recommends providing more detailed analysis of the ablation results. While the suggestion is based on logical reasoning and common knowledge about the structure of an ablation study, it lacks specific examples or references to support the claim that these components should be included. This makes the claim somewhat verifiable, as it provides a clear direction but requires further elaboration to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the ablation study of ENGINE, suggesting that the authors should add specific components, \"Cap-CapNE-ClipNE-EA\" and \"Cap-CapNE-ClipNE-NE-EA,\" according to the overview model of ENGINE. It also recommends providing more detailed analysis of the ablation results. This feedback is clear and actionable, as it offers specific suggestions for improving the ablation study by adding components and providing more detailed analysis. By addressing these points, the authors can enhance the comprehensiveness and depth of their ablation study, which is crucial for understanding the performance of their model. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the discrepancy in mode coverage between GDIM and DDGAN, suggesting that providing results on more challenging high-resolution datasets like LSUN and ImageNet would be beneficial. It also mentions that methods that work well with CIFAR-10/Celeb-64 might struggle with these datasets. While the comment implies that the authors should provide results on more challenging datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct experiments on more challenging datasets. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the discrepancy in mode coverage between GDIM and DDGAN, suggesting that providing results on more challenging high-resolution datasets like LSUN and ImageNet would be beneficial. It also mentions that methods that work well with CIFAR-10/Celeb-64 might struggle with these datasets. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the results or discussion sections where mode coverage is discussed. The comment is specific in its suggestion to provide results on more challenging datasets, but it lacks grounding as it does not explicitly reference a specific part of the paper. Therefore, this comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the discrepancy in mode coverage between GDIM and DDGAN, suggesting that providing results on more challenging high-resolution datasets like LSUN and ImageNet would be beneficial. The reviewer also mentions that methods that work well with CIFAR-10/Celeb-64 might struggle with these datasets. While the comment highlights a potential issue and suggests an area for improvement, it lacks specific examples or references to support the claim about the difficulty of working with CIFAR-10/Celeb-64. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the discrepancy in mode coverage between GDIM and DDGAN, suggesting that providing results on more challenging high-resolution datasets like LSUN and ImageNet would be beneficial. It also points out that methods that work well with CIFAR-10/Celeb-64 might struggle with these datasets. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting the inclusion of results on more challenging datasets. However, the comment could be more helpful if it provided specific guidance on how to address the issue or what specific aspects of the results should be considered. Overall, the comment offers a direction for improvement but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of the statement \"Each attribute of the table feature represents a scene\" from Section 5.1. While it identifies a potential confusion, it does not provide any explicit or implicit guidance on how the authors should clarify this statement or address the issue. The comment lacks actionable advice or suggestions, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of the statement \"Each attribute of the table feature represents a scene,\" which provides clear guidance on what needs clarification. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about a specific statement in the paper. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of a specific statement in the paper, \"Each attribute of the table feature represents a scene.\" This feedback is somewhat helpful as it prompts the authors to clarify a potentially confusing aspect of their work. However, it lacks depth and does not provide suggestions or guidance on how to improve the clarity or understanding of the statement. While it identifies a potential area for improvement, the comment could be more helpful by offering suggestions or additional context to enhance the clarity. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of an ablation study for the impact of token reweighting versus the logsumexp aggregation scheme. It suggests that the authors should provide a comparison between these methods, specifically asking how much better logsumexp is than direct addition. Additionally, it questions the compatibility of the token reweighting scheme with existing token-to-token classifiers like CTX and FRN, and whether the logsumexp aggregator compares favorably. While the comment provides explicit actions to take, such as conducting an ablation study and comparing the methods, it does not specify how to implement these actions. The authors are left with a clear understanding of what needs to be done but may need to infer the exact steps to execute the suggestions. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of an ablation study for the impact of token reweighting versus the logsumexp aggregation scheme. It also specifies the need for a comparison between these methods, such as basic prototype comparison with reweighted averages on each prototype. Additionally, it questions the compatibility of the token reweighting scheme with existing token-to-token classifiers like CTX and FRN. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the absence of an ablation study for the impact of token reweighting versus the logsumexp aggregation scheme. It suggests that the authors should provide a comparison between these methods, such as basic prototype comparison with reweighted averages on each prototype. The comment also questions the compatibility of the token reweighting scheme with existing token-to-token classifiers like CTX and FRN, and whether the logsumexp aggregator compares favorably. While the comment identifies a gap in the study and suggests potential areas for improvement, it lacks specific examples or references to support the claim about the superiority of logsumexp over direct addition. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of an ablation study for the impact of token reweighting versus the logsumexp aggregation scheme. It suggests that the authors should provide a comparison between these methods, such as basic prototype comparison with reweighted averages on each prototype. Additionally, it questions the compatibility of the token reweighting scheme with existing token-to-token classifiers like CTX and FRN, and whether the logsumexp aggregator compares favorably. This feedback is clear and actionable, providing the authors with specific areas to address in their draft. By addressing these points, the authors can enhance the comprehensiveness and robustness of their study. However, the comment could be more helpful if it offered additional suggestions or examples on how to conduct the ablation study or compare the methods. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper regarding the use of limited datasets for evaluating the effectiveness of ECGs. It suggests that the authors should consider using the large-scale datasets mentioned in [2] and references specific papers that discuss the use of such datasets. This feedback provides explicit guidance on what additional datasets should be considered and references specific works that could be relevant. However, it does not offer detailed instructions on how to incorporate these datasets or suggest specific ways to improve the evaluation process. While the action is clear, the comment could be more helpful with additional details on how to implement the suggestion. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"large-scale datasets\" mentioned in [2] and references specific papers that discuss the use of such datasets. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed by suggesting the inclusion of these datasets for evaluating the effectiveness of ECGs. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of five datasets is insufficient to evaluate the effectiveness of ECGs, suggesting that the large-scale datasets mentioned in [2] should be considered. The reviewer supports this claim by referencing specific papers that discuss the use of large-scale datasets in related work. This provides a logical basis for the claim and references external sources, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how these datasets could be used to enhance the evaluation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper regarding the use of limited datasets for evaluating the effectiveness of ECGs. It suggests that the authors should consider using the large-scale datasets mentioned in [2] and references specific papers that discuss the use of such datasets. This feedback is clear and actionable, as it provides a concrete suggestion for improving the evaluation process by incorporating additional datasets. However, the comment could be more helpful if it offered specific guidance on how to incorporate these datasets or provided examples of how they could be used effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clearly state the limitation of their analysis, which is that they only analyze fully connected ResNets, despite the fact that ResNets typically use convolutional layers in practice. The comment also suggests that this limitation should be included in the Broader Impact section. This feedback is clear and provides a direct action for the authors to take, ensuring that they are aware of the need to address this limitation. The explicit nature of the action and the concrete guidance on where to include it make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"fully connected ResNets\" and suggests that the paper should include a statement about the limitation of only analyzing these networks. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the limitation of only analyzing fully connected ResNets and its relevance to the broader impact section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper only analyzes fully connected ResNets, which is a limitation, and suggests that this should be addressed in the Broader Impact section. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation is significant or how it affects the broader impact of the work. Without additional context or examples, the claim remains somewhat verifiable, as it lacks detailed justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the paper, noting that it only analyzes fully connected ResNets, despite the fact that ResNets typically use convolutional layers in practice. This feedback is clear and actionable, as it prompts the authors to acknowledge and address this limitation by including it in the Broader Impact section. By doing so, the authors can enhance the comprehensiveness and relevance of their analysis. However, the comment could be more helpful if it provided suggestions on how to incorporate this limitation into the broader impact section or offered guidance on how to present it effectively. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the training of a student model on the training set, specifically considering the size of the model (ResNet18). It provides examples of standard KD methods that have surpassed the reported KD performance, such as Early KD methods like Hinton et al. (2015) and FitNets by Romero et al. (2015). However, the comment does not explicitly instruct the authors to adopt these methods or provide guidance on how to improve their training process. The action is implicit and somewhat vague, as the authors need to infer that they should consider these methods and potentially modify their approach. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the training of a student model on the training set, specifically considering the size of the model (ResNet18). It provides examples of standard KD methods that have surpassed the reported KD performance, such as Early KD methods like Hinton et al. (2015) and FitNets by Romero et al. (2015). However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the training process and the examples of standard KD methods that have surpassed the reported performance. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point makes a claim about the performance of a student model trained on the training set, specifically considering the model size (ResNet18). It provides examples of standard KD methods that have surpassed the reported KD performance, such as Early KD methods like Hinton et al. (2015) and FitNets by Romero et al. (2015). This claim is supported by specific examples of benchmarks, which provides a logical basis for the critique. However, the comment could be strengthened by referencing the specific experiments or studies that demonstrate these benchmarks, which would further substantiate the claim. Overall, the claim is mostly verifiable, as it provides a logical basis for the critique but lacks detailed references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the training of a student model on the training set, specifically considering the size of the model (ResNet18). It provides examples of standard KD methods that have surpassed the reported KD performance, such as Early KD methods like Hinton et al. (2015) and FitNets by Romero et al. (2015). This feedback highlights a potential area for improvement in the training process, suggesting that the authors consider adopting these methods to enhance their results. However, the comment could be more helpful by offering specific suggestions or guidance on how to implement these methods or address the identified issue. Overall, the comment provides valuable insights but lacks actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the causal graph assumption in the proposed framework, specifically questioning whether the message and passing routes (sub-graph structure) in some GCN variants, such as Geniepath[1] or Gated GNN[2], would break the causal graph assumption. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this concern or what specific steps they should consider to validate their causal graph assumption. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the causal graph assumption in the proposed framework, specifically questioning whether the message and passing routes (sub-graph structure) in some GCN variants, such as Geniepath[1] or Gated GNN[2], would break the causal graph assumption. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its questioning of the causal graph assumption, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the causal graph assumption in the proposed framework, specifically questioning whether the message and passing routes (sub-graph structure) in some GCN variants, such as Geniepath[1] or Gated GNN[2], would break the causal graph assumption. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. The lack of detailed reasoning or evidence makes the claim unverifiable, as it does not provide sufficient justification for the authors to address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the causal graph assumption in the proposed framework, specifically questioning whether the message and passing routes (sub-graph structure) in some GCN variants, such as Geniepath[1] or Gated GNN[2], would break the causal graph assumption. This is a relevant and thought-provoking question that prompts the authors to consider the robustness of their framework. However, the comment does not provide any actionable feedback or suggestions for how the authors might address this concern or improve their analysis. It lacks depth and specificity, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete suggestions for improvement. It points out that the author only considered message-passing layers and argues that this is not convincing, as different tasks may require different pre- and post-processing modules. The reviewer suggests that listing the performance of SOTA algorithms in each dataset discussed in Table 1 would help readers understand the gap between NAS models and human-engineered SOTA architectures. This feedback is clear and provides specific actions for the authors to take, such as including performance comparisons and listing SOTA algorithms. The explicit nature of the suggestions and the concrete details on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"pre-processing, message-passing, and post-processing,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to list the performance of SOTA algorithms in each dataset discussed in Table 1 to help readers understand the gap between NAS models and human-engineered SOTA architectures. This provides clear guidance on how the authors can improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors only considered message-passing layers and stated that this is commonly regarded as the most important part of GNN. However, the comment suggests that different tasks may require different pre- and post-processing modules, which could affect the conclusion about the importance of message-passing. The reviewer provides a suggestion to list the performance of SOTA algorithms in each dataset discussed in Table 1, which would help readers understand the gap between NAS models and human-engineered SOTA architectures. This feedback is somewhat verifiable as it logically suggests that different tasks may require different processing modules, but it lacks specific examples or references to support the claim about the importance of message-passing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improvement. It points out that the authors only considered message-passing layers and argued that this conclusion might not be convincing due to the variability of pre- and post-processing modules across different tasks. The reviewer suggests that listing the performance of SOTA algorithms in each dataset discussed in Table 1 would help readers understand the gap between NAS models and human-engineered SOTA architectures. This feedback is specific and provides a clear direction for the authors to enhance their draft by including performance comparisons, which would strengthen their argument and improve the comprehensiveness of the paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be useful to show whether learning the advantage directly is beneficial, and questions the importance of learning it directly compared to other methods. While the comment implies that the authors should provide evidence or examples to support their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional evidence or examples to address the reviewer\\'s concerns. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it would be useful to show whether learning the advantage directly is beneficial, and questions the importance of learning it directly compared to other methods. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the methodology or results sections, but the lack of explicit mention makes it weakly grounded. The comment is specific in its request for evidence or examples to support the claim, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be useful to show whether learning the advantage directly is beneficial, questioning the importance of learning it directly compared to other methods. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it effectively. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification or examples to fully substantiate the argument.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by questioning the importance of learning the advantage directly compared to other methods. It suggests that the paper should provide evidence or examples to support the claim that learning the advantage directly is beneficial. While the comment highlights an area for improvement, it lacks specific guidance on how to address this issue or what kind of evidence would be most effective. The feedback is somewhat helpful as it points out a potential gap in the paper\\'s argumentation, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that explanations about the meaning of variable symbols such as \u03c2 , r_i , \u03b1_i, and others in the appended algorithms should be added. While the comment implies that the authors should provide explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide explanations but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that explanations about the meaning of variable symbols such as \u03c2 , r_i , \u03b1_i, and others in the appended algorithms should be added. However, it does not specify which part of the paper these symbols are used in, making it difficult for the authors to pinpoint the exact sections that need clarification. The comment is specific in suggesting the need for explanations but lacks grounding, as it does not identify the exact parts of the paper that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that explanations about the meaning of variable symbols such as \u03c2 , r_i , \u03b1_i, and others in the appended algorithms should be added. However, the comment does not provide any reasoning, examples, or references to support why these explanations are necessary or how they would enhance the clarity of the paper. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that explanations about the meaning of variable symbols such as \u03c2 , r_i , \u03b1_i, and others in the appended algorithms should be added. This feedback is clear and actionable, as it directs the authors to provide additional clarity on the symbols used in their work. However, the comment could be more helpful if it offered specific examples or guidance on how to present these explanations effectively. Despite this, the feedback is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to enhance the clarity of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the limited performance gains of the method indicate a lack of innovation and potential incremental changes to established methods. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to improve the innovation or differentiate the method from existing approaches. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the limited performance gains of the method indicate a lack of innovation and potential incremental changes to established methods. However, it does not specify which part of the paper discusses the performance gains or how they are measured. Without explicit references to sections, figures, or specific performance metrics, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the method are considered incremental or lacking in innovation. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the method lacks innovation and suggests it may represent incremental changes to established methods based on the limited performance gains. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the limited performance gains of the method indicate a lack of innovation and potential incremental changes to established methods. While it identifies a concern about the method\\'s impact on the field, it does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their method from existing approaches. The comment lacks actionable feedback or detailed advice, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This implies that the authors should include such comparisons in their work to provide a clearer picture of the relative strengths and weaknesses of their proposed system. However, the comment does not specify which existing methods or systems should be compared or how to conduct the comparative analysis. While the action is implied, it lacks concrete guidance on how to implement it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. However, it does not specify which part of the paper this analysis should be included in, nor does it provide details on what aspects of the proposed system should be compared. This makes it difficult for the authors to identify the exact sections that need revision or how to conduct the comparative analysis. The comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This claim is somewhat verifiable as it provides a logical reasoning for why such an analysis would be beneficial, but it lacks specific examples or references to existing methods or systems that could be compared. The authors would need to infer the need for such an analysis themselves, which could be challenging without additional guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, which could enhance its comprehensiveness and credibility. However, the comment lacks specific guidance on which existing methods or systems should be compared, how to conduct the comparative analysis, or what aspects of the proposed system should be emphasized. While it points out a potential gap, the feedback does not provide actionable steps for the authors to address this suggestion effectively. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the practical usefulness of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ due to its prediction performance not outperforming existing methods on a real dataset. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear path to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ on a real dataset, specifically mentioning the long-range graph benchmark. However, it does not specify which part of the paper discusses this performance, making it weakly grounded. The comment is specific in its critique of the practical usefulness of the method due to its lack of outperformance compared to existing methods. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the prediction performance of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ does not outperform existing methods on a real dataset, which supports the claim that its practical usefulness is limited. However, the comment does not provide specific references or detailed comparisons to existing methods, making it somewhat verifiable. The authors would need to conduct their own research to verify the claim, which adds a level of complexity to the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights a concern about the practical usefulness of the method $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$, which has theoretical guarantees but does not outperform existing methods on a real dataset. This feedback is somewhat helpful as it identifies a potential limitation in the method\\'s practical applicability. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the method\\'s performance. Without actionable advice or detailed feedback, the authors may find it challenging to fully address the critique. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that it is unfair to compare the proposed algorithm with offline RL algorithms for single-agent scenarios, as the target of those algorithms is not to find an equilibrium. However, it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on how to address this issue or what specific changes should be made to the comparison. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the unfairness of comparing the proposed algorithm with offline RL algorithms for single-agent scenarios, specifically mentioning that the target of those algorithms is not to find an equilibrium. However, it does not specify which part of the paper this comparison is made in, nor does it provide details on how the comparison is conducted or why it is considered unfair. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the comparison are problematic or how the authors might address these issues. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that it is unfair to compare the proposed algorithm with offline RL algorithms for single-agent scenarios because the target of those algorithms is not to find an equilibrium. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between the proposed algorithm and offline RL algorithms for single-agent scenarios, noting that the target of the latter is not to find an equilibrium. This feedback highlights a potential misalignment in the comparison, which could be a source of confusion or misinterpretation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the comparison. While it points out a relevant concern, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify their unique contributions in methodology and purpose by providing more detailed comparisons to similar works. This feedback is clear and concrete, as it specifies the exact areas that need improvement and offers a specific action for the authors to take. The authors know exactly what needs to be done to address the issue, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the overlap with prior work, specifically mentioning the three tasks of unanswerable, inconsistent, and counterfactual. However, it does not specify which part of the paper this overlap is discussed in, making it weakly grounded. The comment is specific in suggesting that the paper should clarify its unique contributions in methodology and purpose, and provide more detailed comparisons to similar works. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper overlaps with prior work, specifically mentioning the tasks of unanswerable, inconsistent, and counterfactual. It suggests that the paper should clarify its unique contributions in methodology and purpose, providing more detailed comparisons to similar works. While the comment identifies a potential issue, it lacks specific references to those prior works or detailed examples of how the paper's contributions are similar or different. This makes the claim somewhat verifiable, as it provides a general direction for improvement but requires more detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the three tasks of unanswerable, inconsistent, and counterfactual have been partially covered in prior benchmarks. It suggests that the paper should clarify its unique contributions in methodology and purpose, and provide more detailed comparisons to similar works. This feedback is clear and actionable, as it directs the authors to specify their contributions and provide a more comprehensive comparison with existing literature. However, the comment could be more helpful if it offered specific examples or suggestions on how to improve the comparisons or clarify the unique contributions. Overall, the comment is mostly helpful as it guides the authors toward a more robust and comprehensive presentation of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the claim in Section 1, \"human perception is usually invariant to the texture resampling,\" lacks support materials. This provides a clear and direct action for the authors to take, which is to include additional evidence or examples to support their claim. The comment is specific about what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the claim lacks support materials, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement in Section 1, \"human perception is usually invariant to the texture resampling,\" lacks support materials. However, the comment does not provide any specific examples, reasoning, or references to substantiate this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in Section 1, noting that the claim about human perception being invariant to texture resampling lacks support materials. This feedback is clear and actionable, as it directs the authors to provide additional evidence or examples to substantiate their claim. However, the comment could be more helpful if it suggested specific types of support materials or examples that would strengthen the argument. Overall, the comment is mostly helpful as it guides the authors toward improving the draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should demonstrate the applicability of MiPKD to other computer vision (CV) tasks beyond SR tasks. It explicitly encourages the authors to show the method's generalizability by conducting additional experiments on a broader range of tasks. The comment provides a clear and concrete action for the authors to take, specifying the need for broader applicability and the need for additional experiments. This level of explicitness and concrete guidance makes the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"MiPKD\u2019s performance in SR tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should demonstrate the applicability of MiPKD to other computer vision tasks beyond SR tasks and provide additional experiments to enhance its perceived generalizability. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper primarily discusses MiPKD's performance in SR tasks but does not mention that MiPKD is not specifically designed for SR tasks. The comment suggests that the authors should demonstrate the applicability of MiPKD to other CV tasks and conduct additional experiments to enhance its perceived generalizability. While the comment provides a logical reasoning for the need to expand the applicability of MiPKD, it lacks specific examples or references to support the claim that MiPKD is not designed for SR tasks. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It identifies a limitation in the current work, noting that MiPKD is primarily discussed in the context of SR tasks, despite not being specifically designed for this task. The comment encourages the authors to demonstrate the applicability of MiPKD to other CV tasks and suggests conducting additional experiments to enhance its perceived generalizability. This feedback is specific and provides a concrete direction for the authors to expand the scope of their work and improve its relevance to broader audiences. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Equations 21 and 22, which describe an alternative scheme, may be omitted without affecting the flow of the section. This feedback implies that the authors should consider removing these equations if they are not being used in the paper. However, the comment does not provide explicit instructions on how to implement this suggestion or whether the equations are essential for the paper\\'s flow. While the action is implied, it lacks concrete guidance on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equations 21 and 22,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the omission of equations that are not used in the paper. This provides clear guidance on what changes need to be made to improve the draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Equations 21 and 22 are not used in the paper and suggests that they may be omitted without affecting the flow of the section. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these equations are unnecessary or how their removal would impact the paper\\'s flow. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that Equations 21 and 22 describe an alternative scheme that is not actually used. It suggests that these equations may be omitted without hampering the flow of the section. This feedback is clear and actionable, as it provides the authors with a specific area to consider for simplification and streamlining. However, the comment could be more helpful if it offered suggestions on how to integrate the remaining content or if it provided additional context on why these equations are not essential. Overall, the comment is mostly helpful as it directs the authors\\' attention to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the optimization module applies a simple iteration strategy to optimize the two loss functions, which implies that the model is not innovative or original. However, it does not provide specific guidance on how the authors might improve the model or suggest alternative approaches. The comment lacks concrete actions or detailed suggestions, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the optimization module applies a simple iteration strategy to optimize the two loss functions, implying that the model is not innovative or original. However, it does not specify which part of the paper this optimization module is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the optimization module are considered incremental or how it could be improved. Without clear guidance on where to focus the revision, the authors may find it challenging to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the optimization module applies a simple iteration strategy to optimize the two loss functions, suggesting that the model is not innovative or original. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to traditional approaches that the model is built upon, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to substantiate the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the optimization module applies a simple iteration strategy to optimize the two loss functions, implying that the overall model is not innovative or original. It points out that the model seems incremental, standing on the shoulders of traditional approaches. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might enhance the model's originality or innovation, nor does it suggest alternative approaches or areas for exploration. As a result, the comment is barely helpful, as it provides some insight but lacks depth and actionable advice. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by providing more detailed explanations of the choice of F(X) for the E(d) case, specifically mentioning the 2^d O(d) matrices. It also recommends elaborating on one example of how to construct F(X) in the main paper and then discussing the other two in the appendix. This feedback is explicit and provides concrete steps for the authors to take, such as elaborating on specific examples and reorganizing the paper structure. The action is clear and specific, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"writing of the paper\" and the \"choice of F(X) for the E(d) case,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely the lack of clarity in the choice of F(X) and the need for more detailed explanations of the 2^d O(d) matrices. The comment provides a clear direction for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of F(X) for the E(d) case and suggests elaborating on one example in the main paper and discussing the other two in the appendix. While the comment raises a concern about the clarity of the paper, it does not provide specific examples or references to support the claim that the choice of F(X) is unclear. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered borderline verifiable, as it provides some indication of an issue but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the clarity of the choice of F(X) for the E(d) case. It suggests that the authors elaborate on one example of how to construct F(X) in the main paper and discuss the other two in the appendix. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the clarity and comprehensibility of their work. By addressing this issue, the authors can improve the readability and accessibility of their paper, which is valuable for both the reviewer and the broader audience. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implicit assumptions that the paper makes to ensure the success of few-shot learning. It suggests that the paper might rely on the meta-distribution assumption or distribution-closeness assumption. While the comment implies that the authors should clarify these assumptions, it does not provide explicit guidance on how to address this issue or what specific assumptions should be considered. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the assumptions, but it lacks concrete details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the implicit assumptions that the paper makes to ensure the success of few-shot learning. It suggests that the paper might rely on the meta-distribution assumption or distribution-closeness assumption. However, it does not specify which part of the paper this question pertains to, nor does it provide detailed guidance on how the authors should address this issue. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is weakly grounded because it does not specify where the assumptions are discussed or how they might be addressed. It is also under-specific because it does not provide detailed guidance on how to clarify or address the assumptions. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the implicit assumptions that the paper makes to ensure the success of few-shot learning. It suggests that the paper might rely on the meta-distribution assumption or distribution-closeness assumption. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these assumptions are relevant or how they might impact the paper\\'s claims. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the implicit assumptions that the paper makes to ensure the success of few-shot learning. It suggests that the paper might rely on the meta-distribution assumption or distribution-closeness assumption, which are common assumptions in the field. While the comment identifies a potential area for improvement by suggesting that the authors clarify these assumptions, it does not provide specific guidance on how to address them or what aspects of the paper should be revised. The feedback is somewhat helpful as it prompts the authors to consider these assumptions, but it lacks depth and actionable steps, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models. It also recommends providing results for standard benchmarks in the literature to facilitate comparison with prior work. While the comment implies that the authors should expand their comparison to include more tasks and models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific tasks and models to include in the comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models. It also recommends providing results for standard benchmarks in the literature to facilitate comparison with prior work. However, the comment does not specify which part of the paper this critique pertains to, such as the results or discussion sections. The authors can infer that it relates to the comparison with prior work, but this inference is not direct. The comment is specific in suggesting improvements but lacks full grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models. It also recommends providing results for standard benchmarks in the literature to facilitate comparison with prior work. While the comment provides a logical reasoning for improvement, it lacks specific examples or references to prior work or standard benchmarks that could be considered. This makes the claim somewhat verifiable, as the authors would need to infer the specific tasks and models to include in the comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the comparison to prior work, suggesting that it could be more thorough by considering other tasks and large-scale models. It also recommends providing results for standard benchmarks in the literature to facilitate comparison with prior work. This feedback is clear and actionable, as it provides specific suggestions for improving the comparison and making it more comprehensive. However, the comment could be more helpful if it included examples of tasks or models that should be considered, which would guide the authors more directly. Overall, the comment is mostly helpful as it offers valuable insights and direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. It implies that the contribution of the manuscript still has room for improvement. However, the comment does not provide specific guidance on how the authors might improve their contribution or what aspects of the method need to be revised. The action is implicit and vague, leaving the authors uncertain about how to address the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not specify which part of the paper this assessment is based on, such as the introduction, methodology, or results sections. The authors cannot confidently determine which part of the paper is being addressed, making this comment weakly grounded. The comment does specify that the contribution still has room for improvement, but without specific guidance on what aspects need improvement, it remains under-specific. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide specific references or comparisons to existing methods, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence makes it challenging for the authors to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. It acknowledges that the contribution still has room for improvement, but does not provide specific feedback or suggestions on how the authors might enhance their contribution. The comment lacks actionable guidance or detailed insights into what aspects of the manuscript need improvement, leaving the authors without clear direction on how to enhance their work. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer concrete steps for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two issues with the paper: the abstract nature of Benefit 1 and the lack of supporting references for Benefit 3. While it points out specific areas that need improvement, it does not provide explicit guidance on how to address these issues. The comment implies that the authors should provide more contextual detail for Benefit 1 and specify the references for Benefit 3, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues with the paper, particularly regarding the three claimed benefits. It identifies that Benefit 1 is too abstract and lacks contextual detail, while Benefit 3 includes broad statements without supporting references. This provides clear guidance on what needs to be addressed in the paper, allowing the authors to pinpoint the specific sections that need improvement. However, the comment does not explicitly mention which sections of the paper these issues are related to, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed, making it somewhat grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the three benefits of understanding the agent's performance post-training are difficult to grasp, particularly Benefit 1, which is described as too abstract and lacking contextual detail. The reviewer also criticizes Benefit 3 for including broad statements without supporting references. This claim is somewhat verifiable as it provides a logical reasoning for the critique, but it lacks specific examples or references to substantiate the claims. The authors would need to further explore the issues to fully understand and address them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper\\'s claims regarding the benefits of understanding the agent\\'s performance post-training. It points out that Benefit 1 is too abstract and lacks contextual detail, while Benefit 3 includes broad statements without supporting references. This feedback is clear and actionable, as it directs the authors to provide more context and evidence for their claims. By addressing these issues, the authors can improve the clarity and substantiation of their arguments, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the absence of quantitative results for the Human Shape Bases Synchronization problem and questions the effectiveness of the approach based on qualitative results. It also provides a general conclusion about the paper, noting its novelty and sufficient experimental evidence but highlighting the limited impact. While the comment identifies a gap in the results and suggests a need for quantitative evidence, it does not provide specific guidance on how to address this issue or what additional quantitative results should be included. The feedback is somewhat actionable as it highlights an area for improvement but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the absence of quantitative results for the Human Shape Bases Synchronization problem and questions the effectiveness of the approach based on qualitative results. It also provides a general conclusion about the paper, noting its novelty and sufficient experimental evidence but highlighting the limited impact. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the results and experimental evidence sections. The comment is specific in its critique of the lack of quantitative results and the limited impact, providing clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the absence of quantitative results for the Human Shape Bases Synchronization problem and questions the effectiveness of the approach based on qualitative results. It provides a general conclusion about the paper, noting its novelty and sufficient experimental evidence but highlighting the limited impact. The comment suggests that the paper is borderline, but leans towards acceptance. While the comment identifies a gap in the results and provides a general assessment, it lacks specific examples or detailed reasoning to fully support the claim about the effectiveness of the approach. This makes the claim somewhat verifiable, as it provides some insight but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid point about the absence of quantitative results for the Human Shape Bases Synchronization problem, which is an important aspect of the paper\\'s evaluation. It questions the effectiveness of the approach based on qualitative results and highlights the limited impact of the approach. The comment also provides a general conclusion about the paper, noting its novelty and sufficient experimental evidence but emphasizing the limited impact. While the feedback identifies a gap in the results and suggests a need for quantitative evidence, it lacks specific suggestions or guidance on how to address this issue. The authors are given a clear direction but without detailed guidance on how to improve their work, making the comment somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the categorization of the paper under the Fairness/Accountability/Transparency (FAT) framework. It does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions on how to address this concern. The comment lacks guidance on what the authors should do to clarify or adjust their categorization. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the categorization of the paper under the Fairness/Accountability/Transparency (FAT) framework, but it does not specify which part of the paper is being addressed. The authors cannot confidently determine whether this relates to a specific section, table, or figure. Additionally, the comment lacks specificity regarding what aspect of the categorization is unclear or in need of clarification. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the categorization of the paper under the Fairness/Accountability/Transparency (FAT) framework. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the categorization of the paper under the Fairness/Accountability/Transparency (FAT) framework, which could be a valid concern for the authors. However, the comment lacks depth and does not provide any specific guidance or suggestions on how the authors might address this issue or clarify their categorization. Without actionable feedback or context, the authors are left without a clear path forward. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer sufficient guidance for the authors to make meaningful changes.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include machine learning 2-step baselines to compare their approach with NaviFormer. This feedback implies that the current comparison to baselines is insufficient and lacks depth, as all approaches appear to be heuristic methods. The reviewer implies that including machine learning 2-step baselines would provide a more comprehensive comparison, which would help substantiate the authors\\' claims about NaviFormer\\'s superiority. However, the comment does not specify how to implement this suggestion or provide detailed guidance on which specific machine learning methods should be used. While the action is implicit, it is clear and provides a direction for improvement, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison to baselines, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including machine learning 2-step baselines to provide a more comprehensive comparison, which would help substantiate the authors\\' claims about NaviFormer\\'s superiority. This feedback is clear and provides a clear direction for improvement, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the current comparison to baselines is insufficient and lacks depth, as all approaches appear to be heuristic methods. The reviewer proposes including machine learning 2-step baselines to provide a more comprehensive comparison, which could substantiate the authors\\' claims about NaviFormer\\'s superiority. This suggestion is based on a logical reasoning that adding machine learning baselines would offer a more nuanced comparison. However, the comment does not provide specific examples or references to support the claim that NaviFormer beats baselines due to its joint tackling of routing and path planning problems. This makes the claim somewhat verifiable, as it provides a plausible argument but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the comparison to baselines, noting that all approaches appear to be heuristic methods. It suggests that including machine learning 2-step baselines would provide a more comprehensive comparison, which could substantiate the authors\\' claims about NaviFormer\\'s superiority. This feedback is clear and actionable, as it directs the authors to consider a more nuanced approach to evaluating their method. However, the comment could be more helpful if it provided specific examples of machine learning methods that could be used as baselines or detailed guidance on how to implement this suggestion. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a direction for enhancing the paper\\'s comparative analysis.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct a fair comparison by applying the planning and layering method to the design image generated by other image generative models. This explicit suggestion provides a clear action for the authors to take, which is to conduct a fair comparison. However, the comment does not specify which other image generative models should be used or how to implement the fair comparison. While the action is clear, the lack of detailed guidance on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the results seem better than other compared methods but questions whether this is due to the better image generative model. It recommends conducting a fair comparison by applying the planning and layering method to the design image generated by other image generative models. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or comparisons section. The comment is specific in suggesting a fair comparison and providing a potential method for achieving it. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions whether the results are better than other methods due to a better image generative model. It suggests conducting a fair comparison by applying the planning and layering method to the design image generated by other image generative models. While the comment raises a valid concern, it lacks specific examples or references to support the claim that the image generative model is a significant factor in the results. This makes the claim somewhat verifiable, as the authors would need to make a logical inference to understand the basis of the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s results by questioning whether the observed improvement is due to the better image generative model. It provides a specific suggestion for conducting a fair comparison by applying the planning and layering method to the design image generated by other image generative models. This feedback is clear and actionable, offering a concrete way for the authors to address the concern and improve the robustness of their results. However, the comment could be more helpful if it provided additional guidance on how to conduct the fair comparison or suggested specific image generative models to use. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the comparative study should include more advanced baselines, such as SOTA methods mentioned in the literature. It also points out that the authors' claim about the modality-missing data not being well exploited is not justified due to the lack of comparison with these advanced methods. This feedback provides clear and concrete actions for the authors to take, namely, to include more advanced baselines and justify their claims by comparing their method with these SOTA methods. The explicit nature of the suggestion and the detailed guidance on how to address it make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"baselines such as zero padding,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need to include SOTA methods in the comparative study and the need to justify the claim about the modality-missing data. This provides clear guidance on what the authors need to improve in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparative study should include more advanced baselines, such as SOTA methods, to justify the authors\\' claims about the modality-missing data. The comment provides a logical reasoning by suggesting that including these advanced methods would strengthen the comparative analysis. However, it does not provide specific references to these SOTA methods or examples of how they would enhance the study. While the claim is somewhat verifiable, it lacks detailed evidence or references, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the comparative study, noting that the proposed method is compared with relatively simple baselines like zero padding but lacks comparison with SOTA methods. It highlights the need for a more comprehensive analysis by including these advanced methods. Additionally, it critiques the authors\\' claim about the modality-missing data not being well exploited, suggesting that the lack of comparison with SOTA methods undermines this claim. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance their comparative study and substantiate their claims. By addressing these points, the authors can significantly improve the rigor and comprehensiveness of their work. Therefore, the comment is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the discussion of the dataset is confusing and suggests that if the information about \"opinion holder\" and \"opinion targets\" is not relevant to the experiments, it should not be mentioned. While the comment identifies a potential issue with the clarity of the discussion, it does not provide explicit guidance on how to improve it. The authors are left to infer that they should remove the mentioned information if it is not relevant, but the comment lacks concrete details on how to address this issue. Therefore, the comment is somewhat actionable, as it provides a general direction but lacks specific instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 329-334,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the discussion of the dataset, particularly the mention of \"opinion holder\" and \"opinion targets,\" and suggests that if these are not relevant to the experiments, they should not be included. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion of the dataset is confusing, specifically mentioning the terms \"opinion holder\" and \"opinion targets.\" The reviewer suggests that if these terms are not relevant to the experiments, they should not be included. However, the comment lacks specific examples or references to support the claim that these terms are confusing or unrelated to the experiments. Without additional context or reasoning, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is somewhat verifiable, as it provides a general idea but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the discussion regarding the dataset, particularly the mention of \"opinion holder\" and \"opinion targets.\" It suggests that if these terms are not relevant to the experiments, they should not be included in the discussion. This feedback is clear and actionable, as it provides the authors with a specific area to focus on for improving the clarity and relevance of their discussion. However, the comment could be more helpful if it offered suggestions on how to rephrase or clarify the discussion to enhance its utility. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the restrictiveness of the capsule networks and questions the authors\\' approach to enforcing equivariance. It points out that the group CapNet is deeper than the simple CapNet and that the number of parameters in the group CapNet is not provided, making it difficult to assess the benefits of enforcing equivariance. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their approach. The action is implicit and vague, leaving the authors with a general sense of what needs to be improved but without specific steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the capsule networks and the experiments, specifically mentioning the group CapNet and the lack of information about its parameters. This provides full grounding as it allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of information about the number of parameters in the group CapNet and the potential impact on the evaluation of enforcing equivariance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the restrictiveness of the capsule networks and questions the authors\\' approach to enforcing equivariance. It suggests that the original CapNet captures some variations in the data, but the comment lacks specific evidence or examples to support this claim. The lack of detailed reasoning or references makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the capsule networks, noting that the group CapNet is deeper than the simple CapNet and that the number of parameters in the group CapNet is not provided. This feedback highlights a gap in the experimental setup that could affect the authors\\' ability to assess the benefits of enforcing equivariance. However, the comment does not provide actionable suggestions or guidance on how the authors might address this issue or improve their experimental setup. While it points out a potential limitation, it lacks depth and specificity, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the challenge of obtaining meaningful gradients with respect to noisy intermediate images has been addressed in previous approaches, such as DiME and FastDiME. It also mentions a reference to a more efficient implementation of the Tweedie approach. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their approach. It lacks actionable details, such as recommending specific modifications or improvements to the methodology. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of obtaining meaningful gradients with respect to noisy intermediate images and provides examples of previous approaches, such as DiME and FastDiME, that have addressed this challenge. Additionally, it mentions a reference to a more efficient implementation of the Tweedie approach. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the challenge of obtaining meaningful gradients with respect to noisy intermediate images, which has been addressed in previous approaches such as DiME and FastDiME. The reviewer supports this claim by mentioning specific references to these approaches and their efficiency. However, the comment lacks detailed explanation or examples of how these approaches address the issue, which would strengthen the verifiability. As it stands, the claim is somewhat verifiable, as it provides some context but could be further elaborated to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the challenge of obtaining meaningful gradients with respect to noisy intermediate images has been addressed in previous approaches, such as DiME and FastDiME. It also mentions a reference to a more efficient implementation of the Tweedie approach. While the comment provides some context and background information, it lacks actionable feedback or suggestions for improvement. It does not offer specific guidance or recommendations on how the authors might address this issue or enhance their approach. As a result, the comment is somewhat helpful, as it provides some context but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should include an evaluation of inference speed on the hardware. This is a clear and direct action, providing the authors with a specific and concrete step to take in order to improve their draft. The comment is specific about what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should include an evaluation of inference speed on the hardware. However, it does not specify which part of the paper this evaluation should be included in, nor does it provide any context about where this evaluation would fit within the existing structure. This makes the comment weakly grounded, as the authors cannot confidently determine which section or aspect of the paper is being addressed. The suggestion is specific in terms of what needs to be added, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an evaluation of inference speed on the hardware would be beneficial. However, it does not provide any supporting evidence, reasoning, or examples to justify why this evaluation is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that an evaluation of inference speed on the hardware would be beneficial. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their draft by including a relevant evaluation. However, the comment could be more helpful if it offered guidance on how to conduct this evaluation or suggested specific metrics or methods to use. Despite this, the feedback is mostly helpful as it identifies a meaningful area for improvement and provides a clear action for the authors to take.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks where the SDP (Semi-Definite Programming) formulation is presented in the paper. This question provides a clear and direct action for the authors to take, as it prompts them to include the SDP formulation in their work. The comment is specific and provides a concrete action for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"modified problem\" and the \"SDP formulation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for the inclusion of the SDP formulation, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the presence of the SDP formulation, which is a specific request for clarification. It does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is a factual statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the absence of the SDP formulation for the modified problem. This is a clear and actionable feedback that prompts the authors to include the SDP formulation, which is crucial for understanding the problem and its solution. By addressing this point, the authors can improve the clarity and completeness of their work. However, the comment could be more helpful if it provided additional context or guidance on how to present the SDP formulation effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of information regarding the number of new task combinations used to evaluate the compositional generalizability and notes that the test results in Table 7 are based on only 30 composite instructions. While the comment identifies specific areas that need clarification or expansion, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they should include more details about the task combinations and possibly expand the test results, but the comment lacks the explicit guidance needed to fully actionable. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 558,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of information regarding the number of new task combinations used to evaluate the compositional generalizability and the limited number of test results in Table 7, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors did not specify the number of new task combinations used to evaluate the compositional generalizability and that the test results in Table 7 are based on only 30 composite instructions. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the authors did not specify the number of new task combinations used to evaluate the compositional generalizability. Additionally, it points out that the test results in Table 7 are based on only 30 composite instructions, which is a limited sample size. This feedback is clear and actionable, as it directs the authors to provide more detailed information about the experimental setup and results. However, the comment could be more helpful if it suggested ways to expand the test results or provided examples of how to address this limitation. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper, particularly the figures, is not well-organized in terms of layout. However, it does not provide any specific guidance or suggestions on how to improve the layout or what aspects of the figures need attention. The comment lacks actionable details, such as recommending specific changes or improvements, making it difficult for the authors to know how to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions the layout of the paper and the figures, but it does not specify which sections or figures are problematic. This makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what aspects of the layout are not well-organized or how they could be improved. Without clear guidance or examples, the authors may struggle to understand and address the issue. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper, particularly the figures, is not well-organized in terms of layout. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, namely that the layout of the figures is not well-organized. However, it lacks depth and does not provide any specific suggestions or guidance on how to improve the layout or what aspects of the figures need attention. Without actionable feedback or detailed advice, the authors may find it challenging to address the issue effectively. Therefore, the comment is barely helpful, as it points out a weakness but does not offer a path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the lack of clear differentiation from existing works and detailed comparisons with similar techniques, which could affect the perceived novelty and value of the paper within the NLP community. While the comment identifies an area for improvement, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to provide more detailed comparisons and differentiation, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the need for clear differentiation from existing works and detailed comparisons with similar techniques, which are crucial for establishing the novelty and value of the paper within the NLP community. However, it does not specify which part of the paper should include these comparisons or how they should be presented, leaving the authors to infer the relevant sections. While the authors can infer that the sections discussing related work or techniques might need attention, the comment lacks specific guidance on what aspects need improvement. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific because it does not provide detailed instructions on how to address the issue. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper lacks clear differentiation from existing works and detailed comparisons with similar techniques, which could affect its perceived novelty and value within the NLP community. The comment provides a logical reasoning by suggesting that a lack of differentiation and comparisons could lead to perceptions of incremental progress or insufficient novelty. However, it does not provide specific examples or references to existing works or techniques that could be used for comparison. This makes the claim somewhat verifiable, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, noting that the lack of clear differentiation from existing works and detailed comparisons with similar techniques could affect the perceived novelty and value of the work within the NLP community. This feedback is valuable as it highlights an important area for improvement, particularly in demonstrating the originality and impact of the paper. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as which aspects of the work should be compared or how to differentiate it from existing works. Despite this, the comment still offers a clear direction for the authors to enhance the novelty and impact of their work, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests an explanation for the discrepancy between the baseline results in Table 2 and those from Table 3 in [3]. This is a clear and direct action that the authors can take to address the reviewer\\'s concern. The comment provides a specific area of inquiry, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3 in [3],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it requests an explanation for the discrepancy between the baseline results in the two tables. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the discrepancy between baseline results in Table 2 and those from Table 3 in [3]. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it directly addresses a specific issue by requesting an explanation for the discrepancy between the baseline results in Table 2 and those from Table 3 in [3]. This feedback prompts the authors to clarify their methodology and provide a clear rationale for the differences observed. By addressing this point, the authors can improve the transparency and reproducibility of their work. However, the comment could be more helpful if it suggested ways to resolve the discrepancy or provided additional context for understanding the baseline results. Overall, the comment is clear and actionable, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the use of \"execution feedback\" in the title and Figure 2 is misleading, as no execution feedback is actually used in the work. It further explains that execution feedback is approximated based on structural perturbations in the Abstract Syntax Tree (AST) and that the authors assume any such perturbation results in a failure as execution feedback (EF = 0). The reviewer also notes that Equation 1 defines EF in terms of whether or not the tests in a test suite pass, but there is no guarantee that such perturbations will make the tests fail. The comment provides a clear and specific critique of the use of \"execution feedback\" in the paper, along with a detailed explanation of the misconception. This gives the authors a clear and concrete action to take, which is to revise the use of \"execution feedback\" in the paper and provide a more accurate description of the feedback mechanism. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"Lines 233-238,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the use of \"execution feedback\" is misleading, as no execution feedback is actually used in the work. The comment further explains the misconception by detailing how execution feedback is approximated based on structural perturbations in the AST and how the authors assume any such perturbation results in a failure as execution feedback. Additionally, it clarifies the definition of execution feedback in Equation 1, providing a clear and specific critique of the use of \"execution feedback\" in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of \"execution feedback\" is misleading, as no execution feedback is actually used in the work. It further explains that execution feedback is approximated based on structural perturbations in the Abstract Syntax Tree (AST) and that the authors assume any such perturbation results in a failure as execution feedback (EF = 0). The reviewer references specific lines of code (Lines 233-238) to support their claim. Additionally, the comment provides a detailed explanation of the definition of execution feedback in Equation 1, clarifying that there is no guarantee that such perturbations will make the tests fail. This provides a thorough justification for the claim, making it fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant misconception in the paper regarding the use of \"execution feedback.\" It points out that the term is misleading, as no execution feedback is actually used in the work. The reviewer provides a detailed explanation of how execution feedback is approximated based on structural perturbations in the Abstract Syntax Tree (AST) and how the authors assume any such perturbation results in a failure as execution feedback (EF = 0). Additionally, the comment highlights a discrepancy between the definition of execution feedback in Equation 1 and the assumption made in the paper. This feedback is clear and actionable, as it directs the authors to revise their use of \"execution feedback\" and clarify their methodology. By addressing these points, the authors can significantly improve the accuracy and clarity of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two specific areas where additional information is needed: the use of \"40 target words\" and the method of removing bias through \"a sequence of dots.\" It also points out the lack of detail regarding the sampling of games to demonstrate the severity of the bias problem. While the comment identifies specific areas that need clarification or elaboration, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to provide more information on these aspects, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"40 target words\" and \"a sequence of dots,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by pointing out the lack of information regarding the use of \"40 target words\" and the method of removing bias through \"a sequence of dots.\" Additionally, it highlights the need for more detail on the sampling of games to demonstrate the severity of the bias problem. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of information regarding the use of \"40 target words\" and the method of removing bias through \"a sequence of dots.\" It also questions the detail provided about the sampling of games to demonstrate the severity of the bias problem. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact nature of the issues. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it requires further clarification or evidence to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper lacks detail and clarity, particularly regarding the use of \"40 target words\" and the method of removing bias through \"a sequence of dots.\" It also points out the lack of detail regarding the sampling of games to demonstrate the severity of the bias problem. This feedback is clear and actionable, as it directs the authors to provide more information and context to enhance the understanding and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of what additional information might be needed. Overall, the comment is mostly helpful as it effectively guides the authors toward improving the clarity and completeness of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the experiments: that they are conducted on simple datasets and that the uniformly random missing is unrealistic in practice. However, it does not provide any explicit or implicit suggestions for how the authors might address these issues. There is no guidance on whether the datasets should be more complex or how to improve the realism of the missing data. Without actionable advice or concrete steps, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of conducting experiments on simple datasets and the unrealistic nature of uniformly random missing data. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the experiments and the missing data, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are conducted on simple datasets and that the uniformly random missing is unrealistic in practice. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experiments conducted in the paper, noting that they are conducted on simple datasets. Additionally, it points out the unrealistic nature of the uniformly random missing data. While the comment highlights a potential weakness, it lacks specific suggestions or guidance on how the authors might address these issues or improve their experiments. Without actionable feedback or detailed advice, the authors may find it challenging to make meaningful improvements to their draft. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include legends for the plots in Figure 4, which would make the figures easier to interpret. This feedback is clear and provides a direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and provides concrete guidance, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of legends for the plots to improve interpretability. This provides clear guidance on what the authors need to do to enhance the clarity of their figures. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 4 lacks legends, making it difficult to interpret the plots. This is a factual observation that does not require an opinion or subjective judgment. It provides a clear and objective statement about the content of the figure, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 4, noting that it lacks legends for the plots, making it difficult to interpret. This feedback is clear and actionable, as it directly instructs the authors to include legends for each data point/plot to improve the clarity and accessibility of the figure. By addressing this issue, the authors can enhance the interpretability and usability of their visualizations, which is a crucial aspect of scientific communication. Therefore, the comment is highly helpful as it provides a concrete and constructive suggestion for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the paper is focused on sequence-to-sequence models and suggests that the general quantization aware training strategy could be extended to other models. It also asks if there are specific benefits of the proposed robustness-aware quantization scheme for sequence-to-sequence models. While the comment implies that the authors should clarify these points, it does not provide explicit instructions or concrete actions for the authors to take. The feedback is somewhat actionable as it highlights areas for clarification, but it lacks detailed guidance on how to address these questions.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the focus of the paper and suggests that the general quantization aware training strategy could be extended to other models. It also asks if there are specific benefits of the proposed robustness-aware quantization scheme for sequence-to-sequence models. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the content of the paper. The authors can infer that it pertains to the sections discussing the quantization aware training strategy and the robustness-aware quantization scheme. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the focus of the paper and suggests that the general quantization aware training strategy could be extended to other models. It also asks if there are specific benefits of the proposed robustness-aware quantization scheme for sequence-to-sequence models. While the comment does not contain subjective opinions or claims that require verification, it does ask for clarification and seeks additional information. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the focus of the paper and suggests that the general quantization aware training strategy could be extended to other models. It also asks if there are specific benefits of the proposed robustness-aware quantization scheme for sequence-to-sequence models. While the comment identifies areas for clarification and potential extensions, it lacks specific guidance or suggestions on how the authors might address these points. The feedback is somewhat helpful as it prompts the authors to consider the broader applicability of their work, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests additional ablation on how the algorithm's behavior and accuracy of its Q estimates change as the hyperparameter lambda changes. This is a clear and direct action for the authors to take, as it provides a specific area for further exploration and analysis. The comment is specific about what additional information is needed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 2\" and \"lambda,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests additional ablation on how the algorithm's behavior and accuracy of its Q estimates change as lambda changes. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional ablation on how the algorithm's behavior and accuracy of its Q estimates change as the hyperparameter lambda changes. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by requesting additional ablation on how the algorithm's behavior and accuracy of its Q estimates change as the hyperparameter lambda changes. This feedback is clear and actionable, as it provides a direct suggestion for the authors to explore further. By addressing this request, the authors can enhance their understanding of the algorithm's behavior and potentially improve the robustness of their results. However, the comment could be more helpful if it included specific suggestions on which aspects of the algorithm to focus on or how to conduct the ablation. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two questions: \"What is the base encoder of the proposed model?\" and \"Do the authors train the model from scratch?\" These questions are explicit and provide clear actions for the authors to take. The first question seeks clarification about the base encoder, while the second question asks about the training process. Both questions are direct and provide specific details that the authors can address to improve their draft. The action is explicit and concrete, as it instructs the authors to provide information about the base encoder and training process. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises two questions about the proposed model: \"What is the base encoder of the proposed model?\" and \"Do the authors train the model from scratch?\" These questions are specific and clearly identify areas of the paper that need clarification or explanation. However, they do not specify which part of the paper these questions pertain to, making it weakly grounded. The authors can infer that it relates to the model description or training process, but they cannot confidently determine the exact section. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions: \"What is the base encoder of the proposed model?\" and \"Do the authors train the model from scratch?\" These questions are factual in nature and do not contain subjective claims or opinions. They are purely requests for clarification or information, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment consists of two questions: \"What is the base encoder of the proposed model?\" and \"Do the authors train the model from scratch?\" These questions are clear and direct, as they seek to clarify specific aspects of the proposed model and its training process. By asking for clarification on the base encoder and training method, the reviewer prompts the authors to provide more detailed information about their work. This feedback is actionable and can help the authors improve the clarity and completeness of their draft. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided additional context. Overall, the comment is mostly helpful, as it identifies areas for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the Ethical Statement is well written but should be extended with more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. While the comment implies that the authors should expand their discussion, it does not provide specific guidance on how to do so or what additional aspects to cover. The action is implicit and somewhat vague, as the authors can infer that they need to expand their discussion but may not know exactly what aspects to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Ethical Statement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the Ethical Statement is well written but should be extended with more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. However, the comment does not provide specific examples or detailed reasoning to support why these challenges should be addressed or how they might be discussed. The lack of detailed justification makes it difficult for the authors to understand the basis of the suggestion, rendering the claim borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the Ethical Statement, suggesting that it should be extended to discuss challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. While the comment highlights a relevant point about the limitations of the dataset, it lacks specific guidance or examples on how the authors might address these challenges. Providing more concrete suggestions or examples would make the feedback more actionable and helpful. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the transformation from $\\\\hat{m}_t$ and $g_t$ in equation (13) to $x$ in equation (14). While it identifies a potential confusion, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might clarify this issue or what steps they should take to address it. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (13)\" and \"equation (14),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by asking for clarification on the transformation from $\\\\hat{m}_t$ and $g_t$ to $x$ in equation (14). This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the transformation from $\\\\hat{m}_t$ and $g_t$ in equation (13) to $x$ in equation (14). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the transformation from $\\\\hat{m}_t$ and $g_t$ in equation (13) to $x$ in equation (14), seeking clarity on this transformation. While it identifies a potential area of confusion, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to address this issue or improve the clarity of their work. As a result, it offers limited value to the authors, making it barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the length of the mini-batches tau_t, noting that it may be non-integers and suggesting that this should be clarified. The reviewer also questions the validity of the analysis if tau_t is very small. While the comment identifies a potential issue, it does not provide explicit guidance on how to clarify this aspect or address the concern about the analysis. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the issue and its potential implications. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"length of the mini-batches tau_t,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the potential non-integer values of tau_t and questions the validity of the analysis if tau_t is very small. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the length of the mini-batches tau_t, noting that it may be non-integers and suggesting that this should be clarified. The reviewer questions the validity of the analysis if tau_t is very small, but does not provide specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate the concern, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the issue, as the comment does not provide clear guidance on how to proceed. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the length of the mini-batches tau_t, noting that it may be non-integers and suggesting that this should be clarified. The reviewer raises a question about the validity of the analysis if tau_t is very small, prompting the authors to consider the implications of this potential issue. While the comment highlights a specific area for clarification, it lacks depth and does not provide detailed guidance on how to address the concern or what specific aspects of the analysis might be affected. This limits the comment\\'s helpfulness, as it points out a potential problem but does not offer actionable steps for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to examine the computational cost associated with the inference process of the SCALE model, specifically mentioning the two types of decoding involved: STM decoding and LLM decoding. This provides a clear and direct action for the authors to take, ensuring they understand the need to assess the inference cost. The comment is specific and provides concrete guidance on how to implement the suggested action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the SCALE model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the computational cost associated with the inference process of the SCALE model, and it differentiates between STM decoding and LLM decoding. This provides clear guidance on what aspects of the paper need attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the computational cost associated with the inference process of the SCALE model should be examined. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors examine the computational cost associated with the inference process of the SCALE model. It highlights the importance of considering both STM decoding and LLM decoding, which are two types of decoding processes involved in the model. This feedback is clear and actionable, providing the authors with a direct and specific direction for enhancing their draft. However, the comment could be more helpful if it offered additional guidance on how to assess or analyze the computational cost. Overall, the comment is mostly helpful as it directs the authors to a critical aspect of their work that requires attention.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two main issues with the paper: the limited use of the complete dataset and the lack of performance comparisons with state-of-the-art models, making it difficult to demonstrate the effectiveness of the proposed methods. Additionally, it points out some peculiar experimental results, such as the unsupervised result outperforming the supervised result in the 5th row of Table 2. While the comment identifies these issues, it does not provide explicit guidance on how to address them. The authors can infer that they need to expand their dataset and include comparisons with state-of-the-art models, but the comment lacks concrete suggestions on how to implement these improvements. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks detailed guidance.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two main issues with the paper: the limited use of the complete dataset and the lack of performance comparisons with state-of-the-art models, making it difficult to demonstrate the effectiveness of the proposed methods. It also points out some peculiar experimental results, such as the unsupervised result outperforming the supervised result in the 5th row of Table 2. While the comment does not explicitly mention specific sections of the paper, it is clear that it relates to the experimental results and methodology sections. The comment is specific in detailing what needs to be addressed, such as the need for expanded datasets and comparisons with state-of-the-art models. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks performance comparisons with state-of-the-art models and uses only a subset of the complete dataset, making it difficult to demonstrate the effectiveness of the proposed methods. The comment also points out some peculiar experimental results, such as the unsupervised result outperforming the supervised result in the 5th row of Table 2. While the comment identifies specific issues, it does not provide detailed reasoning or references to support the claims. The lack of specific examples or detailed justification makes it challenging for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is somewhat verifiable, as it highlights areas for improvement but lacks sufficient evidence or detailed reasoning to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the limited use of the complete dataset and the lack of performance comparisons with state-of-the-art models, making it difficult to demonstrate the effectiveness of the proposed methods. Additionally, it points out some peculiar experimental results, such as the unsupervised result outperforming the supervised result in the 5th row of Table 2. While the comment highlights these areas for improvement, it does not provide specific suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it directs the authors\\' attention to areas needing improvement, but it lacks detailed guidance or actionable steps to enhance the draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the phrase \"lacks inherent semantic meaning\" is used but not further elaborated upon. However, it does not provide any guidance on how the authors should address this issue or what specific elaboration is needed. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is vague and not actionable, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the phrase \"lacks inherent semantic meaning,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of elaboration on the meaning of the phrase. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the phrase \"lacks inherent semantic meaning\" is used but not further elaborated upon. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a specific issue with the phrase \"lacks inherent semantic meaning,\" noting that it is used but not further elaborated upon. While this feedback identifies a potential weakness in the paper, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their argument. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the paper, such as the lack of details or justification for using a large number of hidden units and an additional elementwise function, as well as the potential bias introduced by treating unobserved ratings as zeros. However, it does not provide explicit guidance on how the authors should address these issues. The comment implies that the authors should provide more detailed explanations or justification for their choices, but it lacks concrete steps or suggestions on how to improve the draft. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific issues with the paper, such as the lack of details or justification for using a large number of hidden units and an additional elementwise function, as well as the potential bias introduced by treating unobserved ratings as zeros. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for more justification or explanation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient details or justification for using a large number of hidden units and an additional elementwise function, and that treating unobserved ratings as zeros may introduce bias. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes it challenging for the authors to address the issues effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper could be improved, such as the lack of justification or details regarding the use of a large number of hidden units and an additional elementwise function. It also points out the potential bias introduced by treating unobserved ratings as zeros. While the comment highlights important areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it directs the authors\\' attention to specific areas needing attention, but it lacks actionable advice or detailed guidance. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a weakness in the claim regarding motivation, specifically noting that MathGLM achieves a high accuracy of 93.03% on a constructed dataset for complex computations, which can be replicated with 100% accuracy using other tools. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their motivation. It lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific claim regarding the motivation of the paper, specifically mentioning the high accuracy of 93.03% achieved by MathGLM on a constructed dataset for complex computations. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in detailing the issue with the claim, noting that these calculations can be replicated with 100% accuracy using other tools. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation for the paper is not robust, as MathGLM achieves a high accuracy of 93.03% on a constructed dataset for complex computations, which can be replicated with 100% accuracy using other tools. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a weakness in the paper\\'s motivation, specifically noting that the claim regarding the high accuracy of MathGLM is not robust. It points out that the high accuracy of 93.03% on a constructed dataset for complex computations can be replicated with 100% accuracy using other tools. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their motivation. While it highlights a potential weakness, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation in the paper, specifically that the authors rely on synthetic datasets for evaluating event-based dense tracking, which does not accurately reflect the real-world scenario. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative datasets or methods for evaluating event-based dense tracking in real-world settings. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation in the paper regarding the use of synthetic datasets for evaluating event-based dense tracking, which does not accurately reflect real-world scenarios. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the evaluation methodology, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of synthetic datasets for evaluating event-based dense tracking does not accurately reflect real-world scenarios, which is a significant weakness. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue. Without concrete evidence or reasoning, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the reliance on synthetic datasets for evaluating event-based dense tracking, which does not accurately reflect real-world scenarios. This is a critical observation that highlights a limitation in the paper\\'s evaluation methodology. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending alternative datasets or methods for evaluating event-based dense tracking in real-world settings. While it points out a significant weakness, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the motivation of the paper is unclear and questions the justification for opposing the common understanding of the importance of diversity in instruction-tuning data. It also criticizes the experiments as weak due to the limited dataset and LLM size, suggesting that the results may be unconvincing and potentially misleading. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their work. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide stronger justification and validation for their claims. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the motivation of the paper, specifically questioning the justification for opposing the common understanding of the importance of diversity in instruction-tuning data. It also critiques the experiments as weak due to the limited dataset and LLM size, suggesting that the results may be unconvincing and potentially misleading. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The authors can infer that it relates to the motivation and experimental sections, but this inference is not direct. The comment is specific in detailing the issues with the motivation and experiments, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation of the paper is unclear and questions the justification for opposing the common understanding of the importance of diversity in instruction-tuning data. It also criticizes the experiments as weak due to the limited dataset and LLM size, suggesting that the results may be unconvincing and potentially misleading. The comment provides some reasoning by referencing the common understanding of diversity importance, but it lacks specific examples or references to support the claim about the experiments being weak. This makes the claim somewhat verifiable, as it provides some basis but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s motivation, questioning the justification for opposing the common understanding of the importance of diversity in instruction-tuning data. It also critiques the experiments as weak due to the limited dataset and LLM size, suggesting that the results may be unconvincing and potentially misleading. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is somewhat helpful as it points out critical weaknesses but does not provide actionable steps for improvement, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the absence of confidence intervals in Table 3, specifically regarding the substitution ASR. While it identifies a potential issue, it does not provide any explicit or implicit suggestions for how the authors might address this concern. The comment lacks actionable guidance or advice on how to include confidence intervals or what specific steps to take to improve the table. As a result, the authors are left without a clear understanding of what changes to make or how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the absence of confidence intervals on the substitution ASR, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the absence of confidence intervals in Table 3, specifically regarding the substitution ASR. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the absence of confidence intervals in Table 3, particularly regarding the substitution ASR. This feedback is clear and actionable, as it prompts the authors to consider including confidence intervals in their analysis. However, the comment lacks depth and does not provide suggestions on how to address this issue or what specific data or analysis might be needed to include confidence intervals. While it identifies a potential area for improvement, it could be more helpful with additional guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity regarding how to estimate the mean element mu_g for different kernel spaces. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific methods or approaches to estimate mu_g, or suggesting ways to clarify the explanation in the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of estimating the mean element mu_g for different kernel spaces, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in estimating mu_g. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is not clear how to estimate the mean element mu_g for different kernel spaces. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the estimation of the mean element mu_g for different kernel spaces. It highlights a potential gap in the clarity of the paper, which could impact the readers\\' understanding of the methodology. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it points out a relevant area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides some insight but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that while some baselines may not work on larger datasets, it is still beneficial to consider datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions. This feedback implies that the authors should consider these datasets as part of their evaluation, which provides a clear action for the authors to take. However, the comment does not specify which baselines are problematic or how to implement the suggested evaluation on ImageNet. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that while some baselines may not work on larger datasets, it is still beneficial to consider datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of datasets with larger numbers of clusters, but without explicit references to specific sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that while some baselines may not work on larger datasets, it is still beneficial to consider datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions. This claim is somewhat verifiable as it provides a logical reasoning for considering larger datasets with more clusters, which could enhance the study's completeness. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of this suggestion themselves, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that while some baselines may not work on larger datasets, it is still beneficial to consider datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions. This makes the story more complete. The comment provides a constructive suggestion for enhancing the study by considering datasets with larger numbers of clusters, which could help validate the results and provide a more comprehensive understanding of the baselines. However, the comment could be more helpful if it offered specific guidance on how to implement this suggestion or which baselines might be suitable for such datasets. Overall, the comment is mostly helpful as it provides a clear direction for improvement but lacks detailed guidance, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the Cosine similarity score would be more effective than the Euclidean distance when computing the Decidability. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or whether it should be considered in the paper. As a result, the authors are left without any clear direction on how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the effectiveness of using Cosine similarity score versus Euclidean distance when computing the Decidability. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment where this comparison is made. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, the comment lacks specificity as it does not provide details on why Cosine similarity might be more effective or how it could be incorporated into the paper. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the effectiveness of using Cosine similarity score versus Euclidean distance when computing the Decidability. However, it does not provide any supporting evidence, reasoning, or references to justify why Cosine similarity might be more effective. Without such information, the claim remains unverifiable, as it lacks the necessary justification to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the effectiveness of using Cosine similarity score versus Euclidean distance when computing the Decidability. While it identifies a potential area for improvement, it lacks depth and does not provide specific suggestions or guidance on how to address this issue. The comment prompts the authors to consider the use of Cosine similarity, but without further elaboration or actionable advice, it does not offer much value to the authors in terms of improving their draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the experiments, including the lack of comparison with other counterpart methods and the insufficiency of experimental results to validate the effectiveness of the proposed method. However, it does not provide explicit guidance on how the authors should address these issues or what specific changes should be made. The feedback is vague and lacks concrete steps for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the experiments, specifically mentioning that the paper only conducts a toy experiment and an experiment on a real-world dataset. It also notes the lack of comparison with other counterpart methods and the insufficiency of experimental results to validate the effectiveness of the proposed method. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what is missing or inadequate in the experiments, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are weak and lacks comparison with other counterpart methods. It also criticizes the insufficiency of experimental results to validate the effectiveness of the proposed method. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claims but lacks sufficient detail to fully substantiate them.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several weaknesses in the experiments, including the lack of comparison with other counterpart methods and the insufficiency of experimental results to validate the effectiveness of the proposed method. It highlights specific issues with the experiments, such as the limited scope of the toy experiment and the absence of a real-world dataset comparison. However, the comment does not provide actionable suggestions or guidance on how the authors might address these weaknesses or improve their experiments. While it points out areas for improvement, the feedback lacks depth and specificity, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the figures related to completion errors are not referenced in the relevant analysis sections of the appendix. This provides a clear and direct action for the authors to take, which is to ensure that the figures are properly referenced in the relevant analysis sections. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"figures related to completion errors\" and the \"relevant analysis sections of the appendix,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of references to the figures in the relevant analysis sections of the appendix. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the figures related to completion errors are not referenced in the relevant analysis sections of the appendix. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that the figures related to completion errors are not referenced in the relevant analysis sections of the appendix. This is a clear and actionable point that the authors can address to improve the clarity and completeness of their draft. However, the comment could be more helpful if it provided additional context or suggestions on how to reference these figures effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether perplexity is measured consistently across validation sets at different levels. While it identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment lacks actionable details, such as recommending specific steps to ensure consistency or suggesting alternative methods for measuring perplexity. As a result, the authors are left without a clear understanding of what changes need to be made to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about whether perplexity is measured consistently across validation sets at different levels. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the measurement of perplexity, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether perplexity is measured consistently across validation sets at different levels. However, it does not provide any supporting evidence, reasoning, or references to justify why this inconsistency might be problematic or how it affects the results. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the consistency of perplexity measurements across validation sets at different levels. While it identifies a potential issue, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this concern. The comment does not offer actionable feedback or detailed advice, leaving the authors without a clear path for improvement. Therefore, it is rated as barely helpful, as it provides some insight but does not fully support the authors in enhancing their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the setting and algorithm lack originality and are incremental combinations of methods for graph labelings prediction and online learning in a switching environment. However, it also acknowledges the efficiency and uniqueness of the algorithm for graph labelings. While the comment implies that the authors should consider making their work more original, it does not provide specific guidance on how to achieve this or what aspects need to be revised. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance the originality of their work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the setting and algorithm lack originality and are incremental combinations of methods for graph labelings prediction and online learning in a switching environment. However, it also acknowledges the efficiency and uniqueness of the algorithm for graph labelings. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the introduction or discussion sections where the setting and algorithm are described. The comment is specific in pointing out the issue of lack of originality and the uniqueness of the algorithm, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the setting and algorithm lack originality and are incremental combinations of methods for graph labelings prediction and online learning in a switching environment. However, it also acknowledges the efficiency and uniqueness of the algorithm for graph labelings. The comment provides a subjective opinion without supporting evidence or references to substantiate the claim about originality. The mention of the algorithm's efficiency and uniqueness offers some justification, but the overall claim remains somewhat verifiable due to the lack of detailed reasoning or specific examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the setting and algorithm lack originality and are incremental combinations of methods for graph labelings prediction and online learning in a switching environment. However, it also acknowledges the efficiency and uniqueness of the algorithm for graph labelings. This feedback provides a somewhat helpful insight into the perception of the work\\'s originality, but it lacks specific suggestions or guidance on how to enhance the originality or differentiate the work further. The comment highlights a potential issue but does not offer actionable advice or detailed feedback for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with using the state action of the current policy in the target environment as regularization, as it could lead to suboptimal learning. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider the potential negative impact of using state actions for regularization, but it lacks concrete steps or recommendations on how to mitigate this issue. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of state action of the current policy in the target environment as regularization, suggesting that it could harm learning due to the potential for suboptimal state action distribution. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its concern about the potential negative impact of using state actions for regularization, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using state action of the current policy in the target environment as regularization can harm learning, as it could lead to suboptimal state action distribution used for regularization. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides a logical argument but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with using state action of the current policy in the target environment as regularization, suggesting that it could lead to suboptimal learning due to the distribution of suboptimal state actions. This is a valuable observation that could help the authors reconsider their approach to regularization. However, the comment lacks specific guidance or suggestions on how to address this issue or mitigate the potential negative effects. While it highlights a critical aspect of the paper, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential negative impact of the feature compactness loss and sharpness-aware minimization on the model's performance on base classes. It suggests that if such degradation occurs, the authors should discuss how to mitigate it to maintain performance on the base classes. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss mitigation strategies. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the objective of the feature compactness loss and sharpness-aware minimization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the potential negative impact of these operations on the model's performance on base classes and suggests discussing mitigation strategies. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the potential negative impact of the feature compactness loss and sharpness-aware minimization on the model's performance on base classes. It suggests that if such degradation occurs, the authors should discuss how to mitigate it to maintain performance on the base classes. However, the comment lacks specific examples or references to support the claim that such degradation might occur. Without detailed evidence or reasoning, the claim remains somewhat verifiable, as the authors would need to infer the potential impact and explore mitigation strategies on their own. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the objective of the feature compactness loss and sharpness-aware minimization, suggesting that it could negatively impact the model's performance on base classes. It raises a critical question about the consequences of such degradation and encourages the authors to discuss mitigation strategies if necessary. This feedback is clear and actionable, as it prompts the authors to consider the potential impact on their model and provides a direction for addressing it. However, the comment could be more helpful if it offered specific suggestions or examples of how to mitigate the issue. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: \"What is the insight from this work to develop new methods?\" and \"How to prevent the attention collapse in CL?\" These questions are explicit and provide clear guidance on what the authors need to address. However, the comment does not offer specific suggestions or examples on how to address these questions, leaving the authors with a general idea of what needs to be improved but without concrete steps to take. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions about the insights gained from the work and how to prevent attention collapse in CL. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions themselves are specific, as they ask for clarification on the insights and the methodology for preventing attention collapse. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions: \"What is the insight from this work to develop new methods?\" and \"How to prevent the attention collapse in CL?\" These questions are factual and do not contain subjective claims, opinions, or suggestions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions that are relevant to the paper\\'s contribution and potential impact. The first question, \"What is the insight from this work to develop new methods?\", seeks to understand the novelty and practical applications of the work. The second question, \"How to prevent the attention collapse in CL?\", highlights a potential challenge in the context of CL and invites the authors to address it. While the questions themselves are clear and actionable, the comment could be more helpful by providing specific suggestions or examples on how to address these questions. Overall, the comment is somewhat helpful as it directs the authors\\' attention to important areas for improvement, but it lacks depth and detailed guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the lack of clarity regarding how the CHC model affects the capabilities of MLLMs and suggests that the paper should provide more information on specific attributes or behaviors that a powerful MLLM would exhibit when grounded in CHC theory. It also questions whether there are any case studies or pilot experiments that illustrate the significance of this influence. While the comment implies that the authors should provide more detailed information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information on the influence of the CHC model. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"main content\" and \"CHC model,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a clear question about how the CHC model affects the capabilities of MLLMs and suggests that the paper should provide more information on specific attributes or behaviors that a powerful MLLM would exhibit when grounded in CHC theory. Additionally, it questions whether there are any case studies or pilot experiments that illustrate the significance of this influence. This provides a clear direction for the authors to improve their draft by addressing the identified gap. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the influence of the CHC model on the capabilities of MLLMs and suggests that the paper should provide more information on specific attributes or behaviors that a powerful MLLM would exhibit when grounded in CHC theory. The reviewer also questions whether there are any case studies or pilot experiments that illustrate the significance of this influence. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim that the influence is unclear or insufficiently explored. This makes the claim somewhat verifiable, as it provides a direction for improvement but does not fully substantiate the claim with evidence or detailed reasoning. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the influence of the CHC model on the capabilities of MLLMs. It questions what specific attributes or behaviors a powerful MLLM would exhibit when grounded in CHC theory and suggests that the paper should provide more information on this topic. Additionally, it questions whether there are any case studies or pilot experiments that illustrate the significance of this influence. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by addressing the identified gap in understanding. However, the comment could be more helpful if it offered suggestions on how to conduct these case studies or experiments. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider integrating more up-to-date pretraining models to showcase the significance and practical usage of their approach. It provides examples of recent works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation with Hierarchical Prompts,\" which could be integrated. However, the comment does not explicitly instruct the authors to integrate these models or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should integrate these models to enhance their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Pre-GNN\" model, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors consider integrating more up-to-date pretraining models to showcase the significance and practical usage of their approach. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors consider integrating more up-to-date pretraining models to showcase the significance and practical usage of their approach. The reviewer provides examples of recent works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation with Hierarchical Prompts,\" which could be integrated. However, the comment lacks detailed reasoning or specific examples of how these newer models would enhance the authors\\' approach. While the suggestion is logical, the lack of detailed justification or comparisons makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by noting that the pretraining model used is relatively old in the context of molecular pretraining. It suggests that the authors consider integrating more up-to-date pretraining models to showcase the significance and practical usage of their approach. The comment provides specific examples of recent works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation with Hierarchical Prompts,\" which could be integrated. This feedback is clear and actionable, as it directs the authors to consider incorporating more recent models to enhance the relevance and impact of their work. However, the comment could be more helpful if it provided additional guidance on how to integrate these models or why they are particularly relevant to the paper. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the model takes the difference between current object pose and target object pose as input, which can present significant engineering challenges. However, it also notes that the authors have documented their approach well in Section A.3. While the comment highlights a potential issue, it does not provide any explicit or implicit actions for the authors to take. It does not suggest improvements, nor does it offer guidance on how to address the engineering challenges or improve the documentation. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the model's input, specifically the difference between current object pose and target object pose, which can present significant engineering challenges. It acknowledges that the authors have documented their approach well in Section A.3. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential engineering challenges and the authors\\' approach, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges that the model takes the difference between current object pose and target object pose as input, which can present significant engineering challenges. It also notes that the authors have documented their approach well in Section A.3. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim about the engineering challenges or the effectiveness of the documentation. This lack of supporting evidence or justification makes the claim borderline verifiable, as it provides some insight but lacks the necessary detail for the authors to fully understand and address the feedback. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges that the model takes the difference between current object pose and target object pose as input, which can present significant engineering challenges. It also notes that the authors have documented their approach well in Section A.3. However, the comment does not provide any specific suggestions or guidance on how the authors might address these challenges or improve their documentation. While it highlights a potential issue, it lacks actionable feedback or detailed advice, making it barely helpful. The authors are informed of a potential problem but are not given clear steps to address it, limiting the utility of the comment. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more downstream performance examples of their controllable text generation models, specifically mentioning the connection to real NLG applications and the potential advantage of their model. It also mentions style transfer as a potential starting point. While the comment implies that the authors should provide more detailed information about the downstream performance, it does not explicitly instruct them to do so or provide specific guidance on how to connect the models to real-world applications. The action is somewhat clear but lacks concrete details on how to implement it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 116-117,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what the authors need to address: providing more downstream performance examples of their controllable text generation models and connecting them to real NLG applications. The comment suggests that style transfer could be a good starting point. This provides clear guidance on what needs to be improved, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more downstream performance examples of their controllable text generation models, specifically mentioning the connection to real NLG applications and the potential advantage of their model. The reviewer provides a suggestion to consider style transfer as a starting point. However, the comment lacks specific examples or detailed reasoning to support the claim about the need for more downstream performance or the potential advantage of the proposed models. This makes the claim somewhat verifiable, as it provides a general direction but lacks detailed justification or evidence. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides constructive feedback by suggesting that the authors should provide more downstream performance examples of their controllable text generation models, specifically focusing on their connection to real NLG applications and the potential advantage of their model. The reviewer mentions style transfer as a potential starting point, which offers a clear direction for the authors to enhance their draft. However, the comment could be more helpful if it provided specific examples or guidance on how to connect the models to real-world applications or how to demonstrate the advantage of the proposed models. Despite this, the feedback is mostly helpful as it encourages the authors to expand on their experimental results and provide more detailed explanations of their work. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the test set performance on GLUE datasets, specifically asking if the labels for these datasets are not available to the public. While the comment implies that the authors should clarify this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question about the availability of labels. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the test set performance on GLUE datasets, specifically asking if the labels for these datasets are not available to the public. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where this information is discussed. This makes it difficult for the authors to identify the exact part of the paper that needs clarification. Additionally, the comment lacks specificity in detailing what aspect of the test set performance is confusing or how it relates to the availability of labels. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the test set performance on GLUE datasets, specifically inquiring about the availability of labels for these datasets. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the test set performance on GLUE datasets, specifically inquiring about the availability of labels for these datasets. While this question highlights a potential area of confusion, it does not provide any actionable feedback or suggestions for improvement. The authors are left with a vague request to clarify the issue, but without guidance on how to address it or what specific aspects of the test set performance need clarification. This lack of actionable feedback limits the helpfulness of the comment, making it barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 3.2 may be shortened because many equations are not proposed by the work but are already well-known in the community. It implies that the authors should consider removing these equations to save space and include important details that are missing. While the comment provides a clear action\u2014to shorten the section\u2014it does not specify which equations should be removed or how to prioritize the inclusion of missing details. The action is explicit but lacks concrete guidance on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that Section 3.2 may be shortened because many equations are not proposed by the work but are already well-known in the community. However, it does not specify which equations are in question or where they are located in the paper. This makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what additional details should be included or how they should be integrated into the section. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that Section 3.2 may be shortened because many equations are not proposed by the work but are already well-known in the community. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion to shorten the section. However, it lacks specific examples or references to the equations or their well-known status, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that Section 3.2 may be shortened because many equations are not proposed by the work but are already well-known in the community. This feedback is somewhat helpful as it identifies an area where the paper could be streamlined by removing redundant information. However, the comment lacks specific guidance on which equations to remove or how to prioritize the inclusion of missing details. While it points out a potential improvement, it does not provide detailed suggestions or examples, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the evaluation method used in Figure 3, Table 3, and Figure 5, specifically inquiring about whether it is based on automatic or human evaluation. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the evaluation method. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3, Table 3, and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks a clear question about the evaluation method used, which provides a clear direction for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the evaluation method used in Figure 3, Table 3, and Figure 5. It does not contain any claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the evaluation method used in Figure 3, Table 3, and Figure 5, which is a clear and actionable point. By asking for clarification on the evaluation method, the reviewer prompts the authors to provide more detailed information about their methodology. This feedback is valuable as it directs the authors to a specific area where their draft could be improved by offering more transparency about their evaluation process. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details should be included. Overall, the comment is mostly helpful as it identifies a critical area for clarification and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the average coverage rate being larger than the bound by theorem, suggesting that the authors should correct their understanding or provide additional assumptions to achieve the desired coverage rate. However, the comment does not explicitly instruct the authors to make these corrections or specify how to address the issue. While it implies that the authors should take action, the lack of concrete guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific numerical result, specifically the average coverage rate being larger than the bound by theorem. However, it does not explicitly mention which part of the paper this result is presented in, making it weakly grounded. The comment is specific in detailing the issue with the average coverage rate and suggesting that the authors correct their understanding or provide additional assumptions to achieve the desired coverage rate. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the average coverage rate being larger than the bound by theorem, suggesting that the authors should correct their understanding or provide additional assumptions to achieve the desired coverage rate. However, the comment lacks specific reasoning or evidence to support the claim that the average coverage rate is larger than the bound by theorem. Without detailed explanations or references, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the average coverage rate being larger than the bound by theorem, suggesting that the authors should correct their understanding or provide additional assumptions to achieve the desired coverage rate. While the comment highlights a specific area of concern, it lacks depth and does not provide detailed guidance on how to address this issue or what assumptions might be necessary. The feedback is somewhat helpful as it points out a potential problem but does not offer actionable steps for improvement, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that using a single translator per language for producing annotations may not be sufficient, as different translators may have different choices. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue, such as suggesting multiple translators or providing more detailed instructions for annotation production. As a result, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of using a single translator per language for producing annotations, suggesting that this approach may not be sufficient due to the potential for different choices among translators. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. The authors can infer that it relates to the annotation process, but the lack of explicit mention makes it weakly grounded. The comment is specific in detailing the potential issue with using a single translator per language, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using a single translator per language for producing annotations may not be sufficient because different translators may have different choices. However, the comment lacks specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the methodology, specifically the use of a single translator per language for producing annotations. It suggests that this approach may not be sufficient, as different translators may have different choices. While the comment highlights an important consideration, it lacks specific guidance or suggestions on how the authors might address this issue, such as suggesting multiple translators or providing more detailed instructions for annotation production. The feedback is somewhat helpful as it points out a potential weakness but does not offer actionable steps for improvement, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the statement \"people wear a hat and play guitar not vice-versa,\" suggesting that the authors should provide a rationale for this claim. However, the comment does not explicitly instruct the authors to provide this rationale or suggest how to address the issue. While the action is implied, it is vague and lacks concrete guidance on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the statement \"people wear a hat and play guitar not vice-versa,\" suggesting that the authors should provide a rationale for this claim. However, it does not specify which part of the paper this statement is found in, making it weakly grounded. The comment is specific in its request for an explanation or rationale, but without explicit references to sections or details, it is difficult for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the statement \"people wear a hat and play guitar not vice-versa,\" suggesting that the authors should provide a rationale for this claim. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this claim is questionable or how it might be improved. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the statement \"people wear a hat and play guitar not vice-versa,\" suggesting that the authors should provide a rationale for this claim. While the comment identifies a potential issue with the statement, it lacks depth and does not offer specific suggestions or guidance on how the authors might address this concern. The feedback is somewhat helpful as it points out a potential weakness, but it does not provide actionable advice or detailed feedback for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the number of examples provided may be insufficient for the model to learn the transformation correctly. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how many examples would be sufficient or what steps to take to ensure the model learns the transformation effectively. Without actionable advice or suggestions, the authors are left without a clear path to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the number of examples provided may be insufficient for the model to learn the transformation correctly. However, it does not specify which part of the paper this issue pertains to, such as the experimental setup or results section. Without explicit references to sections or figures, the authors cannot confidently determine where to address this concern. Additionally, the comment lacks specificity regarding what aspects of the model's learning process might be insufficient or how the authors might improve it. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the number of examples provided may be insufficient for the model to learn the transformation correctly. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the number of examples provided in the paper, suggesting that it may be insufficient for the model to learn the transformation correctly. However, it lacks specificity and does not provide any guidance on how the authors might address this issue or what additional examples might be needed. Without actionable advice or suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the difference between Algorithm 1 and variational inference, specifically asking for clarification on the advantages of Algorithm 1. While the comment implies that the authors should provide a comparison or explanation of the differences, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed comparison or explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on the difference between Algorithm 1 and variational inference, as well as the advantages of Algorithm 1. This provides clear guidance on what the authors need to address. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the difference between Algorithm 1 and variational inference, as well as the advantages of Algorithm 1. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the difference between Algorithm 1 and variational inference, as well as the advantages of Algorithm 1. By doing so, it prompts the authors to clarify and differentiate their approach from existing methods. This feedback is clear and actionable, as it encourages the authors to provide a detailed explanation or comparison of their algorithm with existing methods. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of potential advantages. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and differentiation of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the entailment exercise lacks basic details and is difficult to assess due to the lack of empirical and analyzed information. It suggests that either the exercise should be removed or provided with more details. This feedback provides clear and direct instructions for the authors to either remove the exercise or add more information to support it. The action is explicit and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"entailment exercise,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is lacking in the exercise, namely basic details and empirical evidence, and suggests that it should be removed or provided with more information. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the entailment exercise lacks basic details and is difficult to assess due to the lack of empirical and analyzed information. This claim is somewhat verifiable as it provides a logical reasoning for the need of additional details, but it lacks specific examples or references to support the claim. The authors would need to infer the specific details that are missing and the importance of providing them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the entailment exercise, noting that it lacks basic details and is difficult to assess due to the lack of empirical and analyzed information. It suggests that either the exercise should be removed or provided with more details. This feedback is clear and actionable, providing the authors with a direct path to improve their draft by either removing the exercise or adding more information to support it. However, the comment could be more helpful if it offered specific suggestions on what kind of empirical evidence or details would be beneficial. Overall, the comment is mostly helpful, as it effectively guides the authors on how to enhance their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the mathematical expression of the Gaussian distribution is ambiguous in lines 225 and 227. This provides a clear and direct action for the authors to take, which is to clarify or correct the expression. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (225 and 227) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issue with the mathematical expression of the Gaussian distribution being ambiguous. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the mathematical expression of the Gaussian distribution is ambiguous in lines 225 and 227. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the mathematical expression of the Gaussian distribution in lines 225 and 227, noting that it is ambiguous. This feedback is clear and actionable, as it directs the authors to clarify or correct the expression to improve the clarity of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the expression or offered examples of how similar expressions have been clarified in similar contexts. Despite this, the comment still offers valuable insights that can help the authors enhance the accuracy and readability of their draft. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the current testing is insufficient and recommends considering additional types of responses. However, it does not provide specific guidance on which types of responses should be considered or how to implement this suggestion. The action is implicit and vague, leaving the authors to infer that they need to expand their testing but without detailed instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the current testing is insufficient and recommends considering additional types of responses. However, it does not specify which part of the paper this pertains to, such as the experimental setup or results section. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The suggestion to consider additional types of responses is specific, but without grounding, the comment lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the current testing is insufficient and suggests considering additional types of responses. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the current testing is insufficient and recommends considering additional types of responses. While it identifies a potential weakness in the testing, it lacks specificity and does not provide any guidance on which types of responses should be considered or how to implement this suggestion. The feedback is somewhat helpful as it points out a potential area for improvement, but it does not offer actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the privacy protection capability of the paper, noting that the use of chatGPT for text paraphrasing does not guarantee the removal of privacy information. It also points out that relying solely on manipulating the temperature (T) may not effectively achieve text sanitization. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their privacy protection capabilities. The action is implicit and somewhat vague, as the authors can infer that they need to consider additional methods for ensuring privacy protection, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of chatGPT for text paraphrasing and the issue of privacy protection capability. It also specifies the concern that relying solely on manipulating the temperature (T) may not effectively achieve text sanitization. This provides clear guidance on what needs to be addressed, making it specific. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the privacy protection capability is insufficient and that the use of chatGPT for text paraphrasing does not guarantee the removal of privacy information. It also suggests that relying solely on manipulating the temperature (T) may not effectively achieve text sanitization. The comment provides a logical reasoning by pointing out the limitations of chatGPT and the need for additional methods to ensure privacy protection. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the issue and provide evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the privacy protection capability of the paper, noting that the use of chatGPT for text paraphrasing does not guarantee the removal of privacy information. It also points out that relying solely on manipulating the temperature (T) may not effectively achieve text sanitization. This feedback is clear and actionable, as it highlights a critical area for improvement in the paper\\'s privacy protection capabilities. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of alternative methods for ensuring privacy protection. Overall, the comment is mostly helpful as it directs the authors\\' attention to a significant weakness in their work and offers a direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the general discussion in the manuscript describes an approach in sentimental analysis using word embeddings to define the weight of each lexicon term. However, it notes that the novelty of this approach is not significant enough. While the comment identifies a potential issue with the novelty of the approach, it does not provide explicit guidance on how the authors should address this concern or improve the manuscript. The action is implicit and vague, leaving the authors to infer that they need to enhance the novelty or provide more context to justify the approach. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"general discussion\" section of the manuscript, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the novelty of the approach, noting that the use of word embeddings to define the weight of each lexicon term is not significant enough. This provides clear guidance on what needs to be improved in the manuscript. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty of the approach described in the manuscript is not significant enough. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, noting that the novelty of the approach described in the general discussion is not significant enough. However, it does not provide any further explanation or suggestions on how the authors might enhance the novelty or address this concern. Without actionable feedback or guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from comparing its method to non-NeRF methods on the mentioned tasks. This implies that the authors should include such a comparison in their work to enhance its understanding and evaluation. However, the comment does not specify which non-NeRF methods should be compared or how the comparison should be structured, leaving the authors with a general suggestion but without concrete guidance on execution. The action is explicit but somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from comparing its method to non-NeRF methods on the mentioned tasks. However, it does not specify which tasks or which non-NeRF methods should be compared, making it difficult for the authors to pinpoint the exact parts of the paper that need revision. The comment is specific in suggesting a potential improvement but lacks grounding as it does not identify specific sections or elements of the paper that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from comparing its method to non-NeRF methods on the mentioned tasks. This claim is somewhat verifiable as it provides a logical reasoning for why such a comparison would be beneficial, namely to help readers understand the method's advantages and its position relative to conventional methods. However, the comment lacks specific examples of non-NeRF methods or detailed guidance on how to conduct the comparison, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from comparing its method to non-NeRF methods on the mentioned tasks. This feedback is valuable as it identifies a potential area for improvement in demonstrating the advantages of the proposed method over existing approaches. By including such a comparison, the authors can enhance the clarity and comprehensiveness of their work, helping readers better understand its strengths and limitations. However, the comment could be more helpful if it provided specific non-NeRF methods to consider or detailed guidance on how to structure the comparison. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the use of the term \"NLU\" in the paper, questioning whether certain lower-level tasks should be considered NLU or syntactic tasks. While the comment identifies a potential issue with the terminology, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction between NLU and syntactic tasks. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific lines in the paper (178:181) and raises a question about the use of the term \"NLU\" throughout the paper. It also mentions a specific work (LINSPECTOR: Multilingual Probing Tasks for Word Representations) to provide context. However, the comment does not explicitly mention which part of the paper discusses the use of \"NLU\" or how it relates to the syntactic tasks mentioned. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the use of \"NLU\" and the distinction between lower-level tasks and syntactic tasks. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of the term \"NLU\" in the paper, specifically questioning whether certain lower-level tasks should be considered NLU or syntactic tasks. The comment provides a reference to a specific work (LINSPECTOR: Multilingual Probing Tasks for Word Representations) to support its claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the context and distinction between NLU and syntactic tasks to fully address the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of the term \"NLU\" in the paper, questioning whether certain lower-level tasks should be considered NLU or syntactic tasks. It provides a specific reference to a relevant work (LINSPECTOR: Multilingual Probing Tasks for Word Representations) to support its claim. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might clarify or address this issue. While it points out a potential area for improvement, it does not provide actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should briefly discuss the relationship of their idea to traditional approaches in computer vision, specifically mentioning the use of long-term motion trajectories. While the comment implies that this discussion would enhance the theoretical and academic value of their work, it does not explicitly instruct the authors to include this discussion. The action is implicit and somewhat vague, as the authors need to infer that they should include this discussion but are not provided with specific guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of long-term motion trajectories, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should discuss the relationship of their idea to traditional approaches in computer vision, such as motion segmentation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that using long-term motion trajectories is a traditional idea in computer vision, especially for motion segmentation. The reviewer provides a reference to a specific work, Keuper et al. (2015), which supports the claim by citing a relevant example. However, the comment also suggests that discussing the relationship of the authors\\' idea to these traditional approaches would enhance its theoretical and academic value. While the reference provides some context, the comment could be strengthened by further elaboration on how this discussion would contribute to the paper. Therefore, the comment is mostly verifiable, as it provides a logical basis for the claim but lacks detailed justification or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a constructive suggestion by recommending that the authors briefly discuss the relationship of their idea to traditional approaches in computer vision, specifically mentioning the use of long-term motion trajectories. This feedback is actionable and offers a clear path for enhancing the theoretical and academic value of the paper. By including this discussion, the authors could strengthen the context and relevance of their contribution, which is a valuable suggestion for improving the draft. However, the comment could be more helpful if it provided specific examples or guidance on how to approach this discussion. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the problem formalization section, noting that it lacks a clear description of the specific task types addressed on graph data. It also points out that the purpose of this section is unclear, as it fails to convey the author\\'s task objectives. This feedback provides a clear and explicit action for the authors to take, which is to clarify the specific task types and objectives in the problem formalization section. The comment is concrete and provides a direct action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"problem formalization section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a clear description of specific task types addressed on graph data and the failure to convey the author\\'s task objectives. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the problem formalization section lacks a clear description of specific task types addressed on graph data, and it focuses primarily on formalizing challenges faced. The reviewer suggests that this section is inconsistent with its intended purpose, as it fails to convey the author\\'s task objectives. The comment provides a logical reasoning by pointing out the lack of clarity in the section, which is a valid observation. However, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to make a concerted effort to address the issue, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the problem formalization section, noting that it lacks a clear description of the specific task types addressed on graph data. It also points out that the purpose of this section is unclear, as it fails to convey the author\\'s task objectives. This feedback is clear and actionable, as it provides the authors with a direct and specific area to focus on to improve the clarity and coherence of their work. By addressing these issues, the authors can enhance the comprehensibility and effectiveness of their section. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that an ablation study on training techniques is missing, specifically mentioning Informative Prior Initialization (IPI) and v-prediction. It highlights the importance of this study to assess the specific impact of these techniques and to compare YOSO's performance with other models that could potentially leverage them. The comment provides a clear and concrete action for the authors to include an ablation study, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of an ablation study on training techniques, such as Informative Prior Initialization (IPI) and v-prediction. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014an ablation study on these components\u2014and why it is important for assessing the impact of these techniques and comparing YOSO's performance with other models. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of an ablation study on training techniques, specifically mentioning Informative Prior Initialization (IPI) and v-prediction, makes it difficult to assess their specific impact and compare YOSO's performance with other models. This claim is somewhat verifiable as it logically highlights the importance of an ablation study to understand the impact of these techniques. However, the comment lacks specific examples or references to support the claim, such as detailed comparisons with other models or detailed analyses of the impact of these techniques. This makes the claim somewhat verifiable, as it provides a clear rationale but requires more detailed evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, namely the lack of an ablation study on training techniques, specifically mentioning Informative Prior Initialization (IPI) and v-prediction. This feedback is clear and actionable, as it highlights a critical area for improvement in assessing the impact of these techniques and comparing YOSO's performance with other models that could potentially leverage them. By addressing this gap, the authors can enhance the comprehensiveness and rigor of their evaluation, which is valuable guidance for improving the draft. However, the comment could be more helpful if it provided specific suggestions on how to conduct the ablation study or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the paper, such as redundant descriptions and a lack of validation experiments. It provides explicit actions for the authors to take, such as suggesting that they present a small-scale validation experiment using one of the datasets mentioned in the paper. The comment also highlights specific paragraphs that could be revised to avoid redundancy. While the action is clear, the comment could be more helpful by providing more detailed guidance on how to conduct the validation experiment or which datasets to use. Overall, the comment is mostly actionable as it clearly identifies areas for improvement and provides concrete suggestions for enhancing the paper.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (229 to 272) and datasets, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with redundancy and suggests a specific action, such as conducting a small-scale validation experiment using one of the mentioned datasets. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper's content is limited and contains redundant descriptions, specifically mentioning the two paragraphs from lines 229 to 272 that redundantly describe the motivation and work approach already covered in the introduction. The reviewer also suggests conducting a small-scale validation experiment using one of the datasets mentioned in the paper to address the lack of domain knowledge in LLMs for specific tasks. The comment provides specific examples of redundant descriptions and suggests a concrete action for improvement, making it mostly verifiable. However, it could be strengthened by providing more detailed reasoning or references to similar studies that have addressed this issue. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the content is limited and contains redundant descriptions. It provides a concrete example by pointing out two paragraphs that redundantly describe the motivation and work approach already covered in the introduction. Additionally, the reviewer suggests conducting a small-scale validation experiment using one of the datasets mentioned in the paper, which could help address the lack of domain knowledge in LLMs for specific tasks. This feedback is actionable and provides clear guidance for the authors to improve their draft. However, it could be more helpful if it included suggestions on which datasets to use or how to design the validation experiment. Overall, the comment is mostly helpful as it directs the authors toward a specific area for improvement and offers a concrete suggestion for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rewrite the section to make the connections between the theoretical contributions and the proposed method clearer. It provides a specific area for improvement by pointing out that the theoretical contributions seem too abstract and not directly related to the method. This feedback is concrete, as it identifies a specific action the authors need to take to improve their draft. However, it could be more helpful if it provided additional guidance on how to make these connections clearer or suggested specific language or examples to include. Overall, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"theoretical contributions\" and the \"section\" that needs revision. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the connection between the theoretical contributions and the proposed method. The comment provides guidance on how to improve the clarity of the connections, which is a clear and actionable suggestion. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical contributions are too abstract and not directly related to the proposed method, specifically mentioning the use of segregated feature vectors for backdoored vs. clean data. The reviewer suggests that the connections between the theoretical contributions and the proposed method are unclear, asking the authors to rewrite the section to clarify these connections. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the theoretical contributions are too abstract. This makes the claim somewhat verifiable, as it provides a general idea but requires more detailed evidence or reasoning to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the theoretical contributions, noting that they seem too abstract and not directly related to the proposed method. It provides a clear and actionable suggestion by asking the authors to rewrite the section to clarify the connections between the theoretical contributions and the proposed method. This feedback is valuable as it guides the authors on how to enhance the clarity and relevance of their theoretical contributions, which is an important aspect of the paper. However, the comment could be more helpful if it offered additional suggestions or examples on how to improve the connections or rephrased the theoretical contributions to better align with the proposed method. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of whether the code will be released, noting that the GCN implementation may be difficult to reproduce without the original code. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should consider releasing the code, but it lacks concrete steps or details on how to do so. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of whether the code will be released, specifically mentioning the GCN implementation and the difficulty in reproducing it without the original code. However, it does not specify which part of the paper this concern relates to, such as a specific section or figure where the code is discussed. The authors can infer that it relates to the discussion of code availability or reproducibility, but this inference is not direct. The comment is specific in detailing the issue with code availability, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of whether the code will be released, noting that the GCN implementation may be difficult to reproduce without the original code. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the code is difficult to reproduce or why the original code is necessary. Without additional context or examples, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a concern about the clarity of whether the code will be released, noting that the GCN implementation may be difficult to reproduce without the original code. While it identifies a potential issue with reproducibility, it does not provide specific suggestions or guidance on how the authors might address this concern. The comment highlights a potential problem but lacks actionable advice or detailed feedback on how to improve the draft. As a result, the feedback is somewhat helpful, as it points out a potential weakness but does not fully support the authors in resolving it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of second-order Taylor expansions in Equations (9) and (10) instead of the differential functions themselves. While it implies that the authors should consider using the differential functions directly, it does not provide explicit guidance on how to implement this change or why it might be beneficial. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equations (9) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the use of second-order Taylor expansions in place of differential functions and suggests that the differential functions themselves might be a better choice. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of second-order Taylor expansions in Equations (9) and (10) instead of the differential functions themselves. However, it does not provide any reasoning or evidence to support why the differential functions might be a better choice. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the suggestion.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the use of second-order Taylor expansions in Equations (9) and (10) instead of the differential functions themselves. It suggests that the differential functions might be a better choice, implying that the current approach could be improved. However, the comment lacks depth and does not provide specific reasoning or examples to support the suggestion. It does not offer actionable guidance or detailed feedback on how the authors might address this issue, making it somewhat helpful. The authors are given a direction to consider but lack the necessary information to fully understand and implement the suggested change. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the results presented in Table 3, specifically regarding the en-cs BPE to character results. It references external works that provide examples of recall on lemmas/forms seen in training, which suggests that the authors should include this information in their results. However, the comment does not explicitly instruct the authors to include this information or provide guidance on how to incorporate it into their analysis. The action is implicit and somewhat vague, as the authors need to infer that they should include this information but may not be entirely sure how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3\" and provides specific references to external works, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the missing recall on lemmas/forms seen in training, which is a clear and specific concern. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the en-cs BPE to character results in Table 3 are missing recall on lemmas/forms seen in training, referencing specific external works. This claim is supported by the references to [1], [2], and [3], which provide evidence of similar results in related studies. The references offer a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed analysis or explanation of why this discrepancy is significant. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results presented in Table 3, noting the missing recall on lemmas/forms seen in training. It provides references to external works that demonstrate similar results, which is helpful in guiding the authors to understand the expected behavior of their model. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context on why this discrepancy is significant. Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing attention and provides relevant references for further exploration. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of the proposed method on the MLSC setup, specifically questioning why the method does not improve many-to-many translation despite the claim of better word-alignment. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The authors are left to infer that they should provide an explanation or justification for the lack of impact, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it highlights an area for improvement but does not offer specific guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions why the proposed method has no impact on the MLSC setup, despite the claim of better word-alignment improving many-to-many translation. The comment further specifies that Section 4 touches on this point but lacks an explanation, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that better word-alignment improves many-to-many translation, given that the proposed method has no impact on the MLSC setup (Table 3) and Section 4 touches on this point but lacks an explanation. This claim is somewhat verifiable as it highlights a discrepancy between the claim and the results presented, prompting the authors to provide a rationale or explanation. However, the comment does not provide specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential discrepancy between the claim of better word-alignment improving many-to-many translation and the lack of impact on the MLSC setup (Table 3) as observed in the proposed method. It questions why the method does not have an impact on this setup, despite the claim. The comment is somewhat helpful as it prompts the authors to consider this inconsistency and potentially address it in their work. However, it lacks specific suggestions or guidance on how to address this issue, such as providing a rationale or alternative explanation. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the method is restricted to an offline setting and cannot be applied in an online setting where policies interact with the environment. It highlights the limitation of the offline assumption on the applicability of the method. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this limitation or suggest ways to adapt the method for online settings. Without actionable guidance or specific steps, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"offline setting\" and the \"method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the method, which is that it requires pre-collected offline datasets and cannot be applied in an online setting where policies interact with the environment. This provides clear guidance on what needs to be addressed to improve the applicability of the method. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is restricted to an offline setting and cannot be applied in an online setting where policies interact with the environment. This claim is somewhat verifiable as it highlights a limitation of the method, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors might need to explore how the method could be adapted for online settings or how the offline assumption affects its applicability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation of the method, noting that it is restricted to an offline setting and cannot be applied in an online setting where policies interact with the environment. This feedback highlights a potential weakness in the applicability of the method, which could limit its impact or usefulness. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or adapt the method for online settings. While it points out an important area for improvement, the lack of actionable advice makes the comment somewhat helpful, as it provides insight but not detailed guidance for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the evaluation of the learned representation, noting that it was only evaluated on the linear evaluation setting. It suggests that additional downstream tasks could be used, such as fine-tuning, detection, and segmentation, as reported in the literature. While the comment implies that the authors should consider these additional tasks, it does not explicitly instruct them to do so or provide specific guidance on how to implement these tasks. The action is implicit and somewhat vague, as the authors need to infer that they should expand their evaluation to include these tasks. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"linear evaluation setting,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the quality of the learned representation was only evaluated on this setting and suggests additional downstream tasks that could be used, such as fine-tuning, detection, and segmentation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation of the learned representation is insufficient because it was only conducted on the linear evaluation setting. The comment suggests that additional downstream tasks, such as fine-tuning, detection, and segmentation, could be used as reported in the literature. However, the comment lacks specific examples or references to support the claim that these tasks are necessary or how they would improve the evaluation. Without detailed reasoning or evidence, the claim is difficult for the authors to verify and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of the learned representation, noting that it was only evaluated on the linear evaluation setting. It suggests that additional downstream tasks, such as fine-tuning, detection, and segmentation, could be used to provide a more comprehensive evaluation. This feedback is somewhat helpful as it points out a potential area for improvement and suggests additional tasks that could enhance the evaluation. However, the comment lacks specific guidance on how to implement these tasks or why they are necessary, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the novelty of the paper is very low due to the use of stage-wise and progressive training, which have been used for a long time. It does not provide any explicit or implicit actions for the authors to take, such as suggesting improvements or alternative approaches. The lack of guidance or suggestions makes it difficult for the authors to understand how to address the issue of novelty. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the paper, specifically mentioning that stage-wise and progressive training have been used for a long time, making the novelty very low. However, it does not specify which part of the paper discusses these concepts, leaving the authors to infer that it relates to the methodology or results sections. The comment is specific in its critique of the novelty, but it lacks grounding as it does not identify the exact sections being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the paper is very low due to the use of stage-wise and progressive training, which have been used for a long time. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the novelty of the paper, stating that stage-wise and progressive training have been used for a long time, making the novelty very low. However, it does not provide specific examples or suggestions for how the authors could enhance the novelty or address this issue. The comment lacks actionable feedback or guidance, leaving the authors without a clear understanding of how to improve their draft. As a result, the feedback is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the generalizability of the analysis to more complex cases, such as handling more general Markov chains and considering the presence of a FFN and nonlinearity on top of the attention layer. While these questions imply that the authors should consider these aspects in their analysis, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions to improve the generalizability of their analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the generalizability of the analysis to more complex cases, such as handling more general Markov chains and considering the presence of a FFN and nonlinearity on top of the attention layer. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions themselves are specific, as they outline areas where the analysis could be extended or improved. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the generalizability of the analysis to more complex cases, such as handling more general Markov chains and considering the presence of a FFN and nonlinearity on top of the attention layer. However, it does not provide any supporting evidence, reasoning, or references to justify why these cases are relevant or how they might impact the analysis. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the generalizability of the analysis to more complex cases, such as handling more general Markov chains and considering the presence of a FFN and nonlinearity on top of the attention layer. These questions highlight potential limitations in the current analysis and prompt the authors to consider how their findings might be extended to more complex scenarios. However, the comment does not provide specific suggestions or guidance on how to address these issues, leaving the authors with a general direction but without detailed actionable steps. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the use of the Fine state automaton in [19] in section 3.1 and on line 57. While it implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detail about the use of the Fine state automaton. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.1\" and \"line 57,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the lack of clarity regarding the use of the Fine state automaton in [19] and questions whether there is any difference. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the use of the Fine state automaton in [19] in section 3.1 and on line 57. It suggests that the authors should clarify whether there is any difference in the use of this automaton. However, the comment does not provide specific examples or references to support the claim that the clarity is lacking. Without additional context or evidence, the claim remains vague, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the use of the Fine state automaton in [19] in section 3.1 and on line 57. It points out that the authors discuss [19] but do not explicitly mention the use of the same automaton, which could lead to confusion. This feedback is clear and actionable, as it directs the authors to clarify the use of the automaton in their work. However, the comment could be more helpful if it provided suggestions on how to clarify this point or offered additional context for the authors to consider. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the memory requirements of the auto_weight scheme in Algorithm 1, suggesting that it might need a lot of memory due to the need for intermediate gradients for each domain. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific steps they should consider to mitigate the memory requirements. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of Algorithm 1, specifically the auto_weight scheme and its memory requirements. It references two external works, [1] and [2], which provide additional context and potential solutions to the issue. However, the comment does not explicitly mention which section of the paper discusses Algorithm 1, making it weakly grounded. The comment is specific in detailing the issue with the memory requirements and suggesting potential solutions, such as using buffer-based gradient projection or cross-silo federated learning. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the memory requirements of the auto_weight scheme in Algorithm 1, suggesting that it might need a lot of memory due to the need for intermediate gradients for each domain. The reviewer supports this claim by referencing two external works, [1] and [2], which discuss buffer-based gradient projection and cross-silo federated learning. However, the comment does not provide detailed reasoning or examples from the referenced works to fully substantiate the claim. While the references offer some support, the comment lacks comprehensive justification, making it somewhat verifiable. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the memory requirements of the auto_weight scheme in Algorithm 1, suggesting that it might require a lot of memory due to the need for intermediate gradients for each domain. While the comment raises an important concern, it lacks specific guidance or suggestions on how the authors might address this issue or mitigate the memory requirements. The references to external works, [1] and [2], provide some context but do not offer actionable advice or detailed feedback. As a result, the comment is somewhat helpful, as it highlights a potential problem but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation of the proposed method, specifically the use of a double LSTM as the backbone while excluding popular transformers. It points out that this approach may not be sufficient for more extensive model structures and suggests that the limitations are not adequately addressed in Section 6. However, the comment does not provide explicit guidance on how the authors should address these limitations or improve their method. The action is implicit and somewhat vague, as the authors can infer that they need to consider the use of transformers and address the limitations in Section 6, but the comment lacks concrete steps or detailed suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of a double LSTM as the backbone and the exclusion of popular transformers, suggesting that this may not be sufficient for more extensive model structures. It also mentions the limitations discussed in Section 6, implying that they are not adequately addressed. However, the comment does not specify which part of the paper discusses the backbone or the limitations, making it weakly grounded. The comment is specific in identifying the limitations and suggesting that they are not adequately addressed, but without clear grounding, it is difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the use of a double LSTM as the backbone and the exclusion of popular transformers, suggesting that this may not be sufficient for more extensive model structures. It also mentions that limitations are discussed in Section 6 but are not adequately addressed. However, the comment does not provide specific examples or references to support the claim that the limitations are not adequately addressed. The reasoning is somewhat based on logical reasoning and common knowledge, but it lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the critique but requires more detailed evidence to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the proposed method, specifically the use of a double LSTM as the backbone and the exclusion of popular transformers. It points out that this approach may not be sufficient for more extensive model structures and suggests that the limitations are not adequately addressed in Section 6. However, the comment does not provide specific suggestions or guidance on how the authors might address these limitations or improve their method. While it highlights an important area for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the contribution and novelty of the paper are limited, as the proposed model essentially combines existing techniques, such as structure learning regularization and missing value imputation, with variational inference for model parameter learning. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or contribution of the paper, nor are there suggestions for alternative approaches or improvements. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the contribution and novelty of the paper, stating that the proposed model essentially combines existing techniques, such as structure learning regularization and missing value imputation, with variational inference for model parameter learning. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact sections that need attention. The comment lacks specificity regarding what aspects of the model or its combination are problematic, leaving the authors without clear guidance on how to address the issue. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution and novelty of the paper are limited, as the proposed model essentially combines existing techniques, such as structure learning regularization and missing value imputation, with variational inference for model parameter learning. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to existing techniques or studies that demonstrate the lack of novelty or contribution. As a result, the claim is not fully verifiable, making it difficult for the authors to understand and address the critique. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the contribution and novelty of the paper, stating that the proposed model essentially combines existing techniques, such as structure learning regularization and missing value imputation, with variational inference for model parameter learning. While the comment identifies a potential issue with the novelty and contribution of the paper, it lacks specificity and actionable suggestions for improvement. It does not provide guidance on how the authors might enhance the originality or impact of their work, nor does it offer alternative approaches or suggestions for addressing the critique. As a result, the comment is somewhat helpful, as it points out a potential weakness but does not provide detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the need to tune unimodal models in advance for MSLR, which can be costly and resource-intensive. It suggests comparing this approach with directly tuning a late-fusion model with separate learning rates for each modality, especially with a similar or less compute budget. While the comment implies that the authors should consider this alternative approach, it does not explicitly instruct them to do so or provide specific guidance on how to implement this comparison. The action is implicit and somewhat vague, as the authors need to infer the need for this comparison and determine how to execute it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of MSLR requiring the knowledge of unimodal optimal learning rates in advance, which is a specific concern regarding the methodology. It suggests comparing this approach with directly tuning a late-fusion model with separate learning rates for each modality, especially with a similar or less compute budget. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion for a comparison, providing clear guidance on what the authors should consider. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the need to tune unimodal models in advance for MSLR, which can be costly and resource-intensive. It suggests comparing this approach with directly tuning a late-fusion model with separate learning rates for each modality, especially with a similar or less compute budget. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that this approach would be more effective or efficient. The suggestion is somewhat verifiable, as it provides a logical reasoning but requires more detailed evidence or comparisons to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the methodology used in MSLR, which requires the knowledge of unimodal optimal learning rates in advance. It suggests an alternative approach by comparing the performance of directly tuning a late-fusion model with separate learning rates for each modality, especially with a similar or less compute budget. This feedback is clear and actionable, as it provides a specific direction for the authors to explore and potentially improve their methodology. However, the comment could be more helpful if it included additional details or examples on how to implement this comparison or why it might be beneficial. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the notation for L_{flow}(X) and suggests that L_{flow}(F) or L_{flow}(F,S) might be more appropriate to reflect the actual inputs. While the comment implies that the authors should consider this change, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their notation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the notation for L_{flow}(X) and suggests that L_{flow}(F) or L_{flow}(F,S) might be more appropriate to reflect the actual inputs. However, it does not specify which part of the paper this notation is used in, making it weakly grounded. The comment is specific in suggesting that the notation might be ambiguous and that a change might be necessary. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the notation for L_{flow}(X) and suggests that L_{flow}(F) or L_{flow}(F,S) might be more appropriate to reflect the actual inputs. However, the comment does not provide any reasoning, examples, or references to support why these alternatives might be more appropriate. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the notation for L_{flow}(X) and suggests that L_{flow}(F) or L_{flow}(F,S) might be more appropriate to reflect the actual inputs. This feedback is somewhat helpful as it identifies a potential source of ambiguity in the notation and provides a suggestion for clarification. However, the comment lacks depth and does not offer detailed guidance or examples on how to implement this change or why it might be beneficial. To be more helpful, the comment could provide additional context or reasoning to support the suggestion. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the novelty of the work, specifically questioning the point of representing the input using 8 bits. It references a previous work that used 8-bit batch norm, which undermines the novelty of the current work. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the novelty of their work. The action is implicit and vague, as the authors are left to infer that they need to justify the novelty of their work, but without specific guidance on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the novelty of the work, specifically questioning the point of representing the input using 8 bits. It references a previous work that used 8-bit batch norm, which undermines the novelty of the current work. However, the comment does not specify which part of the paper this question pertains to, such as a particular section or figure where the input representation is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the novelty, as it references a specific prior work, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of the work by referencing a previous work that used 8-bit batch norm. This claim is somewhat verifiable as it references a specific prior work, which provides some basis for the critique. However, the comment lacks detailed reasoning or explanation of why the use of 8-bit batch norm undermines the novelty of the current work. The authors would need more information to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the novelty of the work, specifically questioning the point of representing the input using 8 bits. It references a previous work that used 8-bit batch norm, which undermines the novelty of the current work. While the comment identifies a potential weakness in the novelty of the paper, it lacks specific guidance or suggestions on how the authors might address this issue or improve the novelty of their work. The feedback is somewhat helpful as it points out a potential problem but does not provide actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to improve the framework's practical relevance or how to differentiate it from existing GNNs. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not specify which part of the paper this concern is related to, making it weakly grounded. The comment is specific in its suggestion that the practical relevance may be limited, but without explicit references to specific sections or details, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples, data, or comparisons, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. While it identifies a potential issue, it lacks specificity and actionable guidance on how the authors might address this concern or differentiate their framework from existing GNNs. Without detailed suggestions or examples, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include an experiment demonstrating the necessity of including $X$ in the calculation of M_{t}. While the comment implies that the authors should add this experiment, it does not explicitly instruct them to do so. The action is concrete, as it specifies the exact addition needed, but it is somewhat vague due to the lack of detailed guidance on how to conduct the experiment. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors should include an experiment demonstrating the necessity of including $X$ in the calculation of M_{t}. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where this experiment could be included. The authors can infer that it relates to the methodology or results sections, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting the need for an additional experiment, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of including $X$ in the calculation of M_{t} and suggests that an experiment should be added to demonstrate this necessity. However, the comment does not provide any reasoning, examples, or references to support why $X$ is necessary or how it affects the results. Without additional context or explanation, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by questioning the necessity of including $X$ in the calculation of M_{t}. It suggests that an experiment should be added to demonstrate the necessity of $X$. While the comment highlights an area for improvement, it lacks specific guidance on how to conduct the experiment or what aspects of the results would be impacted by the inclusion of $X$. This limits the comment\\'s usefulness, as it provides a general direction but does not offer detailed suggestions or examples. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment states a fact about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. It does not provide any actionable advice or suggestions for the authors to improve their draft. The authors are left without any guidance on how to address this observation or what changes they should consider making. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment does not specify which part of the paper it addresses, making it not grounded. It is a general observation about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. The comment lacks specificity because it does not provide any details on what aspects of the paper should be addressed or improved based on this observation. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a factual observation about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. It does not express an opinion, suggestion, or request for change, making it a purely descriptive statement. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment is a factual observation about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. While it provides some insight into the nature of these problems, it does not offer any actionable feedback or suggestions for improvement. The authors are left without any guidance on how to address this observation or what aspects of their work might need further exploration or clarification. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss the generalizability of their observations, specifically those in Figure 4. It points out that various hyperparameters, such as optimization algorithms, weight initialization methods, batch size, learning rate, and scheduling, could influence implicit biases in the algorithm, affecting neural representations, geometric metrics, and the stages of learning. While the comment implies that the authors should discuss these factors, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss these aspects. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing the generalizability of the observations, specifically those in Figure 4. It mentions various hyperparameters that could influence implicit biases in the algorithm, affecting neural representations, geometric metrics, and the stages of learning. However, it does not explicitly mention which part of the paper Figure 4 is in, making it weakly grounded. The comment is specific in detailing the potential factors that could influence generalizability, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the generalizability of the observations, specifically those in Figure 4, should be discussed. It mentions various hyperparameters that could influence implicit biases in the algorithm, affecting neural representations, geometric metrics, and the stages of learning. While the comment provides a logical reasoning for why generalizability should be discussed, it lacks specific examples or references to support the claim about the influence of hyperparameters. This makes the claim somewhat verifiable, as it provides a clear direction but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to discuss the generalizability of their observations, specifically those in Figure 4. It highlights the potential influence of various hyperparameters, such as optimization algorithms, weight initialization methods, batch size, learning rate, and scheduling, on implicit biases in the algorithm, affecting neural representations, geometric metrics, and the stages of learning. This feedback is valuable as it directs the authors to consider an important aspect of their work that could impact its applicability and robustness. However, the comment could be more helpful if it included specific examples or references to support the claim about the influence of hyperparameters. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper is not well-organized and uses non-standard terminology, specifically mentioning the term \"semi-honest\" in section 4. The reviewer suggests using \"honest-but-curious\" instead, which is a more standard term to describe a server that cannot modify local updates but tries to infer private information of clients. While the comment provides a specific suggestion for terminology, it does not offer guidance on how to improve the organization of the paper or suggest other areas for improvement. The action is explicit but somewhat vague, as the authors know what term to use but may not fully understand how to address the issue of organization. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the terminology used, suggesting that \"semi-honest\" should be replaced with \"honest-but-curious\" to describe a server that cannot modify local updates but tries to infer private information of clients. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not well-organized and uses non-standard terminology, specifically mentioning the term \"semi-honest\" in section 4. The reviewer suggests using \"honest-but-curious\" instead, which is a more standard term to describe a server that cannot modify local updates but tries to infer private information of clients. The comment provides a specific example of the non-standard terminology and suggests a more appropriate alternative, offering a clear and actionable suggestion for improvement. This makes the claim mostly verifiable, as it provides a logical and justifiable basis for the critique. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s organization, noting that it is not well-organized and uses non-standard terminology. The reviewer provides a specific example by pointing out the use of the term \"semi-honest\" in section 4, suggesting that \"honest-but-curious\" would be a more standard term to describe a server that cannot modify local updates but tries to infer private information of clients. This feedback is clear and actionable, offering a concrete suggestion for improving the paper\\'s organization and terminology. By addressing this issue, the authors can enhance the clarity and accessibility of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several areas where experimental details are missing, including the type of optimizer, initialization, and PPO-zero. While the comment identifies specific aspects that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these gaps. The authors are left to infer that they need to provide more information about these aspects, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights specific areas where experimental details are missing, such as the type of optimizer, initialization, and PPO-zero. However, it does not specify which part of the paper these details are missing in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in identifying what is missing, it lacks grounding as it does not specify where these details should be included. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of factual statements and questions about the experimental details, such as the type of optimizer, initialization, and PPO-zero. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific areas where experimental details are missing, such as the type of optimizer, initialization, and PPO-zero. This feedback is clear and actionable, as it directs the authors to provide more information about these aspects of their work. However, the comment could be more helpful if it offered suggestions on how to address these gaps or provided examples of how similar details might be presented in other works. Despite this, the feedback is mostly helpful as it guides the authors toward improving the clarity and completeness of their experimental details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the need for a detailed comparison of the proposed method's efficiency and complexity in terms of model parameters, FLOPs, and memory, specifically comparing it to other existing works. While the comment identifies a gap in the analysis, it does not explicitly instruct the authors to conduct this comparison or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a detailed efficiency analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the efficiency and complexity of the proposed method, specifically mentioning the use of two image encoders (LaVIT and Eva-CLIP) and a detector in the decoding process. It suggests a detailed comparison of these components with other existing works in terms of model parameters, FLOPs, and memory. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections. The comment is specific in detailing what needs to be compared and why, providing clear guidance on how to improve the analysis. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method requires additional components, such as two image encoders and a detector, which are not present in other existing works. The reviewer suggests a detailed comparison of the efficiency and complexity of the proposed method, including model parameters, FLOPs, and memory, with and without these additional components. While the comment provides a logical reasoning for the need for such a comparison, it lacks specific examples or references to existing works that support the claim. This makes the claim somewhat verifiable, as the authors would need to conduct the comparison themselves to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the efficiency and complexity of the proposed method, noting that it requires two image encoders and a detector for various tasks. It suggests a detailed comparison with other existing works in terms of model parameters, FLOPs, and memory, which would provide valuable insights into the method's efficiency. This feedback is clear and actionable, as it directs the authors to conduct a specific analysis that could significantly impact the paper\\'s comprehensiveness and clarity. However, the comment could be more helpful if it included specific suggestions on how to conduct this comparison or what aspects to focus on. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims extrapolation error is a major issue in MARL but lacks evidence to support this claim. It also notes that the proposed techniques are for bias/variance reduction and do not seem directly related to extrapolation error. The reviewer suggests that the authors should provide evidence to demonstrate how their method mitigates extrapolation error, which would lead to better performance. This feedback is explicit and provides a clear action for the authors to take, namely, to provide evidence or additional analysis to support their claim. The comment is concrete and specific, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about extrapolation error being a major issue in MARL, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the authors do not provide evidence to support this claim and that the proposed techniques are for bias/variance reduction, which are not directly related to extrapolation error. The comment further highlights the need for evidence to demonstrate how the proposed method mitigates extrapolation error, making it clear what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper makes a claim about extrapolation error being a major issue in MARL but lacks evidence to support it. The reviewer also questions the relevance of the proposed techniques to extrapolation error, as they are primarily for bias/variance reduction. The comment suggests that the authors should provide evidence or examples to demonstrate how their method addresses extrapolation error. This claim is somewhat verifiable as it highlights a potential gap in the paper\\'s evidence, but it lacks specific examples or references to fully substantiate the claim. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s claim about extrapolation error being a major issue in MARL. It points out that the authors do not provide any evidence to support this claim, which is a critical oversight. The comment also questions the relevance of the proposed techniques, which are primarily for bias/variance reduction, to extrapolation error. Additionally, it suggests that the authors should provide evidence or examples to demonstrate how their method addresses extrapolation error, which would enhance the paper\\'s credibility and impact. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft. However, it could be more helpful if it offered suggestions on how to present this evidence or examples. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a concrete direction for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the paper regarding the exploration of on-device efficiency for SCHEME. It suggests that while the theoretical complexity advantages are demonstrated, the on-device efficiency is underexplored. The reviewer recommends presenting detailed on-device results across ablation and comparison studies, which would substantiate claims about SCHEME's efficiency over conventional FFNs. Additionally, it suggests providing details on the benchmark configurations, hardware, and input shapes to ensure fair comparisons. While the comment provides explicit actions for the authors to take, such as presenting on-device results and detailing benchmark configurations, it does not specify how to implement these actions or what specific details should be included. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 4 and 8,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detailed on-device results and the need for benchmark configurations, hardware, and input shapes to ensure fair comparisons. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical complexity advantages of SCHEME are demonstrated but that its on-device efficiency is underexplored. It suggests that presenting detailed on-device results across ablation and comparison studies would substantiate claims about SCHEME's efficiency over conventional FFNs. The comment also requests details on benchmark configurations, hardware, and input shapes to ensure fair comparisons. While the comment provides a logical reasoning for the need to explore on-device efficiency, it lacks specific examples or references to substantiate the claim about the theoretical complexity advantages. Therefore, the comment is somewhat verifiable, as it provides a clear direction for improvement but could benefit from more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the exploration of on-device efficiency for SCHEME. It highlights that while the theoretical complexity advantages are demonstrated, the on-device efficiency is underexplored, and limited throughput comparisons are presented in Tables 4 and 8. The comment suggests that presenting detailed on-device results across ablation and comparison studies would substantiate claims about SCHEME's efficiency over conventional FFNs. Additionally, it recommends providing details on the benchmark configurations, hardware, and input shapes to ensure fair comparisons. This feedback is clear and actionable, offering specific suggestions for improving the paper by addressing a critical area of evaluation. However, it could be more helpful if it provided additional guidance on how to conduct these comparisons or what specific details should be included in the on-device results. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the name of the strategy, \"LongShortTerm Strategy,\" may be misleading and reminiscent of Long Short Term Memory (LSTM), which could lead to confusion. However, it does not provide explicit guidance on what alternative name might be more appropriate or how to address this issue. The action is implicit and vague, as the authors are left to infer that they should consider changing the name but without specific suggestions or details on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the name of the strategy, \"LongShortTerm Strategy,\" may be misleading and reminiscent of Long Short Term Memory (LSTM), which could lead to confusion. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table where the name is mentioned. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in suggesting that the name may be misleading, but without grounding, it lacks full specificity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the name of the strategy, \"LongShortTerm Strategy,\" may be misleading and reminiscent of Long Short Term Memory (LSTM), which could lead to confusion. However, the comment does not provide any specific reasoning or evidence to support why the name is problematic or how it might mislead readers. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the name of the strategy, \"LongShortTerm Strategy,\" suggesting that it may be misleading and reminiscent of Long Short Term Memory (LSTM). While it identifies a potential source of confusion, it does not provide specific suggestions or guidance on how to address this issue. The comment highlights a potential problem but lacks actionable advice or detailed feedback, making it somewhat helpful. The authors are given a direction to consider but without detailed guidance, the comment does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the experiments results show that the proposed method is not the best performer in both robustness and fidelity. However, it does not provide any explicit or implicit suggestions for improvement or action. The authors are left without guidance on how to address this issue or what specific changes could be made to improve the method\\'s performance. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments results,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the proposed method is not the best performer in both robustness and fidelity. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not the best performer in both robustness and fidelity, based on the experiments results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or details, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed method, stating that it is not the best performer in both robustness and fidelity. This feedback highlights a weakness in the method\\'s performance, which the authors should address to improve the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the method or address the identified weaknesses. While it points out a critical area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides insight but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the motivation and logical connection between the concepts of isometry, OT, and disentanglement. It points out that the authors claim that adding geometrical constraints (isometry) can help disentanglement but does not explain this connection well. The reviewer suggests that the authors should clarify these connections more clearly in the paper, specifically by explaining why OT is required for isometry and how it connects to disentanglement. This feedback provides explicit and concrete guidance on what the authors need to address to improve their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the concepts of isometry, OT, and disentanglement, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in the motivation and logical connection between these concepts. The comment provides a detailed critique of the paper, highlighting the need for clearer explanations and connections, which helps the authors understand the areas that need improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation and logical connection between the concepts of isometry, OT, and disentanglement are not clear. It specifically notes that the authors claim that adding geometrical constraints (isometry) can help disentanglement but do not explain this connection well. The reviewer suggests that the authors should clarify these connections more clearly in the revision. While the comment identifies a potential issue with the clarity of the paper, it lacks specific examples or references to support the claim that the connection is not well-explained. This makes the comment somewhat verifiable, as it provides a general critique but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the motivation and logical connection between the concepts of isometry, OT, and disentanglement. It points out that the authors claim that adding geometrical constraints (isometry) can help disentanglement but do not explain this connection well, making it difficult for readers to understand the connection between isometry and disentanglement. The comment suggests that the authors should clarify these connections more clearly in the revision, which is a clear and actionable piece of feedback. By providing specific guidance on how to improve the clarity of the paper, the comment offers valuable insights for the authors to enhance the comprehensibility and coherence of their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relevance of the results on regular languages to understanding how and why real-world language models work. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific steps they could take to improve the connection between the results and real-world applications. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the relevance of the results on regular languages to understanding how and why real-world language models work. However, it does not specify which part of the paper these results are presented in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its question about the connection between regular languages and real-world applications, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the relevance of the results on regular languages to understanding how and why real-world language models work. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the relevance of the results on regular languages to understanding how and why real-world language models work. It highlights a potential gap in the paper\\'s explanation of its findings and their practical implications. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the connection between their results and real-world applications. While it points out an area for improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the novelty of the paper, specifically questioning the differences between it and the Venom paper. It does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions for improvement or clarification. The authors are left without any guidance on how to address this concern or what changes to make. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the novelty of the paper, specifically questioning the differences between it and the Venom paper. However, it does not specify which part of the paper this question pertains to, such as a particular section or claim. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in its question about the differences between the two papers, but without explicit grounding, it is difficult for the authors to address the concern effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the differences between the paper and the Venom paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the novelty of the paper, specifically questioning the differences between it and the Venom paper. It points out that V:N:M was proposed in the Venom paper and asks how the current paper differs from Venom. While the comment identifies a potential area of confusion or misalignment, it lacks depth and does not provide any actionable feedback or suggestions for improvement. The authors are left with a vague inquiry that does not guide them on how to address the issue or enhance their draft. Therefore, the comment is rated as barely helpful, as it provides some insight but lacks comprehensive guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the qualitative intuitiveness of the attribution maps, specifically pointing out issues with the attended areas of the image not being related to the actual task and clusters of attended pixels without clear semantic meaning. While the reviewer acknowledges that the resulting analysis seems to work, they question the lack of qualitative value. However, the comment does not provide explicit guidance on how the authors should address these issues or improve the qualitative aspect of the attribution maps. The action is implicit and somewhat vague, as the authors are left to infer that they need to make the attribution maps more intuitive and meaningful. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the qualitative intuitiveness of the attribution maps, specifically pointing out issues with the attended areas of the image not being related to the actual task and clusters of attended pixels without clear semantic meaning. It also acknowledges that the resulting analysis seems to work, but questions the lack of qualitative value. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the visualization and interpretation of results, such as Figure 2. The comment is specific in detailing what needs to be addressed regarding the attribution maps, making it fully grounded. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the qualitative intuitiveness of the attribution maps, specifically mentioning issues with the attended areas of the image not being related to the actual task and clusters of attended pixels without clear semantic meaning. The reviewer acknowledges that the resulting analysis seems to work, but questions the lack of qualitative value. This critique is supported by logical reasoning and specific observations, providing a clear basis for the claim. However, the comment could be strengthened by referencing specific examples or additional details to further substantiate the critique. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment critiques the qualitative intuitiveness of the attribution maps, specifically pointing out issues with the attended areas of the image not being related to the actual task and clusters of attended pixels without clear semantic meaning. The reviewer acknowledges that the resulting analysis seems to work, but questions the lack of qualitative value. While the comment identifies a potential weakness in the visualization and interpretation of results, it does not provide specific suggestions or guidance on how the authors might address these issues or improve the qualitative aspect of the attribution maps. The feedback is somewhat helpful as it highlights a potential area for improvement, but it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the title of the paper, suggesting that it overclaims the contribution. It also points out a specific concern regarding the results not being shown for large language models (LLMs) like Llama2-70b, questioning the scalability of the proposed method. The comment provides a clear direction for the authors to address this issue by suggesting they show empirical justification for the scalability of their method to LLMs. Additionally, it offers a minor suggestion to maintain consistency in the use of the term \"RoBERTa\" in different sections of the paper. The feedback is explicit and concrete, providing actionable steps for the authors to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the title overclaims the contribution of the paper, given that the results are shown only on two language models (BERT and RoBERTa), and it raises a question about the scalability of the proposed method to larger language models like Llama2-70b. The comment also provides a minor suggestion to maintain consistency in the use of the term \"RoBERTa\" in different sections of the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the title of the paper, suggesting that it overclaims the contribution. The reviewer notes that the results are shown only on two language models (BERT and RoBERTa) and questions whether the proposed method can be scalable to larger language models like Llama2-70b. The comment also suggests maintaining consistency in the use of the term \"RoBERTa\" in different sections of the paper. While the comment identifies a potential issue with the title and suggests improvements, it lacks specific examples or references to support the claim about scalability. The suggestion for consistency is also somewhat vague. Therefore, the comment is somewhat verifiable, as it provides some justification but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable critique of the paper\\'s title, suggesting that it overclaims the contribution by only showing results on two language models (BERT and RoBERTa) and questioning the scalability of the proposed method to larger language models like Llama2-70b. It also offers a minor suggestion to maintain consistency in the use of the term \"RoBERTa\" in different sections of the paper. This feedback is valuable as it prompts the authors to reconsider the scope and impact of their work, potentially leading to a more accurate and comprehensive representation of their contribution. However, the comment could be more helpful if it provided specific guidance on how to address the scalability issue or how to justify the proposed method\\'s applicability to larger models. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement and offers a minor suggestion for clarity.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not provide a clear motivation for choosing date and country as potential spurious correlating variables with gender. It suggests that the authors speculate that they could show spurious correlations, but does not provide specific guidance on how to address this issue. The comment implies that the authors should provide a more detailed justification or rationale for their choice, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed justification, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of motivation for choosing date and country as potential spurious correlating variables with gender. It suggests that the authors speculate that they could show spurious correlations, but does not provide specific examples or references to support this claim. The comment is weakly grounded as it does not explicitly mention which part of the paper discusses this issue, making it difficult for the authors to pinpoint the exact section that needs attention. However, it is specific in its critique of the lack of motivation and the need for a more detailed justification. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks motivation for choosing date and country as potential spurious correlating variables with gender. The reviewer suggests that the authors speculate that these variables could show spurious correlations, but does not provide specific examples or references to support this claim. The comment is somewhat verifiable as it highlights a potential issue but lacks detailed evidence or reasoning to substantiate the claim. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of motivation for choosing date and country as potential spurious correlating variables with gender. It suggests that the authors speculate that these variables could show spurious correlations, but does not provide further explanation or justification for this choice. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or provide a more detailed justification. The feedback is somewhat helpful as it points out a critical weakness but does not offer actionable steps for improvement, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the contribution of exchanging channels, suggesting that it is only achieved using BN and questioning the incremental nature of the contribution. It also critiques the rationale of Theorem 1, suggesting it is based on external work and seems like a simple fact. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific concerns about the contribution of exchanging channels and the rationale of Theorem 1, suggesting that the contribution is based on BN and that Theorem 1 seems like a simple fact. However, it does not specify which part of the paper these concerns are based on, such as sections or figures, making it weakly grounded. The comment is specific in detailing the concerns about the contribution and the rationale, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the contribution of exchanging channels, suggesting that it is only achieved using BN and that the rationale of Theorem 1 is based on external work. The reviewer also claims that Theorem 1 seems like a simple fact. While the comment raises valid concerns, it lacks specific examples or references to support the claim that the contribution is not incremental or that Theorem 1 is a simple fact. The lack of detailed evidence or reasoning makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the critique but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the contribution of exchanging channels, suggesting that it is only achieved using BN and questioning the incremental nature of the contribution. It also critiques the rationale of Theorem 1, suggesting it is based on external work and seems like a simple fact. While the comment identifies potential weaknesses and areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is somewhat helpful as it points out potential areas for improvement, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the contribution of the paper, specifically questioning whether it improves damping in second-order methods. It also asks for clarification on what \"K\" denotes, first appearing in section 4.1, and whether \"K=NC\" is correct. While the comment identifies areas that need clarification and potential improvements, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should provide more in-depth studies and clarify the meaning of \"K.\" Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the contribution of the paper, particularly whether it improves damping in second-order methods, and it asks for clarification on the meaning of \"K\" and whether \"K=NC.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification, rather than making subjective claims or suggestions. It does not contain any opinions, judgments, or statements that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s contribution, questioning whether it improves damping in second-order methods. It also seeks clarification on the meaning of \"K\" and whether \"K=NC.\" While the comment raises important questions that could guide the authors in improving their draft, it lacks specific suggestions or actionable feedback on how to address these issues. The authors are given direction but not detailed guidance on how to proceed. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that an in-depth analysis of the parameters k and N in the ablation study would enhance readers\\' understanding of the algorithm. It also recommends additional analysis of the running time or complexity, specifically the impact of the parameters k and N on the running time. While the comment provides a clear action for the authors to take, it lacks specific guidance on how to conduct this analysis or what aspects to focus on. The second comment about the mismatch between Figure 2 and the corresponding description is also explicit but lacks actionable details, such as suggesting how to resolve the discrepancy. Overall, the comment is mostly actionable as it provides clear directions for improvement but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests an in-depth analysis of the parameters k and N in the ablation study, which would enhance readers\\' understanding of the algorithm. It also recommends additional analysis of the running time or complexity, specifically the impact of the parameters k and N on the running time. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The authors can infer that it relates to the ablation study or the discussion of running time, but this inference is not direct. The second comment about the mismatch between Figure 2 and the corresponding description is explicit and specific, as it points out the discrepancy and suggests a resolution. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an in-depth analysis of the parameters k and N in the ablation study would enhance readers\\' understanding of the algorithm. It also recommends additional analysis of the running time or complexity, specifically the impact of the parameters k and N on the running time. The comment provides a logical reasoning for the need for these analyses, as they would help clarify the algorithm\\'s behavior and performance. However, it lacks specific examples or references to support the claim about the impact of the parameters on running time. This makes the claim somewhat verifiable, as it provides a rationale but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it suggests that an in-depth analysis of the parameters k and N in the ablation study would enhance readers\\' understanding of the algorithm. This is a clear and actionable suggestion that could significantly improve the clarity and depth of the paper. Second, it recommends additional analysis of the running time or complexity, specifically the impact of the parameters k and N on the running time. This suggestion is also actionable and could help the authors better understand and explain the performance of their algorithm. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful as it offers valuable insights and suggestions for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the details in Appendix B, specifically asking why there is no indication of standard deviation. It also inquires whether the 10 runs were conducted over random hyperparameter configurations for all baselines or with the best selected hyperparameters. While the comment identifies a potential issue with the presentation of results, it does not provide explicit guidance on how the authors should address this. The action is implicit and somewhat vague, as the authors need to infer that they should include standard deviation and clarify the nature of the 10 runs. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix B,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the absence of standard deviation in the results and inquires about the nature of the 10 runs. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the absence of standard deviation in the results presented in Appendix B. It also inquires about the nature of the 10 runs, whether they were conducted over random hyperparameter configurations for all baselines or with the best selected hyperparameters. This comment is a request for clarification and does not contain subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Appendix B, noting the absence of standard deviation and questioning the nature of the 10 runs. It prompts the authors to clarify whether these runs were conducted over random hyperparameter configurations for all baselines or with the best selected hyperparameters. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the transparency and reproducibility of their results. However, the comment could be more helpful if it offered suggestions on how to present this information or what additional details might be beneficial. Overall, the comment is mostly helpful as it provides a concrete direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include more details about the task generation process in the main text, rather than only in the appendix section. This provides a clear and direct action for the authors to take, ensuring that the readers have a better understanding of the experimental setup. The comment also suggests that this inclusion would strengthen the paper\\'s presentation, offering a concrete rationale for the action. Therefore, the comment is highly actionable, as it provides explicit guidance on how to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"task generation process,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the main text to provide a better understanding of the experimental setup and strengthen the paper\\'s presentation. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more details about the task generation process should be included in the main text to provide a better understanding of the experimental setup and strengthen the paper\\'s presentation. However, the comment does not provide specific reasoning or examples to support why these details are crucial or how they would enhance the paper. Without additional context or evidence, the claim remains somewhat verifiable, as it lacks the necessary justification to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It highlights the need to include more details about the task generation process in the main text, rather than relegating them to the appendix section. This feedback is valuable as it directly addresses a potential weakness in the paper\\'s presentation, which could enhance the reader\\'s understanding of the experimental setup. By following this suggestion, the authors can strengthen the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided specific examples or guidance on how to present these details effectively. Overall, the comment is mostly helpful, as it offers a clear path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors clarify that entropy depends on a datapoint, such as $H(p^a|x)$, to make formulas like $\\\\text{argmax}_{x \\\\in U, a \\\\in A} H^a$ more understandable. This feedback provides a clear and explicit action for the authors to take, which is to explicitly mention the dependency of entropy on a datapoint in their formulas. The comment is concrete and provides a specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"paragraphs Individual-level entropy and Group-level entropy,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of entropy dependence on a datapoint, and provides a suggestion to make formulas like $\\\\text{argmax}_{x \\\\in U, a \\\\in A} H^a$ more understandable by including the dependency on $H(p^a|x)$. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors clarify the dependency of entropy on a datapoint, such as $H(p^a|x)$, to improve the clarity of formulas like $\\\\text{argmax}_{x \\\\in U, a \\\\in A} H^a$. This claim is somewhat verifiable as it provides a logical reasoning for why clarifying the dependency would enhance the understanding of the formulas. However, it lacks specific examples or references to similar works that have addressed this issue, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, particularly in the context of entropy and its dependence on a datapoint. It suggests that the authors clarify this dependency to improve the understanding of formulas like $\\\\text{argmax}_{x \\\\in U, a \\\\in A} H^a$. This feedback is clear and actionable, providing the authors with a concrete suggestion for enhancing the clarity and comprehensibility of their work. By addressing this point, the authors can significantly improve the readability and accessibility of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper connects tokens beyond local windows by forming new groups across previous local windows. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to implement this suggestion or what specific changes are needed. Without any actionable advice or steps, the authors are left without a clear understanding of how to address the comment. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper connects tokens beyond local windows by forming new groups across previous local windows. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what changes or improvements are needed to address this issue. Without explicit references or detailed guidance, the authors cannot effectively determine where to focus their revisions. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper connects tokens beyond local windows by forming new groups across previous local windows. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper connects tokens beyond local windows by forming new groups across previous local windows. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might improve this aspect of their work. Without detailed guidance or examples, the comment does not offer much value to the authors in terms of enhancing their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors provide a more comprehensive illustration of the advantages of using entropy to capture the difference between distributions in the context of Distributionally Robust Optimization (DRO). It highlights that the proposed DD risk has a similar formulation to the DRO risk and questions the specific advantage of using entropy. The comment is clear and provides a direct action for the authors to take, which is to provide a more comprehensive illustration of the benefits of their approach. The explicit nature of the suggestion and the concrete request for additional information make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Relationship with Distributionally Robust Optimization\" and the \"proposed DD risk,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the advantage of using entropy to capture the difference between distributions in the context of DRO and suggests that the authors provide a more comprehensive illustration of this advantage. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the advantage of using entropy to capture the difference between distributions in the context of Distributionally Robust Optimization (DRO). It suggests that the authors should provide a more comprehensive illustration of this advantage, referencing specific works that use different distance metrics in DRO. The comment is somewhat verifiable as it provides a logical basis for the request by referencing existing literature, which could help the authors understand the need for a more comprehensive illustration. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improvement. It highlights a potential gap in the paper regarding the relationship with Distributionally Robust Optimization (DRO) and the use of entropy to capture the difference between distributions. The reviewer questions the specific advantage of using entropy and suggests that the authors provide a more comprehensive illustration of this advantage. This feedback is valuable as it prompts the authors to clarify and strengthen their connection to existing literature, which could enhance the paper\\'s clarity and impact. By addressing this feedback, the authors can improve the comprehensiveness and rigor of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the nature of the T-REx dataset, specifically whether it is a distantly supervised dataset with no human labels. The reviewer asks if it is possible to evaluate over an annotated dataset, such as TACRED or FewRel. While the comment implies that the authors should consider evaluating their model on an annotated dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should evaluate on an annotated dataset. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the nature of the T-REx dataset, specifically whether it is a distantly supervised dataset with no human labels. It also asks if it is possible to evaluate over an annotated dataset, such as TACRED or FewRel. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the dataset used for evaluation. The comment is specific in its inquiry about the dataset and its evaluation possibilities, making it fully grounded. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the nature of the T-REx dataset and whether it is possible to evaluate it over an annotated dataset, such as TACRED or FewRel. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the nature of the T-REx dataset, specifically whether it is a distantly supervised dataset with no human labels. It also inquires about the possibility of evaluating the model on an annotated dataset, such as TACRED or FewRel. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions for improvement. The authors are left with a question but no actionable feedback or direction on how to address the issue. Therefore, the comment is barely helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take. It suggests that the appendix should be proofread and mentions specific issues with formatting, such as \"poster mean\" and \"peicewise-linear,\" which should be corrected. Additionally, it recommends expanding the discussion on potential negative societal impacts. These actions are clear and concrete, giving the authors a direct path to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as formatting issues with \"poster mean\" and \"peicewise-linear\" and recommending a proofread for the appendix. Additionally, it suggests expanding the discussion on potential negative societal impacts. This level of detail provides the authors with clear instructions on how to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and observations about the paper, such as the appendix not following NeurIPS 2021 style files and the need for a proofread. It also suggests expanding the discussion on potential negative societal impacts. These statements are not claims but rather descriptive observations or suggestions, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides several pieces of feedback that are mostly actionable. It points out a formatting issue with the appendix, specifically mentioning that it does not follow the NeurIPS 2021 style files. This is a clear and specific suggestion that the authors can address to improve the presentation of their work. Additionally, the comment recommends a proofread for the appendix, which is a helpful suggestion for ensuring the overall quality of the paper. The reviewer also suggests expanding the discussion on potential negative societal impacts, which is a valuable suggestion for broadening the scope of the paper. However, the comment could be more helpful if it provided specific examples or guidance on how to address these potential negative impacts. Overall, the comment is mostly helpful as it identifies areas for improvement and offers actionable suggestions, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider examining training and validation curves for different losses and determine whether the model can bring all three losses down simultaneously. Additionally, it raises a question about any tricks related to weighing these losses. While the comment implies that the authors should investigate these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these aspects further. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests examining training and validation curves for different losses and determining whether the model can bring all three losses down simultaneously. It also raises a question about any tricks related to weighing these losses. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the model development and evaluation sections. The suggestion to explore training and validation curves is specific, and the question about weighing losses is also relevant. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should examine training and validation curves for different losses and determine whether the model can bring all three losses down simultaneously. It also raises a question about any tricks related to weighing these losses. While the comment provides a logical suggestion for further investigation, it lacks specific examples or references to support the claim that the model should be able to bring down all losses simultaneously. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of this analysis themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should examine training and validation curves for different losses and determine whether the model is able to bring all three losses down simultaneously. It also raises a question about any tricks related to weighing these losses. This feedback is somewhat helpful as it identifies a potential area for further investigation and provides a direction for the authors to explore. However, the comment lacks specific guidance or examples on how to conduct this analysis or what specific tricks might be relevant. While it points out a potential area for improvement, it does not offer detailed guidance or actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of rigor in the paper\\'s claim that computing the GOSPA metric is NP-hard. It highlights that the paper does not provide a theoretical argument or proof, merely stating that it is due to the binary constraint in (4) and citing a reference. The reviewer also questions the general applicability of this claim, as it may be possible to reduce GOSPA to an exact polynomial-time computable assignment problem. The comment implies that the authors should provide a more detailed and rigorous theoretical argument or proof to substantiate their claim. However, it does not explicitly instruct the authors on how to do this or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"NP-hardness\" claim and the specific section where it is discussed, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not provide a rigorous theoretical argument or proof for the NP-hardness claim, despite claiming it. Additionally, it questions the general applicability of the claim and suggests that it may be possible to reduce GOSPA to an exact polynomial-time computable assignment problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s claim of NP-hardness for computing the GOSPA metric is not substantiated by a rigorous theoretical argument or proof. It questions the general applicability of this claim and suggests that it may be possible to reduce GOSPA to an exact polynomial-time computable assignment problem. The reviewer provides some reasoning by pointing out that the paper assumes access to the optimal assignment matrix, which could limit its applicability. However, the comment lacks specific references or detailed examples to fully substantiate the claim. While it raises valid points, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s claim of NP-hardness for computing the GOSPA metric. It points out that the paper does not provide a rigorous theoretical argument or proof, merely stating that it is due to the binary constraint in (4) and citing a reference. This lack of substantiation is a critical oversight, as it undermines the credibility of the claim and its applicability. The reviewer also questions the general applicability of the claim, suggesting that it may be possible to reduce GOSPA to an exact polynomial-time computable assignment problem. This feedback is valuable as it highlights a critical gap in the paper\\'s argumentation, which the authors should address to strengthen their work. However, the comment could be more helpful if it provided specific suggestions on how to substantiate the claim or what additional evidence might be needed. Overall, the comment is mostly helpful as it identifies a significant weakness and offers a direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be helpful to have an algorithmic writeup of the solution to the pricing problem. This feedback implies that the authors should include a detailed description of their algorithmic approach to address the pricing problem. However, the comment does not specify which part of the paper should include this writeup or provide guidance on how to structure it. While the action is clear, the lack of concrete details on implementation makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it would be helpful to have an algorithmic writeup of the solution to the pricing problem. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for an algorithmic writeup, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be helpful to have an algorithmic writeup of the solution to the pricing problem. However, it does not provide any reasoning, evidence, or examples to support why this is necessary or how it would benefit the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that it would be helpful to include an algorithmic writeup of the solution to the pricing problem. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by providing a more detailed description of the algorithmic approach. However, the comment lacks depth and does not offer specific guidance on how to structure or present the algorithmic writeup, leaving the authors with a general suggestion without detailed instructions. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the role of model averaging in balancing the trade-off between KL divergence and reward. It suggests that achieving this balance requires the policy to explore intelligently and update gradually during initialization. However, it does not provide specific guidance on how the authors should address this issue or what steps they should take to clarify their explanation. The comment implies that the authors should provide more detailed explanations or examples, but it does not explicitly instruct them to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"numerical evaluation\" and \"model averaging,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the rationale behind using model averaging to balance the trade-off between KL divergence and reward, and suggests that achieving this balance requires the policy to explore intelligently and update gradually during initialization. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the rationale behind using model averaging to balance the trade-off between KL divergence and reward, suggesting that achieving this balance requires the policy to explore intelligently and update gradually during initialization. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The reviewer provides a logical reasoning but does not provide sufficient evidence or detailed explanations to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the rationale behind using model averaging to balance the trade-off between KL divergence and reward. It questions the effectiveness of this approach and suggests that achieving this balance requires the policy to explore intelligently and update gradually during initialization. While the comment highlights an important area for clarification, it does not provide specific suggestions or examples on how the authors might address this issue or improve their explanation. The feedback is somewhat helpful as it points out a critical area for improvement but lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a discussion on a possible generalization with a different distribution for the size of the batches could be included. While the comment implies that the authors should consider this topic, it does not provide specific guidance on how to integrate this discussion into the paper or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on generalization with different batch sizes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a discussion regarding a possible generalization with a different distribution for the size of the batches could be included. However, it does not specify which part of the paper this discussion should be included in, such as a particular section, figure, or table. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The suggestion is specific, as it clearly identifies a potential area for discussion, but the lack of grounding makes it difficult for the authors to effectively address the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a discussion regarding a possible generalization with a different distribution for the size of the batches could be included. However, it does not provide any reasoning, evidence, or examples to support why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that a discussion on a possible generalization with a different distribution for the size of the batches could be included. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to integrate this discussion into the paper or what aspects to focus on. The comment is somewhat helpful as it points out a potential area for enhancement, but it does not offer actionable steps or detailed suggestions for the authors to consider. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive to be fully beneficial.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis only considers the case of batch size equal to 1 and questions how the batch size affects the effective initialization scale. While the comment identifies a specific issue with the analysis, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to consider different batch sizes but are not given specific instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"analysis\" and the specific issue of considering only batch size = 1. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the impact of batch size on effective initialization scale. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis only considers the case of batch size equal to 1 and questions how the batch size affects the effective initialization scale. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the analysis, noting that it only considers the case of batch size equal to 1 and questions how the batch size affects the effective initialization scale. This feedback is clear and actionable, as it prompts the authors to consider the impact of different batch sizes on their analysis. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to incorporate this consideration into the analysis. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the results shown in Figure 7, specifically questioning why more data leads to lower results on the ImageNet linear evaluation. It suggests that sampling 50% of the data seems to yield better results than sampling 100% of the data. While the comment implies that the authors should provide an explanation or analysis for this observation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation or analysis to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the results shown in the figure and suggests an explanation for why more data leads to lower results on the ImageNet linear evaluation. The comment provides a clear direction for the authors to consider, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for an explanation of the results shown in Figure 7. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the results shown in Figure 7, specifically questioning why more data leads to lower results on the ImageNet linear evaluation. It suggests that sampling 50% of the data seems to yield better results than sampling 100% of the data. While the comment identifies a potential issue with the results, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback is somewhat helpful as it points out a potential area for concern, but it lacks actionable advice or detailed guidance. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of comprehensive evaluation, specifically mentioning the absence of quantitative results on mainstream metrics like FVD. It suggests that including these metrics would enhance the paper\\'s credibility and comparability with other video generation methods. While the comment implies that the authors should include these metrics, it does not explicitly instruct them to do so. The action is clear but not explicitly stated, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"primary evaluation benchmark\" and \"mainstream metrics\" such as FVD, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of comprehensive evaluation, particularly the absence of quantitative results on FVD, which is a widely recognized metric for evaluating temporal video prediction. This provides clear guidance on what needs to be addressed to enhance the paper\\'s credibility and comparability with other video generation methods. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comprehensive evaluation, specifically mentioning the absence of quantitative results on FVD, a widely recognized metric for evaluating temporal video prediction. The comment suggests that including these results would enhance the paper\\'s credibility and comparability with other video generation methods. While the comment provides a logical reasoning for why FVD should be included, it lacks specific examples or references to support the claim that FVD is a necessary metric. This makes the claim somewhat verifiable, as the authors would need to infer the importance of FVD and make the connection themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s evaluation, noting the lack of comprehensive evaluation and the absence of quantitative results on mainstream metrics like FVD. It suggests that including these metrics would enhance the paper\\'s credibility and comparability with other video generation methods. While the comment highlights a critical area for improvement, it does not provide specific guidance on how to implement this change or what metrics should be included. The feedback is somewhat helpful as it points out a significant gap in the evaluation but lacks detailed suggestions for improvement, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the technical details in section 2.2 are difficult to follow. However, it does not provide any explicit or implicit suggestions for how the authors might improve the clarity of these details. There is no guidance on whether the technical details should be revised, simplified, or expanded. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"2.2,\" which provides some grounding by referencing a specific section of the paper. However, it does not specify what aspect of the technical details is difficult to follow, making it weakly grounded. The comment is specific in identifying the issue with the technical details being hard to follow, but it lacks detailed guidance on how to improve clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical details in section 2.2 are difficult to follow. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a specific issue with the technical details in section 2.2, noting that they are difficult to follow. However, it does not provide any suggestions or guidance on how the authors might improve the clarity or accessibility of these details. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the improvement of EVA over the backbone models, specifically OT-Flow, in terms of designability and success rates. It suggests that if the main contribution is the addition of geometry information and motif-interpolation, the reviewer would like to know if these design choices benefit over prior backbones. While the comment implies that the authors should provide a comparison between EVA and OT-Flow, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"RFDiffusion benchmark\" and \"in-silico vaccine design benchmark,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the improvement of EVA over backbone models, particularly OT-Flow, in terms of designability and success rates. The comment further asks for clarification on the benefits of the proposed design choices, which adds specificity to the feedback. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the improvement of EVA over backbone models, specifically OT-Flow, in terms of designability and success rates. It suggests that if the main contribution is the addition of geometry information and motif-interpolation, the authors should provide a comparison between EVA and OT-Flow. The comment is somewhat verifiable as it logically questions the improvement of EVA over existing backbones, but it lacks specific examples or references to support the claim. The authors would need to make a significant effort to provide a detailed comparison, which is not explicitly stated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the improvement of EVA over existing backbone models, specifically OT-Flow, in terms of designability and success rates. It suggests that if the main contribution is the addition of geometry information and motif-interpolation, the authors should provide a comparison between EVA and OT-Flow to demonstrate the benefits of their design choices. This feedback is somewhat helpful as it prompts the authors to clarify their contributions and provide evidence for their claims. However, the comment could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that there are too many identical sentences in the Abstract, Introduction, and Conclusion sections of the paper. While it identifies an issue, it does not provide explicit guidance on how to address this problem. The authors are left to infer that they should revise or eliminate these repetitive sentences, but the comment lacks specific suggestions or examples on how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment points out a specific issue with the repetition of identical sentences in the Abstract, Introduction, and Conclusion sections of the paper. However, it does not specify which sections or sentences are repetitive, making it difficult for the authors to pinpoint the exact parts that need revision. The comment lacks specificity regarding the exact changes needed to address this issue. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, and it is not specific because it does not provide detailed guidance on how to improve the draft.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that there are too many identical sentences in the Abstract, Introduction, and Conclusion sections of the paper. However, it does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim lacks verifiability, as it does not provide a clear rationale for the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that there are too many identical sentences in the Abstract, Introduction, and Conclusion sections. While this feedback highlights a potential problem, it lacks depth and does not provide specific suggestions or guidance on how to address this issue. The comment does not offer actionable advice or examples of how to improve the draft by varying sentence structure or content. As a result, the feedback is somewhat helpful, as it points out a potential weakness but does not fully support the authors in making improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reward function used in the ablation studies, specifically asking if it is the sEH reward function. While the comment implies that the authors should provide more information about the reward function used, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"reward function\" and \"ablation studies,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the question by asking about the reward function used in the ablation studies, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking about the reward function used in the ablation studies. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the reward function used in the ablation studies, asking if it is the sEH reward function. This is a clear and actionable request for information, as it prompts the authors to provide more detail about their methodology. By addressing this question, the authors can enhance the transparency and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided additional context about the significance of the reward function. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of comparing self-generated code with a placeholder, noting that the former samples the model 2x for each generation. It suggests that using a placeholder was somewhat intended in the original technique. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer that they should consider using a placeholder or make other adjustments to ensure fairness in their comparison. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of using self-generated code as a comparison to previous work, specifically noting that it samples the model 2x for each generation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the comparison, suggesting that using a placeholder code was somewhat intended in the original technique. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using self-generated code as a comparison is not fair because it samples the model 2x for each generation, which was somewhat intended in the original technique. The comment provides a logical reasoning for why this comparison is unfair, suggesting that using a placeholder code was more appropriate. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the reasoning and make a connection themselves, which is not as straightforward as it could be. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of self-generated code versus a placeholder, noting that the former samples the model 2x for each generation. This observation highlights a potential weakness in the fairness of the comparison, as it suggests that using a placeholder was somewhat intended in the original technique. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the fairness of their comparison. While it points out a relevant concern, the feedback lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the presentation of Sections 3 and 4, suggesting that they should be the main contributions of the paper but are instead squeezed into a single page. It points out the absence of precise mathematical definitions for the quantum states in Equation (4), which makes it difficult to follow. While the comment identifies specific issues, it does not provide explicit guidance on how to address these concerns, such as recommending a reorganization of the sections or suggesting how to present the missing definitions. The action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be improved but without concrete steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sections 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the presentation of these sections, noting that they are squeezed into a single page and pointing out the absence of precise mathematical definitions for the quantum states in Equation (4). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Sections 3 and 4, which are labeled as the main contributions of the paper, are squeezed into a single page and lack precise mathematical definitions. This claim is somewhat verifiable as it provides a specific example (the absence of definitions in Equation (4)) to support the assertion that the content is difficult to follow. However, the comment lacks detailed reasoning or references to fully substantiate the claim, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the issue, which is not as straightforward as it could be. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the presentation of Sections 3 and 4, which are labeled as the main contributions of the paper. It points out that these sections are squeezed into a single page, making it challenging for readers to fully understand and follow the content. Additionally, it highlights the absence of precise mathematical definitions for the quantum states in Equation (4), which further impairs the clarity of the presentation. This feedback is clear and actionable, as it directs the authors to address the issue of section organization and provide necessary definitions to enhance the comprehensibility of their work. However, the comment could be more helpful if it offered specific suggestions on how to reorganize the sections or suggested ways to present the missing definitions. Overall, the comment is mostly helpful as it effectively guides the authors on improving the clarity and accessibility of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of the results with respect to under-represented groups, specifically asking if females or blacks are discriminated by the recommendations of LLMs. While this comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence or analysis to demonstrate fairness. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the fairness of the results with respect to under-represented groups, specifically asking if females or blacks are discriminated by the recommendations of LLMs. However, it does not specify which part of the paper this question pertains to, such as a particular section or table where the results are presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for evidence or analysis regarding fairness, but without explicit grounding, it is difficult for the authors to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the fairness of the results with respect to under-represented groups, specifically asking if females or blacks are discriminated by the recommendations of LLMs. However, the comment lacks any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the fairness of the results with respect to under-represented groups, specifically asking if females or blacks are discriminated by the recommendations of LLMs. This is an important consideration that could impact the overall impact and relevance of the work. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what evidence would be needed to demonstrate fairness. While it highlights a potential area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests that the paragraph describing Co-variance is too long, which reduces the legibility of the paper. It also recommends adding more details on the generation of two types of long-tailed datasets, as experiments on these datasets are important for affirming the paper's contribution. Additionally, the reviewer suggests that due to the limited page count, the tables and figures might be too dense, and recommends using more pages for the experiments on long-tailed datasets. Each of these points is clearly stated and provides specific guidance on how to improve the paper. The actions are explicit and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1\" and \"the paragraph that describes Co-variance,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the length of the paragraph and the need for more details on the generation of long-tailed datasets. The comment also suggests that the tables and figures might be too dense due to the limited page count, and recommends using more pages for the experiments on long-tailed datasets. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple claims and suggestions, each of which is supported by logical reasoning and specific examples. The comment suggests that the paragraph describing Co-variance is too long, which reduces the legibility of the paper. It also recommends adding more details on the generation of long-tailed datasets, which are important for affirming the paper's contribution. Additionally, the reviewer suggests that due to the limited page count, the tables and figures might be too dense, and recommends using more pages for the experiments on long-tailed datasets. These claims are supported by specific observations and suggestions, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to support the importance of the experiments on long-tailed datasets. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides multiple actionable suggestions for improving the paper. It identifies specific areas where the paper could be improved, such as suggesting that the paragraph describing Co-variance is too long and should be revised for better legibility. Additionally, it recommends adding more details on the generation of long-tailed datasets, which are important for affirming the paper's contribution. The comment also suggests that due to the limited page count, the tables and figures might be too dense, and recommends using more pages for the experiments on long-tailed datasets. These suggestions are clear and provide the authors with concrete steps to enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered additional guidance on how to effectively present these details or suggested specific ways to improve the presentation. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the necessary changes required to make EC-Diffusers work on real-world data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific modifications or experiments should be conducted to address this issue. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the necessary changes required to make EC-Diffusers work on real-world data. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment. This lack of grounding makes it difficult for the authors to identify the exact area needing attention. Additionally, the comment lacks specificity as it does not provide details on what changes are needed or how they might be implemented. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the necessary changes required to make EC-Diffusers work on real-world data. It does not express an opinion, judgment, or suggestion that would require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the necessary changes required to make EC-Diffusers work on real-world data. While it highlights an area of interest for the authors, it lacks specificity and does not provide any actionable feedback or suggestions on how to address this issue. Without detailed guidance or examples, the authors are left without a clear path forward. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the reliability of the evaluation and suggests the need for a human study to gauge the efficacy of the evaluation protocol. While the comment implies that the authors should consider conducting a human study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a human study to address the concerns raised. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the reliability of the evaluation and suggests the need for a human study to gauge the efficacy of the evaluation protocol. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in its request for a human study to evaluate the protocol, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the reliability of the evaluation and suggests the need for a human study to gauge the efficacy of the evaluation protocol. However, it does not provide any supporting evidence, reasoning, or references to justify why a human study is necessary or how it would improve the evaluation. Without additional context or examples, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the reliability of the evaluation and suggests the need for a human study to gauge the efficacy of the evaluation protocol. This feedback is somewhat helpful as it identifies a potential weakness in the paper\\'s evaluation process and prompts the authors to consider conducting a human study. However, the comment lacks specific guidance on how to conduct such a study or what aspects of the evaluation protocol would benefit from human validation. While it provides a direction for improvement, it could be more actionable with additional details. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the novelty of the work, comparing it to prior work and suggesting that the technical contribution appears incremental. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to improve the novelty or how to differentiate the work from prior studies. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the work, comparing it to prior work and suggesting that the technical contribution appears incremental. However, it does not specify which part of the paper this concern is related to, such as the introduction, methodology, or results sections. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity in detailing what aspects of the work are considered incremental or how it could be improved. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution of the work appears incremental when compared to prior studies. However, it does not provide specific references to those studies or detailed reasoning to support this claim. Without specific examples or detailed evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a concern about the novelty of the work, suggesting that the technical contribution appears incremental when compared to prior studies. However, it does not provide specific examples or detailed reasoning to support this claim, nor does it offer suggestions for how the authors might address this issue or improve the novelty of their work. Without actionable feedback or guidance, the comment lacks depth and does not assist the authors in improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting an analysis on the performance of PromptMix in relation to the quality of questions/answers generated by a language model (LLM). It proposes two specific actions: (1) examining which open-source LLMs would work with this approach and (2) identifying a lower LLM parameter count cutoff (e.g., 7B) that would lead to degradation in performance. Both of these actions are explicit and provide clear guidance on how the authors can improve their draft. The first action is specific and actionable, while the second action is also explicit but could be more detailed. Overall, the comment is mostly actionable, as it provides clear directions for the authors to follow.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the performance of PromptMix and its dependence on the quality of questions/answers generated by a language model (LLM). It suggests conducting an analysis on which open-source LLMs would work with this approach and proposes a parameter count cutoff (e.g., 7B) that could indicate when performance starts to degrade. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the performance analysis or results section. The comment is specific in suggesting a direction for further analysis, making it fully grounded. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the performance of PromptMix depends on the quality of questions/answers generated by a language model (LLM). It proposes an analysis to determine which open-source LLMs would work with this approach and suggests a parameter count cutoff (e.g., 7B) that could indicate when performance starts to degrade. While the comment provides a logical basis for the claim, it lacks specific examples or references to support the assertion about the parameter count cutoff. This makes the claim somewhat verifiable, as the authors would need to conduct the analysis themselves to fully understand the claim\\'s validity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the paper by proposing an analysis on the performance of PromptMix in relation to the quality of questions/answers generated by a language model (LLM). It suggests examining which open-source LLMs would work with this approach and identifies a parameter count cutoff (e.g., 7B) that could indicate when performance starts to degrade. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their analysis and potentially improving the quality of their results. By addressing these points, the authors can strengthen their paper and provide more robust evidence for their claims. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the feasibility of the submodularity approach used in the paper, specifically regarding the SATURATE algorithm and its scalability with N. The reviewer suggests that it would be worth commenting on the runtimes of the simulations for large models in Section 6. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide runtime information. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"submodularity approach subroutine\" and \"SATURATE algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the feasibility of the approach, suggesting that the authors should comment on the runtimes of simulations for large models in Section 6. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the feasibility of the submodularity approach used in the paper, specifically regarding the SATURATE algorithm and its scalability with N. The reviewer suggests that it would be worth commenting on the runtimes of the simulations for large models in Section 6. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim about the scalability of the approach. Without additional context or evidence, the claim remains unverifiable, as it lacks the necessary justification to be considered a claim. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the feasibility of the submodularity approach used in the paper, specifically regarding the SATURATE algorithm and its scalability with N. It suggests that the authors should comment on the runtimes of the simulations for large models in Section 6. This feedback is somewhat helpful as it identifies a potential area for improvement by prompting the authors to address the scalability of their approach. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Overall, the comment offers a direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the inference at test time could benefit from more details, but it does not explicitly instruct the authors to provide these details. While the comment implies that additional information is needed, it lacks specific guidance on what kind of details should be included or how to present them. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more information but without clear direction on what that information should be. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"594,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more details on inference at test time. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the inference at test time could benefit from more details, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could benefit from more detail, specifically regarding inference at test time. While it points out a gap in the explanation, it does not provide specific suggestions or guidance on how to enhance the explanation or what additional details would be beneficial. The comment highlights an area for improvement but lacks actionable advice, making it somewhat helpful. The authors are given a direction for improvement but without detailed guidance, which limits the comment\\'s utility. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several concerns about the correctness and soundness of the paper, particularly regarding the evaluation of programs generated by CodeChain, the effectiveness of sub-module generation, and the analysis of chain of self-revisions. However, it does not provide explicit or implicit actions for the authors to take. The authors are left to infer that they need to address these concerns, but without specific guidance on how to do so. The feedback lacks actionable details, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses several issues related to the evaluation of programs generated by CodeChain, the effectiveness of sub-module generation, and the analysis of chain of self-revisions. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in detailing the concerns about the evaluation and the effectiveness of the programs, but it lacks grounding as it does not specify where these issues are discussed in the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims about the correctness and soundness of the paper, including the evaluation of programs generated by CodeChain, the effectiveness of sub-module generation, and the analysis of chain of self-revisions. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The authors would need to infer the basis of these claims and determine how to address them, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several areas of concern regarding the correctness and soundness of the paper, including the evaluation of programs generated by CodeChain, the effectiveness of sub-module generation, and the analysis of chain of self-revisions. It points out that the evaluation of programs generated by CodeChain is unclear in terms of human preference, and that the effectiveness of sub-module generation is unclear. Additionally, it notes a slight performance drop in the analysis of chain of self-revisions, which suggests a limitation in the self-revising prompt. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it provides insight into potential weaknesses but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the authors\\' argument regarding the accuracy of deferring classifiers compared to other classifiers. It seeks clarification on whether the authors\\' conclusion implies that deferring classifiers are less fair due to larger differences in error rates between subgroups. While the comment implies that the authors should clarify their argument or provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of fairness in their argument. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 306-307,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the authors\\' argument about the accuracy of deferring classifiers and seeks clarification on the implications for fairness. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the authors\\' argument regarding the accuracy of deferring classifiers. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the authors\\' argument regarding the accuracy of deferring classifiers compared to other classifiers. It seeks clarification on whether the authors\\' conclusion implies that deferring classifiers are less fair due to larger differences in error rates between subgroups. This feedback is somewhat helpful as it prompts the authors to reconsider their argument and potentially revise their conclusion to ensure fairness. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to present the argument more clearly. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a critical aspect of their argument but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to report the improvement in object classification directly, in addition to the overall scene graph results. This is a clear and concrete action that the authors can take to strengthen their case. The comment provides a specific suggestion for enhancing the paper\\'s evidence, which is direct and actionable. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L107,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of results to support the claim about the relational embedding module\\'s improvement in object classification. The comment provides a clear direction for the authors to improve their draft by including results to support the claim. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the relational embedding module significantly improves object classification, but it lacks supporting evidence or references to substantiate this claim. The comment suggests that reporting the improvement in object classification directly would strengthen the paper\\'s case. However, without specific examples or references to support the claim, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of evidence to support the claim that the relational embedding module significantly improves object classification. It suggests that reporting the improvement in object classification directly, in addition to the overall scene graph results, would strengthen the case of the paper. This feedback is clear and actionable, providing the authors with a direct path to enhance the robustness and credibility of their findings. However, it could be more helpful if it included specific examples or guidance on how to present the additional results. Overall, the comment is mostly helpful, as it effectively points out a gap in the paper\\'s evidence and offers a constructive suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a critique of the paper\\'s scope, noting that it combines self-supervised learning with multimodal representation learning based on hypergraph. It references a previous work on hypergraph attention networks for multimodal learning, suggesting that the novelty of the manuscript is limited to adding self-supervised learning on top of it. However, the comment does not provide explicit guidance or suggestions on how the authors might expand the scope or enhance the novelty of their work. The action is implicit and vague, leaving the authors to infer that they need to explore additional aspects or improvements to their work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the scope of the paper, noting that it combines self-supervised learning with multimodal representation learning based on hypergraph. It references a previous work on hypergraph attention networks for multimodal learning, which provides some grounding by allowing the authors to infer the part of the paper being addressed. However, the comment does not specify what aspect of the paper\\'s scope is narrow or how the authors might expand it. Additionally, it lacks specificity regarding how the addition of self-supervised learning enhances the novelty of the work. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper\\'s scope is narrow because it combines self-supervised learning with multimodal representation learning based on hypergraph, which has been explored in a previous work. The reviewer references a specific paper to support their claim, providing a clear reference to the previous work. This makes the claim mostly verifiable, as it is based on a specific example and a well-known reference. However, the comment could be strengthened by further elaborating on why the addition of self-supervised learning is not a significant contribution or how it might impact the broader field. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a critique of the paper\\'s scope, noting that it combines self-supervised learning with multimodal representation learning based on hypergraph. It references a previous work on hypergraph attention networks for multimodal learning, suggesting that the novelty of the manuscript is limited to adding self-supervised learning on top of it. However, the comment does not offer specific suggestions or guidance on how the authors might expand the scope or enhance the novelty of their work. While it identifies a potential limitation, it lacks actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the difficulty of finding intuitive attention examples similar to those in Figure 4. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what specific actions they should take. The comment lacks actionable advice or suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment does not specify which part of the paper it addresses, making it weakly grounded. It lacks specificity because it does not provide any details on what is considered intuitive attention examples or how they are relevant to the paper. Without this context, the authors cannot effectively address the question. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the difficulty of finding intuitive attention examples similar to those in Figure 4. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment raises a question about the difficulty of finding intuitive attention examples similar to those in Figure 4. While it prompts the authors to consider this aspect, it lacks specificity and does not provide any guidance or suggestions on how to address this issue or improve the paper. Without actionable feedback or context, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the difference between two specific values, 01 and 10, in Figure 1. While it does not explicitly instruct the authors to make any changes or provide guidance on how to address this question, it does imply that the authors should clarify this difference in their paper. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification or explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the difference between two specific values, 01 and 10, in Figure 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the difference between two specific values, 01 and 10, in Figure 1. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the difference between two specific values, 01 and 10, in Figure 1. While it highlights an area of confusion, it does not provide any guidance or suggestions for clarification or improvement. The authors are left with a question but no actionable feedback or direction on how to address this issue. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to create a separate \"Related Work\" section and suggests moving the three bullet points about related work from the \"Introduction\" section to this new section. This provides a clear and concrete action for the authors to take, ensuring that the feedback is highly actionable. The comment also offers a specific rationale for the suggested change, which further guides the authors on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Introduction\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, suggesting that the authors should create a separate \"Related Work\" section and move the three bullet points about related work to this section. This provides a clear direction for improvement, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the \"Introduction\" section of the paper is too long and should be separated into a \"Related Work\" section. The reviewer provides a specific suggestion to move the three bullet points about related work to this new section. This claim is somewhat verifiable as it provides a logical reasoning for separating the related work information, but it lacks detailed justification or examples to fully substantiate the need for this change. The authors may need to infer the reasoning behind the suggestion, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion to improve the organization and clarity of the paper. It suggests creating a separate \"Related Work\" section, which would help the authors clearly present their work in relation to existing literature. This feedback is valuable as it directly addresses a potential issue with the paper's structure and offers a concrete way to improve it. By following this suggestion, the authors can enhance the clarity and coherence of their work, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the overall process and rationale for constructing the benchmark, suggesting that the paper could present these aspects more clearly. However, it does not provide specific guidance on how to improve the clarity or what aspects need more detail. The feedback lacks concrete steps or examples of what the authors should focus on to enhance the clarity of their work. As a result, the authors are left without a clear understanding of what actions to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of clarity in the overall process and rationale for constructing the benchmark, suggesting that these aspects could be presented more clearly. However, it does not specify which part of the paper this issue pertains to, such as the sections discussing the rules or data augmentation methods. Without explicit references to sections or specific elements, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects need more clarity or how to improve the presentation. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper dedicates significant space to describing rules and data augmentation methods but lacks clarity in the overall process and rationale for constructing the benchmark. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact areas that need improvement. The lack of supporting evidence or examples makes it challenging for the authors to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of clarity in the overall process and rationale for constructing the benchmark. It highlights that while the paper dedicates significant space to describing rules and data augmentation methods, it lacks clarity in presenting the overall process and rationale. However, the comment does not provide specific suggestions or guidance on how to improve the clarity or what aspects need more detail. This feedback is somewhat helpful as it points out a potential weakness but lacks actionable advice, making it challenging for the authors to fully address the issue. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a significant lack of literature reviews on recent advances in active learning communities, particularly in the context of Bayesian learning. It points out that the Bayesian Coreset is directly relevant to the work and has been overlooked in the literature review. Additionally, it suggests that the current setup might be more advanced than related studies, which could be discussed further. While the comment provides explicit actions\u2014to include literature reviews and discuss the current setup's advancements\u2014it does so in a somewhat vague manner. The authors are given a clear direction but may need to infer the specific details of how to implement these suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of content and the specific areas of literature reviews, such as Bayesian learning and the Bayesian Coreset, which are relevant to the work. It also provides specific examples of related works, such as [1][2], that discuss similar topics. This level of detail allows the authors to accurately identify the parts of the paper being addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks content and specifically identifies a significant lack of literature reviews on recent advances in active learning communities, particularly in the context of Bayesian learning. The reviewer provides examples of relevant works, such as the Bayesian Coreset, which are directly relevant to the paper. Additionally, the reviewer suggests that the current setup might be more advanced than related studies, which could be discussed further. The comment is supported by logical reasoning and specific examples, making it mostly verifiable. However, it could be strengthened by providing more detailed references or additional examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper\\'s content, specifically the lack of literature reviews on recent advances in active learning communities, particularly in the context of Bayesian learning. It provides specific examples of relevant works, such as the Bayesian Coreset, which are directly relevant to the paper but have been overlooked in the literature review. Additionally, it suggests discussing how the current setup is more advanced than related studies. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their literature review and potentially strengthening their paper. However, the comment could be more helpful if it provided additional guidance on how to integrate these references or discuss the advancements. Overall, the comment is mostly helpful as it effectively points out areas for improvement and offers specific suggestions for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the \"one-to-many relationship\" in Figure 2 makes it difficult to understand the presented trends, and that the plots seem to contain a considerable amount of noise. However, it does not provide explicit guidance on how the authors should address these issues, such as suggesting specific changes to the plot or explaining the trends more clearly. The feedback is vague and lacks concrete details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Fig 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the plot, stating that the \"one-to-many relationship\" makes it difficult to understand the presented trends and that the plots contain a considerable amount of noise. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"one-to-many relationship\" in Figure 2 makes it difficult to understand the presented trends and that the plots contain a considerable amount of noise. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to address the issues effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 2, noting that the \"one-to-many relationship\" in the plot makes it difficult to understand the presented trends. Additionally, it points out that the plots seem to contain a considerable amount of noise. While the comment highlights these concerns, it lacks specific suggestions or guidance on how the authors might address these issues, such as recommending alternative visualizations or explaining the trends more clearly. The feedback is somewhat helpful as it provides insight into potential areas for improvement, but it could be more actionable with additional details. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the comparison between DFSSATTEN and other algorithms like Performer and Reformer, suggesting that the speedup observed in DFSSATTEN is mostly due to low-level optimization and hardware support. It also points out that these algorithms are not deeply optimized and that comparing them with DFSSATTEN might be unfair. The comment further suggests that the authors should consider whether DFSSATTEN supports training from scratch, which could be a significant contribution. While the comment identifies a potential issue and suggests an area for improvement, it does not provide explicit instructions on how to address this issue or conduct the comparison. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DFSSATTEN,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison between DFSSATTEN and other algorithms, suggesting that the speedup observed is mostly due to low-level optimization and hardware support. The comment also raises a question about whether DFSSATTEN supports training from scratch, which is a relevant point for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the speedup observed by DFSSATTEN is mostly due to low-level optimization and hardware support, suggesting that this might be unfair when comparing with other algorithms like Performer and Reformer. The reviewer also questions whether DFSSATTEN supports training from scratch, which is a significant direction in pretraining. The comment provides some reasoning by pointing out that these methods are not deeply optimized and are often trained from scratch. However, it lacks specific examples or references to support the claim about the unfairness of the comparison. The suggestion to consider training from scratch is logical but could be strengthened with more detailed evidence or examples. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between DFSSATTEN and other algorithms, suggesting that the speedup observed might be due to low-level optimization and hardware support rather than the algorithm itself. It also raises a relevant question about whether DFSSATTEN supports training from scratch, which could be a significant contribution. The comment provides clear and actionable feedback by suggesting that the authors should consider whether the algorithm can be trained from scratch, offering a direction for further exploration. However, the comment could be more helpful if it provided specific guidance on how to address the issue of fairness in the comparison or how to conduct the training from scratch. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a constructive suggestion for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point mentions that the VMI-SI-TI-DI-FDSM method was evaluated on a black-box setting when their method was tested on a defended model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific improvements could be made. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"VMI-SI-TI-DI-FDSM\" and \"black-box setting,\" which provides some grounding by referencing specific methods and settings. However, it does not specify which part of the paper these evaluations are discussed in, making it weakly grounded. The comment is specific in detailing what was evaluated and how it was conducted, but it lacks guidance on what aspects need improvement or how the authors should address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the VMI-SI-TI-DI-FDSM method was evaluated on a black-box setting when their method was tested on a defended model. However, the comment lacks specific details or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment mentions that the VMI-SI-TI-DI-FDSM method was evaluated on a black-box setting when their method was tested on a defended model. However, it does not provide any further context, explanation, or suggestions for improvement. Without additional information or guidance, the authors are left without actionable feedback or insights into how to address the issue. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the clarity of the proposed method's description could be improved and recommends referring to the questions section for details. While the comment implies that the authors should clarify their method, it does not provide specific guidance on how to do so or which aspects of the description need improvement. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance the clarity of their method description. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the clarity of the proposed method's description could be improved, but it does not specify which part of the paper this pertains to. The authors cannot confidently determine whether it relates to the introduction, methodology, results, or another section. Additionally, the comment suggests referring to the questions section for details, but it does not specify which questions are relevant or how they relate to the clarity issue. This lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the clarity of the proposed method's description could be improved, but it does not provide any specific examples, reasoning, or references to support this claim. The suggestion to refer to the questions section for details is vague and does not offer a clear path for improvement. Without additional context or evidence, the claim remains unverifiable. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the clarity of the proposed method's description could be improved, specifically mentioning that the questions section might provide more details. While this feedback points out an area for improvement, it lacks specificity and does not offer guidance on how to enhance the clarity of the description. The comment does not provide actionable steps or examples of what could be improved, leaving the authors with a general suggestion that requires further exploration. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the independence of the pruning strategy across different layers in the GNN and suggests that if an edge is pruned in one layer, it should also be pruned in other layers. It asks if there are any observations made in the empirical evaluations regarding such correlations and if the authors can explain why they are not considered. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale or explanation for the independence of the pruning strategy across layers. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the independence of the pruning strategy across different layers in the GNN and suggests that if an edge is pruned in one layer, it should also be pruned in other layers. It asks if there are any observations made in the empirical evaluations regarding such correlations and if the authors can explain why they are not considered. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology or results sections where the pruning strategy is discussed. The comment is specific in its inquiry about the independence of the pruning strategy and the need for an explanation, making it fully grounded. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the independence of the pruning strategy across different layers in the GNN and suggests that if an edge is pruned in one layer, it should also be pruned in other layers. It asks if there are any observations made in the empirical evaluations regarding such correlations and if the authors can explain why they are not considered. The comment is somewhat verifiable as it logically questions the independence of the pruning strategy and suggests a potential area for further exploration. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the independence of the pruning strategy across different layers in the GNN, suggesting that if an edge is pruned in one layer, it should also be pruned in other layers. It prompts the authors to consider whether there are any observations made in the empirical evaluations regarding such correlations and why they are not considered. This feedback is valuable as it encourages the authors to reevaluate their methodology and potentially explore the impact of pruning correlations across layers. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Overall, the comment is mostly helpful as it identifies a potential area for improvement and prompts the authors to consider a relevant aspect of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the experimental validation, specifically noting that it only considers CIFAR-10/100 as in-distribution data. It questions whether the results would generalize to other datasets and suggests that some conclusions might need to be nuanced. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure generalizability. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider additional datasets and possibly revise their conclusions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental validation\" and \"CIFAR-10/100 as in-distribution data,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the generalizability of the results to other datasets and suggests that some conclusions might need to be nuanced. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the generalizability of the results to other datasets beyond CIFAR-10/100. It suggests that the conclusions might need to be nuanced, implying that the results could be stronger if other datasets were considered. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the significance of this concern and potentially conduct additional experiments to validate the generalizability of their results. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the generalizability of the experimental validation, noting that it only considers CIFAR-10/100 as in-distribution data. It questions whether the results would generalize to other datasets and suggests that some conclusions might need to be nuanced. While the comment identifies a potential weakness in the experimental setup, it does not provide specific suggestions or guidance on how the authors might address this issue or expand their validation to other datasets. The feedback is somewhat helpful as it highlights an area for improvement but lacks actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alpha-divergence to provide insights into the effectiveness of their method. This feedback is explicit and provides a clear action for the authors to take, which is to include this additional information in their analysis. The comment is specific about what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including the gradient conflicts ratio for AlphaNets trained with alpha-divergence to provide insights into the effectiveness of the method. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include the gradient conflicts ratio for AlphaNets trained with alpha-divergence to provide insights into the effectiveness of their method. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this additional information is necessary or how it would benefit the analysis. Without such justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where additional information could be beneficial. It suggests that the authors should include the gradient conflicts ratio for AlphaNets trained with alpha-divergence to provide insights into the effectiveness of their method. This feedback is clear and actionable, as it directs the authors to include a specific piece of data that could enhance their analysis. However, the comment could be more helpful if it explained why this information is important or how it would contribute to the overall understanding of the results. Despite this, the feedback is mostly helpful as it provides a concrete suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the explicit SDF supervision in Section 3.2 and its connection to occlusion handling and view-aware reasoning. It suggests that the authors should provide a clearer explanation of why this supervision is necessary and how it relates to the color rendering process. The reviewer also proposes a simpler approach, suggesting that a subset of the sparse point cloud could be sampled without occlusion reasoning. The comment implies that a good reason or ablation study for this setup is missing, but it does not explicitly instruct the authors to include these elements. While the action is implicit, it is concrete in that it specifies what needs to be addressed and provides a suggestion for improvement. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 3.2\" and \"L. 165,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue by questioning the rationale behind the explicit SDF supervision and its connection to occlusion handling and view-aware reasoning. The comment suggests a simpler approach and implies the need for a good reason or ablation study. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the explicit SDF supervision in Section 3.2 and its connection to occlusion handling and view-aware reasoning. The reviewer questions the necessity of this supervision and suggests a simpler approach. However, the comment lacks specific examples or references to support the claim that the current setup is overly complicated or that the proposed simpler approach is more straightforward. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it provides a general critique but lacks the necessary justification for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the explicit SDF supervision in Section 3.2 and its connection to occlusion handling and view-aware reasoning. It questions the necessity of this supervision and suggests a simpler approach that could be considered. The reviewer also points out that the current setup is not well-explained and implies the need for a good reason or ablation study to justify the complexity. This feedback is clear and actionable, providing the authors with specific guidance on how to improve the clarity and rationale of their explanation. By offering a concrete suggestion and highlighting a gap in the explanation, the comment is highly helpful in guiding the authors towards a more comprehensive and understandable draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
