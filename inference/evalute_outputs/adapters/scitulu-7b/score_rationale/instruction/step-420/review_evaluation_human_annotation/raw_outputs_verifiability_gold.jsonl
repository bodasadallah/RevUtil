{"generated_text": "{'actionability_rationale': 'The review comment identifies two issues with the baseline models: the lack of comparison to Campos et al. (2020) and the absence of comparison with other domain adaptation methods. It explicitly states that the authors should compare their work with Campos et al. and provide a reference to the domain adaptation methods in Section 8. Additionally, it suggests that the authors should clarify the attribution of the results in Line 277. While the comment provides clear and explicit actions, it does not specify how to implement these comparisons or clarify the attribution. The authors know what needs to be done but may need to infer the exact steps to take. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison to Campos et al. (2020) and the absence of comparison with other domain adaptation methods. The comment provides a clear direction for improvement by suggesting the inclusion of these comparisons. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the baseline models are weak and suggests that the authors should compare their work with Campos et al. (2020) and other domain adaptation methods. While the comment identifies a potential issue with the baseline models, it lacks specific examples or references to Campos et al. or other domain adaptation methods to support the claim. This makes it somewhat verifiable, as the authors would need to infer the specific comparisons and references needed to address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the baseline models, noting that they are weak and suggesting that the authors should compare their work with Campos et al. (2020) and other domain adaptation methods. This feedback is clear and actionable, as it provides a concrete direction for improvement by suggesting specific comparisons that could strengthen the paper. Additionally, the comment highlights a potential oversight in the lack of comparison with other domain adaptation methods mentioned in Section 8. However, the comment could be more helpful if it provided examples of how these comparisons could be conducted or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should add information about the input being word embeddings, similar to the approach used by Lample et al. The reviewer also questions the KNs in Figure 3, asking about their language (either source or English). The authors are instructed to correct the figure. While the comment provides explicit actions to take, it does not specify how to implement these changes or what specific details should be included in the correction. The action is clear but lacks concrete guidance on execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be added (information about the input being word embeddings) and questions the KNs in Figure 3, asking about their language (source or English). This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and requests for clarification. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the authors use the Lample et al. Bi-LSTM-CRF model without mentioning that the input is word embeddings, similar to Lample et al. This is a clear and actionable feedback that prompts the authors to add this information to their work. Additionally, the comment raises a question about the KNs in Figure 3, asking about their language (source or English). While the comment provides valuable insights, it could be more helpful if it offered suggestions on how to address these issues or provided additional context. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement and clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from more in-depth analysis of its claims. However, it does not provide specific claims or examples from the paper that need further exploration, nor does it offer guidance on how to conduct this analysis. The action is implicit and vague, as the authors are left to infer what aspects of the paper need more depth. Without concrete details or suggestions, the authors are unable to determine exactly what changes are needed to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that a number of claims from the paper would benefit from more in-depth analysis, but it does not specify which claims or parts of the paper are being referred to. The authors cannot confidently determine which sections or claims need more analysis, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the claims need further exploration or how to conduct this analysis. Therefore, this comment is weakly grounded and not specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from more in-depth analysis of its claims. However, it does not provide specific examples or detailed reasoning to support this claim. Without specific claims or evidence, it is difficult for the authors to understand which claims need further analysis or how to improve them. The lack of specificity and supporting details makes the claim unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from more in-depth analysis of its claims. However, it does not provide specific claims or examples from the paper that need further exploration, nor does it offer guidance on how to conduct this analysis. Without actionable feedback or detailed suggestions, the authors are left with a general suggestion that lacks specificity and depth. This makes the comment barely helpful, as it provides some insight but not enough to guide the authors effectively in improving their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies two specific areas where the presentation of the model needs improvement: the pooling method used for embedding features and the clarity of Equation (7). It provides explicit questions about the pooling method and the definition of E_i in Equation (7), asking for clarification on whether it represents the type or identity of AC i. The reviewer also suggests that the LHS of Equation (7) should be a conditional probability. This feedback is clear and provides specific actions for the authors to take, such as clarifying the pooling method and the definition of E_i. The explicit nature of the questions and the concrete suggestions make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also provides specific details about what needs to be clarified, such as the pooling method used for embedding features and the definition of E_i in Equation (7). This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the clarity of the pooling method used for embedding features and the definition of E_i in Equation (7). It suggests that the LHS of Equation (7) should be a conditional probability. While the comment identifies specific areas that need clarification, it lacks detailed reasoning or references to support the claim that these elements are unclear or misleading. The authors would need to make a significant effort to understand and address the feedback, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas where the presentation of the model needs improvement, providing clear and actionable feedback. It points out that the pooling method used for embedding features is not clearly explained and suggests that the definition of E_i in Equation (7) is unclear. The reviewer also questions whether E_i represents the type or identity of AC i, which is an important distinction that needs clarification. Additionally, the comment suggests that the LHS of Equation (7) should be a conditional probability, which is a valuable suggestion for improving the clarity of the model presentation. This feedback is detailed and constructive, offering the authors specific steps to enhance the clarity and accuracy of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. While the comment implies that the authors should include such evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide empirical evidence to support their claim. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, it does not specify which part of the paper this claim is made in, nor does it provide detailed guidance on what kind of evidence would be sufficient. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its request for empirical evidence, but without full grounding, it is difficult for the authors to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is somewhat helpful as it identifies a specific area where the paper could be strengthened by providing empirical evidence. However, the comment lacks depth and does not provide detailed guidance on how to conduct such experiments or what specific evidence would be most relevant. While it points out a potential weakness, it does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment recommends additional analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also challenges the authors\\' viewpoint regarding the benefits of increased model capacity for both CNNs and ViTs. However, the comment does not provide specific guidance on what additional analysis or comments should be included, nor does it suggest how the authors should address the disagreement with their viewpoint. The action is implicit and somewhat vague, as the authors are left to infer what specific aspects need to be explored or how to address the critique. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the performance trending of increasing the number of parameters for ViT (DeiT) and challenges the authors\\' viewpoint regarding the benefits of increased model capacity. The comment suggests additional analysis and comments on the performance trending and provides specific examples of where the DeiT-B models do not outperform DeiT-T or DeiT-S. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the authors\\' claim that both CNNs and ViTs seem to benefit similarly from increased model capacity. It provides specific examples from Figure 3, where the DeiT-B models do not outperform DeiT-T or DeiT-S on multiple datasets. This supports the claim by providing concrete evidence from the figures, making the comment mostly verifiable. However, the comment could be strengthened by referencing specific experiments or analyses that support the authors\\' viewpoint, which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by recommending additional analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also challenges the authors\\' viewpoint regarding the benefits of increased model capacity, pointing out that the DeiT-B models do not outperform DeiT-T or DeiT-S on multiple datasets. This feedback is valuable as it encourages the authors to reconsider their claims and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on what additional analysis or comments should be included to support the authors\\' viewpoint. Overall, the comment is mostly helpful as it provides a clear direction for enhancing the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a limitation in the novelty of the proposed method, noting its similarity to other attentional modules in previous works. It specifically mentions the group attention design as being related to ResNeSt but not discussed in the paper. The comment implies that the authors should discuss the similarities and differences between their method and existing works, but it does not provide explicit instructions or concrete steps on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison or discussion of related works. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"group attention design\" and \"ResNeSt,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the similarity between the proposed method and other attentional modules in previous works, particularly ResNeSt. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. The reviewer supports this claim by referencing specific works, such as ResNeSt, and noting the absence of a discussion on the group attention design. However, the comment lacks detailed comparisons or specific examples from these works to fully substantiate the claim. While the references provide some context, the lack of detailed analysis or specific examples makes the claim somewhat verifiable, as the authors would need to conduct further research to fully understand the similarities and differences. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the novelty of the proposed method, noting its similarity to other attentional modules in previous works. It specifically mentions the group attention design as being related to ResNeSt but not discussed in the paper. This feedback is somewhat helpful as it points out a potential gap in the paper\\'s discussion of related work, which could impact the originality and impact of the proposed method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or differentiate their work from existing literature. To be more helpful, the comment could provide examples of how other works have addressed similar challenges or suggest ways to enhance the discussion of related work. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the required implicit call to the Witness oracle is confusing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific changes or clarifications to improve the clarity of the call. As a result, the authors are left without a clear understanding of what steps to take to improve the draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"Witness oracle,\" allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what is confusing about the implicit call to the Witness oracle, leaving the authors to infer the exact issue. The comment is specific in identifying the confusion but lacks detailed guidance on how to address it. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the required implicit call to the Witness oracle is confusing. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the confusion caused by the implicit call to the Witness oracle. However, it does not provide any guidance or suggestions on how the authors might clarify or improve this aspect of the paper. Without actionable feedback or detailed explanations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the authors for reproducing a well-known result about left political bias in ChatGPT and LLMs, noting that this observation has been made throughout the evolution of these models. The reviewer questions why the authors need to repeat this observation using their \"coarse\" methodology. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methodology. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the authors for reproducing a well-known result about left political bias in ChatGPT and LLMs, noting that this observation has been made throughout the evolution of these models. It specifically mentions the authors\\' \"coarse\" methodology of passing a binary stance classifier over ChatGPT\\'s output. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Additionally, while the comment highlights a specific issue with the methodology, it does not provide specific guidance on how to address this observation or improve the methodology. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point critiques the authors for reproducing a well-known result about left political bias in ChatGPT and LLMs, noting that this observation has been made throughout the evolution of these models. The reviewer questions why the authors need to repeat this observation using their \"coarse\" methodology, suggesting that it is unclear why this observation needs to be made again. However, the comment lacks specific examples or references to support the claim that this observation is already well-known or that the authors' methodology is unnecessary. Without detailed evidence or references, the claim remains somewhat verifiable, as it provides a logical argument but lacks sufficient justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the authors for reproducing a well-known result about left political bias in ChatGPT and LLMs, noting that this observation has been made throughout the evolution of these models. The reviewer questions why the authors need to repeat this observation using their \"coarse\" methodology, suggesting that it is unclear why this observation needs to be made again. While the comment identifies a potential weakness in the paper\\'s contribution, it lacks specific guidance or suggestions on how the authors might address this issue or improve their methodology. The feedback is somewhat helpful as it points out a potential gap in the paper\\'s originality, but it does not provide actionable advice for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It suggests that the authors should clarify when the proposed method is trained using weak supervision and when it is semi-supervised. The reviewer provides specific guidance by suggesting that the authors rename the column in Table 1 from \"Supervised\" to \"Fully Supervised\" and propose a better idea of specifying the data used to train each part of the model. This feedback is clear and actionable, as it directly instructs the authors on how to improve their draft by making the distinction between weak and semi-supervised training more explicit. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between weak supervision and semi-supervised training. The comment provides a detailed suggestion to rename the column in Table 1 and proposes a better way to specify the data used for training. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify the distinction between weak supervision and semi-supervised training, specifically in Table 1. The reviewer provides a specific example by suggesting that the column \"Supervised\" should be renamed to \"Fully Supervised\" to better reflect the distinction. The comment also proposes a more comprehensive approach by suggesting the addition of two columns, \"Mixture training data\" and \"Single source data,\" to clarify the data used for training. This provides a clear and actionable suggestion, supported by logical reasoning and specific examples. Therefore, the comment is mostly verifiable, as it offers a thorough and well-supported claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the authors clarify the distinction between weak supervision and semi-supervised training. It offers a specific example by proposing that the column \"Supervised\" in Table 1 should be renamed to \"Fully Supervised\" to better reflect the distinction. Additionally, the comment proposes a more comprehensive approach by suggesting the addition of two columns, \"Mixture training data\" and \"Single source data,\" to clarify the data used for training. This feedback is detailed and constructive, empowering the authors to make significant improvements to their draft by clarifying the training methods and providing a more transparent representation of their data. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies the main weakness of the paper as the lack of consideration of other datasets from the Federated learning benchmarks, specifically mentioning the datasets CIFAR-10 and LEAF. It suggests that the authors should consider relevant works such as FedProx and FedMAX for details on different datasets and model types. While the comment implies that the authors should expand their experimental evaluation, it does not provide explicit instructions on how to do so or which datasets to include. The action is implicit and somewhat vague, as the authors need to infer the specific steps to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the main weakness of the paper, which is the lack of consideration of other datasets from Federated learning benchmarks, and suggests that the authors should consider relevant works like FedProx and FedMAX. This provides clear guidance on what needs to be addressed in the experiments section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main weakness of the paper is the lack of consideration of other datasets from Federated learning benchmarks, specifically mentioning CIFAR-10 and LEAF. The reviewer suggests that the authors should consider relevant works like FedProx and FedMAX for details on different datasets and model types. This claim is somewhat verifiable as it provides a specific critique and suggests potential improvements, but it lacks detailed reasoning or references to fully substantiate the claim. The authors would need to conduct further research to understand the full implications of this critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the lack of consideration of other datasets from Federated learning benchmarks, such as CIFAR-10 and LEAF. It suggests that the authors should consider relevant works like FedProx and FedMAX for details on different datasets and model types. This feedback is clear and actionable, as it provides specific guidance on how the authors can enhance the comprehensiveness and relevance of their experimental evaluation. By addressing this feedback, the authors can significantly improve the rigor and impact of their work. However, the comment could be more helpful if it offered additional suggestions on how to incorporate these datasets or provided examples of how other studies have addressed this issue. Overall, the comment is mostly helpful as it effectively directs the authors toward a meaningful enhancement of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use a more convincing setting when training their model, similar to what was done in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification. It provides a specific reference to a related work, He et al. (EMNLP 2018), which directly samples unlabeled data from millions of reviews. While the comment implies that the authors should adopt this approach, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors need to infer the exact steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of unbalanced data in the preprocessed Amazon review dataset, specifically mentioning the unlabeled data (2000) and the impracticality of balanced data in real-world applications. It suggests that the authors should use a more convincing setting, similar to what was done in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification. However, the comment does not specify which part of the paper discusses the dataset or the issue of unbalanced data. While the authors can infer that it relates to the dataset section, the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting a solution, providing a reference to a specific work, which helps guide the authors on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the unlabeled data from the preprocessed Amazon review dataset is perfectly balanced, which is impractical in real-world applications. The reviewer suggests that the authors should use a more convincing setting, similar to what was done in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification. The comment provides a specific reference to a related work, He et al. (EMNLP 2018), which directly samples unlabeled data from millions of reviews. This reference provides a clear rationale for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by including more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific issue with the dataset used in the paper, noting that the unlabeled data from the preprocessed Amazon review dataset is perfectly balanced, which is impractical in real-world applications. It suggests that the authors should use a more convincing setting, similar to what was done in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification. The comment provides a specific reference to a related work, He et al. (EMNLP 2018), which directly samples unlabeled data from millions of reviews. This feedback is clear and actionable, as it points out a potential weakness in the dataset and offers a concrete suggestion for improvement. However, it could be more helpful if it provided additional guidance on how to implement the suggested setting or explained why it is more convincing. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement and offers a clear path forward.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out confusion in the description of the MFDA setting, specifically regarding the notation for target domain \\u03c4 and the use of sparse labels. It questions whether unlabeled data in source domains are used during training, similar to the original MFDA paper. The comment implies that the authors should clarify this confusion in their description, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the notation and the use of unlabeled data. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first paragraph of the Method Section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the notation for target domain \\u03c4 and the use of sparse labels, as well as the question about the use of unlabeled data in source domains. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the description of the MFDA setting, specifically regarding the notation for target domain \\u03c4 and the use of sparse labels. The reviewer questions whether unlabeled data in source domains are used during training, similar to the original MFDA paper. The comment is somewhat verifiable as it provides a specific example of confusion in the description and seeks clarification on a particular aspect of the methodology. However, it lacks detailed reasoning or references to support the claim that the description is confusing or misleading. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the description of the MFDA setting, particularly regarding the notation for target domain \\u03c4 and the use of sparse labels. It questions whether unlabeled data in source domains are used during training, similar to the original MFDA paper, and points out that the problem setting description is confusing and defers significantly. This feedback is clear and actionable, as it highlights a critical area for improvement in the paper\\'s presentation and methodology. By addressing these points, the authors can enhance the clarity and coherence of their work, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the immense workload, the incremental contribution, and the lack of citation of key baselines. It also points out that the paper focuses on RAG for EHR and suggests that essential RAG algorithms, such as MedRetriever and KGRAG, should be introduced. While the comment provides specific suggestions for improvement, it lacks explicit instructions on how to implement these changes. The authors are given a clear idea of what needs to be addressed, but the action is implicit and somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"details in the article\" and \"your workload is immense,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by pointing out that the contribution is incremental and that the paper essentially combines GraphRAG and GraphCare. Additionally, it suggests that key baselines were not cited and that essential RAG algorithms, such as MedRetriever and KGRAG, should be introduced. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is incremental and essentially a combination of GraphRAG and GraphCare, referencing the combination of these two approaches. It also notes that key baselines were not cited and suggests that essential RAG algorithms, such as MedRetriever and KGRAG, should be introduced. The comment provides some justification by referencing specific works, which helps to substantiate the claim. However, it could be strengthened by providing more detailed reasoning or examples of how these algorithms would enhance the paper. Overall, the claim is mostly verifiable, as it provides a logical basis but lacks complete evidence or detailed justification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the immense workload and the incremental nature of the contribution. It points out that the paper essentially combines GraphRAG and GraphCare, which is not a significant contribution. Additionally, it notes that key baselines were not cited and suggests that essential RAG algorithms, such as MedRetriever and KGRAG, should be introduced. These suggestions provide clear and actionable feedback for the authors to improve their draft. However, the comment could be more helpful by offering specific guidance on how to address these issues, such as suggesting which algorithms to include or how to better justify the contribution. Overall, the comment is mostly helpful as it highlights areas for improvement but lacks detailed guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific omission in the experiment of face recognition, noting the absence of certain state-of-the-art references, such as Baidu\\'s work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\" and its reported results. It also highlights the use of the triplet loss in that work and its performance on a similar dataset. While the comment explicitly identifies the missing references and suggests that the authors should include them, it does not provide specific guidance on how to integrate these references into the paper or how to improve upon the existing results. The action is clear but lacks detailed instructions on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experiment of face recognition\" and \"the state-of-the-art references,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the references to Baidu\\'s work and the triplet loss used in that work. The comment provides a clear direction for improvement by suggesting the inclusion of these references, which are relevant to the experiment. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some state-of-the-art references are missing in the experiment of face recognition, specifically mentioning Baidu\\'s work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\" and its reported results. The reviewer provides a specific reference to the work and its results, which is a clear and robust justification for the claim. This level of detail and specificity makes the claim fully verifiable, as it provides the authors with a clear direction for improvement by suggesting the inclusion of relevant references. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, noting the absence of certain state-of-the-art references, such as Baidu\\'s work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding.\" It also highlights the use of the triplet loss in that work and its reported results, which are relevant to the experiment. This feedback is clear and actionable, as it directs the authors to include these references and potentially improve upon the existing results. However, the comment could be more helpful if it provided suggestions on how to integrate these references into the paper or how to build upon the existing work. Overall, the comment is mostly helpful, as it effectively points out a gap in the literature review and offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to cite the source of the rock-paper-scissors example, which is clearly inspired by a previous work. This is a direct and concrete action, as it specifies the exact requirement for proper attribution. The authors know exactly what needs to be done to address the comment, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"rock-paper-scissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to cite the source of the example. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the rock-paper-scissors example is \"clearly inspired by an example that appeared in many previous works,\" suggesting that the authors should cite the source appropriately. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the rock-paper-scissors example, noting that it is clearly inspired by a previous work. It explicitly instructs the authors to cite the source appropriately, which is a clear and actionable suggestion. This feedback is valuable as it helps the authors ensure proper attribution and avoid plagiarism, improving the originality and credibility of their work. However, the comment could be more helpful if it provided additional context or examples of similar instances in previous work. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and offers a clear action to improve the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific sentence (L.490) and suggests that it might be clearer if it mentioned averaging over subword representations, as it is common practice. The reviewer provides a specific example of where this practice is used, referencing a specific paper. While the comment implies that the authors should consider including this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information but are not given explicit guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a suggestion to clarify the embedding process by mentioning the common practice of averaging over subword representations, as demonstrated in the reference to [Hewitt and Manning (2019, footnote 4)](https://aclanthology.org/N19-1419.pdf). This feedback is clear and provides a concrete action for the authors to take, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the sentence \"we take the embedding of the first subword token as the verb embedding\" might be clearer if it mentioned averaging over subword representations, as it is a common practice. The reviewer provides a specific example by referencing [Hewitt and Manning (2019, footnote 4)](https://aclanthology.org/N19-1419.pdf). This reference provides a logical basis for the suggestion, making the claim mostly verifiable. The authors can understand the need for clarification and the potential improvement, but the comment could be strengthened with more detailed reasoning or examples. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific sentence in the paper that might be unclear and suggests a potential clarification by mentioning the common practice of averaging over subword representations. It provides a specific example by referencing [Hewitt and Manning (2019, footnote 4)](https://aclanthology.org/N19-1419.pdf), which is helpful in guiding the authors toward a clearer explanation of their methodology. However, the comment could be more helpful if it offered additional suggestions or examples on how to incorporate this clarification into the paper. Overall, the comment is mostly helpful as it provides actionable feedback on a specific area of the paper, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatch and cross-domain imitation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the experiments, what specific aspects need further exploration, or how to address the identified challenges. As a result, the authors are left without any clear direction on how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatch and cross-domain imitation. However, it does not specify which part of the paper these experiments are discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in detailing the experiments conducted, but it lacks grounding as it does not specify where in the paper this information is presented. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatch and cross-domain imitation. However, it does not provide any specific claims, opinions, or suggestions for improvement. It simply describes the experiments without offering any analysis, reasoning, or evidence to support or challenge the findings. As a result, the comment lacks verifiability and is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatch and cross-domain imitation. However, it does not provide any specific feedback or suggestions for improvement. It lacks actionable guidance or constructive criticism that could help the authors enhance their work. Without detailed feedback or constructive suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the common use of bounded noise assumptions in stochastic optimization literature but questions their restrictiveness. It suggests that the authors should consider extending these noise conditions, citing specific references to recent works that have explored this topic. While the comment provides a direction for improvement, it does not explicitly instruct the authors to adopt these references or suggest specific ways to extend the noise conditions. The action is implicit and somewhat vague, as the authors need to infer the need for extension and determine how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the bounded noise assumption in the context of stochastic optimization literature, specifically mentioning that it is common but somewhat restrictive. It suggests that there have been efforts to extend these noise conditions, providing specific references to recent works. However, the comment does not specify which part of the paper discusses the bounded noise assumption, making it weakly grounded. The references provided are specific, which helps the authors understand the need for addressing this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the common use of bounded noise assumptions in stochastic optimization literature but questions their restrictiveness. It suggests that there have been efforts to extend these noise conditions, providing specific references to recent works. This provides a logical basis for the claim that the bounded noise assumption may be restrictive, but it lacks detailed justification or examples to fully substantiate the claim. The references provided are helpful in supporting the claim, but the comment could be strengthened with more detailed reasoning or examples. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the common use of bounded noise assumptions in stochastic optimization literature but questions their restrictiveness. It suggests that there have been efforts to extend these noise conditions, providing specific references to recent works that explore this topic. This feedback is valuable as it highlights a potential area for improvement in the paper, encouraging the authors to consider extending their noise conditions. However, the comment could be more helpful if it provided more detailed guidance on how to incorporate these references or how to address the restrictiveness of the bounded noise assumption. Overall, the comment is mostly helpful as it identifies a relevant area for improvement and offers specific references, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison. It does not provide any explicit or implicit actions for the authors to take, nor does it suggest any improvements or changes to the draft. The authors are left without any guidance on how to address this issue or what steps to take to clarify the meaning of \"100 steps.\" Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"100 steps\" in the context of search models comparison, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the meaning of \"100 steps\" in the context of search models comparison. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"100 steps\" in the context of search models comparison, specifically in section 5.1. This question highlights a potential area of confusion or ambiguity in the paper, which could be clarified to enhance the reader\\'s understanding. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of the section. While it identifies a potential area for improvement, it does not offer actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors discuss the reason why the proposed algorithm, DMLCBO, does not achieve the same convergence rate as previous works that used the double momentum technique, such as SUSTAIN[1] and MRBO[2]. It also encourages the authors to explore the theoretical technique differences between DMLCBO and these works. This feedback provides clear and concrete actions for the authors to take, including identifying the reason for the discrepancy and exploring the theoretical differences between their work and others. The explicit nature of the suggestion and the specific references to previous works make it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed algorithm, DMLCBO, and references specific works, SUSTAIN[1] and MRBO[2], which used the double momentum technique. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the reason why DMLCBO does not achieve the same convergence rate as previous works and the theoretical technique differences between DMLCBO and these works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed algorithm, DMLCBO, does not achieve the same convergence rate as previous works that used the double momentum technique, such as SUSTAIN[1] and MRBO[2]. The reviewer supports this claim by referencing these specific works, providing a basis for comparison. However, the comment could be strengthened by offering more detailed analysis or examples of how the double momentum technique improves convergence rates in these works. Despite this, the claim is mostly verifiable due to the reference to specific works and the suggestion for further exploration.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the proposed algorithm, DMLCBO, which is based on the double momentum technique. It points out that previous works, such as SUSTAIN[1] and MRBO[2], have achieved a convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$ using this technique, while DMLCBO only achieves $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-4})$. The comment encourages the authors to discuss the reason for this discrepancy and explore the theoretical differences between DMLCBO and the aforementioned works. This feedback is clear and actionable, providing the authors with a specific area to focus on and a direction for further exploration. By addressing these points, the authors can enhance the understanding and robustness of their algorithm. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the modulator is heuristically designed and questions the scalability issue that might require tedious hyperparameter tuning for diverse training data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the scalability issue or suggestions for improving the modulator design. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of scalability in the modulator design, specifically questioning whether there is a scalability issue that might require tedious hyperparameter tuning for diverse training data. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the scalability issue and the potential need for hyperparameter tuning, but without explicit references to specific sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the scalability of the modulator design and whether it requires tedious hyperparameter tuning for diverse training data. However, it lacks specific examples or detailed reasoning to support this claim. The comment does not provide evidence or references to substantiate the concern, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not offer sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the scalability of the modulator design, questioning whether there is a scalability issue that might require tedious hyperparameter tuning for diverse training data. While it points out a potential concern, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue. The comment highlights a potential weakness but does not offer detailed feedback or constructive advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is barely helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should mention the recent work on untrained NNs for inverse problems, specifically mentioning a paper by Ulyanov et al. (CVPR 2018). It also suggests placing the current method in context and potentially comparing it with these methods. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the exact details of how to incorporate this information into their paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"OOD experiments\" and the \"untrained NNs\" used for inverse problems, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely mentioning the recent work on untrained NNs and placing the current method in context. Additionally, it suggests comparing the current method with those class of methods. This provides clear guidance on how to enhance the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors mention recent work on untrained NNs for inverse problems, specifically mentioning a paper by Ulyanov et al. (CVPR 2018). The comment also suggests placing the current method in context and potentially comparing it with those class of methods. While the comment provides a reference to a specific paper, it lacks detailed reasoning or examples to fully substantiate the claim that the current method should be compared with these methods. The suggestion is somewhat verifiable, as it provides a starting point for the authors to explore, but more detailed justification or examples would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive suggestion by pointing out that the authors should mention recent work on untrained NNs for inverse problems, specifically referencing a paper by Ulyanov et al. (CVPR 2018). It also suggests placing the current method in context and potentially comparing it with other methods in this class. This feedback is actionable and offers a clear direction for the authors to enhance their paper by incorporating relevant references and comparisons. By doing so, the authors can strengthen the context and depth of their work. However, the comment could be more helpful if it provided specific guidance on how to integrate these comparisons into the paper. Overall, the comment is mostly helpful as it offers valuable suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the clarity of the first two sections of the paper, particularly regarding the explanation of previous approaches. It provides examples of unclear explanations, such as the stacked LSTM in Fig 2(a) and the sentence in line 96. The comment explicitly asks for clarification on these points, providing concrete guidance on what needs to be improved. This level of detail and specificity makes the comment highly actionable, as the authors know exactly what parts of the paper need to be clarified and how to address the issues. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the clarity of the explanations, providing examples of unclear statements and asking for clarification. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5. Therefore, the comment is labeled as 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of the first two sections of the paper, specifically questioning the explanation of previous approaches. The reviewer provides examples of unclear statements, such as \"trivial\" in the context of Fig 2(a) and \"our lower hierarchical layers zoom in time\" in line 96. These examples are specific and provide a clear rationale for the claim, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed explanations or references to support the critique. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the clarity and comprehensibility of the first two sections of the paper, particularly regarding the explanation of previous approaches. It provides examples of unclear statements and requests for clarification, which are actionable suggestions for improvement. By highlighting these areas, the comment helps the authors understand where their draft needs further development and provides a clear direction for enhancing the clarity and accessibility of their work. However, the comment could be more helpful if it offered suggestions on how to improve the explanations or provided additional examples. Overall, the comment is mostly helpful as it directs the authors to specific areas needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the goal of the paper, specifically noting the absence of a comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and the lack of justification for the benefits of the proposed method. It suggests that if the claim is to establish the paper as a foundation model, the authors should clarify this and provide evidence or justification for its usefulness. While the comment implies that the authors should provide a comparison or justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison or justification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first concern,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of a comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and the lack of justification for the benefits of the proposed method against these existing methods. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the goal of the paper, specifically noting the absence of a comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and the lack of justification for the benefits of the proposed method against these existing methods. The reviewer suggests that if the claim is to establish the paper as a foundation model, the authors should clarify this and provide evidence or justification for its usefulness. This feedback is somewhat verifiable as it highlights a gap in the paper\\'s justification and suggests a direction for improvement. However, it lacks specific examples or references to support the claim, which would make it more fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the goal of the paper, noting the absence of a comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and the lack of justification for the benefits of the proposed method against these existing methods. It suggests that if the paper\\'s claim is to establish a foundation model, the authors should clarify this and provide evidence or justification for its usefulness. This feedback is clear and actionable, as it directs the authors to address a critical gap in their work by providing a comparison or justification for their method. However, the comment could be more helpful if it offered specific suggestions on how to conduct this comparison or what aspects to focus on. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that similar analyses have been conducted in prior works, specifically mentioning the robustness of CIFAR-10 models on distribution shifts. It references specific works that have previously explored these topics, such as RobustBench and [A, B]. The comment suggests that the current work may not provide novel insights or results, as the analyses are already present in prior works. However, it does not provide explicit guidance or suggestions on how the authors could address this issue or improve their work. The action is implicit and vague, leaving the authors without clear direction on how to respond to the critique. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific analyses and prior works, such as RobustBench and [A, B], allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that similar analyses have been conducted in prior works, which may not provide novel insights or results. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that similar analyses have been conducted in prior works, specifically mentioning the robustness of CIFAR-10 models on distribution shifts. It references specific works, such as RobustBench and [A, B], which have explored these topics. The comment also mentions that the results are not particularly surprising, as they align with previous findings. This provides a logical reasoning and references to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or specific examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty and impact of the current work, noting that similar analyses have been conducted in prior works. It specifically references specific studies, such as RobustBench and [A, B], which have explored similar topics. The comment highlights that the results may not be particularly surprising, as they align with previous findings. While the comment points out a potential weakness, it does not provide specific suggestions or guidance on how the authors could address this issue or enhance the novelty of their work. The feedback is somewhat helpful as it alerts the authors to a potential problem but lacks actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: first, that the claim about \"simple SGD for decentralized optimization\" is inaccurate, as the Walkman algorithm uses ADMM with two versions; and second, that the phrase \"it can often have faster convergence and better generalization\" lacks a clear reference. While the first point is explicit in its critique, the second point is implicit in its suggestion for clarification. Both points are somewhat actionable, as the authors need to revise the claims to be more accurate and provide a clear reference for the second point. However, the feedback is vague in terms of how to address the issue, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the inaccuracy of the claim about \"simple SGD for decentralized optimization\" and points out the use of ADMM in the Walkman algorithm. Additionally, it suggests clarifying the reference to \"it\" in Section 3. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim about \"simple SGD for decentralized optimization\" by pointing out that the Walkman algorithm uses ADMM with two versions, which is not accurate. The reviewer provides a logical reasoning by explaining that the Walkman algorithm is not based on simple SGD but rather ADMM. This makes the claim unverifiable, as it lacks supporting evidence or references to substantiate the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: first, it challenges the accuracy of a claim about \"simple SGD for decentralized optimization\" by pointing out that the Walkman algorithm uses ADMM with two versions; and second, it notes that the phrase \"it can often have faster convergence and better generalization\" lacks a clear reference. These points are clear and actionable, as they provide the authors with specific areas to revise and improve their draft. The feedback is detailed and constructive, offering the authors a clear path to enhance the accuracy and clarity of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. While it implies that the authors should expand their experimental section, it does not provide specific guidance on which additional baselines or comparisons to include. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or a particular table or figure. The authors can infer that it relates to the experimental section, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting the need for additional comparisons, but without explicit references to the experimental section or specific baselines, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. However, it does not provide specific references to external works or studies that have addressed similar questions, making it difficult for the authors to understand the relevance of these comparisons. The comment lacks detailed reasoning or examples to support the claim, leaving it somewhat verifiable. The authors would need to infer the importance of the additional comparisons and potentially conduct their own research to understand the relevance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experimental section, suggesting that the authors should include more experimental comparisons to demonstrate the effectiveness of their proposed method. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\\'s experimental analysis. However, the comment could be more helpful if it mentioned specific baselines or comparisons that the authors should consider, which would provide even more detailed guidance. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the filtering process used to create the Arabic climate change QA dataset is lacking and that more information on the translation and filtering methodology is needed to assess the dataset quality. This provides a clear and direct action for the authors to take, which is to provide additional details on the filtering process. The comment is specific about what information is missing and how it could be improved, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Arabic climate change QA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is lacking\u2014details on the filtering process used to create the dataset\u2014and what needs to be addressed, such as more information on the translation and filtering methodology. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"details around the filtering process used to create the Arabic climate change QA dataset are lacking,\" suggesting that more information is needed on the translation and filtering methodology. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of detailed reasoning or evidence makes the claim borderline verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, namely the details on the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to provide additional details that could enhance the transparency and credibility of their work. However, the comment could be more helpful if it offered suggestions on how to improve the filtering process or what specific details should be included. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, particularly regarding long-context language models. It specifies that this should include discussions on sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods for handling very long documents. This feedback is clear and provides concrete actions for the authors to take, such as including these topics in the Related Work section. The comment is highly actionable as it directly guides the authors on how to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Related Work section\" and the specific paragraph on long-context language models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more comprehensive overview of existing methods and their limitations, including discussions on sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods for handling very long documents. This provides clear guidance on what needs to be improved in the Related Work section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Related Work section is lacking details, specifically mentioning the need for a more comprehensive overview of existing methods and their limitations. The comment provides a specific example of the long-context language models, suggesting that the authors should discuss sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods for handling very long documents. This provides a clear and detailed justification for the claim, making it mostly verifiable. However, the comment could be further strengthened by referencing specific works or studies that support the need for these discussions. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the Related Work section, particularly regarding the lack of comprehensive details on existing methods and their limitations. It suggests that the authors should provide a more detailed overview of existing approaches, including sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods for handling very long documents. This feedback is clear and constructive, guiding the authors on how to improve their draft by enhancing the context and depth of their Related Work section. By addressing these points, the authors can significantly enhance the comprehensiveness and relevance of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the writing should be improved and mentions that some points in the paper are unclear. However, it does not provide specific examples or details about what aspects of the writing are unclear or how they could be improved. The feedback lacks concrete guidance on how to address the issues, leaving the authors without a clear understanding of what changes are needed to improve the clarity of their draft. As a result, the comment is vague and lacks actionable details, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the writing should be improved and that some points in the paper are unclear, but it does not specify which parts of the paper are unclear or where the writing needs improvement. Without explicit references to specific sections or examples, the authors cannot confidently determine which parts of the paper need attention. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing should be improved and that some points in the paper are unclear. However, it does not provide specific examples or detailed reasoning to support these claims. Without specific references or detailed explanations, the authors may find it challenging to understand which parts of the paper are unclear or how to improve the writing. This lack of specificity and supporting evidence makes the claim unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a general issue with the writing, stating that it should be improved. However, it does not provide specific examples or details about what aspects of the writing are unclear or how they could be improved. Without this level of detail, the authors are left without actionable feedback on how to enhance their draft. The comment lacks depth and specificity, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the synthetic experiment in a non-separable case and questions how the data distribution illustrated in Figure 1 can be inseparable from the network model, given the nonlinear expression ability of neural networks. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or what specific steps they should take to clarify the issue. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the synthetic experiment in a non-separable case and questions the inseparability of the data distribution illustrated in Figure 1 from the network model, given the nonlinear expression ability of neural networks. However, it does not specify which part of the paper this concern is related to, such as the synthetic experiment or the Figure 1 discussion. The authors can infer that it relates to the experimental setup or the data analysis, but this inference is not direct. The comment is specific in questioning the inseparability but lacks full grounding as it does not explicitly mention the section or figure in question. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the validity of the synthetic experiment in a non-separable case, specifically questioning how the data distribution illustrated in Figure 1 can be inseparable from the network model, given the nonlinear expression ability of neural networks. However, the comment lacks specific examples or detailed reasoning to support the claim that the experiment is problematic. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides a logical basis for the question but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the synthetic experiment in a non-separable case, questioning the inseparability of the data distribution illustrated in Figure 1 from the network model, given the nonlinear expression ability of neural networks. This is a valid point that could lead to a deeper understanding of the experiment's limitations and potential sources of error. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or improve the experiment. It does not provide actionable feedback or detailed advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is somewhat helpful, as it identifies a potential issue but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the efficiency of their pairwise matching. There is no guidance on potential solutions, alternative approaches, or specific actions to take. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the efficiency of pairwise matching, specifically mentioning that it is very low and difficult to use in practical application systems. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the problem with the pairwise matching efficiency, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the efficiency of pairwise matching, noting that it is very low and difficult to use in practical application systems. This feedback highlights a potential weakness in the paper that could impact its practical applicability. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the efficiency of their pairwise matching. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but without clear steps to improve their draft. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that adding a method to improve transferability is a positive step but not a significant contribution. However, it does not provide any explicit guidance or suggestions on how the authors might improve the transferability or what specific steps they should take to make it more significant. The comment lacks concrete details or actionable advice, leaving the authors uncertain about how to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that adding a method to improve transferability is a positive step but not a significant contribution. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section, method, or result. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in its suggestion that adding a method is not a significant contribution, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that adding a method to improve transferability is a positive step but not a significant contribution. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition is not significant. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that adding a method to improve transferability is a positive step but not a significant contribution. However, it does not provide any specific guidance or suggestions on how the authors might improve the transferability or what aspects of the method need attention. Without actionable feedback or detailed reasoning, the comment lacks depth and does not assist the authors in enhancing their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take. It suggests toning down the statement about the neural network memorizing critical points, as it is not accurate according to the reviewer's understanding. Additionally, it advises the authors to compress the method section, particularly on essential definitions, and to double-check for grammatical errors, focusing on plurals and articles. These are clear and concrete actions that the authors can take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sentence \"to force the neural network to memorize them,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be toned down and suggests compressing the method section. Additionally, it points out specific grammatical errors and requests a double-check for plurals and articles. This level of detail provides the authors with clear instructions on how to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a critique of a specific statement in the paper and a suggestion for improvement. The claim that the neural network does not memorize exact \"critical points\" as in TopoNet is supported by the reviewer\\'s understanding, which is based on their knowledge of the field. However, the suggestion to tone down the statement is not further elaborated or substantiated with references or examples. The feedback on the method section being wordy and needing compression is also somewhat vague, as it does not specify which definitions or sections are too detailed. The grammatical errors mentioned are identified, but the comment lacks detailed guidance on how to address them. Overall, the claim is somewhat verifiable, as it provides some justification but lacks specific examples or detailed guidance.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several pieces of constructive feedback that can help the authors improve their draft. First, it suggests toning down a specific statement about the neural network memorizing critical points, which is not accurate according to the reviewer\\'s understanding. This feedback is clear and actionable, as it directs the authors to revise their language to avoid misleading claims. Second, the comment suggests compressing the method section, particularly on essential definitions, which can help streamline the paper and make it more concise. This suggestion is also actionable and can improve the clarity of the paper. Finally, the comment points out several grammatical errors, such as plurals and articles, which are important to correct for clarity and professionalism. Overall, the feedback is mostly helpful as it identifies specific areas for improvement and provides actionable guidance. However, it could be more helpful if it offered suggestions on how to compress the method section or provided examples of how to improve the clarity of the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the overemphasis on the comparison with Megatron and suggests that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It also questions the claim of COCO-LM being parameter-efficient, suggesting that the conclusion might apply to these other works as well. The comment provides a specific question about the authors\\' experimental setup, asking why they switched from uncased to cased BPE vocabulary and whether this change affects performance variance. While the comment identifies areas for improvement and questions that need clarification, it does not explicitly instruct the authors on how to address these issues. The actions are implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison with Megatron, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the overemphasis on the comparison with Megatron and suggests that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The comment further questions the claim of COCO-LM being parameter-efficient and raises a specific question about the experimental setup, asking why the authors switched from uncased to cased BPE vocabulary. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the overemphasis on the comparison with Megatron and suggests that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The comment also questions the claim of COCO-LM being parameter-efficient, suggesting that the conclusion might apply to these other works as well. The reviewer provides a logical reasoning by comparing the performance of COCO-LM with other models of similar size, which supports the claim that the overemphasis on Megatron might be misplaced. However, the comment lacks specific references or detailed comparisons to substantiate the claim fully. Therefore, the comment is somewhat verifiable, as it provides a logical argument but requires more detailed evidence or references to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a critical analysis of the comparison with Megatron, suggesting that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar size. This feedback highlights an overemphasis on the comparison with Megatron and questions the claim of COCO-LM being parameter-efficient. The comment also raises a specific question about the experimental setup, asking why the authors switched from uncased to cased BPE vocabulary and whether this change affects performance variance. This feedback is mostly helpful as it identifies areas for improvement and provides a clear direction for the authors to address. However, it could be more helpful if it offered suggestions on how to address the issues raised or provided additional context on the implications of the changes in the experimental setup. Overall, the comment is mostly helpful as it guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the analysis from line 128 to 149, noting that the histogram in Figure 3 suggests that the GS-P-50 model has a smaller class selectivity score, which may indicate that it shares more features with ResNet-50. The reviewer questions the authors\\' hypothesis that additional context may allow the network to reduce its dependency. The comment references two external works, [1] and [2], which could be used to provide additional context or evidence to support the authors\\' claims. However, the comment does not explicitly instruct the authors to use these references or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should use these references to support their analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 128 to 149\" and \"Fig 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the analysis, noting that the histogram in Figure 3 suggests that the GS-P-50 model has a smaller class selectivity score, which may indicate that it shares more features with ResNet-50. The comment further questions the authors\\' hypothesis about additional context and references two external works to provide context. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the analysis from line 128 to 149, specifically regarding the class selectivity score of the GS-P-50 model compared to ResNet-50. The reviewer references external works, [1] and [2], to provide context and support their claim. These references are relevant and provide a basis for the critique, making the claim mostly verifiable. However, the comment could be strengthened by further explaining why the class selectivity score is important or how it relates to the authors\\' hypothesis about additional context. Overall, the claim is supported by logical reasoning and references, but could be more fully developed to achieve a higher verifiability score.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the analysis presented in the paper, particularly regarding the class selectivity score of the GS-P-50 model compared to ResNet-50. The reviewer questions the authors\\' hypothesis that additional context may allow the network to reduce its dependency, and references two external works to provide context and support their claim. This feedback is somewhat helpful as it points out a potential weakness in the analysis and suggests a direction for further exploration. However, it could be more helpful if it provided more detailed guidance on how the authors might address this issue or what specific aspects of the analysis need improvement. Overall, the comment offers some insight but lacks depth and actionable suggestions, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of convincing evidence in the paper's conclusions, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer suggests that the results might be due to limited exploration of combination methods and points to recent works that have demonstrated the potential of feature-replay methods in continual learning. While the comment provides a specific area for improvement by suggesting the exploration of combination methods, it does not offer concrete guidance on how to implement this suggestion or what specific combination methods should be considered. The action is implicit and somewhat vague, as the authors need to infer the need for exploring combination methods and determine which methods to use. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific conclusion about continuous learning with unlabeled data and the claim that it accumulates noise, which is detrimental to representation quality. It also references specific works, such as [R1], [R2], and [R3], to support the claim. This provides clear guidance on what part of the paper is being addressed and what needs to be addressed. The comment is specific because it details the issue with the conclusions, suggesting that the results might be due to limited exploration of combination methods and points to recent works that have demonstrated the potential of feature-replay methods in continual learning. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the conclusions in the paper are not convincing, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer supports this claim by referencing recent works, such as [R1], [R2], and [R3], which have demonstrated the potential of feature-replay methods in continual learning and CCD. These references provide a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed explanations or comparisons between the results in the paper and those from the referenced works. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the paper\\'s conclusions, specifically the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer provides a rationale for this claim by suggesting that the results might be due to the limited exploration of combination methods, referencing recent works that have demonstrated the potential of feature-replay methods in continual learning and CCD. This feedback is clear and actionable, as it points out a potential weakness in the paper\\'s conclusions and suggests a direction for improvement by encouraging the authors to explore combination methods. However, the comment could be more helpful if it provided specific suggestions on which combination methods to consider or how to effectively integrate them into the paper. Overall, the comment is mostly helpful as it directs the authors toward a meaningful area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent, which implies that the authors should consider this aspect when presenting their work. However, it does not provide specific guidance on how to address this issue or what aspects of the observations or design decisions are dependent on hardware and software. The comment lacks concrete details on how the authors should proceed, leaving them uncertain about the exact steps to take. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which part of the paper this pertains to. The authors cannot confidently determine the exact section or sections that need attention, making the comment weakly grounded. The comment is specific in identifying the potential hardware and software dependencies, but without clear grounding, it lacks actionable guidance. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, suggesting that some observations and design decisions might be hardware and software dependent. While this is an important consideration, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or what aspects of the paper might be affected. Without further details or suggestions, the authors are left without a clear path forward, making the feedback barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of novelty in the paper, specifically noting that it is a straightforward application of existing literature, such as DeCorr, in a specific application domain. It also points out that the contribution of the study is mainly the transposition of DeCorr's insights into graph collaborative filtering. While the comment acknowledges some modifications, such as different penalty coefficients for users and items, it does not provide specific guidance on how the authors could address the issue of overcorrelation in recommender systems or what unique challenges they should focus on. The feedback lacks actionable details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper, specifically noting that it is a straightforward application of existing literature, such as DeCorr, in a specific application domain. It also points out that the contribution of the study is mainly the transposition of DeCorr's insights into graph collaborative filtering. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the introduction or the application of existing methods. The comment is specific in detailing what is lacking, namely insights about unique challenges of overcorrelation in recommender systems. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks novelty and is a straightforward application of existing literature, specifically DeCorr. The reviewer supports this claim by noting that the contribution of the study is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment does not provide specific examples or references to DeCorr or other relevant works to substantiate the claim. While the critique is logical, the lack of detailed evidence or references makes it somewhat verifiable, as the authors would need to infer the basis of the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that it lacks novelty and is a straightforward application of existing literature, specifically DeCorr. The reviewer highlights that the contribution of the study is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment acknowledges some modifications, such as different penalty coefficients for users and items, but does not provide specific guidance or suggestions on how the authors could enhance the novelty or depth of their work. While it points out a weakness, the feedback lacks actionable advice or detailed critiques that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not offer comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a discrepancy between the description in Section 4.2 and the equation presented, specifically regarding the question representation and the use of r^q. It suggests clarifying the question representation and providing more information on what \\sigma means in the equation. Additionally, it raises a concern about the stability of the computation involving two sigmoid activations. The comment is explicit in its request for clarification and provides specific guidance on what needs to be addressed. However, it does not offer detailed instructions on how to clarify the discrepancy or address the concern about numerical stability. While the action is clear, the comment could be more helpful with additional details on how to implement the suggested clarifications. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the equation, pointing out the lack of a term for r^q, which is the question representation, and questioning the meaning of \\sigma. The comment also raises a concern about the stability of the computation involving two sigmoid activations. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the question representation in Section 4.2, specifically mentioning the absence of a term for r^q, which is the question representation. It also questions the meaning of \\sigma in the equation and suggests that multiplying two sigmoid activations might be ill-conditioned and numerically unstable. The comment provides a logical reasoning by pointing out the discrepancy between the description and the equation, which could be improved by clarifying the question representation. However, it lacks specific examples or references to support the claim about numerical stability. Therefore, the comment is somewhat verifiable, as it provides a clear rationale but requires additional evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the question representation in Section 4.2, noting the absence of a term for r^q, which is the question representation. It also questions the meaning of \\sigma in the equation and raises a concern about the stability of the computation involving two sigmoid activations. This feedback is clear and actionable, as it provides the authors with specific areas to clarify and improve in their draft. By addressing these points, the authors can enhance the clarity and accuracy of their explanation, which is valuable for improving the overall quality of the paper. However, the comment could be more helpful if it offered suggestions on how to clarify the question representation or address the stability concerns. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the paper appears to be limited, specifically mentioning that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their draft. The comment lacks guidance on how to enhance the novelty or what specific aspects of the decomposition part need attention. As a result, the authors are left without any clear direction on how to improve their work in response to this feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the methodology aspect of the paper, specifically mentioning the novelty of the ENCODE part and the incremental contribution of the decomposition part. However, it does not specify which section of the paper this critique pertains to, making it weakly grounded. The comment is specific in detailing the limitations of the ENCODE part and the incremental contribution of the decomposition part, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the novelty of the paper, specifically mentioning that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The comment lacks actionable feedback or detailed advice, leaving the authors without a clear path for improvement. Therefore, it is rated as barely helpful, as it points out a potential weakness but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper violates the 9-page limit due to the cramped spacing of equations and captions close to figures. This provides a clear and direct action for the authors to take, which is to address the spacing issues. The comment also implies that the current formatting may not be suitable for a 9-page paper, making it highly actionable. The authors know exactly what needs to be done to improve the draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W1,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issue with the spacing of equations and captions being too close to figures, which is a clear violation of the 9-page paper limit. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper violates the 9-page limit due to the cramped spacing of equations and captions close to figures. This claim is somewhat verifiable as it provides a logical reasoning for the issue, but it lacks specific examples or references to support the assertion that this spacing issue alone is grounds for rejection. The comment could be strengthened by providing more detailed examples or references to similar cases where such spacing issues have led to rejection. As it stands, the authors may find it challenging to fully understand and address the issue without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the formatting of the paper, noting that equations and captions are crammed together, and that captions are too close to the figures. This is a clear and actionable observation, as it highlights a direct violation of the 9-page paper limit. By pointing out this issue, the comment provides the authors with a clear direction for improvement, ensuring that the paper adheres to the formatting guidelines. However, the comment could be more helpful if it offered suggestions on how to address the spacing issues or provided examples of how other papers have successfully navigated similar constraints. Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the technical details and formulations are limited, implying that the main novelty of the paper is based on the scheme or procedure novelty. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical details or formulations, nor are there suggestions for enhancing the novelty of the scheme or procedure. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical details and formulations are limited, implying that the main novelty of the paper is based on the scheme or procedure novelty. However, it does not specify which parts of the paper are lacking in technical details or formulations, nor does it provide any guidance on how to address these issues. The comment lacks specificity and grounding, as it does not identify the sections or elements of the paper that need improvement. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the technical details and formulations are limited, implying that the main novelty of the paper is based on the scheme or procedure novelty. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the technical details and formulations are limited, implying that the main novelty of the paper is based on the scheme or procedure novelty. However, it does not provide any specific feedback or suggestions on how the authors might improve the technical details or formulations. Without actionable guidance or examples, the comment lacks depth and does not assist the authors in enhancing their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential risk of methods that exploit relationships between action units, specifically noting that the relationships can vary across datasets. It suggests that the paper lacks cross-dataset experiments, which would be a good way to test the generalization of the work. While the comment identifies a potential area for improvement, it does not provide explicit instructions on how to conduct these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct cross-dataset experiments to address the risk. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the risk of methods that exploit relationships between action units, noting that these relationships can vary across datasets. The comment further suggests that cross-dataset experiments would be a good way to test the generalization of the work, and it highlights the absence of such experiments in the paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a potential risk of methods that exploit relationships between action units, noting that these relationships can vary across datasets. The comment suggests that cross-dataset experiments would be a good way to test the generalization of the work. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the differences in co-occurrences across datasets. This makes the claim somewhat verifiable, as the authors would need to infer the significance of the differences mentioned in Figure 1 and understand the implications of conducting cross-dataset experiments. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant risk associated with methods that exploit relationships between action units, noting that these relationships can vary across datasets. It highlights the importance of cross-dataset experiments to test the generalization of the work. While the comment effectively points out a potential weakness in the paper, it lacks specific suggestions or guidance on how to conduct cross-dataset experiments or what aspects of the work should be tested. The feedback is somewhat helpful as it provides a direction for improvement but could be more actionable with additional details. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should reconsider their statement about over-parameterization, which is currently perceived as a negative aspect. The reviewer provides a counterargument that over-parameterization can be beneficial for supervised learning of deep neural networks, citing theoretical work that supports this claim. However, the comment does not explicitly instruct the authors to revise their statement or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their stance on over-parameterization. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific lines in the paper, which provides full grounding. It also specifies the issue by questioning the negative assertion about over-parameterization and suggesting that it can be beneficial for supervised learning of deep neural networks. The reviewer provides a counterargument by referencing theoretical work that supports this claim. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim about over-parameterization being detrimental to performance, suggesting that it can be beneficial for supervised learning of deep neural networks. The reviewer provides a counterargument by referencing theoretical work that supports the benefits of over-parameterization, such as [1]. This provides a logical reasoning and a specific reference to support the claim, making it mostly verifiable. However, the comment could be strengthened by further elaboration on the specific aspects of over-parameterization that lead to improved performance. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment challenges the authors\\' assertion that over-parameterization is detrimental to performance, suggesting that it can be beneficial for supervised learning of deep neural networks. The reviewer provides a counterargument by referencing theoretical work that supports the benefits of over-parameterization, such as [1]. This feedback is valuable as it encourages the authors to reconsider their stance on over-parameterization and provides a potential direction for further exploration or discussion. However, the comment could be more helpful if it offered specific examples or further elaboration on the theoretical work or how over-parameterization might be beneficial in practice. Overall, the comment is mostly helpful as it prompts the authors to reconsider their position and provides a direction for further exploration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the fairness of the experimental comparison with other methods, specifically questioning whether the proposed method was initialized with the same or similar pre-trained model as the compared methods. It highlights a potential issue with the results presented in Table 1, where the proposed method without SSL performs inferior to most of the compared methods. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the initialization process and possibly re-evaluate the results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, questioning the fairness of the comparison due to the initialization of the proposed method before the fine-tuning stage. The comment suggests that the authors should clarify whether the compared methods were also initialized with the same or similar pre-trained model, and it points out a potential issue with the results presented in Table 1. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the fairness of the experimental comparison with other methods, specifically questioning whether the proposed method was initialized with the same or similar pre-trained model as the compared methods. The reviewer supports this claim by referencing Table 1, which shows the inferior performance of the proposed method without SSL compared to most of the compared methods. This provides a logical basis for the claim, as it highlights a potential issue in the experimental setup. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that have addressed this issue. Overall, the claim is mostly verifiable, as it is supported by a specific observation and reference to a table, but it could be further substantiated with additional evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness of the comparison due to the initialization of the proposed method before the fine-tuning stage. It highlights a potential problem by pointing out that the proposed method without SSL performs inferior to most of the compared methods, as shown in Table 1. This feedback is valuable as it prompts the authors to reconsider the experimental setup and potentially adjust their methodology to ensure a fair comparison. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to initialize the method fairly. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider using better meta-data embeddings for their zero-shot learning results on the CUB dataset, specifically referring to Table 3 on page 7. It also provides a specific example of a paper that used better meta-data embeddings, Table 1 in \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016.\" The comment is explicit in its suggestion to update the method with better meta-data embeddings, providing a clear action for the authors to take. However, it does not specify how to implement this suggestion or what specific steps to follow. The action is clear but lacks detailed guidance, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of better meta-data embeddings for the zero-shot learning results on the CUB dataset. The comment provides a specific example of a better approach, \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" and suggests that the authors should consider this approach. This level of detail and specificity makes the comment fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should consider using better meta-data embeddings for their zero-shot learning results on the CUB dataset, specifically referring to Table 3 on page 7. The comment provides a specific example of a paper that used better meta-data embeddings, Table 1 in \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016.\" This provides a clear rationale for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim that better meta-data embeddings would significantly improve performance. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending the use of better meta-data embeddings for the zero-shot learning results on the CUB dataset. It references a specific example from a related work, \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" which used better meta-data embeddings to achieve better performance. This feedback is actionable and provides a clear direction for the authors to enhance their results. However, the comment could be more helpful if it included additional details or guidance on how to implement this suggestion or what specific meta-data embeddings options might be best suited for the dataset. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should discuss relevant literature on using moment matching (instead of quantile regression) for distributional RL, specifically mentioning a specific paper (Nguyen-Tang et al AAAI\\u002721, \\u201cDistributional Reinforcement Learning via Moment Matching\\u201d). This provides a clear and direct action for the authors to take, as they are instructed to include this discussion in their paper. The comment is specific and provides concrete guidance on how to enhance the literature review section. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific paragraph (lines 22-30) and discusses the use of moment matching in distributional RL, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on moment matching and its potential use in distributional RL. This provides clear guidance on what the authors should add to their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks relevant literature on using moment matching (instead of quantile regression) for distributional RL, specifically mentioning a specific paper (Nguyen-Tang et al AAAI\\u002721, \\u201cDistributional Reinforcement Learning via Moment Matching\\u201d). This claim is somewhat verifiable as it provides a specific reference to a relevant work, which supports the suggestion that the paper should discuss moment matching. However, the comment could be strengthened by providing more detailed reasoning or examples of how moment matching could be beneficial in the context of distributional RL. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific area where the paper lacks relevant literature, specifically on the use of moment matching instead of quantile regression for distributional RL. It provides a specific reference to a relevant paper (Nguyen-Tang et al AAAI\\u002721, \\u201cDistributional Reinforcement Learning via Moment Matching\\u201d) that could enhance the literature review section. This feedback is clear and actionable, guiding the authors to expand their discussion and include relevant literature that could strengthen their work. By addressing this suggestion, the authors can significantly improve the comprehensiveness and depth of their paper. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the novelty of the paper is limited and criticizes the interpretation of deep neural networks using linear models as not being a new approach for model interpretation. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or improve the novelty of their work. There is no guidance on potential enhancements or alternative approaches that could be considered. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper, specifically mentioning the interpretation of deep neural networks using linear models as not being a new approach for model interpretation. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the novelty, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, specifically mentioning the interpretation of deep neural networks using linear models as not being a new approach for model interpretation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the novelty of the paper, specifically mentioning the interpretation of deep neural networks using linear models as not being a new approach for model interpretation. While it identifies a potential limitation in the novelty of the work, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to enhance the novelty or address this issue. As a result, it offers limited value to the authors in terms of improving their draft. Therefore, the comment is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper's results. It suggests that the use of PCA is intuitive and that the assumptions underlying the method are not well-explained. However, the comment does not provide explicit guidance on how the authors should address these concerns or improve the paper. It lacks actionable steps or specific suggestions for improvement, leaving the authors uncertain about how to respond to the feedback. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper's results. It suggests that the use of PCA is intuitive and that the assumptions underlying the method are not well-explained. However, the comment does not specify which part of the paper discusses the use of PCA or where the assumptions are not well-explained. This makes it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what assumptions are not well-explained or how they could be addressed. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the novelty and significance of the paper, suggesting that using PCA to reduce interaction count is intuitive and that the assumptions underlying the method are not well-explained. The reviewer references a specific work by Dombrowski et al. to support their claim about the use of PCA, but the comment lacks detailed reasoning or examples to fully substantiate the critique. While the reference provides some context, the comment could be strengthened by offering more specific examples or detailed explanations of the assumptions and their implications. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the novelty and significance of the paper, suggesting that the use of PCA to reduce interaction count is intuitive and that the assumptions underlying the method are not well-explained. It references a specific work by Dombrowski et al. to support its claim about the use of PCA. However, the comment lacks specific guidance or suggestions on how the authors might address these concerns or improve the paper. It does not provide actionable feedback or detailed advice, leaving the authors uncertain about how to respond to the feedback. Therefore, the comment is barely helpful, as it identifies a potential weakness but does not offer concrete steps for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the scope of the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models. It raises concerns about the method's broader applicability and suggests that it may not generalize to other reasoning or generation tasks or more advanced models. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or expand the scope of their framework. The action is implicit and somewhat vague, as the authors can infer that they need to consider broader applicability but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the scope of the evaluative framework, specifically noting that it is limited to only three Question-Answering tasks and two language models. This provides a clear indication of what part of the paper is being discussed, making the comment fully grounded. The comment also specifies the issue by questioning the method\\'s broader applicability and potential to generalize to other reasoning or generation tasks or more advanced models. This provides specific guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluative framework is limited in scope, restricted to only three Question-Answering tasks and two language models. It raises concerns about the method\\'s broader applicability and its potential to generalize to other reasoning or generation tasks or more advanced models. The comment provides a logical reasoning by questioning the method\\'s applicability to a wider range of tasks and models. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the potential applicability of the framework to other tasks and models, which could be challenging without additional evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models. This feedback highlights a potential limitation in the method\\'s broader applicability and suggests that it may not generalize to other reasoning or generation tasks or more advanced models. While the comment points out a relevant concern, it lacks specific suggestions or guidance on how the authors might address this limitation or expand the scope of their framework. Without actionable advice or detailed feedback, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 6C is awkward and implies negative rates, which is not accurate. The reviewer recommends using a second y-axis or another visualization that is more physically accurate. While the comment provides a clear suggestion for improvement, it does not explicitly instruct the authors on how to implement this suggestion, such as by providing specific guidance on which visualization to use or how to adjust the figure. The action is concrete but somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which implies negative rates, and suggests using a second y-axis or another visualization that is more physically accurate. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 6C is awkward and implies negative rates, which is not accurate. The reviewer suggests using a second y-axis or another visualization that is more physically accurate. However, the comment lacks specific reasoning or examples to support why Figure 6C is awkward or how it implies negative rates. Without detailed justification or references, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates, which is not accurate. The reviewer suggests a solution by recommending the use of a second y-axis or another visualization that is more physically accurate. This feedback is clear and actionable, providing the authors with a concrete direction for improving the accuracy and clarity of their figure. However, the comment could be more helpful if it included additional context or examples of alternative visualizations that could be used. Overall, the comment is mostly helpful as it effectively guides the authors on how to address a specific issue in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific guidance or suggestions on how to achieve this improvement. The authors are left to infer that they should work on increasing the complexity, but without concrete steps or examples, they are unable to effectively address the comment. The lack of explicit instructions or detailed suggestions makes this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that there is room to improve the complexity of Algorithm 2, but it does not specify which part of the paper discusses Algorithm 2 or where the authors should focus their efforts. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of Algorithm 2 need improvement or how to achieve this improvement. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that there is room to improve the complexity of Algorithm 2, which is a specific area for potential enhancement. However, it lacks depth and does not provide any detailed suggestions or examples on how to achieve this improvement. Without actionable guidance or specific recommendations, the authors are left with a general idea of what needs to be addressed but without clear steps to take. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a questionable statement in the supplemental section D.4 regarding the need for smaller architectures in LM compared to GAN models to avoid overfitting. The reviewer suggests that this claim is not supported by their experience, as they have successfully trained larger models. The comment also questions whether dropout is applied to both embeddings and hidden states, which is a specific area for clarification. While the comment identifies a potential issue and raises a question, it does not provide explicit instructions or concrete steps for the authors to address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the statement and provide additional information about dropout application. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the supplemental section D.4, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that smaller architectures are necessary for LM compared to GAN models, suggesting that this is not supported by the reviewer's experience. The comment further questions whether dropout is applied to both embeddings and hidden states, providing specific areas for clarification. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions a statement in the supplemental section D.4, specifically the claim that smaller architectures are necessary for LM compared to GAN models to avoid overfitting. The reviewer challenges this assertion by citing their own experience, suggesting that larger models can be trained successfully. The comment also raises a question about the application of dropout to both embeddings and hidden states, which is a request for clarification. While the comment provides some evidence by referencing a specific example, it lacks detailed reasoning or references to support the claim that smaller architectures are not necessary. Therefore, the comment is somewhat verifiable, as it provides some evidence but could be strengthened with more detailed justification or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific statement in the supplemental section D.4 that the reviewer finds questionable, suggesting that the claim about smaller architectures being necessary for LM compared to GAN models is not supported by their experience. The comment also raises a question about the application of dropout to both embeddings and hidden states, which is a relevant area for clarification. While the comment highlights a potential issue and prompts the authors to clarify their claims, it could be more helpful by providing additional guidance or suggestions on how to address these concerns. Overall, the comment is somewhat helpful as it directs the authors to specific areas needing clarification, but it lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. While the comment implies that the authors should make their introduction more concise and include empirical results, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. However, it does not specify which part of the paper this pertains to, such as sections or paragraphs. The authors might infer that it relates to the introduction, but this inference is not direct. The comment is specific in suggesting that the introduction should be more concise and include empirical results, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. However, the comment does not provide any specific examples, references, or detailed reasoning to support why the introduction should be more concise or how empirical results could enhance the paper. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. While it identifies a potential area for improvement, it lacks specific guidance or examples on how to achieve this concision or how empirical results could enhance the introduction. The comment provides a general direction for improvement but does not offer actionable steps or detailed suggestions, making it somewhat helpful. The authors are left to infer the specifics of what changes are needed, limiting the comment\\'s utility. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any explicit or implicit actions for the authors to take to clarify the technical contribution or suggest improvements to the analysis. There is no guidance on how to enhance the technical contribution or what specific aspects of the analysis should be revised. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical contribution is unclear and that most of the analysis is standard. However, it does not specify which parts of the paper are unclear or where the analysis is standard. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need clarification or improvement. The comment lacks both grounding and specificity, making it difficult for the authors to understand what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific examples or detailed reasoning to support these claims. Without supporting evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific examples or detailed feedback on how the authors could clarify the technical contribution or improve the analysis. Without actionable guidance or suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful, as it lacks depth and specificity, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the application of regularization to both LN models and GLMs, suggesting that the authors should try to reproduce the main features of previous models to make the comparison fair. While the comment implies that the authors should consider reproducing the main features of previous models, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should replicate the features of previous models. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the application of regularization to both LN models and GLMs, suggesting that the authors should try to reproduce the main features of previous models to make the comparison fair. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the need to replicate the main features of previous models, but without explicit references to sections or specific elements, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the application of regularization to both LN models and GLMs, suggesting that the authors should try to reproduce the main features of previous models to make the comparison fair. The reviewer provides a logical reasoning by pointing out that the GLM by Pillow et al. did not crop the image but used L1 regularization for the filters and a low-rank approximation to the spatial filter. However, the comment lacks specific examples or references to support the claim that the current application of regularization is inappropriate. While the reasoning is clear, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the application of regularization to both LN models and GLMs, suggesting that the authors should try to reproduce the main features of previous models to make the comparison fair. This feedback is somewhat helpful as it highlights a potential inconsistency in the experimental setup and provides a direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to reproduce the main features of previous models or provided examples of how this could be done. Overall, the comment provides some guidance but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to include failure cases and related discussions. While it implies that the authors should include this information, it does not provide specific guidance on how to integrate these elements into the paper or what aspects of the failure cases should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should include failure cases and related discussions, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including failure cases and related discussions, but it does not specify which part of the paper should include this information. The authors cannot confidently determine whether it relates to specific sections, such as experimental results or methodology. Additionally, the comment lacks specificity regarding what aspects of the failure cases should be discussed or how they should be integrated into the paper. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that it would be beneficial to include failure cases and related discussions. However, it does not provide any reasoning, examples, or references to support why this addition would be valuable or how it would enhance the paper. Without specific justification or evidence, the claim remains unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial to include failure cases and related discussions. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance on how to integrate these elements into the paper or what aspects of the failure cases should be discussed. The comment is vague and does not offer actionable advice, leaving the authors without clear direction on how to enhance their draft. Therefore, the feedback is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a discrepancy in the use of \\u03b4 in equations (10) and (11) and suggests introducing \\u03b4 when equation (11) is discussed. This provides a clear and concrete action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1\" and \"equation (10)\" and \"equation (11),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistent use of \\u03b4 in equations (10) and (11) and suggests introducing \\u03b4 when equation (11) is discussed. This provides clear guidance on how to improve the draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \\u03b4 is not used in equation (10) but is used in equation (11). It suggests introducing \\u03b4 when equation (11) is discussed. This claim is somewhat verifiable as it provides a specific observation about the inconsistent use of \\u03b4 in equations, which could be a source of confusion. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of \\u03b4 in equations (10) and (11), noting that \\u03b4 is not used in equation (10) but is used in equation (11). It suggests introducing \\u03b4 when equation (11) is discussed, which could clarify the usage of this symbol. This feedback is clear and actionable, providing the authors with a specific and concrete suggestion for improving the clarity of their equations. By addressing this issue, the authors can enhance the readability and comprehensibility of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the claim about evolutionary dropout and its limitations in addressing internal covariate shift. It suggests that the comment is too limited and does not fully address the issue. The reviewer implies that the authors should discuss the limitations explicitly, but the comment does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to elaborate on the limitations but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the claim about evolutionary dropout and its limitations in addressing internal covariate shift. It suggests that the claim is limited because it only increases the variance of some low-variance units and does not discuss the impact of batch normalization on standardizing variance and centering activation. However, the comment does not specify which part of the paper this critique pertains to, making it weakly grounded. The authors can infer that it relates to the discussion of these methods, but the lack of explicit mention makes it difficult to pinpoint the exact section. The comment is specific in detailing the limitations of the claim, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the claim about evolutionary dropout addressing internal covariate shift is limited, as it only increases the variance of some low-variance units. The reviewer suggests that batch normalization, which standardizes variance and centers activation, is a more effective approach. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it requires further elaboration to be fully understood and actionable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the claim about evolutionary dropout and its limitations in addressing internal covariate shift. It suggests that the claim is too limited and does not fully address the issue, as it only increases the variance of some low-variance units. The reviewer also points out that batch normalization, which standardizes variance and centers activation, is a more effective approach. While the comment identifies a specific limitation in the claim, it lacks detailed guidance or suggestions on how the authors might address this issue or improve their analysis. The feedback is somewhat helpful as it highlights a potential weakness but does not provide actionable steps for improvement, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the author to add more description about the contribution of their paper. This feedback is clear and provides a direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and provides a concrete suggestion for enhancing the paper\\'s clarity and impact. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should add more description about the contribution of their paper. However, it does not specify which part of the paper lacks this description, making it weakly grounded. The comment is specific in its request for additional information, but without explicit references to sections or details, the authors may struggle to identify where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should add more description about the contribution of their paper. However, it does not provide any reasoning, evidence, or examples to support why this additional description is necessary or how it would enhance the paper. Without specific guidance or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should add more description about the contribution of their paper. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance on what aspects of the contribution should be elaborated or how this additional description could enhance the paper. Without detailed feedback or examples, the authors may struggle to understand how to effectively address this feedback. Therefore, the comment is barely helpful, as it points out a potential weakness but does not offer actionable steps for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to honestly represent a graph with repeated vertex or edge labels. While the comment provides a clear and explicit action for the authors to take, it does not offer specific guidance on how to implement this change or what the implications of this change might be. The authors are left with a clear direction but without detailed instructions on execution. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that \"X\" should be a multiset instead of a set to accurately represent a graph with repeated vertex or edge labels. This provides clear guidance on what needs to be changed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that \"X\" should be a multiset instead of a set in Section 4, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. The comment provides a logical reasoning for the change, explaining why the current representation may not be accurate. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to make a significant effort to understand and implement the suggested change, but the reasoning is sound. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the representation of \"X\" in Section 4, suggesting that it should be a multiset instead of a set to accurately represent a graph with repeated vertex or edge labels. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that can enhance the accuracy and comprehensiveness of the paper. However, the comment could be more helpful if it included additional context or explanation on why this change is necessary or how it would impact the overall understanding of the graph. Despite this, the comment is mostly helpful as it directs the authors to a specific area for improvement, making it a valuable contribution to the authors\\' draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the authors\\' derivation for falling into classical learning theory-based bounds, which are not considered realistic without Bayesian considerations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific steps they should consider to improve their derivation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' derivation for falling into classical learning theory-based bounds, which are not considered realistic without Bayesian considerations. However, it does not specify which part of the paper this critique pertains to, such as a particular section or equation. The authors may infer that it relates to the derivation or theoretical sections, but this inference is not direct. The comment is specific in detailing the issue with classical learning theory-based bounds and the need for Bayesian considerations, but it lacks grounding as it does not explicitly mention a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' derivation falls into classical learning theory-based bounds, which are not considered realistic without Bayesian considerations. The reviewer supports this claim by mentioning Bayesian-PAC based bounds as an example of a more realistic approach. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a general idea of the issue, it does not offer enough evidence or detailed reasoning to fully support the claim. Therefore, the comment is somewhat verifiable, as it provides a general understanding but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the authors\\' derivation for falling into classical learning theory-based bounds, which are not considered realistic without Bayesian considerations. It suggests that the authors should consider Bayesian-PAC based bounds as a more realistic approach. While the comment identifies a potential weakness in the derivation, it lacks specific guidance or suggestions on how the authors might address this issue or incorporate Bayesian considerations. The feedback is somewhat helpful as it points out a potential area for improvement but does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between methods. It points out a specific example from line 486 where the authors make a claim about the conversational ability of ChatGPT and GPT-4, but no significance testing is conducted to substantiate this claim. The comment explicitly instructs the authors to conduct significance testing to support their claims, providing a clear and actionable step for improvement. The feedback is concrete and specific, giving the authors a direct path to enhance the rigor and credibility of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 486,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the lack of significance testing to support claims about method differences, providing a clear example from the text. The comment suggests conducting significance testing to substantiate claims, which is a concrete suggestion for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a specific issue with the paper, namely the lack of significance testing to support claims about method differences. The reviewer provides a detailed example from line 486, where the authors make a claim about the conversational ability of ChatGPT and GPT-4, but no significance testing is conducted to substantiate this claim. The comment suggests that the authors should conduct significance testing to support their claims, which is a logical and reasonable suggestion. However, the comment does not provide specific references or examples from the literature to support the need for significance testing, which would enhance its verifiability. Therefore, the comment is somewhat verifiable, as it provides a clear rationale but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of significance testing to support claims about method differences. It provides a specific example from line 486, where the authors make a claim about the conversational ability of ChatGPT and GPT-4, but no significance testing is conducted to substantiate this claim. The comment suggests that the authors should conduct significance testing to support their claims, which is a clear and actionable suggestion. By addressing this feedback, the authors can significantly improve the rigor and credibility of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct significance testing or offered suggestions for interpreting the results. Overall, the comment is mostly helpful as it effectively highlights a critical area for improvement and provides a concrete direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the paper\\'s claim that distillation improves teacher performance, suggesting that the improvements might be due to regularization effects rather than distillation. It raises a concern about the lack of early-stopping and the high variance in fine-tuning on GLUE. The comment implies that proper ablation studies are needed to verify the claims. While the comment identifies a potential issue and suggests a need for further investigation, it does not provide explicit instructions on how to conduct these studies or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s claim that distillation improves teacher performance, suggesting that the improvements might be due to regularization effects rather than distillation. It raises a concern about the lack of early-stopping and the high variance in fine-tuning on GLUE. However, the comment does not specify which part of the paper discusses these claims, making it weakly grounded. The comment is specific in detailing the potential issue with the claim and the need for proper ablation studies to verify it. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that distillation improves teacher performance, suggesting that the improvements might be due to regularization effects rather than distillation. The reviewer provides a logical reasoning by pointing out the lack of early-stopping and high variance in fine-tuning on GLUE, which could lead to overfitting. The comment also suggests the need for proper ablation studies to verify the claims. While the reasoning is sound, it could be strengthened by providing specific examples or references to studies that have observed similar effects. Overall, the claim is mostly verifiable, as it provides a clear rationale and a direction for further investigation, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim that distillation improves teacher performance, suggesting that the improvements might be due to regularization effects rather than distillation. It raises a concern about the lack of early-stopping and the high variance in fine-tuning on GLUE, which could lead to overfitting. The comment also suggests the need for proper ablation studies to verify the claims. While the feedback highlights a critical area for improvement, it could be more helpful by providing specific guidance on how to conduct these studies or what aspects to focus on. Overall, the comment is somewhat helpful as it points out a potential weakness but lacks detailed guidance for addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a subjective opinion that the contribution of the paper appears limited and that the proposed model seems incremental in its approach. However, it does not provide any specific guidance or suggestions on how the authors might address this perception or improve the contribution of their work. There is no explicit or implicit action for the authors to take, leaving them without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the contribution of the paper and the approach of the proposed model, but it does not specify which part of the paper this perception is based on. The authors cannot confidently determine which sections or aspects of the paper are being addressed, making the comment weakly grounded. The comment is specific in its critique of the contribution and the incremental nature of the approach, providing clear guidance on what the authors need to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses an opinion that the contribution of the paper appears limited and that the proposed model seems incremental in its approach. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses an opinion that the contribution of the paper appears limited and that the proposed model seems incremental in its approach. However, it does not provide any specific feedback or suggestions on how the authors might address this perception or improve the contribution of their work. Without actionable guidance or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the use of supervised pretraining based on the prediction of homo-lumo gap, suggesting that it may lead to negative transfer. It provides an example of this issue by pointing out that Transformer-M performs poorly on most tasks other than homo, lumo, and gap on QM9 in downstream experiments. However, the comment does not explicitly instruct the authors to address this issue or suggest specific actions to mitigate negative transfer. While it identifies a potential problem, it lacks concrete guidance on how to resolve it. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but does not offer detailed instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"QM9\" and \"Transformer-M,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of supervised pretraining based on the prediction of homo-lumo gap, providing a concrete example of negative transfer in downstream experiments. This allows the authors to understand the problem and address it effectively. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that supervised pretraining based on the prediction of homo-lumo gap may lead to negative transfer, as evidenced by Transformer-M's poor performance on tasks other than homo, lumo, and gap on QM9. The reviewer provides a specific example of this issue, which is the poor performance of Transformer-M on most tasks. This claim is somewhat verifiable as it provides a concrete example of the issue, but it lacks detailed reasoning or references to support the claim that negative transfer is likely due to the use of homo-lumo gap prediction. The authors would need to further explore the issue and provide additional evidence or analysis to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of supervised pretraining based on the prediction of homo-lumo gap, suggesting that it may lead to negative transfer. It provides a specific example by pointing out that Transformer-M performs poorly on most tasks other than homo, lumo, and gap on QM9 in downstream experiments. This observation highlights a contradiction with the paper\\'s claim of a \"general-purpose neural network model.\" However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or mitigate negative transfer. While it raises an important concern, it does not provide actionable advice or specific steps for improvement, making it somewhat helpful. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the experimental evaluation, including the lack of ablation for a specific aspect of the approach, the limited comparison with the CIFAR dataset, and the unclear evaluation of the DEN approach. While the comment highlights these areas for improvement, it does not provide explicit instructions or concrete suggestions on how to address them. The authors are left to infer that they should include ablation for the \"picking\" step, provide a more comprehensive comparison with the CIFAR dataset, and ensure a fair evaluation of the DEN approach. However, the lack of detailed guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experimental Evaluation 2.1. Ablations 2.1.1\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the experimental evaluation, such as the lack of ablation for a specific aspect of the approach and the limited comparison with the CIFAR dataset. The comment also points out the need for a more comprehensive evaluation of the DEN approach, including using the same setup as in the DEN paper to ensure fairness. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks ablation for a specific aspect of the approach and that the comparison on CIFAR is not convincing. It also questions the evaluation of the DEN approach, suggesting that the authors should use the same setup as in the DEN paper to ensure fairness. These claims are somewhat verifiable as they provide some reasoning and logical reasoning, such as the need for ablation and a more comprehensive comparison. However, the comment could be strengthened by providing specific examples or references to support the claims, which would make it fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the experimental evaluation section. It points out that the paper lacks ablation for a specific aspect of the approach, which is a critical omission. Additionally, it questions the limited comparison with the CIFAR dataset and suggests that the evaluation of the DEN approach is not convincing. The comment highlights the need for a more comprehensive evaluation, including using the same setup as in the DEN paper to ensure fairness. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific suggestions on how to address these issues, such as which aspects to ablate or how to improve the comparison with the CIFAR dataset. Overall, the comment is mostly helpful as it directs the authors to significant areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph. While the comment identifies a potential issue with the method, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should consider the trade-off between computational time and information loss. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a concern about the trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph. However, the comment does not specify which part of the paper this concern is related to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its question about the trade-off and the potential loss of information, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph. The comment is somewhat verifiable as it provides a logical reasoning for the trade-off and suggests that the authors consider the implications of this choice. However, it lacks specific examples or references to support the claim that the output of ACI has less information compared to [10]. This makes the comment somewhat verifiable, as it provides a starting point for the authors to explore but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph, suggesting that the output of ACI may have less information compared to [10]. This feedback is somewhat helpful as it identifies a potential weakness in the methodology and encourages the authors to consider the implications of their choice. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their methodology. To be more helpful, the comment could provide examples or additional context to help the authors understand and address the concern. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the definitions in Table 1, specifically questioning the differences between anchor-based regression, regression in RepPoints, and one-shot regression in RetinaNet. It also mentions that ATSS has proven that regression methods do not significantly influence the results. The reviewer suggests that direct regression to the center point is sufficient and questions the motivation for the current approach if the differences are not clear. While the comment identifies areas of confusion, it does not provide explicit guidance on how the authors should clarify these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and motivations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues with the definitions in Table 1, particularly regarding the differences between anchor-based regression, regression in RepPoints, and one-shot regression in RetinaNet. It also mentions ATSS and its findings regarding the influence of regression methods. The comment is fully grounded as it explicitly mentions \"Table 1\" and provides specific details about the definitions and the methods being compared. It is also specific because it clearly specifies what needs to be clarified and questions the motivation for the current approach. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the definitions in Table 1, specifically questioning the differences between anchor-based regression, regression in RepPoints, and one-shot regression in RetinaNet. It also mentions that ATSS has proven that regression methods do not significantly influence the results. The reviewer suggests that direct regression to the center point is sufficient and questions the motivation for the current approach if the differences are not clear. While the comment identifies potential areas of confusion, it lacks specific examples or references to support the claims about the differences between the methods. This makes the claim somewhat verifiable, as the authors would need to provide additional context or evidence to fully address the reviewer\\'s concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas of confusion regarding the definitions in Table 1, particularly regarding the differences between anchor-based regression, regression in RepPoints, and one-shot regression in RetinaNet. It also questions the motivation for the current approach, given that ATSS has shown that regression methods do not significantly influence results. The reviewer suggests that direct regression to the center point is sufficient and implies that the current approach may not be necessary. While the comment highlights important areas for clarification, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it points out potential weaknesses but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors clarify whether the Fourier modes are real or complex numbers. This is an explicit request for clarification, providing a clear action for the authors to take. The comment is specific in detailing what needs to be clarified, making it highly actionable. Authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests clarifying whether the Fourier modes are real or complex numbers. However, it does not specify which part of the paper this clarification is needed in, such as a particular section, table, or figure. This makes it weakly grounded because the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what needs clarification, but without full grounding, it is difficult for the authors to pinpoint the exact location for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests clarifying whether the Fourier modes are real or complex numbers. However, it does not provide any reasoning, examples, or references to support why this clarification is necessary or how it would impact the understanding of the paper. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors clarify whether the Fourier modes are real or complex numbers. This is a specific and actionable suggestion that can help the authors improve the clarity and accuracy of their draft. By addressing this point, the authors can ensure that their explanation is precise and consistent, which is important for the comprehension of their work. However, the comment could be more helpful if it provided additional context or examples to guide the clarification process. Overall, the comment is mostly helpful as it identifies a specific area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to correct the labeling of Fig. 1 instead of Fig. 5.1 on line 205. It also provides specific guidance on how to resolve the issue by adding the \"\\label\" command after the \"\\caption\" in LaTeX. This feedback is clear and provides concrete steps for the authors to take, ensuring that they know exactly what needs to be done to correct the error. The action is explicit and the authors can easily implement the suggested changes, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 205,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the labeling of Fig. 1 instead of Fig. 5.1 and provides guidance on how to resolve the issue by adding \"\\label\" after \"\\caption\" in LaTeX. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation about the labeling of Fig. 1 instead of Fig. 5.1 on line 205. It provides a clear and specific correction for the authors to make, instructing them to add the \"\\label\" command after the \"\\caption\" in LaTeX. This comment is purely factual and does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific error in the labeling of Fig. 1 instead of Fig. 5.1 on line 205. It provides clear and actionable feedback by instructing the authors to correct the labeling and specify the correct label by adding \"\\label\" after \"\\caption\" in LaTeX. This guidance is precise and straightforward, enabling the authors to make a straightforward correction to their draft. The comment is also somewhat helpful as it highlights a minor technical issue that can be easily resolved, which is beneficial for improving the overall quality of the paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be more convincing by discussing case studies and error studies to highlight the effectiveness of each proposed component. It provides an example of a case study from \"Graph pre-training for AMR parsing and generation\" to illustrate the potential benefits of such an approach. While the comment implies that the authors should include case studies, it does not explicitly instruct them to do so or provide specific guidance on how to structure or conduct these studies. The action is implicit and somewhat vague, as the authors need to infer the need for case studies and how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"case studies and error studies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of case studies and error studies to enhance the paper\\'s effectiveness. This provides clear guidance on how to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that case studies and error studies could enhance the paper\\'s effectiveness by highlighting the effectiveness of each proposed component. The reviewer provides an example of a case study from \"Graph pre-training for AMR parsing and generation,\" which supports the claim that case studies could be beneficial. However, the comment lacks specific examples or detailed reasoning about why case studies are necessary or how they would improve the paper. While the suggestion is logical, the lack of detailed justification makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by discussing case studies and error studies to demonstrate the effectiveness of each proposed component. It offers an example of a case study from \"Graph pre-training for AMR parsing and generation,\" which could help the authors understand the potential benefits of including such studies. This feedback is clear and provides a concrete direction for enhancing the paper\\'s persuasiveness and credibility. However, it could be more helpful if it included additional guidance on how to structure or conduct these studies. Overall, the comment is mostly helpful as it offers a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue in the paper: the use of the notation \"{\\\\cal P}\" with a subscript without being defined. This provides a clear and direct action for the authors to take, which is to define the notation before using it. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the same section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation \"{\\\\cal P}\" being used without being defined, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation \"{\\\\cal P}\" with a subscript is used several times without being defined. This is a factual observation that does not require justification or evidence. It is a request for clarification rather than an opinion or suggestion. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation \"{\\\\cal P}\" being used without being defined in the same section. This is a clear and actionable feedback that prompts the authors to clarify the notation before using it in the paper. By addressing this issue, the authors can improve the clarity and consistency of their notation, which is crucial for effective communication of their ideas. However, the comment could be more helpful if it provided suggestions on how to define the notation or offered examples of how it should be used. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of three separate comments, each addressing specific issues in the paper. The first comment points out a grammatical error in the text, suggesting a correction from \"known\" to \"know.\" The second comment requests clarification on the definition of \"\\gamma_0^{***}.\" The third comment asks for clarification on the meaning of colors in both the caption and the text of the figure. Each of these points is explicit and provides clear actions for the authors to take, such as correcting the grammar, providing definitions, and clarifying the meaning of colors. The feedback is concrete and specific, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment consists of three separate points, each addressing specific issues in the paper. The first point identifies a grammatical error in the text, suggesting a correction from \"known\" to \"know.\" The second point requests clarification on the definition of \"\\gamma_0^{***}.\" The third point asks for clarification on the meaning of colors in the caption and text of Figure 1. While the comment does not explicitly mention which sections or figures these issues pertain to, the authors can infer that they are related to the text and Figure 1. This makes the comment weakly grounded, as the authors can infer the relevant parts but cannot confidently determine the exact sections. The comment is specific in detailing what needs to be addressed, providing clear guidance on each point. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of three separate comments, each addressing specific issues in the paper. The first comment suggests a correction in grammar, pointing out the use of \"known\" instead of \"know.\" The second comment requests clarification on the definition of \"\\gamma_0^{***},\" which is a mathematical term. The third comment asks for clarification on the meaning of colors in the caption and text of Figure 1. These points are factual and do not contain subjective opinions or claims that require verification. Therefore, each comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment consists of three separate points, each addressing specific issues in the paper. The first point identifies a grammatical error in the text, suggesting a correction from \"known\" to \"know.\" This is a minor but actionable suggestion that can improve the clarity of the text. The second point requests clarification on the definition of \"\\gamma_0^{***},\" which is a mathematical term. This feedback is clear and actionable, as it directs the authors to provide a definition for a key concept. The third point asks for clarification on the meaning of colors in the caption and text of Figure 1. This is also a clear and actionable suggestion, as it ensures that the figures are understandable and consistent with the text. Overall, the comment provides clear and actionable feedback, addressing specific areas for improvement in the draft. Therefore, it is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the rationale behind certain decisions in the experimental dataset, specifically regarding the use of a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. While the comment implies that the authors should provide a rationale for these choices, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide a justification but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the main rationales for having a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. This provides clear guidance on what aspects of the experimental dataset need clarification or explanation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification about the rationale behind certain experimental choices. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the rationale behind certain experimental choices, specifically regarding the use of a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. While it identifies areas that need clarification, it does not provide specific guidance or suggestions on how the authors might address these questions or improve their experimental design. The feedback is somewhat helpful as it prompts the authors to consider the rationale behind their choices, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the writing or presentation is jumbled at times, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the clarity or organization of the writing. Without specific suggestions or recommendations, the authors are left without a clear path to follow for enhancing their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"writing / presentation,\" which suggests it relates to the content or structure of the paper. However, it does not specify which part of the paper is being addressed, such as sections, tables, or figures. This makes it weakly grounded, as the authors cannot confidently determine the exact part being referred to. The comment is specific in detailing the issue of jumbled writing or presentation, providing a clear indication of what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the writing or presentation is \"jumbled at times,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without additional context or details, the authors may find it challenging to understand the basis of the critique or how to address it. As a result, the comment lacks verifiability, making it difficult for the authors to understand and improve their draft. Therefore, it is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment mentions that the writing or presentation is \"jumbled at times,\" but it does not provide any specific examples, context, or suggestions for improvement. Without detailed feedback or guidance, the authors are left without actionable steps to address the issue. The comment lacks depth and does not offer any constructive feedback, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates on the potential power demand if the Woodbury flow were to be used on a mobile device. While the comment implies that the authors should provide a comparison with other methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a computational complexity comparison. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates on the potential power demand if the Woodbury flow were to be used on a mobile device. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where the computational complexity is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the computational complexity and power demand, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. The comment suggests that the Woodbury flow could cause a significant power demand if used on a mobile device. However, the comment lacks specific examples or references to support the claim about the computational complexity or power demand. Without detailed evidence or comparisons, the claim is difficult for the authors to verify. Therefore, the comment is considered borderline verifiable, as it provides a logical basis for the question but lacks sufficient evidence or references to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates on the potential power demand if the Woodbury flow were to be used on a mobile device. While this comment identifies a potential area for comparison and consideration, it lacks specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it prompts the authors to consider the computational complexity and power demand of their method, but it does not provide actionable steps or detailed advice on how to improve the draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an incorrect statement in the paper regarding the behavior of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It explicitly states that these heads are active at the S2 token but do not primarily attend to it, referencing Section 3 of Wang et al. (2023). This provides a clear and concrete action for the authors to correct the statement in their draft. The comment is explicit and provides specific guidance on how to revise the text, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific section of the paper, \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the incorrect claim regarding the behavior of these heads, referencing Section 3 of Wang et al. (2023) to provide a clear understanding of the correct behavior. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token\" is incorrect, citing Section 3 of Wang et al. (2023) as the source. This provides a clear and specific reference to the external work that supports the claim, making it fully verifiable. The comment is also supported by the logical reasoning that the heads are active at the S2 token but do not primarily attend to it, which further strengthens the claim. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies an incorrect statement in the paper regarding the behavior of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It provides a specific and clear correction by referencing Section 3 of Wang et al. (2023), which clarifies that these heads are active at the S2 token but do not primarily attend to it. This feedback is actionable and constructive, as it guides the authors to correct a factual inaccuracy in their work. However, the comment could be more helpful if it offered additional context or suggestions on how to revise the section to ensure accuracy and clarity. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit feedback on the vagueness of certain statements regarding RNNs and their effectiveness for natural language reasoning tasks. It suggests that the authors should provide more specific examples or references to support their claims. Additionally, it critiques the use of the reinforcement learning/agent analogy, suggesting that it is out of place and that the examples later in the paper better illustrate generalization capabilities. While the comment provides clear actions for the authors to take, such as providing more specific examples or references, it does not specify how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper (L15 and L16-18), allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear guidance on what needs to be addressed, namely the vagueness of certain RNNs and the use of the reinforcement learning/agent analogy. The comment suggests that the examples later in the paper better illustrate generalization capabilities, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that certain RNNs work well for certain natural language reasoning tasks and suggests that the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/ can provide more context. The reviewer also critiques the use of the reinforcement learning/agent analogy, suggesting that it is out of place and that the examples later in the paper better illustrate generalization capabilities. While the comment provides some reasoning and references, it lacks detailed justification or specific examples to fully substantiate the claims. Therefore, the comment is somewhat verifiable, as it provides some support but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the vagueness of certain statements regarding the effectiveness of RNNs for natural language reasoning tasks. It suggests that the authors should provide more specific examples or references to support their claims, which is a clear and actionable suggestion. Additionally, it critiques the use of the reinforcement learning/agent analogy, suggesting that it is out of place and that the examples later in the paper better illustrate generalization capabilities. This feedback is valuable as it guides the authors on how to improve the clarity and relevance of their arguments. However, the comment could be more helpful if it provided specific examples or references to the literature or examples mentioned later in the paper. Overall, the comment is mostly helpful as it offers actionable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a statement claiming that every kernel can be described by a feature space parameterized by a neural network, which is considered trivially not true. The reviewer provides a specific example of RBF kernels and their infinite-dimensional representation, which challenges the claim. The comment suggests that the limitation of representing infinite-dimensional RKHSs should be made more clear. While the action is explicit, as it instructs the authors to clarify the limitation, it is somewhat vague as it does not provide detailed guidance on how to address this issue. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.\" This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that every kernel can be described by a feature space parameterized by a neural network, pointing out the limitation of representing infinite-dimensional RKHSs. The comment provides a detailed explanation of why this claim is not accurate, making it clear and specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges a claim made in the paper regarding the ability of neural networks to represent infinite-dimensional RKHSs. The reviewer provides a specific example of RBF kernels and their infinite-dimensional representation, which is widely accepted in the field. This logical reasoning and reference to common knowledge supports the claim that the original statement is not accurate. The comment is fully verifiable, as it provides a clear and robust justification for the claim.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific claim made in the paper regarding the ability of neural networks to represent infinite-dimensional RKHSs, which is considered trivially not true. The reviewer provides a detailed explanation, using a well-known example of RBF kernels and their infinite-dimensional representation, to challenge the claim. This feedback is highly helpful as it not only points out a potential misconception but also offers a clear and actionable suggestion for the authors to clarify the limitation of representing infinite-dimensional RKHSs in practice. By addressing this issue, the authors can improve the accuracy and clarity of their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the novelty of the proposed method, noting that the key idea of representing marginal scores as the expectation of scores conditioned on inputs is well-known. It suggests that the authors should conduct a thorough literature review to identify additional works that use this property. While the comment implies that the authors should conduct a literature review, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a literature review to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the novelty of the proposed method, noting that the key idea is well-known and has been used in prior works. The comment provides specific references to the original denoising score matching objective and score-interpolation, which further clarifies the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not well-positioned in literature because the key idea of representing marginal scores as the expectation of scores conditioned on inputs is already known. The reviewer supports this claim by referencing specific works, such as the original denoising score matching objective and score-interpolation, which have used this property. This provides a clear and robust justification for the claim, making it fully verifiable. Therefore, the comment is labeled as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the proposed method, noting that the key idea of representing marginal scores as the expectation of scores conditioned on inputs is already known. It provides specific references to the original denoising score matching objective and score-interpolation, which have used this property. This feedback is valuable as it highlights a potential gap in the literature review and encourages the authors to conduct a thorough literature review to identify additional works that use this property. By addressing this issue, the authors can enhance the novelty and impact of their work. However, the comment could be more helpful if it offered suggestions on how to conduct the literature review or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides a clear direction for improvement but lacks detailed guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the technical contribution is limited, as it does not involve significant technical innovation or extension beyond a typical model for the cross-domain recommendation setting. However, it does not provide any specific guidance or suggestions on how the authors might improve their technical contribution or what aspects of the typical model could be extended. The comment lacks actionable details, leaving the authors uncertain about how to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technical contribution of the paper, stating that it is limited and does not involve significant technical innovation or extension beyond a typical model for the cross-domain recommendation setting. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in detailing the issue with the technical contribution, but without explicit references, it remains weakly grounded. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the technical contribution is limited, as it does not involve significant technical innovation or extension beyond a typical model for the cross-domain recommendation setting. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the technical contribution of the paper, stating that it is limited and does not involve significant technical innovation or extension beyond a typical model for the cross-domain recommendation setting. This feedback highlights a potential weakness in the paper\\'s originality and contribution, which could be a significant concern for the authors. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance their technical contribution. Without actionable advice or detailed feedback, the authors are left without a clear path forward, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the specific components of the approach are not novel, as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. It also notes that the sampling strategy is similar to epsilon-greedy and the same as that in BRP-NAS. Additionally, the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. While the comment identifies specific areas that are not novel, it does not provide explicit guidance on how the authors should address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should make their approach more novel or differentiate it from existing work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"specific components of the approach,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by pointing out that the weak predictors used are not novel and that the sampling strategy is similar to epsilon-greedy and BRP-NAS. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the specific components of the approach are not novel, as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. The reviewer also notes that the sampling strategy is similar to epsilon-greedy and the same as that in BRP-NAS. Additionally, the reviewer states that the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. This claim is supported by references to specific works and a comparison to existing results, providing a logical basis for the critique. However, the comment could be strengthened by including more detailed comparisons or specific examples from the referenced works. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific components of the approach that are not novel, such as the use of MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. It also points out that the sampling strategy is similar to epsilon-greedy and the same as that in BRP-NAS. Additionally, the comment notes that the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. This feedback highlights areas where the approach lacks novelty and differentiates it from existing work. However, the comment could be more helpful by suggesting ways to improve the novelty or by providing specific suggestions for differentiating the approach. Overall, the comment is somewhat helpful as it identifies areas for improvement but lacks detailed guidance on how to address them.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the calculation of precision/recall/F1-score for a 4-class classification of breast density and suggests providing AUC results for breast cancer detection. While the comment implies that the authors should include these details in their paper, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these details. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"4-class classification of breast density\" and \"breast cancer detection,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for clarification on how precision/recall/F1-score were calculated and suggests providing AUC results for breast cancer detection. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and questions seeking clarification. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the calculation of precision/recall/F1-score for a 4-class classification of breast density and suggests providing AUC results for breast cancer detection. This feedback is clear and actionable, as it prompts the authors to clarify their methodology and provide additional data for comparison. By addressing these points, the authors can enhance the transparency and comprehensiveness of their work. However, the comment could be more helpful if it provided specific guidance on how to present these results or suggested additional metrics to consider. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the creation of the dataset is optional and that the Kialo dataset, which is well-studied in the community, provides pairs of short claims and their counters. The reviewer also notes that the Kialo dataset is cleaner than the one created by the authors and can be used as extra data to learn from. While the comment implies that the authors should consider using the Kialo dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should use the Kialo dataset rather than being directly told to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is well-studied in the community. It also notes that the Kialo dataset provides pairs of short claims and their counters and is cleaner than the dataset created by the authors. However, the comment does not specify which part of the paper discusses the dataset creation, making it weakly grounded. The comment is specific in suggesting that the Kialo dataset could be used as extra data to learn from, providing clear guidance on what could be improved. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is well-studied in the community. The reviewer claims that the Kialo dataset provides pairs of short claims and their counters and is cleaner than the dataset created by the authors. This claim is somewhat verifiable as it provides a logical reasoning for why the Kialo dataset might be preferable, but it lacks specific examples or references to support the claim fully. The authors would need to infer the benefits of using the Kialo dataset, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is well-studied in the community and provides pairs of short claims and their counters. The reviewer also notes that the Kialo dataset is cleaner than the one created by the authors and can be used as extra data to learn from. While the comment identifies a potential source of data that could be used, it lacks specific guidance on how to incorporate this data into the paper or why it would be beneficial. The feedback is somewhat helpful as it points out a potential resource for the authors to consider, but it could be more actionable and detailed to fully support the authors in improving their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit feedback on the novelty and effectiveness of the proposed modification to the transformer. It points out that the cross-layer modification does not bring significant insight in the context of machine learning and that the self-cross attention brings limited improvement. The reviewer suggests that the main improvements come from using a naive transformer rather than the proposed modification. This feedback is clear and provides specific guidance on what the authors should consider when evaluating the impact of their proposed modification. The action is explicit and concrete, as the authors know exactly what to address and how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Transformer\" and the \"cross-layer\" modification, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the cross-layer modification does not bring much insight in the context of machine learning and that the self-cross attention brings limited improvement. The comment further suggests that the main improvements come from using a naive transformer instead of the proposed modification. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed modification to the transformer, specifically the cross-layer modification, does not bring significant insight in the context of machine learning. It also questions the significance of the self-cross attention improvement, suggesting that the main improvements come from using a naive transformer instead of the proposed modification. The comment provides some reasoning by comparing the transformer with other methods, but it lacks specific examples or references to support the claim about the lack of novelty or the limited improvement. This makes the claim somewhat verifiable, as it provides some reasoning but requires further elaboration to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed critique of the proposed modification to the transformer, specifically the cross-layer modification. It points out that the modification does not bring significant insight in the context of machine learning and that the self-cross attention brings limited improvement. The reviewer suggests that the main improvements come from using a naive transformer instead of the proposed modification. This feedback is clear and actionable, as it identifies specific areas where the authors need to reconsider their approach and potentially reevaluate the significance of their contribution. However, the comment could be more helpful if it provided suggestions on how to address these issues or what alternative approaches might be considered. Overall, the comment is mostly helpful as it guides the authors toward a more robust evaluation of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to discuss a previous work on joint error for UDA, specifically mentioning \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML2019. It also suggests that the authors should illustrate the relationship between this work and their proposed method, as well as explain why their method is better. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what steps to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML2019, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely discussing the relationship between the previous work and the proposed method, as well as why the proposed method is better. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors make a claim about the lack of research on joint error for UDA, but this assertion is challenged by the reviewer who points out that a previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" has already addressed this issue. The reviewer suggests that the authors should discuss this work and its relationship to their proposed method, as well as explain why their method is better. This claim is supported by the reference to a specific work, providing a clear and logical basis for the critique. Therefore, the comment is categorized as 4: Mostly Verifiable, as it offers a logical reasoning and specific reference to support the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific claim made by the authors regarding the lack of research on joint error for UDA. It challenges this claim by pointing out that a previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" has already addressed this issue. The comment suggests that the authors should discuss this work and its relationship to their proposed method, as well as explain why their method is better. This feedback is clear and actionable, providing the authors with a specific direction for improvement by suggesting they engage with existing literature and provide a more comprehensive comparison. However, the comment could be more helpful if it offered additional guidance on how to effectively integrate this discussion into the paper. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods, noting that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer suggests that the superiority of the proposed method may be due to the larger-scale datasets. While the comment identifies an issue with the comparison, it does not provide explicit guidance on how to address this concern. The authors are left to infer that they should consider the impact of dataset size on performance and possibly adjust the comparison to be more fair. The action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison with state-of-the-art (SOTA) methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods, suggesting that the superiority of the proposed method may be due to the larger-scale datasets. The comment provides a logical reasoning by pointing out that the scale of datasets can impact accuracy, which is a common understanding. However, it lacks specific examples or references to support the claim that the dataset size is the sole factor contributing to the superiority. This makes the claim somewhat verifiable, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison with state-of-the-art (SOTA) methods. It points out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer suggests that this difference in dataset scale may impact the accuracy of the comparison. While the comment highlights an important consideration, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the fairness of the comparison. The feedback is somewhat helpful as it directs the authors\\' attention to a potential problem but lacks actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while several curriculum learning methods have been discussed in Section 1, the need for designing a new method for text graphs is not justified. It also notes the absence of a discussion on the research gap, such as why existing methods cannot be applied. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the research gap should be discussed. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the need for justification regarding the need for a new curriculum learning method for text graphs, as well as the absence of a discussion on the research gap. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the need for designing a new curriculum learning method for text graphs is not justified, as existing methods cannot be applied. However, the comment lacks specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the need for designing a new curriculum learning method for text graphs. It points out that the authors have discussed several curriculum learning methods in Section 1 but have not justified the need for a new method specifically for text graphs. The comment highlights a potential research gap and suggests that the authors should discuss the reasons why existing methods cannot be applied to text graphs. This feedback is clear and actionable, as it directs the authors to address a specific area of concern in their draft. However, it could be more helpful if it provided examples or references to existing methods that might be relevant to the text graphs. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific suggestion for the authors to use powerful pre-trained language models, such as BERT and XLNet, as the base encoder for all methods when dealing with domain adaptation in the NLP field. It suggests comparing the efficacy of the transfer parts instead of using the simplest n-gram features. While the comment implies that the authors should make this change, it does not explicitly instruct them to do so. The action is concrete, as it specifies the exact change needed, but it is somewhat vague due to the lack of detailed guidance on how to implement this suggestion. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"domain adaptation in the NLP field,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for the authors to use powerful pre-trained language models, such as BERT and XLNet, as the base encoder for all methods when dealing with domain adaptation. The comment further specifies that the authors should compare the efficacy of the transfer parts instead of using the simplest n-gram features. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that powerful pre-trained language models, such as BERT and XLNet, can overcome domain-shift problems in the NLP field. The comment provides a logical reasoning by suggesting that using these models as the base encoder would be beneficial for domain adaptation. However, the comment lacks specific examples or references to support the claim that these models are particularly effective in this context. While the suggestion is logical, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for the authors to use powerful pre-trained language models, such as BERT and XLNet, as the base encoder for all methods when dealing with domain adaptation in the NLP field. It suggests that this approach would overcome domain-shift problems to some extent and offers a clear direction for improvement. By recommending the use of these models, the comment provides a concrete and valuable piece of feedback that can help the authors enhance the effectiveness of their methods. However, the comment could be more helpful if it included additional details or examples on how to implement this suggestion effectively. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the quantitative evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It suggests that a quantitative comparison on the final outputs would be more convincing. While the comment implies that the authors should conduct a quantitative comparison on the final outputs, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a quantitative comparison on the final outputs. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the quantitative evaluation results, noting that they only reflect middle outputs rather than the final outputs. The comment further suggests a potential solution by asking if it is possible to conduct a quantitative comparison on the final outputs. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the quantitative evaluation results in Figure 3 only reflect middle outputs and not the final outputs, which is a critique of the evaluation methodology. The reviewer suggests that a quantitative comparison on the final outputs would be more convincing. However, the comment lacks specific examples or detailed reasoning to support why the current evaluation is insufficient. Without additional context or evidence, the claim is somewhat verifiable, as it highlights a potential issue but does not fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the quantitative evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It suggests that a quantitative comparison on the final outputs would be more convincing to confirm ModelAngelo's superiority to competitors. This feedback is clear and actionable, as it provides a concrete suggestion for improving the evaluation methodology and making the results more robust. However, the comment could be more helpful if it offered additional guidance on how to conduct such a comparison or provided examples of how it might be done. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several areas where the paper lacks detail, specifically regarding the techniques used and the reproducibility of the results. It highlights several specific questions that need to be addressed, such as the sparsification process, landmark generation, and the number of landmarks used. The comment also mentions the importance of extracting landmark features and achieving shape invariance. While the comment provides a clear list of questions that need to be answered, it does not explicitly instruct the authors on how to address these issues. The actions are concrete, but the comment could be more helpful if it included suggestions on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the \"techniques\" and \"result,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it details the specific questions that need to be answered, such as the sparsification process, landmark generation, and the number of landmarks used. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several questions about the lack of detail in the paper, specifically regarding the techniques used and the reproducibility of the results. It highlights several areas that are unclear, such as the sparsification process, landmark generation, and the number of landmarks used. The reviewer also questions how to achieve shape invariance. These questions are logical and relevant, as they pertain to the methodology and results sections of the paper. However, the comment does not provide specific examples or references to support the claims, which would make it more verifiable. Therefore, the comment is somewhat verifiable, as it provides a clear rationale but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas where the paper lacks detail and clarity, particularly regarding the techniques used and the reproducibility of the results. It highlights specific questions that need to be addressed, such as the sparsification process, landmark generation, and the number of landmarks used. The comment also questions how to achieve shape invariance and provides a clear list of areas that need further explanation. This feedback is actionable and offers a comprehensive list of improvements that could enhance the clarity and comprehensibility of the paper. However, the comment could be more helpful if it provided suggestions on how to address these questions or offered additional guidance on how to improve the paper. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the utility-based approach used in FIITED, specifically the risk of bias due to temporary high utility scores for recent chunks. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. The comment lacks guidance on how the authors might address this issue or what specific changes they should consider to mitigate bias. As a result, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the utility-based approach used in FIITED, specifically the potential bias introduced by basing eviction decisions solely on utility scores. However, it does not specify which part of the paper discusses this approach or where the issue is located. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in identifying the potential bias issue but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential bias introduced by basing eviction decisions solely on utility scores. It provides a specific example of how temporary high utility scores for recent chunks might lead to premature evictions of other valuable chunks. This claim is somewhat verifiable as it logically explains the potential issue and provides an example to illustrate the problem. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that have encountered similar issues. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the utility-based approach used in FIITED, specifically the risk of bias due to temporary high utility scores for recent chunks. It provides a specific example of how this might lead to premature evictions of other valuable chunks. This feedback is valuable as it highlights a potential flaw in the methodology that the authors may not have considered. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or mitigate the bias. Overall, the comment is somewhat helpful as it provides insight into a potential weakness but lacks actionable guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the first paragraph of the Introduction is not central to the paper and provides little valuable information. It suggests that the introduction should focus on drift, which is the core focus of the paper. The comment provides a clear and direct action for the authors to take, which is to revise the introduction to better align with the paper\\'s focus. The feedback is specific and concrete, giving the authors a clear idea of what changes to make to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is problematic: the lack of mention of drift in the introduction, which is central to the paper\\'s focus. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first paragraph of the Introduction is not central to the paper and provides little valuable information. This claim is somewhat verifiable as it logically argues that the introduction should focus on drift, which is the core focus of the paper. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the reasoning behind the claim and might find it challenging to fully understand the basis of the critique without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The comment suggests that this paragraph provides little valuable information to readers and recommends focusing on drift. This feedback is clear and actionable, as it directs the authors to revise the introduction to better align with the paper\\'s focus. However, the comment could be more helpful if it provided suggestions on how to integrate the discussion of drift into the introduction or offered specific guidance on how to structure the revised paragraph. Overall, the comment is mostly helpful as it effectively points out a critical issue and provides a direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity regarding the performance of the different parts of the framework and the quantitative experiments and comparisons with other algorithms. It suggests that the results section lacks detailed explanations of the individual parts and their performance compared to other solutions. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to address these issues, such as suggesting particular experiments or comparisons to include. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the methodology and experimental aspects of the paper, specifically mentioning the lack of quantitative experiments and comparisons with other algorithms. It also highlights the need for more detailed explanations of the framework's individual parts and their performance compared to other solutions. While the comment does not explicitly mention a specific section or figure, the authors can infer that it relates to the methodology or experimental sections. The comment is specific in detailing what needs to be addressed, such as the need for quantitative experiments and comparisons, and the need for more detailed explanations of the framework. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks clarity regarding the performance of the different parts of the framework and the quantitative experiments and comparisons with other algorithms. It suggests that the results section lacks detailed explanations of the individual parts and their performance compared to other solutions. The reviewer provides some reasoning by mentioning the need for quantitative experiments and comparisons, which adds some level of support to the claim. However, the comment could be strengthened by providing specific examples or references to similar studies that demonstrate the importance of these elements. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of clarity regarding the performance of the different parts of the framework and their contribution to the final result. It points out that while the framework can yield promising visual stimuli results, it lacks quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones. The comment highlights specific areas for improvement, such as the need for quantitative experiments and comparisons, and more detailed explanations of the framework's individual parts and their performance. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing the clarity and comprehensiveness of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the captioning experiment should compare results on the official COOC leaderboard on the blind test set, rather than using a non-official test or development set. It also recommends that the paper should compare its results to those on the leaderboard, specifically mentioning that [5,17] have won the challenge and been evaluated on the blind test set. Additionally, the comment suggests that the paper should compare its results to other approaches that have been proposed since the work was published, as these have significantly improved. While the comment provides explicit actions for the authors to take, such as referencing the official leaderboard and comparing results, it lacks specific guidance on how to implement these changes. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"captioning experiment\" and the specific issue with comparing results on an \"official COOC leader board on the blind test set.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need to compare results on the official COOC leaderboard and the importance of including comparisons to other approaches that have been published since the work was conducted. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the captioning experiment should compare results on the official COOC leaderboard on the blind test set, rather than using a non-official test or development set. The reviewer supports this claim by referencing external sources, such as the COOC leaderboard and specific publications that have won the challenge and been evaluated on the blind test set. This provides a clear and robust justification for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback on the captioning experiment, suggesting that the paper should compare results on the official COOC leaderboard on the blind test set, rather than using a non-official test or development set. It also recommends that the paper should compare its results to those on the leaderboard, specifically mentioning that [5,17] have won the challenge and been evaluated on the blind test set. Additionally, the comment suggests that the paper should compare its results to other approaches that have been proposed since the work was published, as these have significantly improved. This feedback is detailed and provides specific guidance on how the authors can enhance the robustness and credibility of their results. However, it could be more helpful if it offered suggestions on how to implement these changes or provided examples of how other papers have addressed similar issues. Overall, the comment is mostly helpful, as it directs the authors to important areas for improvement and provides a clear path for enhancing the quality of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a specific line (L248) where the term \"wrong\" is used and questions its meaning. It suggests that the paper should clarify what is meant by \"good/bad/wrong\" explanations before using these concepts. This feedback provides a clear and concrete action for the authors to take, which is to clarify the meaning of \"wrong\" in the context of the paper. The comment is explicit and provides a specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the meaning of the term \"wrong\" and the use of concepts like \"good\" and \"bad\" explanations. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the meaning of the term \"wrong\" in a specific context and suggests that the paper should clarify what is meant by \"good\" and \"bad\" explanations before using those concepts. This is a request for clarification rather than a claim or opinion, as it does not express an opinion or judgment. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, particularly regarding the use of terms like \"good\" and \"bad\" explanations. It suggests that the authors should clarify the meaning of these terms before using them in the context of the paper. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to enhance the clarity of the paper. However, the comment could be more helpful if it offered suggestions on how to clarify these terms or provided examples of how they might be clarified. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). It explicitly states that the paper should include such a comparison to prove that the schema searched by ELF is better than the schema in Mid Vision Feedback (MVF). This provides a clear and direct action for the authors to take, ensuring that the paper includes the necessary experimental evidence to substantiate its claims. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of experimental demonstration of the contribution points, specifically referring to the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing\u2014the need for a comparison with the image classification result of Mid Vision Feedback (MVF)\u2014and what needs to be included to substantiate the claims made in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically mentioning the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). The reviewer provides a logical reasoning by stating that such a comparison is necessary to prove that the schema searched by ELF is better than the schema in Mid Vision Feedback (MVF). However, the comment does not provide specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a clear rationale but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). This feedback is clear and actionable, as it highlights a critical area where the paper lacks evidence to support its claims. By pointing out the need for a comparison with the image classification result, the comment provides a direct and concrete suggestion for the authors to enhance their experimental section. However, the comment could be more helpful if it offered specific guidance on how to conduct this comparison or what specific metrics should be considered. Overall, the comment is mostly helpful as it effectively directs the authors to a critical area needing improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the originality of the paper, noting similarities to a previous study. It implies that the authors should address whether their work is an extension of the previous study or if it introduces novel contributions. However, the comment does not provide explicit guidance on how to address these concerns or what specific aspects need to be improved. The action is implicit and somewhat vague, as the authors need to infer that they need to justify the originality of their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the originality of the paper, specifically noting similarities to a previous study, \"How Do Nonlinear Transformers Learn and Generalize in In-Context Learning.\" However, it does not specify which part of the paper this concern relates to, such as the introduction, methodology, or results section. The authors can infer that it pertains to the overall structure and content of the paper, but this inference is not as direct as it could be. The comment is specific in detailing the issue of originality, but it lacks full grounding as it does not explicitly mention sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the originality of the paper, noting similarities to a previous study. However, it does not provide specific examples or references to support the claim that the work is merely an extension of the previous study. The comment lacks detailed evidence or reasoning to substantiate the originality concern, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not provide sufficient evidence or justification to support the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the originality of the paper, noting similarities to a previous study. It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. While this feedback highlights a potential issue, it lacks specificity and does not provide actionable guidance on how the authors might address the originality concerns. The comment does not offer suggestions on how to differentiate the paper from the previous work or suggest ways to enhance the novelty of the contributions. As a result, the feedback is somewhat helpful, as it identifies a potential weakness but lacks depth and actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the discussion on the regret and the proof of the method achieving T^{1/2} regret. It does not provide explicit instructions or suggestions for the authors to address this issue, but it implies that the authors should clarify their discussion and proof. The comment is somewhat actionable as it highlights a potential inconsistency but lacks concrete guidance on how to resolve it. The authors can infer that they need to clarify the discussion and proof, but the comment does not provide specific details on how to do so.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 32 - 37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the discussion on the regret and the proof of the method achieving T^{1/2} regret, providing clear guidance on what needs to be clarified or addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the discussion and proof regarding the regret and T^{1/2} regret. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the discussion and proof regarding the regret and T^{1/2} regret. It questions whether the prediction error over the entire horizon T cannot be sublinear, which is an important point for clarity and understanding. However, the comment does not provide specific suggestions or guidance on how the authors might address this inconsistency or clarify their discussion. While it highlights an area for improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the importance of learning long-range dependencies for powerful predictors, specifically in the context of semantic segmentation. It acknowledges that the example in Table 3 shows this happening, but questions whether it is fully required. The reviewer suggests that the truth lies somewhere in between and suggests a discussion about this. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the discussion should be included. The action is implicit and somewhat vague, as the authors can infer that they need to include a discussion but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the importance of learning long-range dependencies for powerful predictors, specifically in the context of semantic segmentation. It provides a specific example by mentioning the visualizations in Table 3, which helps ground the comment. However, it lacks specificity as it does not clearly indicate which part of the paper should include a discussion about the importance of long-range dependencies. The authors can infer that it relates to the discussion or results section, but the comment does not provide detailed guidance on what aspects of the discussion should be included. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the importance of learning long-range dependencies for powerful predictors, specifically in the context of semantic segmentation. The reviewer acknowledges that the example in Table 3 shows this happening but questions whether it is fully required. The comment suggests that the truth lies somewhere in between and suggests a discussion about this. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that learning long-range dependencies is not fully required. This makes the claim somewhat verifiable, as it provides some insight but requires further elaboration for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid point about the importance of learning long-range dependencies for powerful predictors, specifically in the context of semantic segmentation. It acknowledges that the example in Table 3 shows this happening but questions whether it is fully required. The comment suggests that the truth lies somewhere in between and suggests a discussion about this. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the discussion should be included. This limits the comment\\'s helpfulness, as it provides insight but does not offer actionable steps for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the definition of $e_l$ in Equation (3) and points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also notes that this dependence affects the constant factor of the required feature size. The comment suggests that this may indicate a weakness in the proposed approaches or theoretical results. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take. The feedback is somewhat actionable as it highlights a potential problem but lacks concrete instructions on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. (3)\" and \"Corollaries 1, 2 and 3, and Theorem 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the exponential dependence on the diameter $M$ of the domain of data and how this affects the constant factor of the required feature size. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the definition of $e_l$ in Equation (3) and points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It suggests that this dependence affects the constant factor of the required feature size, which could indicate a weakness in the proposed approaches or theoretical results. The comment provides a logical reasoning by pointing out the exponential dependence on $M$ and its impact on the constant factor, but it lacks specific examples or references to support the claim that this dependence indicates a weakness. Therefore, the comment is somewhat verifiable, as it provides a logical argument but requires further evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of definition for $e_l$ in Equation (3) and the exponential dependence of the results on the diameter $M$ of the domain of data. It points out that this dependence affects the constant factor of the required feature size, which could indicate a weakness in the proposed approaches or theoretical results. The comment highlights a potential problem in the theoretical basis of the paper, prompting the authors to clarify this issue and address the implications. However, the comment could be more helpful if it provided suggestions on how to resolve this issue or what specific steps the authors should take to address it. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the poor long-range modeling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. However, it also suggests that the poor performance could be due to oversmoothing, which is observed in the context of very deep graph networks. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this problem. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate oversmoothing as a potential cause of the poor performance. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the poor long-range modeling ability of DGNs, specifically attributing it to oversquashing and vanishing/exploding gradients. It also suggests that the poor performance could be due to oversmoothing, which is observed in the context of very deep graph networks. However, the comment does not specify which part of the paper discusses the long-range modeling ability or the oversmoothing phenomenon. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing the potential causes of the poor performance, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the poor long-range modeling ability of DGNs is attributed to oversquashing and vanishing/exploding gradients, but also suggests that the poor performance could be due to oversmoothing. The comment provides some support by referencing a source, \"Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning, In AAAI\\u002718,\" which discusses oversmoothing in the context of very deep graph networks. However, the comment lacks specific examples or detailed explanations of how oversmoothing might affect the performance, making it somewhat verifiable. The authors would need to further explore the issue and potentially conduct additional experiments to fully understand and address the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the long-range modeling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that the poor performance could be due to oversmoothing, which is observed in the context of very deep graph networks. While the comment highlights a potential cause of the poor performance, it does not provide specific suggestions or guidance on how the authors might address this issue or investigate oversmoothing further. The feedback is somewhat helpful as it points out a potential problem but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific guidance on how the authors should clarify this issue or what aspects of the formulation are unclear. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors without a clear path to address the feedback. As a result, the action is vague and not actionable, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the problem formulation is unclear in the statement and introduction examples, but it does not specify which parts of the paper are unclear or where the problem lies. Without explicit references to sections or examples, the authors cannot confidently determine where to focus their revisions. The comment is not grounded, as it lacks specificity regarding what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact areas of confusion. Without specific references or detailed explanations, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks specificity and does not provide actionable guidance on how the authors might clarify or improve the formulation. Without detailed suggestions or examples, the authors are left without a clear path to address the feedback. Therefore, the comment is barely helpful, as it points out a potential weakness but does not offer concrete steps for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of grouping for quantization, specifically questioning why per-tensor and per-channel grouping is used instead of finer grouping. While the comment implies that the authors should consider finer grouping, it does not provide explicit guidance on how to implement this change or what specific benefits it might offer. The action is implicit and somewhat vague, as the authors need to infer that they should consider finer grouping. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of grouping for quantization, specifically questioning why per-tensor and per-channel grouping is used instead of finer grouping. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this choice is discussed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in its question about the choice of grouping, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of grouping for quantization, specifically questioning why per-tensor and per-channel grouping is used instead of finer grouping. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why finer grouping might be preferable. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of grouping for quantization, specifically questioning why per-tensor and per-channel grouping is used instead of finer grouping. This feedback prompts the authors to consider a different approach that could potentially improve the quantization process. However, the comment lacks depth and does not provide specific guidance or examples on how finer grouping might be beneficial or how it could be implemented. While it identifies a potential area for improvement, the lack of detailed feedback limits its usefulness. Therefore, the comment is somewhat helpful, as it provides a direction for further exploration but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"epsilon-greedy exploration\" in the context of the proposed strategy. It does not provide explicit guidance or suggestions on how the authors should address this issue, but it implies that the authors should clarify the meaning of \"epsilon-greedy exploration\" in their methodology. The comment is somewhat actionable as it highlights a potential area of confusion, but it lacks concrete instructions on how to clarify the explanation. Therefore, the authors can infer that they need to provide more detailed information about the exploration strategy, but the action is not explicitly stated.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"epsilon-greedy exploration\" in the context of the proposed strategy, providing clear guidance on what needs to be clarified. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the meaning of \"epsilon-greedy exploration\" in the context of the proposed strategy. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"epsilon-greedy exploration\" in the context of the proposed strategy, which is a clear indication of a lack of clarity in the paper. However, it does not provide any suggestions or guidance on how the authors might clarify this point or improve the explanation. While it identifies a potential area of confusion, it lacks actionable feedback that would help the authors address the issue. Therefore, the comment is somewhat helpful as it points out a weakness but does not offer specific guidance for improvement, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed methodology, suggesting that it may only show meaningful performance gains on bit-serial accelerators. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. The comment lacks guidance on how the authors might address this limitation or what steps they could take to broaden the applicability of their methodology. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the potential limitation of the proposed methodology, suggesting that it may only show meaningful performance gains on bit-serial accelerators. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the applicability of the methodology to most existing ML accelerators, which tend to use bit-parallel fixed-point numbers. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that dynamic precision control during training might only show meaningful performance gains on bit-serial accelerators, which is a specific observation. However, the comment lacks supporting evidence or detailed reasoning to substantiate this claim. It does not provide specific examples or references to studies that have demonstrated this limitation, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered borderline verifiable, as it provides a suggestion but lacks sufficient evidence to fully support it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed methodology, suggesting that it may only show meaningful performance gains on bit-serial accelerators. This is a valuable observation that could guide the authors in refining their methodology or considering its applicability to other types of accelerators. However, the comment lacks specific suggestions or actionable advice on how the authors might address this limitation or broaden the applicability of their work. While it highlights an important area for consideration, it does not provide detailed guidance or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Equation 12 is confusing and suggests explaining the network model in Section 4.2 with equations. It also references external works for further clarification. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are given guidance on what needs to be improved but not detailed steps on how to implement those improvements. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 12\" and \"Sec. 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the confusion regarding the reward and the network model explanation. The references to external works provide additional context and guidance for the authors. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of Equation 12 and suggests that explaining the network model in Section 4.2 with equations would improve clarity. It references external works for further clarification, which provides some basis for the claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the references provide some context, the comment could be strengthened by offering more detailed explanations or examples of how the equations could be clarified. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the reward calculation in Equation 12. It suggests that the authors should clarify where the reward comes from at each trial and whether one of the r_i is taken from Equation 11. Additionally, it recommends improving the clarity of the network model explanation in Section 4.2 by using equations. While the comment provides clear guidance on areas for improvement, it could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the feedback is mostly helpful as it directs the authors to specific areas needing clarification and improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the idea is not enough, and that the new metric and method are straightforward. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or make the method less straightforward. Without actionable advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the idea is not enough, and that the new metric and method are straightforward. However, it does not specify which part of the paper this critique pertains to, such as a particular section, table, or figure. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in its critique of the novelty and straightforwardness of the new metric and method, but without explicit references, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the idea is not enough, and that the new metric and method are straightforward. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the novelty of the idea is not enough, and that the new metric and method are straightforward. However, it does not provide specific feedback or suggestions on how the authors might enhance the novelty or complexity of their work. Without actionable advice or guidance, the comment lacks utility for the authors in improving their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model description could be improved by providing a more detailed generative process and presenting it in separate steps for better understanding. It also recommends reducing the number of symbols and using a notation table. While the comment provides specific suggestions for improvement, it lacks explicit instructions on how to implement these changes. The authors are left to infer that they should make these improvements, but the lack of concrete guidance on execution makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the model description could be improved by providing a more detailed generative process and presenting it in separate steps for better understanding. It also recommends reducing the number of symbols and using a notation table. However, the comment does not specify which part of the paper these suggestions pertain to, such as sections or figures, making it weakly grounded. The comment is specific in detailing what needs to be improved, but without explicit references, the authors may struggle to identify the exact areas that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the model description could be improved by providing a more detailed generative process and presenting it in separate steps for better understanding. It also recommends reducing the number of symbols and using a notation table. While the comment provides a logical reasoning for the need to improve the model description, it lacks specific examples or references to support the claim that the current presentation is unclear or inadequate. This makes the claim somewhat verifiable, as the authors would need to infer the specific improvements needed based on the general suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the model description, suggesting that the generative process could be presented in more detail and in separate steps for better understanding. It also recommends reducing the number of symbols and using a notation table, which could enhance the clarity of the presentation. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific examples or guidance on how to implement these improvements. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should motivate the \"Why\" (i.e., the rationale for why the presented information is important). However, it does not provide explicit guidance on how to achieve this motivation or what specific aspects should be addressed. The action is implicit and vague, as the authors are left to infer that they need to provide a rationale but without detailed instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from motivating the \"Why\" (i.e., the rationale for why the presented information is important). However, it does not specify which part of the paper this suggestion pertains to, leaving the authors to infer that it relates to the introduction or motivation section. The comment is specific in its suggestion to provide a rationale, but it lacks grounding as it does not identify a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from motivating the \"Why\" (i.e., the rationale for why the presented information is important). However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this motivation is necessary or how it would enhance the paper. Without specific guidance or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper could benefit from motivating the \"Why\" (i.e., the rationale for why the presented information is important). While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how to achieve this motivation or what aspects of the paper need to be addressed. The comment is vague and does not offer detailed suggestions or examples, making it barely helpful for the authors. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including the claim that the proposed approach does not outperform or is worse than Decouple [Kang et al.] for overall performance. It also points out that Table 5 shows a trade-off between head and tail categories but does not fully investigate the trade-off for baselines. The reviewer suggests that the authors should investigate the trade-off for baselines, such as by changing hyperparameters in Decouple [Kang et al.]. This feedback provides a clear and explicit action for the authors to take, which is to investigate the trade-off for baselines. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5\" and \"Decouple [Kang et al.],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the comparison to Decouple [Kang et al.] and suggests investigating the trade-off for baselines. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed approach does not outperform or is worse than Decouple [Kang et al.] for overall performance, and it provides a specific example of this by referencing Table 5. The comment also suggests that the trade-off between head and tail categories has not been fully investigated for the baselines, specifically by changing hyperparameters in Decouple [Kang et al.]. This provides a logical reasoning and specific examples to support the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific results or studies that demonstrate the potential improvement of Decouple [Kang et al.] with different hyperparameters. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also highlights a trade-off between head and tail categories that has not been fully investigated for baselines, specifically by changing hyperparameters in Decouple [Kang et al.]. The comment suggests that the authors should continue this line of work for future submission. This feedback is clear and actionable, providing the authors with specific areas to address and improve upon. By addressing these points, the authors can significantly enhance the quality and readiness of their paper for submission. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation of weak supervision could be improved by addressing the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it questions the realism of the authors\\' generation process, specifically mentioning that the authors\\' embeddings are initialized by averaging artificial tweets. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions to improve the evaluation. The feedback is somewhat actionable as it highlights areas for improvement but lacks detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"weak supervision\" and the \"evaluated tweets,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the realism of the evaluated tweets and the generation process, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the realism of the evaluated tweets and the generation process, suggesting that the prompt may not be entirely realistic. However, the comment lacks specific examples or references to support these claims. It does not provide detailed reasoning or evidence to substantiate the critique, making it difficult for the authors to understand and address the issue effectively. As a result, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the generation process. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it critiques the authors\\' generation process, suggesting that it is not realistic due to the use of artificial tweets for initialization. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it provides insight into potential weaknesses but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a comparison with existing models, but without explicit references to sections or details, the authors may struggle to identify where this information should be integrated. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the ternary potential is the main factor in the performance improvement of the proposed model and recommends comparing it with existing models that use answers as inputs. However, the comment does not provide specific examples or references to support this claim, such as mentioning the specific models or studies that use answers as inputs. Without detailed evidence or references, the claim remains vague and lacks verifiability. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors compare their proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This feedback is somewhat helpful as it identifies a potential area for comparison that could enhance the paper\\'s contribution. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on. While it provides a direction for improvement, it does not offer detailed suggestions or examples, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given that the question model is a bag of words. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what specific changes they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the design choice of trimming questions after the first 10, given that the question model is a bag of words. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the design choice of trimming questions after the first 10, suggesting it is an odd choice given that the question model is a bag of words. However, the comment lacks specific reasoning or evidence to support why this choice is problematic or how it might impact the paper\\'s results or analysis. Without detailed justification or examples, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given that the question model is a bag of words. This feedback highlights a potential issue with the methodology, which could impact the validity or efficiency of the analysis. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or improve their methodology. While it identifies a potential weakness, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\" in Equation (2). While it identifies a specific part of the paper that needs clarification, it does not provide any guidance on how the authors should address this question or what changes should be made to the equation. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (2),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\" in Equation (2). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\" in Equation (2). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\" in Equation (2), which could be a potential source of confusion or misunderstanding in the paper. While it identifies a specific area that requires clarification, it does not provide any guidance or suggestions on how the authors might address this issue or improve the clarity of the equation. The comment is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable feedback. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies specific lines in the SuppMat that should be moved from red to green. This provides clear and direct instructions for the authors to make the necessary changes to their draft. The action is explicit and concrete, as it specifies the exact lines and their corresponding changes, allowing the authors to easily implement the suggested corrections. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the SuppMat, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, providing detailed guidance on which lines should be moved from red to green. Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and requests for clarification, without any subjective opinions, judgments, or suggestions. It does not contain claims or require justification, making it purely descriptive. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific lines in the SuppMat that should be moved from red to green, providing clear and actionable feedback. This guidance is valuable as it allows the authors to correct errors in their draft, ensuring that the SuppMat is accurate and consistent. However, the comment could be more helpful if it explained why these lines were incorrectly labeled in red or provided additional context on the significance of these corrections. Overall, the comment is mostly helpful as it directs the authors to make specific corrections, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of important references, specifically mentioning GFF[1] and EfficientFCN[2], which aim to implement fast semantic segmentation in the encode-decoder architecture. It encourages the authors to conduct a comprehensive comparison with these works. However, the comment does not provide explicit instructions on how to conduct this comparison or what specific aspects to focus on. While it suggests an action, it lacks concrete guidance on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific references, \"GFF[1]\" and \"EfficientFCN[2],\" which are relevant to the paper. It also provides specific guidance by encouraging the authors to conduct a comprehensive comparison with these works. This level of detail allows the authors to accurately identify the parts of the paper that need attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2], which aim to implement fast semantic segmentation in the encode-decoder architecture. The reviewer provides references to these works, which supports the claim by providing specific examples of relevant literature. However, the comment could be strengthened by explaining why these references are important or how they relate to the paper\\'s content. Despite this, the claim is mostly verifiable due to the inclusion of specific references, making it class 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting the absence of important references, specifically mentioning GFF[1] and EfficientFCN[2], which are relevant to the paper\\'s topic. It encourages the authors to conduct a comprehensive comparison with these works, which could enhance the paper\\'s contribution and relevance. While the comment highlights a critical area for improvement, it does not provide detailed guidance on how to conduct the comparison or what specific aspects to focus on. This limits the comment\\'s helpfulness, as it points out a problem but lacks actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the practical performance of the proposed algorithms, specifically mentioning Algorithm 1 and its reliance on Vandermonde matrices. It highlights the potential numerical instability and ill-conditioning issues for large values of $n$ and small values of $\\\\alpha$. The reviewer suggests that the paper would be more convincing if the authors provided experimental results for the proposed algorithms. While the comment identifies a potential issue and suggests an action, it does not provide explicit guidance on how to conduct these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the details of conducting experiments and addressing the concerns. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"Vandermonde matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the potential numerical instability and ill-conditioning issues with Algorithm 1, particularly when $\\\\alpha$ is small, and suggests providing experimental results to address these concerns. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the practical performance of the proposed algorithms, specifically mentioning Algorithm 1 and its reliance on Vandermonde matrices. The reviewer provides a logical reasoning by pointing out that Vandermonde matrices are known to be ill-conditioned and numerically unstable, especially for large $n$ and small $\\\\alpha$. This is a valid concern, as it highlights a potential issue that could impact the algorithm's effectiveness in practice. However, the comment lacks specific examples or references to support the claim about the numerical instability, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the concern but could be strengthened with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential concern regarding the practical performance of the proposed algorithms, specifically mentioning Algorithm 1 and its reliance on Vandermonde matrices. It highlights the potential numerical instability and ill-conditioning issues that could arise for large values of $n$ and small values of $\\\\alpha$. The reviewer suggests that providing experimental results for the proposed algorithms would enhance the paper's credibility. While the comment effectively points out a potential weakness and suggests a way to address it, it could be more helpful if it provided specific guidance on how to conduct these experiments or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the scalability of the proposed NC measure, suggesting that it may not be practical for large-scale datasets like ImageNet. It implies that the authors should consider addressing this scalability issue to enhance the practicality of their work. However, the comment does not provide specific guidance on how to address this issue or what steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to consider scalability but are not given concrete steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the scalability of the proposed NC measure, suggesting that it may not be practical for large-scale datasets like ImageNet. However, it does not specify which part of the paper discusses the NC measure or where the scalability issue is addressed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its concern about scalability but lacks grounding, as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, suggesting that it may not be practical for large-scale datasets like ImageNet. However, the comment lacks specific examples or references to support the claim that the method is not scalable. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the scalability of the proposed NC measure, suggesting that it may not be practical for large-scale datasets like ImageNet. It raises a valid concern about the practicality of the method, which could significantly impact the contribution of the paper. However, the comment lacks specific suggestions or guidance on how to address the scalability issue or what alternative solutions might exist. While it highlights an important area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It points out that in Algorithm 1, the PSA requires the calculation of all flipped previous layer outputs into the current layer, which contributes to the increased computational complexity. The comment explicitly states that a comparison of computation complexity should be included in the experiment part. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be added to their experiment section. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"the PSA method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the computational complexity of the PSA method, noting that it requires the calculation of all flipped previous layer outputs into the current layer. Additionally, it suggests that a comparison of computation complexity should be included in the experiment part. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed PSA method requires more computation than baselines, specifically mentioning that in Algorithm 1, the PSA requires the calculation of all flipped previous layer outputs into the current layer. The comment suggests that a comparison of computation complexity should be included in the experiment part. This claim is somewhat verifiable as it provides a specific example of the increased computational complexity and suggests a direction for improvement. However, it lacks detailed reasoning or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It provides a detailed explanation of the computational complexity, pointing out that in Algorithm 1, the PSA requires the calculation of all flipped previous layer outputs into the current layer. This feedback is clear and actionable, as it highlights a potential weakness in the methodology and suggests a specific area for improvement. By including a comparison of computation complexity in the experiment part, the authors can address this issue and potentially enhance the robustness of their method. Therefore, the comment is highly helpful, as it provides a concrete direction for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific feedback on the font size and suggests improvements, such as making the words in the grey box larger, increasing the size of V_mem, Th_i, and U_i^t, and using a larger font for the \"CTRL\" label. It also points out the need for more detailed comparisons, such as epochs and number of parameters, with other state-of-the-art Transformer designs. While the comment provides explicit actions and concrete details on how to implement these changes, it could be more helpful if it included suggestions on how to present this information effectively. Overall, the comment is mostly actionable as it provides clear guidance on what needs to be improved, but it could be more detailed in its suggestions for execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures, such as \"fig 1\" and \"figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the font size, the \"CTRL\" label, and the need for more detailed comparisons with other state-of-the-art Transformer designs. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides specific feedback on the font size and suggests improvements, such as making the words in the grey box larger and increasing the size of certain labels. It also mentions the need for more detailed comparisons with other state-of-the-art Transformer designs. This feedback is mostly verifiable as it provides clear and actionable suggestions for improvement, supported by logical reasoning. However, the comment could be strengthened by referencing specific examples or studies that demonstrate the importance of these comparisons. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the figures, suggesting improvements such as increasing the font size of certain labels and words in the grey box. It also highlights the need for more detailed comparisons with other state-of-the-art Transformer designs, which could help justify the improved accuracy. The comment is clear and provides concrete suggestions for enhancing the clarity and comprehensiveness of the figures. However, it could be more helpful if it offered suggestions on how to present this information effectively or provided examples of how similar comparisons have been presented in other works. Overall, the comment is mostly helpful as it identifies specific areas for improvement and provides actionable guidance, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that in Table 2, under the leave one out setting, the proposed method should be compared to \"ATA\" in addition to \"LFP\" as ATA is reported to be better than FP according to the results in Table 1. This feedback provides a clear and explicit action for the authors to take, which is to include ATA in the comparison. The comment is specific and provides a concrete suggestion on how to enhance the comparison, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of ATA in the comparison under the leave one out setting. This provides clear guidance on how to improve the table and its analysis. Therefore, the comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that in Table 2, under the leave one out setting, the proposed method should be compared to \"ATA\" in addition to \"LFP\" because ATA is reported to be better than FP according to the results in Table 1. This claim is somewhat verifiable as it provides a logical reasoning for why ATA should be included in the comparison, based on the results in Table 1. However, the comment lacks specific examples or references to support the claim that ATA is indeed better than FP, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison in Table 2, noting that the proposed method is only compared to \"LFP\" under the leave one out setting, despite ATA being reported as better than FP according to the results in Table 1. The comment suggests that including ATA in the comparison would be more convincing. This feedback is clear and actionable, as it provides a specific suggestion for improving the comparison in the table. However, it could be more helpful if it included additional context or reasoning on why ATA is considered a more convincing comparison. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of mathematical definition for certain architectural details, specifically mentioning multi-head attention. It also raises questions about the split arrow in Figure 2 and the use of vectors for keys and values. While the comment highlights areas that need clarification, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they need to provide a formal definition of these concepts, but the comment lacks specific guidance on how to achieve this. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"multi-head attention,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the lack of mathematical definition for certain architectural details, such as multi-head attention, and raises questions about the split arrow in Figure 2. The comment further specifies that it assumes the inputs for the attention layer are query, keys, and values, and asks about the use of vectors for keys and values. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of mathematical definition for certain architectural details, specifically mentioning multi-head attention. It questions the purpose of the split arrow in Figure 2 and assumes it represents the inputs for the attention layer. The reviewer also asks about the use of vectors for keys and values, suggesting that a formal definition would be beneficial. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that these details are missing or unclear. The reasoning is somewhat valid but could be strengthened with more detailed explanations or references. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where the authors could improve the clarity and mathematical definition of their architecture. It points out the lack of mathematical definition for certain architectural details, such as multi-head attention, and questions the purpose of the split arrow in Figure 2. The reviewer also raises a question about the use of vectors for keys and values, suggesting that a formal definition would be beneficial for readers to understand these concepts. While the comment highlights important areas for improvement, it could be more helpful by providing specific suggestions or examples of how to address these issues. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the presentation of the paper is hard to follow for the reviewer. However, it does not provide any specific guidance or suggestions on how the authors could improve the presentation to make it more understandable. The comment lacks actionable details, such as recommending specific changes or improvements, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the presentation of the paper is hard to follow, but it does not specify which part of the paper is particularly challenging to understand. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot pinpoint the exact areas that need improvement. The comment is not grounded, as it does not specify where the issue lies, and it lacks specificity because it does not provide detailed guidance on what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the presentation of the paper is hard to follow. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment states that the presentation of the paper is hard to follow, but it does not provide any specific details or suggestions on how the authors could improve the presentation. Without actionable feedback or guidance, the authors are left without a clear understanding of what aspects of the presentation need attention or how to address them. This lack of specificity and depth makes the comment not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include works such as [] Li, Xiujun, et al. \"End-to-end task-completion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and compare them conceptually to their work. Additionally, the comment recommends a discussion on how their work differs from other chatbox research works, such as [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015). These suggestions are explicit and provide clear actions for the authors to take, such as including relevant references and conducting a comparative analysis. The feedback is concrete and provides detailed guidance on how to enhance the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the work should include references to specific works, such as [] Li, Xiujun, et al. \"End-to-end task-completion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015), and compare them conceptually. It also recommends a discussion on how the work differs from other chatbox research works. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion or comparison sections. The suggestion is specific, as it provides clear guidance on what needs to be included and how it should be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the work should include references to specific works, such as [] Li, Xiujun, et al. \"End-to-end task-completion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015), and compare them conceptually. It also recommends a discussion on how the work differs from other chatbox research works. While the comment provides a logical reasoning for including these references, it lacks specific examples or detailed comparisons to fully substantiate the claim. The suggestion is somewhat verifiable, as it provides a general direction for improvement but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors should include references to specific works, such as [] Li, Xiujun, et al. \"End-to-end task-completion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015), and compare them conceptually. This feedback is valuable as it directs the authors to include relevant references that could enhance their work. Additionally, the comment recommends a discussion on how their work differs from other chatbox research works, which could further strengthen the paper. This guidance is clear and actionable, providing the authors with specific steps to improve their draft. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should clarify the difference between the meta solvers and centralized RL, specifically mentioning a reference to a relevant paper. This provides a clear and direct action for the authors to take, which is to clarify the distinction between these concepts. The comment also offers a specific reference to a relevant paper, which further guides the authors on how to address the issue. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"meta solvers,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the difference between the meta solvers and centralized RL. The reference to the paper \"Learning to communicate with deep multi-agent reinforcement learning, NIPS 2016\" provides additional guidance on how to clarify this distinction. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the meta solvers are centralized controllers, suggesting that the authors should clarify the distinction between them and centralized RL. The reviewer provides a reference to a specific paper, \"Learning to communicate with deep multi-agent reinforcement learning, NIPS 2016,\" which supports the claim by referencing a relevant work that discusses centralized RL. This reference provides a logical basis for the claim and offers a clear example to support the suggestion for clarification. Therefore, the comment is mostly verifiable, as it provides a logical reasoning and a specific reference to support the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential confusion regarding the distinction between the meta solvers and centralized RL, where agents share weights. It suggests that the authors should clarify this distinction, providing a specific reference to a relevant paper. This feedback is clear and actionable, as it guides the authors on how to improve the clarity and understanding of their work. By addressing this issue, the authors can enhance the comprehensibility of their paper, making it more accessible to readers. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the phrase \"non-sequential information such as chunks\" in line 285, asking if \"chunks\" are still considered sequential information. This question implies that the reviewer is seeking clarification or an explanation of the term \"chunks\" in the context of the paper. However, the comment does not provide explicit guidance or suggestions on how the authors should address this confusion. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the term but may not know exactly how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the phrase \"non-sequential information such as chunks\" and asks if \"chunks\" are still considered sequential information. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the phrase \"non-sequential information such as chunks.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the phrase \"non-sequential information such as chunks\" in line 285, questioning whether \"chunks\" are still considered sequential information. This feedback is somewhat helpful as it prompts the authors to clarify a potentially confusing aspect of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address the confusion. To be more helpful, the reviewer could offer alternative phrasing or explain the context in which \"chunks\" might be considered sequential. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about a discrepancy between equation 9 and figure 1, specifically questioning whether the output patches are cropped parts of the input image or masked versions. It also suggests that Figure 1 might be misleading and proposes using bilinear sampling for better results. While the comment identifies a potential issue and provides a suggestion for improvement, it does not explicitly instruct the authors to address this discrepancy or provide detailed guidance on how to implement the proposed solution. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the discrepancy and consider using bilinear sampling. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a concern about a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions. The comment suggests that Figure 1 might be misleading and proposes using bilinear sampling for better results. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions. The reviewer suggests that Figure 1 might be misleading and proposes using bilinear sampling for better results. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim about the misleading nature of Figure 1. The suggestion to use bilinear sampling is somewhat vague without further explanation. Therefore, the comment is somewhat verifiable, as it provides some evidence but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions. It also suggests that Figure 1 might be misleading and proposes using bilinear sampling for better results. This feedback is somewhat helpful as it points out a potential issue with the clarity of the paper\\'s visual representation and provides a suggestion for improvement. However, the comment could be more helpful if it offered more detailed guidance on how to address the discrepancy or clarify the figure. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). It suggests that the idea, co-attention mechanism, and architecture of the paper are similar to those in the previous papers. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their paper. It lacks concrete suggestions or actionable steps for the authors to take, leaving them without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the two papers (Xing and Tsang, 2022a, b), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of technical novelty and comparing the paper to the mentioned papers, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). The comment provides a specific comparison with the papers, noting that the idea, co-attention mechanism, and architecture of the paper are similar to those in the previous works. This provides a logical basis for the claim, but it could be strengthened by including specific examples or references to the similarities in the papers. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that it lacks technical novelty and is similar to two mentioned papers (Xing and Tsang, 2022a, b). While it provides a specific comparison to these papers, it does not offer any actionable suggestions or guidance on how the authors might address this issue or differentiate their work. The comment highlights a potential weakness but does not provide detailed feedback or constructive advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is rated as barely helpful, as it points out a weakness but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of fairness in the comparison between CPEF and PMEF in Figure 3, specifically noting that PMEF lacks a pre-training module. It suggests that the authors should compare CPEF with another pre-trained model, such as ExpertBert, to demonstrate the advantages of the innovative pre-training module design of CPEF. This feedback provides a clear and explicit action for the authors to take, which is to modify the comparison to ensure fairness and clarity. The suggestion is concrete and specific, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"line 529-lin534,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of fairness in the comparison between CPEF and PMEF. The comment suggests that the authors should compare CPEF with another pre-trained model, such as ExpertBert, to showcase the advantage of the innovative pre-training module design of CPEF. This provides a clear and actionable suggestion for improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between CPEF and PMEF is unfair due to the lack of a pre-training module in PMEF. The reviewer suggests that the authors should compare CPEF with another pre-trained model, such as ExpertBert, to ensure fairness and showcase the advantage of the innovative pre-training module design of CPEF. This claim is somewhat verifiable as it provides a logical reasoning for the need to compare CPEF with another pre-trained model, but it lacks specific examples or references to support the claim fully. The suggestion is clear, but the justification could be strengthened with additional evidence or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the fairness of the comparison between CPEF and PMEF in Figure 3, noting that PMEF lacks a pre-training module. It provides a clear and actionable suggestion by recommending that the authors compare CPEF with another pre-trained model, such as ExpertBert, to ensure fairness and showcase the advantages of the innovative pre-training module design of CPEF. This feedback is valuable as it guides the authors on how to improve the fairness and clarity of their comparison, which is crucial for the validity of their findings. However, the comment could be more helpful if it provided additional context or examples of how the comparison with ExpertBert might be conducted or structured. Overall, the comment is mostly helpful as it offers a concrete and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
