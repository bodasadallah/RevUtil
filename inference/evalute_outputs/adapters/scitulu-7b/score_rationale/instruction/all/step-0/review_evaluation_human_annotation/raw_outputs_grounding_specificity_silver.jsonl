{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more analysis around the quality of the collected dataset and the potential noise it might contain. While the comment implies that the authors should conduct additional analysis, it does not explicitly instruct them to do so or provide specific guidance on how to conduct this analysis. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analysis but are not given detailed instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the artificially created dataset and its potential noise, specifically mentioning the \"pristine\" set of tweets and out-of-context images. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that more analysis is needed around the quality of the dataset and the amount of noise it might have. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the dataset might have noise due to the artificial creation process, and it provides a specific example of the \"pristine\" set of tweets that might contain misinformation or out-of-context images. However, the comment lacks specific examples or references to support the claim that the dataset is indeed noisy. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the issue without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset, suggesting that it might contain noise due to its artificial creation process. It provides a specific example of the \"pristine\" set of tweets that might not be pristine enough and could contain misinformation or out-of-context images. This feedback is valuable as it highlights a potential weakness in the dataset that the authors should address. However, the comment could be more helpful if it offered suggestions on how to analyze the dataset or how to mitigate the potential noise. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the description of HIERENC is unclear and suggests that it might introduce noise due to the averaging of multiple contextual representations. However, it does not provide explicit guidance on how to clarify the description or address the issue of noise. The authors are left to infer that they need to clarify the description and possibly reconsider the averaging approach. While the comment identifies a potential problem, it lacks concrete instructions on how to resolve it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of HIERENC, pointing out that the averaging of multiple contextual representations might introduce noise and suggesting that only one instantiation is likely correct. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of HIERENC is unclear and suggests that averaging multiple contextual representations might introduce noise. The reviewer provides a logical reasoning by explaining that only one instantiation is likely correct and that averaging multiple representations could lead to noise. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the reasoning and potential consequences to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the description of HIERENC, noting that the averaging of multiple contextual representations might introduce noise. It provides a logical reasoning that only one instantiation is likely correct, which could lead to noise. This feedback is clear and actionable, as it points out a potential weakness in the description and suggests a possible improvement. However, the comment could be more helpful if it provided specific suggestions on how to clarify the description or address the issue of noise. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the selection of only 10 answers from all correct answers and asks if this affects the underestimation of performance. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification or explanation for their choice. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discuss the selection of 10 answers from all correct answers, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the potential impact of this selection on the underestimation of performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the selection of only 10 answers from all correct answers and its potential impact on performance underestimation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the selection of only 10 answers from all correct answers and asks if this affects the underestimation of performance. This is a relevant question that could prompt the authors to reconsider their methodology or provide additional context to explain their choice. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a potential area for improvement, it does not provide actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests clarification on the splits used for obtaining the ATIS numbers in Table 4. This is a direct and concrete action for the authors to take, as it clearly identifies the specific area that needs clarification. The comment also expresses gratitude for the authors\\' response, which implies that the authors have already addressed this issue. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the splits used for obtaining the ATIS numbers. This provides clear guidance on what the authors need to address to improve the clarity of their work. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests clarification on the splits used for obtaining the ATIS numbers in Table 4. It does not express an opinion, judgment, or suggestion that requires verification. It is a factual request for additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area that requires clarification, namely the splits used for obtaining the ATIS numbers in Table 4. By asking for clarification, the reviewer provides actionable feedback that can help the authors improve the clarity and transparency of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what additional details might be needed. Overall, the comment is somewhat helpful as it directs the authors to a specific area for improvement but lacks depth in its guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the wording in the paper, specifically the use of \"on par or better\" (l.791). It suggests that there may be a cognitive bias among NLP researchers to phrase results in a certain way, and it recommends correcting the wording. However, the comment does not provide specific guidance on how to rephrase the sentence or what alternative phrasing would be more appropriate. While the action is implicit, as the authors can infer that they need to revise the wording, the lack of concrete details makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.791,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording, suggesting that the authors should correct the phrase \"on par or better\" to avoid a cognitive bias among NLP researchers. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a general cognitive bias among NLP researchers to phrase results in a certain way, specifically by mapping instances where they perform worse to \"on par\" and the rest to \"better.\" The reviewer suggests that the wording in the paper should be corrected, but does not provide specific examples or references to support this claim. While the reasoning is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. The authors may find it challenging to fully understand and address the issue without additional context or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the wording in the paper, specifically the use of \"on par or better\" (l.791). It suggests that there may be a cognitive bias among NLP researchers to phrase results in a certain way, which could lead to misinterpretation. The reviewer acknowledges that the experimental results are acceptable, but recommends correcting the wording to avoid this bias. This feedback is somewhat helpful as it points out a specific issue with the language used in the paper, which could be clarified to improve the clarity and accuracy of the results. However, the comment could be more helpful if it provided examples of alternative phrasing or explained why this bias is problematic. Overall, the comment offers some guidance but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of novelty in the paper, specifically noting that adversarial attacks on text have been done on many NLP and image-text models, and that the paper summarizes this work. The reviewer suggests that the only new effort is to apply similar ideas to video-text models. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the novelty or what specific aspects of the paper could be revised to enhance its originality. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a lack of novelty in the paper, specifically mentioning that adversarial attacks on text have been done on many NLP and image-text models, and that the paper summarizes this work. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is considered a lack of novelty, namely the application of similar ideas to video-text models. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks novelty, specifically mentioning that adversarial attacks on text have been done on many NLP and image-text models. The reviewer supports this claim by referencing related work in the paper, which summarizes the existing literature. However, the comment does not provide specific examples or references to the existing work, making it somewhat verifiable. The authors would need to infer the specific works mentioned and potentially conduct additional research to fully understand the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of novelty in the paper, specifically noting that adversarial attacks on text have been done on many NLP and image-text models. It highlights that the paper summarizes existing work in this area and suggests that the only new effort is to apply similar ideas to video-text models. While the comment points out a potential weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is somewhat helpful as it highlights a potential area for improvement, but it lacks actionable advice or detailed insights that could help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how an antecedent is identified when the prediction is a pronoun, and it suggests a method by matching the head of noun phrases. However, it does not provide explicit guidance on how to handle the situation when the head word is not a pronoun. The comment implies that the authors should consider this issue and provide a solution, but it lacks concrete instructions or examples on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to identifying antecedents in the context of a prediction involving a pronoun. It suggests a method by matching the head of noun phrases, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in detailing the issue with identifying antecedents in the context of a pronoun, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about identifying antecedents in the context of a prediction involving a pronoun. It suggests a method by matching the head of noun phrases, but it does not provide any supporting evidence, reasoning, or references to justify why this method might be insufficient or inadequate. The claim lacks detailed explanation or examples, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the methodology proposed by the authors, specifically regarding the identification of antecedents in the context of a prediction involving a pronoun. It suggests a potential solution by matching the head of noun phrases, which is a reasonable approach. However, the comment lacks depth and does not provide detailed guidance on how to implement this solution or address potential limitations. While it points out a relevant issue, the feedback could be more helpful if it included suggestions for further exploration or testing of this approach. Therefore, the comment is somewhat helpful, as it highlights an important area for improvement but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that discussions are required on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to clarify how stable points in the probabilistic metric space are obtained. This provides a clear and direct action for the authors to take, which is to include these discussions in their draft. The comment is specific and provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"joint learning process\" for RNN and CopyRNN, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the convergence of the proposed joint learning process and how stable points in the probabilistic metric space are obtained. This provides clear guidance on what the authors need to clarify or expand upon in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that discussions are required on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to clarify how stable points in the probabilistic metric space are obtained. This claim is somewhat verifiable as it logically suggests that understanding the convergence process is crucial for reproducing results. However, the comment lacks specific examples or references to support the claim, making it somewhat challenging for the authors to fully grasp the importance of this discussion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that discussions on the convergence of the proposed joint learning process are required. This feedback is clear and actionable, as it directs the authors to clarify how stable points in the probabilistic metric space are obtained. By addressing this point, the authors can enhance the clarity and reproducibility of their results. However, the comment could be more helpful if it provided additional guidance on how to structure these discussions or what specific aspects should be covered. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps to take to ensure that the knowledge bases are free from societal biases. Additionally, the comment mentions a preference for attacking implicit offensive texts with reasoning chains but does not provide any context or explanation for this preference. Overall, the comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment mentions a preference for attacking implicit offensive texts with reasoning chains, but this is not directly related to the issue of societal biases. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. While it identifies a relevant area for consideration, it lacks specific guidance or suggestions on how the authors might address this issue or what steps to take to ensure that the knowledge bases are free from societal biases. Additionally, the comment mentions a preference for attacking implicit offensive texts with reasoning chains but does not provide any context or explanation for this preference. Overall, the comment provides some insight but lacks actionable advice, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to describe the traits of the experts and justify why annotation must be carried out by them, outside of its commercial value. It also asks specific questions about the expertise of the annotators, whether annotation differs from what non-experts would do, and if it introduces any linguistic challenges. These questions provide clear guidance on what the authors need to address to improve their draft. The action is explicit and concrete, as it specifies exactly what needs to be added or clarified. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first point, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the description of the traits of the experts and the justification for why annotation must be carried out by them, outside of its commercial value. The comment also raises questions about the expertise of the annotators, whether annotation differs from what non-experts would do, and if it introduces any linguistic challenges. This level of detail provides clear guidance on what the authors need to address to improve their draft, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the expertise of the annotators and the justification for why annotation must be carried out by them, outside of its commercial value. It asks specific questions about the expertise of the annotators, whether annotation differs from what non-experts would do, and if it introduces any linguistic challenges. These questions imply a need for clarification or evidence to support the claim. However, the comment does not provide any supporting evidence or references to substantiate these claims. Therefore, the comment is considered borderline verifiable, as it raises important questions but lacks the necessary evidence or reasoning to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by questioning the authors about the expertise of the annotators and the justification for why annotation must be carried out by them, outside of its commercial value. It raises important questions about the expertise of the annotators, whether annotation differs from what non-experts would do, and if it introduces any linguistic challenges. This feedback is clear and encourages the authors to provide more detailed descriptions and justifications for their methodology, which could significantly improve the clarity and robustness of their work. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of what such descriptions might entail. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and robustness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing solely on other components and models. While the action is implied, it is clear and provides a concrete direction for the authors to take. The comment explicitly states what the authors should do, which is to include examples of the system on actual texts. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including examples of the system on actual texts, rather than focusing solely on other components and models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where examples could be included. Without explicit references, the authors may struggle to identify the exact areas that need attention. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The comment suggests including examples of the system on actual texts, rather than focusing solely on other components and models. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing solely on other components and models. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, which could enhance the understanding and demonstration of the system\\'s capabilities. However, the comment lacks specific guidance on how to implement this suggestion or what specific examples would be most effective. Without additional details or examples, the authors may struggle to fully understand and act upon the feedback. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the use of the Challenge Set (CS) and seeks clarification on its role in the evaluation process. It implies that the authors should provide more information about how the CS is used, whether it is used for augmenting the training material, and the data split used. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the CS. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Challenge Set\" (CS), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how the CS is used, whether it is used for augmenting the training material, and the data split used. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the use of the Challenge Set (CS) in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the use of the Challenge Set (CS) in the paper, specifically inquiring about its role in evaluation and whether it is used for augmenting the training material. It also asks for clarification on the data split used. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential gap in the paper, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the poor performance on nouns and questions the generalizability of the clustering approach to all parts of speech. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment lacks actionable steps or concrete details on how to improve the draft, such as recommending specific analyses or experiments to better understand the gap between the oracle GAP and the clustering approach. As a result, the authors are left without a clear path forward, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance on nouns and the contradiction between the claim of generalizability to all parts of speech and the poor performance on nouns. It also mentions the oracle GAP for PPDBClus and the fact that the performance is not uniform. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the concerns about the performance and the contradiction with the claim of generalizability. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the performance on nouns and questions the generalizability of the clustering approach to all parts of speech. It references the oracle GAP for PPDBClus and the fact that the performance is not uniform, which directly contradicts the claim of generalizability. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed evidence or references makes the claim somewhat verifiable, as it provides a basis for concern but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a concern about the performance on nouns and questions the generalizability of the clustering approach to all parts of speech. It highlights the contradiction between the claim of generalizability and the poor performance on nouns, as well as the fact that the oracle GAP for PPDBClus is higher than most clustering approaches. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s claims and suggests that the authors should investigate the reasons behind the poor performance on nouns. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or what analyses could be conducted to better understand the gap between the oracle GAP and the clustering approach. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the discussion in Section 5.2 is too abstract and does not provide insights into why the new model is better than MH. It explicitly asks for examples of spurious structures to help clarify the discussion. While the comment identifies a specific issue with the abstractness of the discussion, it provides a clear and concrete action for the authors to take by requesting examples of spurious structures. This guidance is explicit and provides a concrete step for the authors to follow, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, which is that it is too abstract and does not provide insights into why the new model is better than MH. The comment also requests examples of spurious structures to help clarify the discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion in Section 5.2 is too abstract and does not provide insights into why the new model is better than MH. The reviewer requests examples of spurious structures to help clarify the discussion. However, the comment lacks specific examples or references to support the claim that the discussion is abstract or unclear. Without additional context or evidence, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstractness of the discussion in Section 5.2, noting that it does not provide insights into why the new model is better than MH. The reviewer requests examples of spurious structures to help clarify the discussion. This feedback is somewhat helpful as it points out a gap in the paper that could be addressed with additional examples or clarification. However, the comment could be more helpful if it provided specific suggestions on how to improve the discussion or what aspects of the model are particularly relevant for comparison. While it highlights an area for improvement, the feedback lacks depth and actionable guidance, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the probabilistic connection is not well-drawn and recommends either formalizing it more or adjusting the language to clarify the connection. This provides a clear and explicit action for the authors to take, either by strengthening the formal basis of the connection or by rephrasing the language to enhance clarity. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the probabilistic connection is not well-drawn and recommends either formalizing it more or adjusting the language to clarify the connection. However, it does not specify which part of the paper this issue pertains to, such as a particular section, figure, or table. The authors can infer that it relates to the discussion of the probabilistic connection, but this inference is not direct. The comment is specific in suggesting how to address the issue, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the probabilistic connection is not well-drawn and suggests that it should be formalized more or clarified in the language. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or examples from the paper to substantiate the critique, making it difficult for the authors to understand the exact issues and how to address them. As a result, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks the necessary detail to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of formalization or clarity in the probabilistic connection. It suggests that the authors either formalize this connection more or adjust the language to clarify it. This feedback is clear and actionable, as it provides a direct path for the authors to improve the draft by either strengthening the formal basis of the connection or rephrasing the language to enhance clarity. However, the comment could be more helpful if it offered specific suggestions on how to formalize the connection or what aspects of the language need clarification. Overall, the comment is mostly helpful as it effectively guides the authors on how to improve the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is explicit in its request for additional evidence, providing a clear action for the authors to take. However, it does not specify what kind of evidence would be sufficient or how to present it, leaving some room for interpretation. Therefore, the comment is mostly actionable, as it identifies a specific area for improvement but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests providing empirical evidence to support the claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what kind of evidence would be sufficient. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in its request for empirical evidence, it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, the comment does not provide any specific reasoning or examples to substantiate this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is clear and actionable, as it identifies a specific area where the paper could be strengthened by providing empirical evidence to substantiate the claim. However, the comment could be more helpful if it provided guidance on what kind of evidence would be most effective or how to present it. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the choice of datasets and the duration of four years for studying style shifts. It suggests that without answers to these questions, it is difficult to understand what the model is capturing. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns. It lacks concrete steps or specific actions for the authors to take, leaving them uncertain about how to improve their draft. Therefore, the comment is somewhat actionable, as it identifies an area for consideration but does not offer detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the choice of datasets and the duration of four years for studying style shifts. However, it does not specify which part of the paper these questions pertain to, such as the methodology or results sections. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment highlights a potential issue with the study, it lacks specificity in identifying where the authors should address these concerns. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the choice of datasets and the duration of four years for studying style shifts, suggesting that it may not be sufficient to capture all style shifts. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the choice of datasets and the duration of four years for studying style shifts. It questions whether four years is sufficient to capture all style shifts and suggests that the authors should provide more information on what kind of style shifts occur during this period. This feedback is somewhat helpful as it prompts the authors to consider the limitations of their dataset choice and to provide more context for their analysis. However, the comment could be more helpful if it offered specific suggestions on how to address these concerns or what additional information might be needed. Overall, the comment provides a valuable insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment acknowledges that the paper is not difficult to follow but points out specific areas that may cause confusion. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to improve clarity or what specific changes should be made to avoid confusion. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not specify which sections or parts of the paper these areas are located in, making it difficult for the authors to pinpoint the exact issues. The comment lacks specificity regarding the areas that need clarification, leaving the authors without clear guidance on how to address the identified issues. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the identified issues. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not provide any detailed guidance or suggestions on how to address these issues or improve clarity. Without actionable feedback or specific examples, the authors are left without a clear path to enhance the readability and comprehensibility of their draft. Therefore, the comment is rated as barely helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the results more accessible or how to improve the technical competency required to understand them. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, it does not specify which part of the paper this issue pertains to, such as the results section or the methodology. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the results require a higher level of technical competency or how to address this issue. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. This feedback highlights a potential weakness in the paper\\'s presentation, as it may not be accessible to a broader audience. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how to address this issue. Without detailed feedback or examples, the authors may struggle to understand and implement the necessary improvements. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the end-to-end system, questioning the conclusion that the direct model is clearly better. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of the amount of data used to train the text disambiguation model compared to the end-to-end system, questioning the conclusion that the direct model is clearly better. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the discrepancy in data usage and the conclusion, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the conclusion that the direct model is clearly better based on the difference in data usage between the direct and end-to-end systems. However, it does not provide specific data or references to support this claim, making it difficult for the authors to understand the basis of the critique. The comment lacks detailed evidence or reasoning to substantiate the claim, making it somewhat verifiable. The authors would need to further explore the data usage and performance differences to fully address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the conclusion drawn about the superiority of the direct model compared to the end-to-end system. It points out that the difference between the two systems is only a few percentage points, which raises questions about the validity of the conclusion. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights an important area for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues with the paper: a lack of motivation for GaRare and a need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. While the comment explicitly states these areas for improvement, it does not provide specific guidance on how to address them. The authors are left to infer that they need to provide more detailed explanations and evidence for GaRare's advantages over GaLore, as well as clarify the process of updating parameters. However, the lack of concrete steps or examples makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This provides clear guidance on what aspects of the paper need improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks motivation for GaRare and provides a specific suggestion for improvement by stating that a more detailed algorithmic presentation is needed, particularly regarding the process of recovering updated parameters from projected gradients. However, the comment does not provide any supporting evidence, examples, or references to substantiate the claim that GaRare lacks advantages over GaLore or that the current algorithmic presentation is insufficient. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the critique without additional guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the paper: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. By pointing out these gaps, the comment provides actionable feedback that can help the authors enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar topics have been presented in other works. Overall, the comment is mostly helpful as it directs the authors toward important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of a reference to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. While the comment identifies a missing link, it does not provide explicit instructions on how to incorporate this reference or what specific aspects of the work should be compared. The action is implicit and somewhat vague, as the authors need to infer that they should include these references to enhance their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific works, \"Continuous Conditional Random Fields [Ristovski 2013]\" and \"Continuous Conditional Neural Fields [Baltrusaitis 2014],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of references to similar work that shares a similar structure and inference capabilities. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the relevance or significance of these works to their paper. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a missing link by pointing out the absence of references to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. This feedback is somewhat helpful as it highlights a potential gap in the literature review that could enhance the authors\\' understanding and comparison of their work. However, the comment could be more helpful if it provided specific examples or references to these similar works, which would guide the authors on how to incorporate them into their analysis. Overall, the comment offers a clear direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the method part of the paper is similar to a related work mentioned in the paper, \"Generating Adversarial Disturbances for Controller Verification.\" It implies that the authors should provide more clarification on this similarity. However, the comment does not explicitly instruct the authors to clarify this point or specify how they should do so. While the action is implied, it is not as clear as it could be, leaving the authors to infer the need for clarification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"method part\" of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by pointing out the similarity to a related work, \"Generating Adversarial Disturbances for Controller Verification,\" and suggests that the authors provide more clarification on this similarity. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the method part of the paper is similar to a related work mentioned in the paper, \"Generating Adversarial Disturbances for Controller Verification.\" However, the comment does not provide specific details or examples from the related work to support this claim. Without additional context or references, the authors may find it challenging to understand the basis of the comparison and address the issue. Therefore, the claim is considered borderline verifiable, as it lacks sufficient evidence or justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential similarity between the method part of the paper and a related work mentioned in the paper, \"Generating Adversarial Disturbances for Controller Verification.\" It suggests that the authors should provide more clarification on this similarity. While the comment highlights an area for improvement, it does not offer specific guidance on how the authors might clarify this issue or what aspects of the method need to be addressed. The feedback is somewhat helpful as it points out a potential weakness, but it lacks depth and actionable suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison with other methods and consider promoting existing methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the proposed method, such as the use of a proposal generator pretrained on MSCOCO and its potential impact on existing class incremental semantic segmentation methods. It also mentions the authors\\' adequate addressing of limitations and potential negative societal impact. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in its inquiry about the fairness of comparison and the potential promotion of existing methods. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about fairness or the potential impact on existing methods. This makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique and potentially conduct additional research to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. While it identifies areas for consideration, it does not provide actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 4 could benefit from a slower development to improve readability. However, it does not provide specific guidance on how to achieve this or what aspects of the section need more development. The comment lacks concrete details on how to implement this suggestion, such as recommending additional content or a different structure. As a result, the authors are left without clear instructions on how to enhance the readability of the section. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is that the section is \"very tersely written\" and could benefit from a slower development for easier readability. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Section 4 is \"very tersely written\" and could benefit from a slower development to improve readability. However, the comment does not provide any specific reasoning or examples to support this claim. It lacks detailed justification or references to similar works that might have addressed this issue, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the writing style of Section 4, noting that it is \"very tersely written\" and could benefit from a slower development to improve readability. While it highlights a potential problem, it lacks specific suggestions or guidance on how to achieve this improvement. The feedback is somewhat helpful as it points out an area for improvement, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback provides clear and concrete actions for the authors to take, making it highly actionable. The comment is specific about what needs to be added and explained, giving the authors a clear path to improve their draft. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the previous question, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the distribution of videos of different lengths within the benchmark and the explanation of how the authors ensured a balanced representation of different video lengths across the 11 categories. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not provide relevant explanations regarding the distribution of videos of different lengths within the benchmark. It suggests that the authors should include a table showing the distribution of video lengths across the dataset and explain how they ensured a balanced representation of different video lengths across the 11 categories. This claim is somewhat verifiable as it logically points out a gap in the paper\\'s explanation and provides a specific suggestion for improvement. However, the comment lacks detailed reasoning or references to support the importance of this explanation or the impact of the distribution on the assessment of reasoning ability and robustness. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of explanation regarding the distribution of videos of different lengths within the benchmark. It suggests that the authors should include a table showing the distribution of video lengths across the dataset and explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback is clear and actionable, providing the authors with a specific and concrete step to improve their draft. By addressing this issue, the authors can enhance the transparency and clarity of their work, which is valuable for improving the paper\\'s comprehensibility and credibility. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the availability of the promised dataset, suggesting that a cautious approach should be taken regarding the contribution until the dataset is publicly accessible. However, it does not provide any explicit or implicit actions for the authors to take in response to this concern. There is no guidance on how to address the issue, such as suggesting ways to make the dataset more accessible or how to mitigate the potential impact of this limitation. As a result, the authors are left without any clear direction on how to proceed with this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the availability of the promised dataset, suggesting that a cautious approach should be taken until the dataset is publicly accessible. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its concern about the dataset availability, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the promised dataset has not yet been made publicly available, suggesting that a cautious approach should be taken regarding the contribution until the dataset is accessible. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment highlights a potential issue with the paper\\'s contribution, specifically the availability of the promised dataset. It suggests that a cautious approach should be taken regarding the contribution until the dataset is publicly accessible. While this is an important point to consider, the comment lacks specific guidance or suggestions on how the authors might address this issue or mitigate the potential impact of the dataset\\'s unavailability. Without actionable advice or detailed feedback, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not provide comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the limited novelty of the proposed method and its similarity to other attentional modules in previous works. It specifically mentions that the group attention design is related to ResNeSt but not discussed in the paper. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should discuss the similarities and differences between their method and previous works, but the comment lacks concrete suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"group attention design\" and \"ResNeSt,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty and the similarity to other attentional modules in previous works, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. The reviewer supports this claim by referencing specific works, such as ResNeSt, and noting that the group attention design is related to these works but not discussed in the paper. However, the comment lacks detailed comparisons or specific examples from these works to fully substantiate the claim. While the references provide some context, the comment could be strengthened with more detailed comparisons or specific examples to fully support the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the novelty of the proposed method, noting that it is too similar to other attentional modules in previous works. It specifically mentions the group attention design and its relation to ResNeSt, which is not discussed in the paper. This feedback is valuable as it highlights a potential weakness in the originality of the work, prompting the authors to address this issue and provide a more thorough comparison with existing methods. However, the comment could be more helpful if it offered suggestions on how to differentiate the method or discuss the similarities and differences with other works. Overall, the comment is mostly helpful as it provides a clear direction for improvement but could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the authors\\' claim of achieving state-of-the-art results on challenging scene text recognition tasks, suggesting that the performance is mainly due to the first step. The reviewer implies that the authors should conduct comparisons experiments with existing detection methods to substantiate their claims. While the comment does not explicitly instruct the authors to conduct these experiments, it provides a clear direction for action. The authors can infer that they need to conduct comparisons to validate their results, making the action implicit but still clear. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the authors\\' claim of achieving state-of-the-art results on challenging scene text recognition tasks, suggesting that the performance is mainly due to the first step. It implies that the authors should conduct comparisons experiments with existing detection methods to substantiate their claims. However, the comment does not specify which part of the paper this claim is made in, nor does it provide details on what specific comparisons should be conducted. While the authors might have an idea of where this claim is made, the lack of explicit grounding and specificity makes it challenging to pinpoint the exact section that needs attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the authors\\' claim of achieving state-of-the-art results on challenging scene text recognition tasks, suggesting that the performance is mainly due to the first step. The reviewer implies that the authors should conduct comparisons experiments with existing detection methods to substantiate their claims. While the comment provides a logical reasoning for the need for such comparisons, it lacks specific examples or references to existing works that could support the claim. This makes the claim somewhat verifiable, as it provides a rationale but requires more detailed evidence or references to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the authors\\' claim of achieving state-of-the-art results on challenging scene text recognition tasks, suggesting that the performance is mainly due to the first step. It implies that the authors should conduct comparisons experiments with existing detection methods to substantiate their claims. While the comment identifies a potential weakness in the paper\\'s claims, it lacks specific guidance on how to conduct these comparisons or what aspects of the experiments should be compared. This limits the comment\\'s helpfulness, as it points out an area for improvement but does not provide detailed instructions on how to address it. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the required implicit call to the Witness oracle is confusing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending clarification or suggesting a specific approach to improve the clarity. As a result, the authors are left without a clear understanding of what steps to take to improve the draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"Witness oracle,\" allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspect of the Witness oracle is confusing or how it could be clarified, leaving the authors with a general understanding of the issue but without detailed guidance on how to address it. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the required implicit call to the Witness oracle is confusing. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the required implicit call to the Witness oracle being confusing. This feedback is somewhat helpful as it points out a potential source of confusion for readers, which could impact the clarity and accessibility of the paper. However, the comment lacks depth and does not provide suggestions on how to clarify or improve the explanation of this concept. Without additional guidance or examples, the authors may struggle to fully address the issue. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the proposed method's inability to handle headpose and questions why the authors cannot condition the headpose parameters in the NeRF beyond facial expression, similar to a previous work. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method. The comment implies that the authors should consider incorporating headpose control into their method, but it lacks concrete steps or detailed instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"headpose,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the method cannot handle headpose and why it cannot be conditioned like a previous work. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the proposed method\\'s inability to handle headpose, noting that a previous work (e.g., Gafni et al. ICCV 2021) is able to control both facial expression and headpose. The reviewer questions why the NeRF method cannot condition the headpose parameters beyond facial expression, similar to the previous work. This claim is somewhat verifiable as it references a specific work, providing some basis for the comparison. However, the comment lacks detailed explanation or examples of how the NeRF method could be adapted to handle headpose, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the proposed method, noting that it cannot handle headpose while a previous work (e.g., Gafni et al. ICCV 2021) is able to control both facial expression and headpose. The comment questions why the NeRF method cannot condition the headpose parameters beyond facial expression, similar to the previous work. This feedback is valuable as it highlights a potential area for improvement and encourages the authors to consider incorporating headpose control into their method. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how similar approaches have been implemented. Overall, the comment is mostly helpful as it points out a critical weakness and prompts the authors to consider a potential solution, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the structural optimization is a main component and that the optimization algorithm seems to be directly borrowed from previous works, which could be confusing and reduce the contribution. However, it does not provide explicit guidance on how the authors should address this issue or suggest improvements. The comment lacks concrete actions or specific suggestions for enhancing the contribution, such as recommending alternative optimization algorithms or explaining the novelty of the approach. As a result, the authors are left without clear direction on how to improve their draft in this area. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the structural optimization component and mentions that the optimization algorithm seems to be directly borrowed from previous works, which could be confusing and reduce the contribution. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue with the optimization algorithm being directly borrowed, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the structural optimization component is a main component and that the optimization algorithm seems to be directly borrowed from previous works, which could be confusing and reduce the contribution. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically the use of a direct optimization algorithm from previous works. It points out that this could be confusing and reduce the contribution of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the contribution of their work. While it highlights a potential weakness, it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it provides insight into a potential problem but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue with the baseline models or how to improve the pipeline style method. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the pipeline style method, which includes two models, and notes that it does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not specify which part of the paper discusses the pipeline style method or the baseline models, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the issue of average results and the need for better introduction of baseline models, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered borderline verifiable, as it provides some indication but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the pipeline style method, which includes two models, not yielding better average results for both XVNLI and MaRVL. It also notes that the baseline models in the experiments are not well introduced. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address these issues. Without specific recommendations or examples, the authors are left without a clear path forward to improve their draft. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not offer detailed guidance for addressing them.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the authors for reproducing a well-known result about left political bias in ChatGPT and LLMs in general, using a methodology described as \"coarse.\" The reviewer questions why this observation needs to be made again, given that it has been made throughout the evolution of these models. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their methodology. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors for reproducing a well-known result about left political bias in ChatGPT and LLMs in general, using a methodology described as \"coarse.\" However, it does not specify which part of the paper this observation is made in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what needs to be addressed or improved in the methodology. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors are reproducing a well-known result about left political bias in ChatGPT and LLMs in general, using a methodology described as \"coarse.\" The reviewer questions why this observation needs to be made again, given that it has been made throughout the evolution of these models. However, the comment lacks specific examples or references to support the claim that this observation is unnecessary or redundant. Without such evidence, the claim is difficult for the authors to verify or address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the authors for reproducing a well-known result about left political bias in ChatGPT and LLMs in general, using a methodology described as \"coarse.\" The reviewer questions why this observation needs to be made again, given that it has been made throughout the evolution of these models. While the comment identifies a potential redundancy in the authors\\' work, it lacks specific suggestions or guidance on how the authors might address this issue or improve their methodology. The feedback is somewhat helpful as it points out a potential weakness, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to mention related work on modular networks for VQA, specifically referencing work like [A]. This direct suggestion provides a clear and concrete action for the authors to take, ensuring they are aware of the relevant literature and can incorporate it into their introduction. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section discussing related work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of related work on modular networks for VQA, such as [A]. This provides clear guidance on how to improve the introduction by acknowledging relevant work in the field. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is crucial to mention related work on modular networks for VQA, such as [A], to avoid the impression that no one does modular architectures for VQA. However, the comment does not provide specific examples or references to support this claim, nor does it explain why this omission is problematic. Without additional context or evidence, the authors may find it challenging to understand the significance of this claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction section, noting that it gives the impression that no one does modular architectures for VQA. It suggests that the authors should mention related work on modular networks for VQA, such as [A], to provide a more accurate representation of the state of the field. This feedback is clear and actionable, as it directly instructs the authors on how to improve their draft by including relevant references. However, the comment could be more helpful if it explained why this omission is problematic or how it affects the overall context of the paper. Despite this, the feedback is mostly helpful as it guides the authors toward a significant improvement in their introduction section.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors primarily focus on SSC and do not compare their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. While the comment identifies a potential gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors can infer that they need to include comparisons with other methods, but it is vague because it does not specify which methods should be included or how to structure the comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the focus on SSC and the need to contrast the method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison with other methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors primarily focus on SSC and do not contrast their method with other methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. However, the comment lacks specific examples or references to these methods, making it difficult for the authors to understand the exact nature of the comparison being suggested. Without detailed comparisons or references, the claim is not fully substantiated, making it borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. This feedback is somewhat helpful as it points out a gap in the paper that could be addressed by including comparisons with other methods. However, the comment lacks specific suggestions on how to structure these comparisons or which aspects of the other methods should be highlighted. While it highlights an area for improvement, the feedback could be more actionable with additional guidance. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to remove the statement about semantic segmentation being a low-level cue, as it is not accurate given that categories are specified for each pixel. This feedback is clear and concrete, providing a direct action for the authors to take. The comment is specific and leaves no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the term \"semantic\" segmentation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the statement about semantic segmentation being a low-level cue is incorrect, given that categories are specified for each pixel. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement about semantic segmentation being a low-level cue is incorrect, as categories are specified for each pixel. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this claim is valid. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper regarding the use of the term \"semantic\" segmentation. It points out that the categories are specified for each pixel, making the statement about semantic segmentation being a low-level cue inaccurate. This feedback is clear and actionable, as it directs the authors to remove or revise the statement to avoid misleading the reader. However, the comment could be more helpful if it provided additional context or suggestions on how to rephrase the statement to be more accurate. Overall, the comment is mostly helpful as it effectively guides the authors on how to improve the clarity and accuracy of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve their draft. The comment implies that the authors should consider using another dataset, but it lacks concrete details on how to implement this suggestion or what specific aspects of the claim need to be revised. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the table and the claim about accuracy and completeness, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the validity of the claim and suggests using another dataset for the ablation study. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. This is a constructive suggestion that could help the authors strengthen their argument by providing additional evidence or comparisons. However, the comment lacks specific guidance on which dataset to use or how to conduct the ablation study, which would make it more actionable. Overall, the comment is somewhat helpful as it identifies a potential weakness in the paper but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the vulnerability discovery methodology, specifically questioning the authors\\' approach of considering only a single vulnerability at a time. It also questions the ecological validity of such a study and suggests that previous work has considered multiple vulnerabilities simultaneously. The reviewer asks whether the authors argue that identifying one vulnerability at a time is an intended use case. While the comment highlights areas of concern, it does not provide explicit guidance on how the authors should address these issues or improve their methodology. The action is implicit and somewhat vague, as the authors need to infer that they should consider multiple vulnerabilities and justify their approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"vulnerability discovery methodology\" and the \"single vulnerability\" approach, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the ecological validity of the study and suggesting that previous work has considered multiple vulnerabilities. The comment further highlights the difficulty in interpreting the results and whether the authors are arguing for a single-vulnerability approach. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the vulnerability discovery methodology, specifically questioning the authors\\' approach of considering only a single vulnerability at a time. The reviewer questions the ecological validity of such a study and suggests that previous work has considered multiple vulnerabilities simultaneously. The comment also points out that the results are difficult to interpret, or at best, marginal improvements. While the comment provides a logical basis for questioning the methodology, it lacks specific references to external works or detailed reasoning to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a reasonable basis for the critique but requires more detailed evidence or examples to fully support the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the vulnerability discovery methodology, questioning the authors\\' approach of considering only a single vulnerability at a time. It highlights the potential problem of ecological validity and suggests that previous work has considered multiple vulnerabilities simultaneously. The reviewer also points out that the results are difficult to interpret, or at best, marginal improvements. This feedback is valuable as it challenges the authors to reconsider their methodology and potentially improve the robustness and generalizability of their findings. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns or improve the methodology. Overall, the comment is somewhat helpful as it prompts the authors to reevaluate their approach, but it lacks detailed guidance on how to implement the necessary changes.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in understanding the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2. It suggests that additional explanations are needed to address this issue. However, the comment does not provide specific guidance on how to provide these explanations or what aspects of the relationship should be clarified. The action is implicit and somewhat vague, as the authors can infer that they need to provide more explanations but may not be entirely sure of the exact details. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1 and 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity in understanding the relationship between degree bias and the clearer community structure demonstrated by the theorems. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2 is not intuitive enough. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks the necessary evidence or explanation to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2. It points out that while the theorems prove conformity to a clearer community structure, the relationship with degree bias is not intuitive. This feedback is valuable as it highlights a potential gap in the paper\\'s explanation, which the authors can address to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify this relationship or examples of how other works have addressed this issue. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be more detailed, particularly in the definitions of the resistance distance and explanations of Algorithm 1. While it implies that more details should be provided, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper deals with many graph notions and is somewhat hard to understand, but the writing is generally good. It provides specific feedback by mentioning the need for more details, particularly in the definitions of the resistance distance and explanations of Algorithm 1. The authors can infer that these are areas that need attention, but the comment does not explicitly mention which sections or parts of the paper these issues pertain to. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in identifying the need for more detailed explanations. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper is difficult to understand due to its focus on graph notions, but it also acknowledges that the writing is generally good. The comment provides a specific suggestion for improvement by recommending more detailed explanations, particularly for the definitions of the resistance distance and Algorithm 1. This feedback is somewhat verifiable as it identifies a potential area for improvement but lacks detailed guidance on how to achieve it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s complexity, noting that it deals with many graph notions and is somewhat hard to understand. However, it acknowledges that the writing is generally good. The comment provides specific suggestions for improvement by recommending the inclusion of more detailed explanations, particularly for the definitions of the resistance distance and Algorithm 1. This feedback is actionable and can help the authors enhance the clarity and accessibility of their work. However, the comment could be more helpful if it provided examples or guidance on how to present these explanations. Overall, the comment is mostly helpful as it offers clear and actionable suggestions for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the originality of the paper is limited due to the main idea of variable splitting being not new and the algorithm not being new. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the originality or suggest alternative approaches to improve the paper. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of originality, specifically mentioning that the main idea of variable splitting is not new and the algorithm is not new. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is considered unoriginal, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the originality of the paper is limited due to the main idea of variable splitting being not new and the algorithm not being new. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a limitation in the originality of the paper, specifically noting that the main idea of variable splitting is not new and the algorithm is not new. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or enhance the originality of their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the evaluation of shape model invariance, specifically asking if there are any quantitative results on testing images. While it implies that the authors should include such results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide quantitative results on testing images. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the evaluation on transformations of training images and asks for quantitative results on testing images. This provides clear guidance on what additional information is needed to support the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of the evaluation on transformations of training images for the shape model invariance study. It suggests that quantitative results on testing images might be needed to fully prove the point. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid point about the evaluation of shape model invariance, specifically questioning the use of transformations of training images to prove the point. It suggests that quantitative results on testing images might be necessary to fully substantiate the claim. This feedback is somewhat helpful as it identifies a potential gap in the evaluation process and prompts the authors to consider additional evidence. However, the comment could be more helpful if it provided specific suggestions on how to conduct the testing or what types of quantitative results might be relevant. Overall, the comment offers a constructive direction for improvement, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the omission of a related work, the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati. It suggests that this paper should be discussed and compared with the current work to provide a better understanding of the state-of-the-art. The action is clear and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the omission of this related work and its potential impact on the understanding of the state-of-the-art. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati is a related work that should be discussed and compared with the current work. The reviewer provides a logical reasoning by suggesting that the AAAI15 paper deals with hypergraph data with tensors, which is relevant to the current work. However, the comment lacks specific examples or references to the content of the AAAI15 paper, making it somewhat verifiable. The authors would need to conduct additional research to fully understand the relevance and potential contributions of the AAAI15 paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific related work, the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which is relevant to the current work but has been overlooked. It suggests that this paper should be discussed and compared with the current work to provide a better understanding of the state-of-the-art. This feedback is clear and actionable, as it directs the authors to include a relevant reference and comparison that could enhance the paper\\'s comprehensiveness and depth. However, the comment could be more helpful if it provided specific guidance on how to integrate this reference into the paper or what aspects to focus on for comparison. Overall, the comment is mostly helpful as it points out a valuable addition to the literature review but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the scalability of the method and the computation of optimal transport distance, suggesting that it would be beneficial to test its scalability on normal machines with a few cores. It also questions how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific tests should be conducted. The action is implicit and somewhat vague, as the authors need to infer that they should test scalability and clarify the computation of optimal transport. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Approach\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the scalability of the method and questions how the authors compute the optimal transport distance, particularly in relation to the Sinkhorn method. The comment provides clear guidance on what needs to be addressed, such as testing scalability on normal machines and clarifying the computation of optimal transport. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the scalability of the method and the computation of optimal transport distance, suggesting that it is not clear how scalable the method is. The reviewer questions how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. While the comment identifies potential issues, it lacks specific examples or references to support the claim that the method is not scalable or how it could be improved. The lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the scalability of the method and its computation of optimal transport distance. It raises questions about how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. This feedback is valuable as it prompts the authors to consider the scalability of their method on normal machines with a few cores, which is an important aspect for practical applications. Additionally, the comment highlights the need to clarify the computation of optimal transport, providing a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions or examples of how to test scalability or how to compute optimal transport. Overall, the comment is mostly helpful as it provides actionable guidance for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper is extremely hard to follow, indicating that the authors need to improve the clarity and accessibility of their experimental procedures and evaluations. However, it does not provide specific guidance on how to achieve this improvement, such as recommending changes to the structure, language, or presentation of the paper. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance the clarity of their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the paper is difficult to follow, specifically mentioning the experimental procedures and evaluations. However, it does not specify which sections or parts of the paper are particularly challenging to understand. Without explicit references to sections or details, the authors cannot confidently determine which parts need improvement. The comment is not grounded and lacks specificity, making it difficult for the authors to address the issue effectively. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is \"extremely hard to follow,\" indicating that the reviewer had trouble understanding the experimental procedures and evaluations. However, the comment does not provide specific examples or details about what was difficult to follow, nor does it offer suggestions for improvement. Without these details, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, stating that it is \"extremely hard to follow.\" This feedback highlights a critical weakness in the clarity and accessibility of the experimental procedures and evaluations, which is crucial for readers to understand and replicate the work. However, the comment lacks specificity and does not provide actionable guidance on how the authors might improve the clarity or structure of their paper. Without detailed suggestions or examples, the authors are left without a clear path to enhance the readability and comprehensibility of their draft. Therefore, the comment is somewhat helpful, as it points out a significant problem but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to consider introducing specific aspects of their model that are specific to the example model. It provides a clear and concrete action for the authors to take, specifying that they should clarify the model's parameters and settings, such as the boundedness of acceleration and scaling parameters. This feedback is direct and provides specific guidance on how to enhance the clarity of the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l132,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the introduction of specific aspects of the model that are specific to the example model, such as the boundedness of certain parameters. This provides clear guidance on what the authors need to clarify or expand upon in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should introduce specific aspects of their model that are specific to the example model, such as the boundedness of certain parameters. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these aspects are important or how they impact the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors introduce specific aspects of their model that are specific to the example model. It highlights the importance of clarifying the boundedness of certain parameters, such as acceleration and scaling, and emphasizes the need to ensure that the model is not operating in an infinite subdivision setting. This feedback is clear and constructive, as it guides the authors on how to enhance the clarity and precision of their model description. By addressing these points, the authors can improve the comprehensibility and robustness of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. The reviewer suggests that this condition is not realistic and may lead to unreasonably large learning rates when learning on large-scale datasets. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. There is no guidance on whether the authors should adjust the condition, provide a rationale for its necessity, or explore alternative approaches. As a result, the authors are left without actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. It provides a clear rationale for why this condition is not realistic and may lead to unreasonably large learning rates when learning on large-scale datasets. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue with the learning rate condition and its implications, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the condition on the learning rate is not scalable, as it does not grow with the number of samples in practice. The reviewer provides a logical reasoning by explaining that this condition leads to unreasonably large learning rates when learning on large-scale datasets. However, the comment lacks specific examples or references to support the claim that this condition is not realistic. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. This is a critical observation, as it highlights a potential flaw in the methodology that could lead to unreasonably large learning rates when learning on large-scale datasets. The reviewer provides a logical reasoning for why this condition is not realistic and suggests that the authors need a way to precisely characterize the benefit of large learning rates. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or explore alternative approaches. Despite this, the feedback is still valuable as it points out a critical aspect of the methodology that the authors should consider improving. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity regarding how to sample from the DPP when the eigenfunctions e_n are inaccessible, referencing a similar issue with sampling from the leverage score in [3]. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve the clarity of their explanation. The comment implies that the authors should clarify their approach, but it lacks concrete steps or detailed advice on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq (10) line 130,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how to sample from the DPP when the eigenfunctions e_n are inaccessible, referencing a similar problem with sampling from the leverage score in [3]. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, referencing a similar issue in [3]. However, the comment does not provide specific examples or detailed reasoning to support the claim that sampling from the DPP is more difficult than sampling from the leverage score. While it highlights a potential issue, the lack of detailed justification or evidence makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is somewhat verifiable, as it points out a potential problem but lacks the necessary evidence or explanation to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper regarding how to sample from the DPP when the eigenfunctions e_n are inaccessible. It references a similar problem in [3] and questions the ease of sampling from the DPP compared to the leverage score. This feedback is somewhat helpful as it points out a potential area of confusion that the authors need to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the clarity or address the issue. While it highlights an important area for improvement, it could be more helpful with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. This feedback provides clear and concrete actions for the authors to take, such as adding a description of the evaluation process and addressing language issues. The comment is specific and direct, giving the authors a clear understanding of what needs to be added or improved. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. Additionally, it mentions minor language issues on page, providing specific guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, noting that it does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. This feedback is clear and actionable, as it provides the authors with a concrete direction for improving their draft by adding a description of the evaluation process and addressing language issues. However, the comment could be more helpful if it offered suggestions on how to structure the evaluation section or provided examples of what such a description might look like. Overall, the comment is mostly helpful as it guides the authors toward improving their draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses skepticism about the experimental results and questions the absence of experiments on a specific setting. It highlights the need for experiments on surveillance in museums with thresholded rewards and privacy-preserving data collection. While the comment identifies a specific issue with the experimental section, it does not provide explicit guidance on how to address this concern. The authors are left to infer that they should include experiments on these settings, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental results and the specific setting of the POMDP problem with non-convex value functions. It also specifies the issue with the experiments section, noting the absence of experiments on surveillance in museums with thresholded rewards and privacy-preserving data collection. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of the experimental results, specifically the absence of experiments on specific settings. It references the examples of surveillance in museums with thresholded rewards and privacy-preserving data collection as motivating cases for the paper. However, the comment lacks specific evidence or detailed reasoning to support why these examples are insufficient or why the experiments are not useful. The claim is somewhat verifiable, as it highlights a potential issue but does not provide sufficient justification or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experimental results, questioning the relevance of the examples used to motivate the paper's solution. It points out the absence of experiments on specific settings, such as surveillance in museums with thresholded rewards and privacy-preserving data collection. This feedback is valuable as it highlights a critical gap in the experimental section, which could impact the paper\\'s credibility and impact. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific experiments or modifications to the existing ones. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a critical area for improvement, but it lacks detailed guidance on how to address the issue.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the immense workload, the incremental contribution, and the lack of citation of key baselines. It also points out that the paper focuses on RAG for EHR and suggests that essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG should be introduced. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issues. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"details in the article\" and \"your workload is immense,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the contribution being incremental and the lack of citation of key baselines, as well as the need to introduce essential RAG algorithms like MedRetriever and KGRAG. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is incremental and essentially a combination of GraphRAG and GraphCare, referencing the lack of citation of key baselines and the absence of essential RAG algorithms like MedRetriever and KGRAG. The reviewer supports this claim by referencing specific works, which provides a logical basis for the critique. However, the comment could be strengthened by providing more detailed reasoning or examples of how these algorithms would enhance the paper. Overall, the claim is mostly verifiable due to the reference to specific works, but it could be further substantiated with additional details or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the immense workload and the incremental contribution, which are not fully explained. It points out that the paper essentially combines GraphRAG and GraphCare, and that key baselines were not cited. The reviewer also suggests that essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG should be introduced to enhance the paper's contribution. These suggestions provide clear and actionable feedback for the authors to improve their draft. However, the comment could be more helpful if it offered specific guidance on how to integrate these algorithms or why they are essential for the paper. Overall, the comment is mostly helpful as it highlights areas for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be included in the graph and why it is important. The comment also offers a rationale for why this graph is necessary, helping the authors understand the potential sources of performance improvement. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be included in the graph and why it is important to understand the sources of performance improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This claim is somewhat verifiable as it logically suggests that such a graph would help clarify whether the performance improvement is solely due to the network design or whether it is influenced by the nature of ImageNet. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This is a specific and detailed piece of feedback that can help the authors better understand the performance improvement and its potential sources. By including this graph, the authors can provide a more comprehensive analysis of their results, which could enhance the clarity and robustness of their paper. However, the comment could be more helpful if it explained why this graph is important or how it might influence the interpretation of the results. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the performance of the baseline model and the time-aware model is similar when trained and evaluated with the same time-step, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed method might make more sense in scenarios where the training and evaluation time-steps are different. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the method. The action is implicit and somewhat vague, as the authors need to infer that they should consider different time-steps for training and evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance of the baseline model and the time-aware model is similar when trained and evaluated with the same time-step, which raises questions about the effectiveness of the proposed methods. The comment suggests that the proposed method might make more sense in scenarios where the training and evaluation time-steps are different. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of the baseline model and the time-aware model is similar when trained and evaluated with the same time-step, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed method might make more sense in scenarios where the training and evaluation time-steps are different. However, the comment lacks specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors would need to infer the relevance of different time-steps and how they might impact the effectiveness of the proposed methods. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the effectiveness of the proposed methods, noting that the performance of the baseline model and the time-aware model is similar when trained and evaluated with the same time-step. This observation raises questions about the novelty and practical relevance of the proposed methods. The comment suggests that the proposed method might make more sense in scenarios where the training and evaluation time-steps are different. While the comment highlights an important point, it lacks specific suggestions or guidance on how the authors might address this issue or explore different time-steps. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the disentanglement aspect of the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions a limitation related to disentangled latent vectors, it does not provide sufficient detail on how disentanglement is achieved and guaranteed. The reviewer suggests that the authors should clarify this aspect by explaining how disentanglement is realized and what types of bias are involved. This feedback is explicit and provides concrete guidance on what the authors need to address to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Disentanglement\" and \"Broader Impacts and Limitations,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding how disentanglement is achieved and guaranteed without certain bias types. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that disentanglement is not clearly explained and questions how it is achieved and guaranteed without certain bias types. While the comment references the \"Broader Impacts and Limitations\" section, it does not provide specific examples or detailed reasoning to support the claim that disentanglement is unclear. The reviewer suggests that the authors should clarify this aspect, but without further elaboration or evidence, the claim remains somewhat verifiable. The authors would need to make a significant effort to understand and address the issue, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of the disentanglement aspect in the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions a limitation related to disentangled latent vectors, it does not provide sufficient detail on how disentanglement is achieved and guaranteed without certain bias types. The comment suggests that the authors should clarify this aspect to enhance the clarity and comprehensiveness of their work. This feedback is somewhat helpful as it highlights an important area for improvement, but it could be more beneficial if it offered specific suggestions or examples on how to address the issue. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case, the authors should use a standard regularization trick. While the comment implies that the authors should apply this standard technique, it does not provide explicit instructions on how to implement it or which specific regularization trick to use. The action is clear but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the comparison is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the use of a standard regularization trick, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this standard technique is necessary or how it would improve the comparison. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be considered a valid suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case. While it identifies a potential area for improvement, the comment lacks depth and does not provide specific guidance on which standard regularization trick to use or how it would impact the comparison. The feedback is somewhat helpful as it points out a potential issue but does not offer detailed instructions or examples to help the authors address it effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns: the need to discuss how to handle different types of inputs, such as bio-medical signals or speech, and the disorderly citation style. While the first point suggests a specific area for improvement by asking for a discussion on handling different input types, it does not provide explicit guidance on how to structure this discussion or what specific aspects to cover. The second point about the citation style is also vague, as it does not specify which citations are disordered or how they should be organized. The comment lacks concrete details on how to address these issues, making it somewhat actionable. The authors can infer that they need to discuss input types and organize their citations, but the lack of explicit instructions makes it challenging to implement the suggested changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to discuss \"different types of inputs\" and the disorderly citation style, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need to discuss the handling of different input types and the disorderly citation style, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two claims: the need to discuss different types of inputs and the disorderly citation style. The first claim is somewhat verifiable as it suggests a potential area for improvement, but it lacks specific examples or detailed reasoning on how to address the issue. The second claim about the citation style is also somewhat verifiable, as it points out a potential problem but does not provide specific guidance on how to improve the organization or formatting of the citations. Overall, the comment provides some direction but lacks detailed justification or examples, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two areas for improvement: discussing different types of inputs and addressing the disorderly citation style. While it highlights a potential gap in the paper, it does not provide specific guidance on how to address these issues or what aspects of the input types should be discussed. The comment also mentions the disorderly citation style but does not offer suggestions on how to improve it. This lack of detailed feedback limits the comment\\'s usefulness, as it points out areas for improvement but does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Wh-types\" or transformable. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the generalization. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their approach to question answering, but the comment lacks concrete details on how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Wh-types\" or transformable. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential problem with the question answering process, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the question answering process, which involves template mapping to transform questions into masked statements, might lead to poor generalization to questions that are not \"Wh-types\" or transformable. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to studies or literature that demonstrate the limitations of this approach or how it affects generalization. As a result, the claim is somewhat verifiable, as it requires further elaboration and evidence to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Wh-types\" or transformable. While the comment highlights a relevant concern, it lacks specific guidance or suggestions on how the authors might address this issue or improve the generalization of their question answering process. The feedback is somewhat helpful as it points out a potential problem but does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the ICL-HAR has impeded accuracy scores, dropping them from 70.4 to 55.6 on TRIP. It suggests that this issue should be discussed or at least acknowledged in the main text in more detail. This provides a clear and direct action for the authors to take, as they are instructed to address this issue in their draft. The comment is specific and provides concrete guidance on how to improve the paper by discussing or acknowledging the impact of the ICL-HAR on accuracy scores. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the ICL-HAR, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ICL-HAR, stating that it has impeded accuracy scores and dropping them from 70.4 to 55.6 on TRIP. This provides clear guidance on what needs to be addressed in the paper, namely the discussion or acknowledgment of this issue in more detail. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ICL-HAR has impeded accuracy scores, dropping them from 70.4 to 55.6 on TRIP. This claim is supported by the provided data, which shows a significant decline in accuracy scores. However, the comment could be strengthened by providing more detailed analysis or explanation of why this decline occurred or how it affects the overall contribution of the paper. While the data itself is a strong indicator, additional context or reasoning would enhance the verifiability of the claim. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the ICL-HAR, noting that it has impeded accuracy scores, dropping them from 70.4 to 55.6 on TRIP. This is a clear and actionable observation that the authors should address in their draft. The comment suggests that the issue should be discussed or acknowledged in more detail in the main text, providing a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how to address this issue or what aspects of the ICL-HAR might be contributing to the accuracy drop. Overall, the comment is mostly helpful as it highlights a significant issue that the authors should address, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to cite the source of the rock-paper-scissors example, which is clearly inspired by previous work. This is a direct and concrete action, as it specifies the exact source that needs to be cited. The authors know exactly what needs to be done to address the comment, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"rock-paper-scissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need to cite the source of the example. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the rock-paper-scissors example is inspired by previous work and suggests that the source should be cited appropriately. However, the comment does not provide specific examples or references to the previous work that inspired the example, making it difficult for the authors to verify the claim. Without additional context or evidence, the authors may find it challenging to address the suggestion effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the rock-paper-scissors example is inspired by previous work and should be appropriately cited. This is a clear and actionable piece of feedback, as it directly instructs the authors to cite the source of the example. By addressing this point, the authors can ensure that their work is properly credited and that they are not plagiarizing others\\' work. Therefore, the comment is highly helpful, as it provides a clear and constructive suggestion for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that comparing the performance of a model pre-trained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors instead. It further suggests that the authors should provide the performance of the model pre-trained on synthetic data but fine-tuned on real-world datasets with different losses. While the comment provides a clear action\u2014to demonstrate the importance of the projection errors and fine-tune the model on real-world datasets\u2014it does not specify how to implement this action or what specific steps to take. The authors are left with a general idea of what needs to be done but without detailed guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of comparing the performance of a model pre-trained on synthetic data, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the need to demonstrate the importance of the proposed three projection errors and suggests providing performance metrics for models pre-trained on synthetic data but fine-tuned on real-world datasets with different losses. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that comparing the performance of a model pre-trained on synthetic data is unfair and suggests demonstrating the importance of the proposed three projection errors instead. The comment provides a logical reasoning by suggesting that fine-tuning the model on real-world datasets with different losses is necessary to showcase the model\\'s performance. However, the comment lacks specific examples or references to support the claim that the current comparison is unfair. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s comparison of model performance, suggesting that comparing a model pre-trained on synthetic data is unfair. It recommends demonstrating the importance of the proposed three projection errors and provides a clear suggestion for improvement by suggesting that the authors should provide performance metrics for models pre-trained on synthetic data but fine-tuned on real-world datasets with different losses. This feedback is actionable and offers a clear direction for the authors to enhance their analysis and presentation of results. However, it could be more helpful if it provided additional guidance on how to implement this suggestion or what specific metrics to use. Overall, the comment is mostly helpful as it effectively points out a weakness and provides a clear path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. It also encourages the authors to discuss the difference between their method and traditional methods. While the comment provides a clear action to take, it lacks specific guidance on how to conduct the calibration curves or what aspects of the traditional method should be discussed. The authors are given a general direction but may need to infer the exact steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the model AUC and its ability to assess model discriminant ability, as well as the consistency between predicted scores and actual risks. It suggests conducting calibration curves to demonstrate this consistency, which is crucial for the clinical scoring system. The comment also mentions the difference between the traditional method and the authors\\' method, which could be discussed in the paper. However, the comment does not explicitly mention which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as conducting calibration curves and discussing the difference between traditional and novel methods. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model AUC can assess the model discriminant ability but may not demonstrate consistency between predicted scores and actual risks. It suggests that this consistency is crucial for the clinical scoring system and recommends conducting calibration curves to show this consistency. The comment also mentions the importance of discussing the difference between the traditional method and the authors\\' method. While the comment provides a logical reasoning for the need to demonstrate consistency, it lacks specific examples or references to support the claim about the importance of calibration curves. Therefore, the comment is somewhat verifiable, as it provides a reasonable argument but could be strengthened with more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It highlights the importance of demonstrating consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. The comment suggests conducting calibration curves to show this consistency, offering a specific and concrete step for the authors to take. Additionally, it encourages the authors to discuss the difference between their method and traditional methods, providing a direction for further exploration and comparison. While the comment could be more helpful by offering examples of how to conduct calibration curves or suggesting specific aspects of the traditional method to discuss, it still provides valuable guidance for improving the draft. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that all sparsity patterns seem to perform equally well and questions whether this is unique to the sparsity detection problem or applies to GNNs in general. It also notes a discrepancy in the presentation of \"bits\" in Section 4.3. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should provide more insight into the results and clarify the presentation of \"bits.\" The action is implicit and somewhat vague, as it lacks concrete details on how to implement the suggested improvements. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the uniqueness of the results and suggesting that the authors provide more insight into the sparsity patterns. The comment is specific because it clearly identifies what needs to be addressed, namely the lack of insight into the results and the discrepancy in the presentation of \"bits.\" Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the uniqueness of the results and suggests that all sparsity patterns perform equally well. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific examples or data to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not provide sufficient evidence or justification to support the assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the results, noting that all sparsity patterns seem to perform equally well and questioning whether this is unique to the sparsity detection problem or applies to GNNs in general. It also points out a discrepancy in the presentation of \"bits\" in Section 4.3. While the comment highlights areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or provide more insight into the results. The feedback is somewhat helpful as it prompts the authors to consider the generalizability of their findings and the presentation of their work, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values over other methods. Additionally, it recommends including a discussion on the advantages and disadvantages of each method for transforming high-dimensional data to low-dimensional latent space. While the comment provides explicit actions, it lacks concrete details on how to conduct these comparisons or what specific aspects of the methods should be discussed. The authors are given a clear direction but may need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of Shapely values over other methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for experimental comparisons with other methods and a discussion on the advantages and disadvantages of each method for transforming high-dimensional data to low-dimensional latent space. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors need to provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values over other methods. It also recommends a discussion on the advantages and disadvantages of each method for transforming high-dimensional data to low-dimensional latent space. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that Shapely values are superior to other methods. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It highlights the need for experimental comparisons with other methods, such as CaCE or raw gradients, to support the authors\\' argument for using Shapely values over other methods. Additionally, it recommends a significant discussion on the advantages and disadvantages of each method for transforming high-dimensional data to low-dimensional latent space. This feedback is valuable as it guides the authors to strengthen their argument and provide a more comprehensive analysis of their method. However, the comment could be more helpful if it included specific examples or references to similar studies that have conducted such comparisons. Overall, the comment is mostly helpful as it offers clear and actionable guidance for improving the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that the authors should make this comparison, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 needs this comparison or what aspects of the prior efforts should be compared. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the prior efforts should be compared or how this comparison would enhance the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks the necessary evidence or justification to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in Section 6 by suggesting that the perspective taken in the manuscript could be compared to the contributions of prior efforts. This feedback is somewhat helpful as it points out a specific area where the authors could enhance their work by providing a more comprehensive comparison. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, leaving the authors with a general direction but not detailed steps for implementation. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. While the comment implies that the authors should conduct this experiment, it does not explicitly instruct them to do so. The action is concrete, as it specifies the exact change needed (examining performance with different numbers of scenarios), but it is somewhat vague because it does not provide detailed guidance on how to conduct the experiment or what specific aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. The authors can infer that it relates to the training process or results, but this inference is not direct. The comment is specific in its suggestion to examine performance with different scenarios, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion or how it could be tested. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential relationship between the performance and the number of scenarios used for training, suggesting that examining performance with different numbers of scenarios could be interesting. This is a valuable observation that could lead to a meaningful experiment or analysis. However, the comment lacks specific guidance on how to conduct this experiment or what aspects of the performance to focus on. While it points out a potential area for improvement, it does not provide detailed instructions or suggestions for the authors to follow. Therefore, the comment is somewhat helpful, as it highlights an interesting area for exploration but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, additional experiments, or guidance on how to enhance the validation process. As a result, the authors are left without any clear direction on how to address the comment. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and cross-domain imitation. However, it does not specify which part of the paper these experiments are discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in detailing the types of experiments conducted, but it lacks grounding as it does not specify where in the paper this information is presented. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and cross-domain imitation. However, it does not provide any specific examples, references, or detailed reasoning to support the claim that these experiments are comprehensive. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and cross-domain imitation. However, it lacks specificity and actionable feedback. It does not provide guidance on how the authors could improve or expand upon these experiments, nor does it offer suggestions for potential areas of exploration or enhancement. As a result, the comment is somewhat helpful, as it identifies a strength but does not provide detailed guidance for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that Appendix A.2 does not illustrate the state space representation of the environment clearly. This provides a direct and concrete action for the authors to take, which is to improve the clarity of the illustration in Appendix A.2. The comment is specific about what needs to be addressed, making it highly actionable. Authors know exactly what needs to be done to enhance the clarity of their illustration.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be improved in the appendix. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the state space representation in Appendix A.2. It points out that the illustration is not clear, which is a critical aspect of the paper\\'s presentation. This feedback is actionable as it directs the authors to improve the clarity of the illustration, ensuring that readers can better understand the environment\\'s state space. However, the comment could be more helpful if it provided suggestions on how to enhance the clarity or examples of how similar illustrations have been effectively presented. Despite this, the comment is mostly helpful as it highlights an area for improvement and offers a clear direction for the authors to take.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the authors\\' approach, noting that it is only applicable for small or medium-scale problems. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve their approach to handle larger problems. There is no guidance on potential modifications, alternative methods, or additional experiments that could be conducted to address this issue. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation in the authors\\' approach, noting that it is only applicable for small or medium-scale problems. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the approach are insufficient for larger problems or how the authors might address this limitation. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors\\' approach is only applicable for small or medium-scale problems, suggesting that larger problems will overwhelm current LP-solvers. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the authors\\' approach, noting that it is only applicable for small or medium-scale problems. This feedback highlights a potential weakness in the applicability of the authors\\' work, which could limit its impact or usefulness in real-world scenarios. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or expand their approach to handle larger problems. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the bounded noise assumption in the context of stochastic optimization literature and suggests that it is somewhat restrictive. It references external works that discuss better theory for stochastic gradient descent (SGD) in the nonconvex world and provides specific references to papers that explore SGD for structured nonconvex functions. While the comment implies that the authors should consider these references to enhance their understanding of the topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these references to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the bounded noise assumption, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this assumption is somewhat restrictive in the stochastic optimization literature and suggests that there are efforts to extend these noise conditions. The comment provides specific references to external works that discuss better theory for SGD in the nonconvex world, which further clarifies the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the bounded noise assumption is somewhat restrictive in the stochastic optimization literature and suggests that there are efforts to extend these noise conditions. The reviewer provides specific references to external works, such as A. Khaled and P. Richt\\'arik, R. Gower, O. Sebbouh, and N. Loizou, which support the claim by offering additional theoretical insights and references. This provides a robust foundation for the claim, making it mostly verifiable. However, the comment could be further strengthened by explaining why the bounded noise assumption is restrictive or how these references might impact the paper\\'s findings. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s approach by noting that the bounded noise assumption is somewhat restrictive in the stochastic optimization literature. It suggests that there have been efforts to extend these noise conditions, providing specific references to external works that discuss better theory for stochastic gradient descent (SGD) in the nonconvex world. This feedback is valuable as it encourages the authors to explore these references and potentially enhance their understanding of the topic. However, the comment could be more helpful if it offered suggestions on how to incorporate these references or integrate the new theory into the paper. Overall, the comment is mostly helpful as it provides actionable guidance for the authors to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the motivation for using characteristic function regularization is not clear. However, it does not provide any explicit or implicit suggestions for how the authors might clarify this motivation or what specific aspects of the motivation are unclear. There is no guidance on how to address this issue, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the motivation for using characteristic function regularization is not clear, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine whether it relates to the introduction, methodology, or results sections. Additionally, the comment lacks specificity regarding what aspects of the motivation are unclear or how they could be clarified. Without explicit references or detailed guidance, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the motivation for using characteristic function regularization is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a lack of clarity in the motivation for using characteristic function regularization, which is an important aspect of the paper. However, it does not provide specific guidance or suggestions on how the authors might clarify this motivation or what aspects of it are unclear. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it points out an area for improvement but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper appears to be limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It suggests that the contribution is incremental because these techniques are not novel. However, the comment does not provide any explicit or implicit actions for the authors to take to address this limitation or improve their draft. There is no guidance on how to differentiate their work from existing techniques or how to enhance the contribution. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific techniques used in the paper, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue with the paper, namely that the combination of these techniques is not novel and therefore the contribution is considered incremental. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that these results are not surprising and that the contribution is incremental. However, the comment lacks specific examples or references to these existing techniques, making it difficult for the authors to understand the exact nature of the limitations. Additionally, the claim is not supported by detailed reasoning or evidence, such as specific examples or comparisons to similar works. As a result, the comment is considered unverifiable due to the lack of detailed justification and evidence.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that it appears to be limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that these results are not surprising and that the contribution is incremental. While the comment highlights a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this limitation or enhance their contribution. The feedback lacks actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more details about the aggregation operation after \"Integration\" in the main paper. It also suggests acknowledging the structure of other architectures if they are referred to. This feedback is clear and concrete, as it specifies exactly what needs to be added or clarified in the paper. The authors know exactly what information is missing and how to address it, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"aggregation operation after \"Integration,\"\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the details of the aggregation operation and the acknowledgment of other architectures if they are referred to. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the aggregation operation after \"Integration\" needs further clarification and that if other architectures are referred to, their structure should be acknowledged properly. However, the comment does not provide specific examples or detailed reasoning to support why these clarifications are necessary or how they would improve the paper. Without additional context or examples, the claim is somewhat verifiable, as it requires the authors to infer the importance of the suggested clarifications. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires further clarification, namely the aggregation operation after \"Integration.\" It suggests that the authors provide more details in the main paper and acknowledge the structure of other architectures if they are referred to. This feedback is clear and actionable, as it directs the authors to enhance the clarity and completeness of their explanation. However, the comment could be more helpful if it provided specific examples or guidance on what additional details should be included. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the potential of exploring energy models for image generation and suggests that it is less explored compared to GANs and VAEs. However, it also points out that the motivation and goals of the model are similar to a prior VAE paper, which is discussed in the related work review section. While the comment implies that the authors should consider this similarity and potentially address it in their work, it does not provide explicit guidance on how to do so or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should address the similarity to the prior work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of energy models for image generation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the motivation and goals of the model are similar to a prior VAE paper, which is discussed in the related work review section. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the use of energy models for image generation is less explored compared to GANs and VAEs, and it acknowledges that the motivation and goals of the model are similar to a prior VAE paper. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the comparison to the prior work. The lack of specific examples or detailed justification makes the claim somewhat verifiable, as the authors would need to infer the basis of the comparison and potentially conduct additional research to fully understand the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the potential of exploring energy models for image generation, noting that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model, which involve compositional generation through logical combination of concepts learned through data subsets, are similar to a prior VAE paper. This feedback is somewhat helpful as it highlights an area of potential interest and a similarity to prior work, which the authors could consider addressing or differentiating. However, the comment lacks specific suggestions or guidance on how to address the similarity or explore the potential of energy models. To be more helpful, the comment could provide actionable advice on how to differentiate the model or suggest specific aspects to focus on in the related work review section. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly recommends conducting experiments on a different benchmark, such as Atari, to verify the generalizability of the method. This suggestion is clear and provides a specific action for the authors to take. Additionally, it highlights the importance of evaluating the method on a diverse set of domains to ensure its applicability beyond the current domain. The comment is concrete in its guidance, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation on a single domain, Meta World, and suggests running experiments on a different benchmark, such as Atari. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the need for generalizability testing and the importance of evaluating the method on a diverse set of domains. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is evaluated only on the tasks from Meta World, a robotic manipulation domain, which makes it difficult to judge whether the results will generalize to other domains. The reviewer suggests running experiments on a different benchmark, such as Atari, which is commonly used in the literature. This suggestion is based on the need to verify whether the method works with discrete action spaces and high-dimensional observations. The comment provides a logical reasoning for the need to test generalizability, but it lacks specific examples or references to support the claim that Atari is a suitable benchmark. Therefore, the claim is somewhat verifiable, as it provides a clear rationale but requires more detailed evidence or references to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of the method, noting that it is evaluated only on the tasks from Meta World, a robotic manipulation domain. This observation highlights the need for generalizability testing to ensure that the method can be applied to other domains. The comment provides a specific recommendation to conduct experiments on a different benchmark, such as Atari, which is commonly used in the literature. This suggestion is actionable and offers a clear path for the authors to improve their draft by expanding the evaluation to a more diverse set of domains. However, the comment could be more helpful if it included examples of how Atari could be used to test the method or why it is a suitable benchmark. Overall, the comment is mostly helpful as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include an analysis of what the model does, which could be interesting. However, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The comment implies that the authors should add more depth to the explanation of the model, but it lacks concrete instructions or examples on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks an analysis of what the model does, which could be interesting. However, it does not specify which part of the paper this analysis should be included in, nor does it provide details on what aspects of the model should be analyzed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. The comment is specific in suggesting the need for an analysis but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks an analysis of what the model does, which could be interesting. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper, noting that while the method is presented well and the experiments are thorough, there is a lack of analysis on what the model does. This feedback highlights an area for improvement, suggesting that the authors should include an analysis of the model's functionality, which could be interesting. However, the comment does not provide specific guidance or examples on how to conduct this analysis or what aspects to focus on. While it points out a potential weakness, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the task setup is not described clearly, specifically mentioning the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify these aspects, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the task setup, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the task setup is not described clearly, particularly regarding the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the task setup is not described clearly, specifically mentioning the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact issue and how to address it. Therefore, the claim is considered borderline verifiable, as it provides some indication of a problem but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the task setup, noting that the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date are not clearly described. This feedback is clear and actionable, as it points out a specific area where the authors need to provide more detail to improve the clarity of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how similar tasks have been described in other works. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors discuss the reason why the proposed algorithm, DMLCBO, does not achieve the convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$ and the theoretical technique difference between DMLCBO and previous works that have achieved this rate, such as SUSTAIN and MRBO. This feedback provides a clear and concrete action for the authors to take, as it specifies the need for a detailed discussion on the convergence rate and theoretical differences. The comment is explicit and provides specific guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed algorithm, DMLCBO, and references specific works, SUSTAIN and MRBO, which have achieved a convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the reason why DMLCBO does not achieve the same convergence rate and the theoretical technique difference between DMLCBO and the mentioned works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed algorithm, DMLCBO, does not achieve the same convergence rate as previous works, specifically mentioning SUSTAIN and MRBO, which have achieved $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$. The reviewer supports this claim by referencing these specific works and their convergence rates, providing a logical basis for the comparison. However, the comment could be strengthened by providing more detailed analysis or references to the theoretical differences between DMLCBO and the mentioned works. Despite this, the claim is mostly verifiable due to the reference to specific works and the logical reasoning provided.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the convergence rate of the proposed algorithm, DMLCBO, compared to previous works that have achieved a convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$. It references specific works, SUSTAIN and MRBO, which have achieved this rate, and encourages the authors to discuss the reason why DMLCBO does not achieve the same rate. This feedback is clear and actionable, as it provides a concrete direction for the authors to explore and address the convergence rate issue. By addressing this point, the authors can enhance the clarity and robustness of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the modulator is heuristically designed and questions whether there is a scalability issue that might require tedious hyperparameter tuning for diverse training data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the scalability issue or suggestions for improving the modulator design. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make or how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of scalability in the modulator design, specifically questioning whether there is a scalability issue that might require tedious hyperparameter tuning for diverse training data. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the scalability issue and the potential need for hyperparameter tuning, but without clear grounding, the authors cannot confidently determine which part of the paper to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the modulator is heuristically designed and questions whether there is a scalability issue that might require tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the modulator design, noting that it is heuristically designed and questioning whether there is a scalability issue that might require tedious hyperparameter tuning for diverse training data. While the comment highlights a potential concern, it lacks specific guidance or suggestions on how the authors might address this issue or improve the scalability of the modulator. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for experiments on the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. However, it does not provide explicit instructions or suggestions on how the authors should conduct these experiments or what specific aspects to focus on. The action is implicit and lacks concrete guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the need for experiments on the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments where these aspects are discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that obtaining labeled data is necessary for imitation learning and suggests that experiments should be conducted to determine the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. It highlights the importance of conducting experiments to address these issues. However, the comment lacks specific suggestions or guidance on how to conduct these experiments or what aspects to focus on. While it points out an area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it directs the authors to a potential area for enhancement but does not fully support them in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the paper, noting that it does not explore the implications of the proposed method for other NLP tasks. However, it does not provide specific guidance on how the authors should address this issue or what additional exploration is needed. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to enhance the generalizability of their results. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s exploration of the implications of the proposed method for other NLP tasks, suggesting that the paper\\'s generalizability is somewhat limited due to this lack of exploration. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of limited generalizability, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which somewhat limits its generalizability. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that it does not explore the implications of the proposed method for other NLP tasks. This observation highlights a potential weakness in the generalizability of the results, which could impact the paper\\'s impact and relevance. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional exploration could be conducted. While it points out an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the use of the terminology \"certificate\" in the paper, as it has a strong meaning in complexity theory. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to avoid misinterpretation. The action is implicit and vague, as the authors are left to infer that they need to reconsider the use of this terminology and possibly provide clarification. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 267,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the terminology \"certificate,\" which could be misinterpreted due to its strong meaning in complexity theory. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of the terminology \"certificate\" in some contexts could be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of terminology in the paper, specifically the term \"certificate,\" which could be misinterpreted due to its strong meaning in complexity theory. This is a valuable observation that could help the authors avoid confusion or misunderstanding in their work. However, the comment lacks specific guidance on how to address this issue, such as suggesting alternative terminology or providing examples of where the term might be misinterpreted. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. While the comment implies that additional experiments are necessary, it does not provide specific guidance on how to conduct these experiments or what aspects to focus on. The references provided are relevant but do not offer detailed instructions on how to implement the suggested experiments. The action is implicit and somewhat vague, as the authors need to infer the specific details of how to proceed with the additional experiments. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results discussion. The references provided are relevant but do not directly address the comment\\'s suggestion. Therefore, the comment is weakly grounded because it does not specify where in the paper these experiments should be conducted, and it is not specific in detailing what aspects need to be addressed. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. The reviewer provides references to relevant works, which supports the claim that these experiments could enhance the paper. However, the comment lacks detailed reasoning or specific examples of how these additional experiments would benefit the paper. While the references provide some context, the claim could be strengthened with more detailed justification or examples of how these experiments would contribute to the paper. Therefore, the comment is somewhat verifiable, as it provides some support but lacks full justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific guidance on which aspects of the paper would benefit from these additional experiments or how they should be conducted. The references provided are relevant but do not offer detailed instructions or suggestions for the authors to follow. Therefore, the comment is somewhat helpful as it points out a potential area for improvement but does not provide actionable steps for the authors to take.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the results and analysis are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not provide any explicit or implicit suggestions for improvement or additional models to consider. The authors are left without guidance on how to enhance the scope or relevance of their evaluation. As a result, the comment lacks actionable advice, leaving the authors uncertain about how to address the issue. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the results and analysis, noting that they are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not specify which part of the paper this critique pertains to, such as the results or analysis sections. Without explicit references to sections or figures, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the evaluation are limited by the choice of models. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the results and analysis are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a limitation in the evaluation of results and analysis, noting that only two relatively old and small models are considered. This feedback highlights an area where the authors could potentially expand the scope and relevance of their work by including more diverse or contemporary models. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional models or methods to consider. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS, particularly when certain conditions are met. However, it does not provide any explicit or implicit actions for the authors to take based on this observation. There is no guidance on how to incorporate this understanding into the paper or what specific aspects of the paper should be revised to reflect this view. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS under certain conditions. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the paper should be revised or how the authors should address this suggestion. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that KD can be considered a special form of LS under certain conditions, specifically when the teacher network is uniformly distributed and the temperature is set at 1. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS under certain conditions. It provides a specific scenario where this equivalence occurs, which could be valuable for the authors to consider when discussing their results or methodology. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might incorporate this understanding into their work. While it provides some insight, it could be more helpful with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include results on large-scale datasets, such as ImageNet, to verify the effectiveness of their proposed method. This feedback is explicit and provides a clear action for the authors to take, which is to include results on larger datasets. The comment also mentions that competing dynamic-pruning methods are outdated, implying that the authors should consider more recent works. However, it does not specify which recent works should be included or how to incorporate them into the paper. While the action is clear, the lack of detailed guidance on how to implement it makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"No.3. 2021\" and \"Competing dynamic-pruning methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the inclusion of results on large-scale datasets, such as ImageNet, to verify the effectiveness of the proposed method. Additionally, it points out that competing dynamic-pruning methods are outdated, suggesting that more recent works should be included. This provides clear guidance on what needs to be improved in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that competing dynamic-pruning methods are outdated and suggests that more recent works should be included. However, the comment does not provide specific examples of these outdated methods or recent works that should be considered. Without detailed references or specific examples, the claim lacks sufficient evidence or justification to be fully verifiable. The authors would need to make a significant effort to identify and incorporate the suggested works, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the authors include results on large-scale datasets, such as ImageNet, to verify the effectiveness of their proposed method. It also points out that competing dynamic-pruning methods are outdated, implying that more recent works should be considered. This feedback is specific and offers a concrete direction for improvement, making it highly helpful for the authors to enhance the comprehensiveness and relevance of their work. By addressing these suggestions, the authors can significantly strengthen their paper and demonstrate the applicability of their method in a broader context. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It raises a valid point about the interest in this particular dimension of difficulty, but it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment lacks actionable details, such as recommending alternative methods or explaining why this choice might be less effective. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of CIFAR images as backgrounds, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the motivation behind this choice and seeks clarification on why this particular dimension of difficulty is interesting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It suggests that this choice is not well-motivated and raises a valid point about the interest in this particular dimension of difficulty. However, the comment lacks specific examples or references to support the claim that this choice is not well-motivated. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that this choice is not well-motivated. It raises a valid point about the interest in this particular dimension of difficulty, which could be an important consideration for the authors. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or provide a more compelling justification for their choice. While it identifies a potential weakness, it does not offer actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to make the text inside the figure and labels roughly the same size as the manuscript text. This is a clear and direct action that the authors can easily implement to improve the readability of their figures. The comment provides concrete guidance on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"text inside the figure and the labels,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the size of the text compared to the manuscript text. This provides clear guidance on how to improve the readability of the figures. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the text inside the figure and labels is too small to read without zooming, suggesting that it should be roughly the same size as the manuscript text. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the readability of the figures, noting that the text inside the figure and the labels are too small to read without zooming. It provides a clear and actionable suggestion to make the text roughly the same size as the manuscript text. This feedback is valuable as it directly addresses a usability concern that could impact the accessibility and comprehension of the figures. However, the comment could be more helpful if it included examples or additional guidance on how to achieve this improvement. Overall, the comment is mostly helpful as it effectively points out a specific issue and offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the motivation is not clear and suggests that the introduction should be revised to make the paper easier to follow. This provides a direct and concrete action for the authors to take, which is to revise the introduction to clarify the motivation. The comment is specific in identifying the issue and offers a clear direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the motivation. This provides clear guidance on what the authors need to improve in their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation is not clear, suggesting that the introduction should be revised to make the paper easier to follow. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, namely that the motivation is not clear. It suggests that the introduction should be revised to make the paper easier to follow. While the comment highlights a critical area for improvement, it lacks specific guidance on how to address the issue or what aspects of the motivation are unclear. Providing more detailed feedback on what specific aspects of the motivation need clarification or how to improve the introduction would make the comment more actionable. As it stands, the comment is somewhat helpful as it points out a critical area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that using multiple local prompts can be beneficial but notes that the features and their positions differ across categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improving the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the use of multiple local prompts and notes that the features and their positions differ across categories. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the features or positions are problematic or how they could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that using multiple local prompts can be beneficial but notes that the features and their positions differ across categories. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges the use of multiple local prompts and notes that the features and their positions differ across categories. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to validate the alignment or what specific steps to take to ensure its validity. As a result, the authors are left without any clear direction on how to improve their draft in this area. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the alignment of relabeled reward data with human annotator judgments, indicating that this alignment is insufficiently validated. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of insufficient validation, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the insufficient validation of the alignment between relabeled reward data and human annotator judgments. This is a critical point that could impact the reliability and robustness of the results. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending additional validation methods or providing examples of how to validate the alignment more effectively. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper only conducts experiments on a limited number of molecules and provides in-distribution testing for these samples. It suggests that the method's value would be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or expand their experiments to include more molecules. The action is implicit and vague, as the authors are left to infer that they should consider expanding their experiments to include more molecules. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the limited scope of the experiments conducted in the paper, specifically mentioning that only a few molecules are tested and that in-distribution testing is provided for these samples. However, it does not specify which sections of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its critique of the limited scope of the experiments and the potential limitations of the method if it requires training for each molecule individually. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper only conducts experiments on a limited number of molecules and provides in-distribution testing for these samples. It suggests that the method's value would be limited if it requires training for each molecule individually. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically noting that the experiments are conducted on a limited number of molecules and only provide in-distribution testing for these samples. It suggests that the method's value would be limited if it requires training for each molecule individually. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s scope and suggests an area for improvement. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand their experiments to include more molecules. While it highlights an important issue, the feedback could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the symbols or how to make them more accessible to the reader. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not specify which symbols or parts of the paper are causing this issue, making it difficult for the authors to pinpoint the exact areas that need improvement. Without specific references to sections, figures, or symbols, the authors cannot effectively address the issue. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not provide any specific examples or reasoning to support this claim. Without detailed evidence or references, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not provide any specific examples or guidance on how to simplify these symbols or make them more accessible to the reader. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment does not provide explicit instructions or concrete steps for the authors to take. It lacks actionable details, such as recommending specific modifications or experiments to address this concern. As a result, the authors are left without a clear path forward, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment does not specify which part of the paper this question pertains to, such as specific experiments or sections where the results are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the role of periodicity in the results, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment lacks specific evidence or examples to support this claim. It does not provide detailed reasoning or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides a logical basis for the question but lacks sufficient evidence or references to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a pertinent question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. This is a valuable observation that could prompt the authors to reconsider their approach and potentially improve their results. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending experiments or modifications to the model. While it provides a thought-provoking insight, it could be more helpful with additional actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper is not well-written and suggests that it may have been rushed, making it difficult to read. It also mentions that there is a lot left desired in presentation and formatting, particularly in figures and tables. While the comment identifies areas for improvement, it does not provide specific guidance on how to address these issues, such as suggesting particular formatting changes or improvements to the figures and tables. The authors are left to infer that they need to improve the writing and formatting, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the paper\\'s writing quality, suggesting that it may be rushed and difficult to read. It also mentions specific areas for improvement, such as presentation and formatting, particularly in figures and tables. However, the comment does not explicitly mention which sections or parts of the paper are problematic, making it weakly grounded. The authors can infer that it relates to the writing and formatting sections, but this inference is not direct. The comment is specific in detailing what needs to be improved, such as the figures and tables, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is not well-written and suggests that it may have been rushed, making it difficult to read. It also mentions that there is a lot left desired in presentation and formatting, particularly in figures and tables. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of specificity and detailed evidence or references makes the claim borderline verifiable, as it provides some indication but not enough detail for the authors to fully understand and act upon the feedback. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s writing quality, suggesting that it may be rushed and difficult to read. It also points out that there is a lot left desired in presentation and formatting, particularly in figures and tables. While the comment highlights areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are left with a general understanding of the problem but without actionable steps to improve their draft. Therefore, the comment is somewhat helpful, as it provides insight into potential weaknesses but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the introduction to orthogonality in Part 2 could be more detailed. This provides a clear and direct action for the authors to take, which is to expand or clarify the introduction to make it more comprehensive. The comment is specific in identifying the need for more detail, making it highly actionable. Authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Part 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the introduction to orthogonality. This provides clear guidance on what the authors need to improve, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific reasoning or examples to support why this detail is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, as it does not provide sufficient evidence or justification for the authors to understand the need for more detail. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area for improvement in the paper, namely the introduction to orthogonality in Part 2. It suggests that the introduction could be more detailed, providing a clear direction for the authors to enhance their draft. However, the comment lacks depth and does not offer specific suggestions or examples of what additional details might be beneficial. While it points out a potential weakness, it does not provide actionable guidance on how to address it, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that similar analyses have been conducted in prior works, specifically mentioning the robustness of CIFAR-10 models on distribution shifts. It references specific works that have already explored these topics, such as RobustBench and [A, B]. The comment suggests that the current work may not provide novel insights or results, as the analyses are not particularly surprising. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes could be made to enhance the novelty or impact of their work. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the novelty and impact of their work based on the references provided. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific analyses and prior works, such as RobustBench and [A, B], allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that similar analyses have been conducted in prior works, which may not provide novel insights or results. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that similar analyses have been conducted in prior works, specifically mentioning the robustness of CIFAR-10 models on distribution shifts. It references specific works, such as RobustBench and [A, B], which have already explored these topics. The comment also mentions that the results are not particularly surprising, as they align with prior work. This provides a logical reasoning and references to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or specific examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty and impact of the current work, noting that similar analyses have been conducted in prior works. It specifically references specific works, such as RobustBench and [A, B], which have explored similar topics. The comment suggests that the current work may not provide novel insights or results, as the analyses are not particularly surprising. However, it does not provide specific suggestions or guidance on how the authors could address this issue or enhance the novelty or impact of their work. While it points out a potential weakness, the feedback lacks actionable advice or constructive suggestions, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the hyper-parameters $b$ (bit-width) and $\\\\alpha$ (stability factor) introducing significant computational overhead in the pursuit of determining the optimal trade-off between model size and accuracy. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative approaches or methods to mitigate the overhead. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of hyper-parameters $b$ (bit-width) and $\\\\alpha$ (stability factor) introducing significant computational overhead in the pursuit of determining the optimal trade-off between model size and accuracy. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the hyper-parameters, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the hyper-parameters $b$ (bit-width) and $\\\\alpha$ (stability factor) may introduce significant computational overhead in the pursuit of determining the optimal trade-off between model size and accuracy. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the hyper-parameters $b$ (bit-width) and $\\\\alpha$ (stability factor) introducing significant computational overhead in the pursuit of determining the optimal trade-off between model size and accuracy. This is a relevant concern that could impact the efficiency and effectiveness of the model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending alternative hyper-parameter settings or methods to mitigate the overhead. While it points out a potential problem, it does not provide actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the classification of the study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what changes should be made to the study. The comment lacks actionable advice or suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the study\\'s classification but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. While it identifies a potential issue with the study\\'s designation, it lacks depth and does not provide specific suggestions or guidance on how the authors might clarify or reframe their study. The feedback is somewhat helpful as it points out a potential misclassification, but it does not offer actionable advice or detailed critique to help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the proposed TransferNorm (TN) architecture to similar competitors like AutoDial and AdaBN. This feedback provides a clear and explicit action for the authors to take, which is to extend the evaluation to include these additional competitors. The suggestion is concrete, as it specifies exactly what needs to be done to enhance the evaluation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"evaluation\" and \"comparing several base DA methods with and without the proposed TransferNorm architecture.\" This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the evaluation could be strengthened by including comparisons with other architectural competitors like AutoDial and AdaBN. This provides clear guidance on what additional evaluations could be conducted to enhance the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation could be strengthened by including comparisons with other architectural competitors like AutoDial and AdaBN. However, the comment does not provide specific reasoning or evidence to support why these competitors are necessary or how they would enhance the evaluation. Without detailed justification or examples, the claim remains somewhat verifiable, as the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the evaluation section by suggesting that the base DA methods should be evaluated with and without the proposed TransferNorm (TN) architecture, as well as with other architectural competitors like AutoDial and AdaBN. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their evaluation by including additional comparisons that could strengthen their results. By addressing this suggestion, the authors can improve the robustness and comprehensiveness of their evaluation, which is valuable guidance for improving the draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit suggestions for how the authors could improve the evaluation or address this issue. There is no guidance on what specific changes could be made to the evaluation or how to ensure that the baselines are appropriate for fair classification. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"evaluation\" and \"baselines used in the paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the evaluation being weak and the baselines not being designed for fair classification. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation, noting that the baselines used in the paper are not designed for fair classification. This is a critical observation that highlights a potential weakness in the paper\\'s methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the evaluation. Without actionable advice or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the setting needs to be spelled out more clearly in the first three paragraphs of Section 2. It suggests that the authors are trying to present something in greater generality than what is actually presented, which muddles the exposition. However, the comment does not provide specific guidance on how to clarify the setting or what aspects need to be clarified. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the setting but may not be entirely sure of the exact details to address. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first three paragraphs of Section 2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting needs to be spelled out more clearly and suggesting that the authors may be trying to present something in greater generality than what is actually presented, which muddles the exposition. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the setting needs to be spelled out more clearly in the first three paragraphs of Section 2. The reviewer suggests that the authors are trying to present something in greater generality than what is actually presented, which muddles the exposition. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors may find it challenging to understand the exact issue without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of Section 2. It suggests that the authors may be presenting something in greater generality than what is actually shown, which muddles the exposition. This feedback is clear and actionable, as it points out a specific area where the authors need to clarify their work to improve the reader\\'s understanding. However, the comment could be more helpful if it provided suggestions on how to clarify the setting or what specific aspects need to be addressed. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the convincing nature of the experiments and questions the choice of the old baseline, R3D and C3D. It suggests that the authors should consider whether their proposed method works on other 3D CNNs, such as X3D, SlowFast, etc., and compare its advantages to those approaches. While the comment implies that the authors should conduct additional experiments or comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments or comparisons to address the concerns raised. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of the old baseline and suggesting that the proposed method should be evaluated on other 3D CNNs, such as X3D and SlowFast. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the convincing nature of the experiments and suggests that the authors should consider whether their proposed method works on other 3D CNNs, such as X3D and SlowFast. The comment provides a logical reasoning by mentioning the existence of alternative approaches and the need to compare the proposed method to these existing methods. However, it lacks specific examples or references to support the claim that the proposed method is not convincing. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the experiments, questioning the choice of the old baseline and suggesting that the proposed method should be evaluated on other 3D CNNs, such as X3D and SlowFast. This feedback is somewhat helpful as it points out a specific area for improvement and encourages the authors to consider alternative approaches. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment offers some insight but lacks depth and actionable suggestions, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to clarify how the attention module is attached to the backbone ResNet-20 architecture, including the number of attention modules used, their placement (after each block or stage), and how they are integrated into the overall architecture. This feedback provides clear and specific guidance on what the authors need to address to improve the clarity of their draft. The action is concrete, as it details the exact information that needs to be clarified, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"attention module attached to the backbone ResNet-20 architecture\" and asks for clarification on the number of attention modules, their placement, and how they are integrated into the architecture. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be clarified, such as the number of attention modules and their placement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of how the attention module is attached to the backbone ResNet-20 architecture, specifically asking for clarification on the number of attention modules, their placement, and how they are integrated into the architecture. This is a request for more detailed information, which is not a claim but rather a request for clarification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the integration of the attention module with the backbone ResNet-20 architecture. It asks for clarification on the number of attention modules used, their placement, and how they are integrated into the architecture. This feedback is clear and actionable, as it provides the authors with specific questions to address in order to improve the clarity of their draft. By addressing these points, the authors can enhance the understanding of their method and its implementation. However, the comment could be more helpful if it offered suggestions on how to present this information in a clearer manner. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the proposed method's performance at low bitrates, suggesting that it is close to the baselines in this range. It also asks for clarification on the precise bitrate range used for BD-rate comparison and suggests discussing a related work about implementing content-adaptive algorithms in learned video compression. While the comment provides explicit actions\u2014asking for clarification and suggesting a related work for discussion\u2014it does not offer specific guidance on how to implement the content-adaptive algorithm or what aspects of the method need improvement. The authors are given clear directions but may need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"BD-rate comparison,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a concern about the method's performance at low bitrates and suggests discussing a related work about implementing content-adaptive algorithms in learned video compression. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the proposed method's performance at low bitrates, suggesting that it is close to the baselines in this range. The reviewer asks for clarification on the precise bitrate range used for BD-rate comparison and suggests discussing a related work about implementing content-adaptive algorithms in learned video compression. While the comment identifies a potential issue with the method\\'s performance, it lacks specific examples or detailed reasoning to support the claim. The suggestion to discuss a related work is helpful but does not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but lacks detailed evidence or reasoning to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, noting that it performs stronger at high bitrates but is close to the baselines at low bitrates. This is a valuable observation that prompts the authors to reconsider the method\\'s performance range and potentially adjust their claims. Additionally, the comment suggests discussing a related work about implementing content-adaptive algorithms in learned video compression, which could provide a valuable context for the authors to consider. While the comment does not offer specific suggestions on how to address the issue or implement the content-adaptive algorithm, it provides clear and actionable feedback that can guide the authors in improving their draft. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. While the comment implies that the authors should make this distinction, it does not provide explicit instructions on how to do so or what specific aspects of the paper need to be revised. The action is implicit and somewhat vague, as the authors need to infer that they need to make a distinction between the two concepts. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, it does not specify which part of the paper this distinction should be made in, nor does it provide detailed guidance on how to make this distinction. The authors can infer that it relates to the discussion or analysis of the results, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a distinction needs to be made. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or how it would benefit the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. This feedback is somewhat helpful as it identifies a potential area for clarification and differentiation in the paper. However, the comment lacks specific guidance on how to make this distinction or what aspects of the paper need to be revised to achieve this clarity. While it points out a potential issue, it does not provide detailed suggestions or examples to help the authors effectively address the concern. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with the theoretical result, noting that it only provides utility guarantees for the proposed algorithm when the features and noise are Gaussian, which is a strong requirement on the data. It also suggests that the authors should compare their rates to existing rates in the literature. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct this comparison or what specific rates should be compared. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"main (and only) theoretical result\" and the \"utility guarantees,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the results are only valid when the features and noise are Gaussian, which is a strong requirement on the data. Additionally, it suggests that the authors should compare their rates to existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main theoretical result in the paper provides utility guarantees only when the features and noise are Gaussian, which is a strong requirement on the data. The reviewer suggests that this assumption is not necessary for previous algorithms and that the authors should compare their rates to existing rates in the literature. While the comment identifies a potential issue with the assumption and suggests a comparison, it lacks specific examples or references to support the claim that previous algorithms do not require this assumption. This makes the claim somewhat verifiable, as the authors would need to further explore the literature to fully understand the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the theoretical result, noting that it only provides utility guarantees for the proposed algorithm when the features and noise are Gaussian, which is a strong requirement on the data. It also suggests that the authors should compare their rates to existing rates in the literature, which is a valuable suggestion for improving the paper. However, the comment could be more helpful if it provided specific examples or references to existing works that demonstrate the applicability of the algorithm to non-Gaussian data. While the feedback highlights a critical area for improvement, it lacks detailed guidance on how to address it, making it somewhat helpful. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This implies that the authors should include such a comparison in their paper. However, the comment does not specify how to conduct this comparison or what specific aspects to focus on. While the action is implied, it is not as concrete as it could be, as it lacks detailed guidance on how to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a comparison with the original approach, but it lacks detailed guidance on how to implement this comparison or what aspects to focus on. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be useful to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or beneficial. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a comparison that could enhance the paper\\'s credibility and rigor. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, such as which specific aspects of the original approach should be compared or how to interpret the results. While it provides a general direction, the authors would need to make additional efforts to fully understand and implement the suggestion. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. While it implies that the authors should include additional experiments, it does not specify which specific baselines or comparisons should be included. The action is clear but lacks concrete details on which additional experiments to conduct or how to present them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more experimental comparisons to demonstrate the effectiveness of the proposed method, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. While it references specific works that focus on similar questions, it does not provide detailed reasoning or evidence to support why these additional comparisons are necessary or how they would enhance the paper. The reference to specific works is a helpful starting point, but the comment lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some support but requires more detailed explanation to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experimental section, suggesting that the authors should include more experimental comparisons to demonstrate the effectiveness of their proposed method. It references specific works that focus on similar questions, providing a clear direction for the authors to expand their experimental analysis. However, the comment could be more helpful by offering specific suggestions on which additional baselines or comparisons to include, or how to present the results in a more comprehensive manner. Overall, the feedback is somewhat helpful as it points out a clear area for improvement but lacks detailed guidance on execution.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis on BRP-NAS is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot approaches. This feedback implies that the authors should expand their analysis to include more comparisons and consider additional NAS approaches. However, the comment does not explicitly instruct the authors to do so, nor does it provide specific guidance on which NAS approaches to include or how to conduct the analysis. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis on BRP-NAS, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the analysis is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot approaches. This provides clear guidance on what needs to be addressed in the analysis section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis on BRP-NAS is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot approaches. However, the comment does not provide specific examples or references to these other NAS approaches, nor does it explain why these comparisons are necessary or how they would enhance the analysis. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the analysis section of the paper, specifically noting that the BRP-NAS analysis only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot approaches. This feedback highlights an area where the paper could be expanded to provide a more comprehensive analysis. However, the comment does not offer specific suggestions on how to address this issue or which NAS approaches to consider, leaving the authors with a general direction but without detailed guidance on how to improve their draft. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors need to provide more information on the filtering process used to create the Arabic climate change QA dataset. It highlights the need for details on the translation and filtering methodology to assess the dataset quality. This feedback is clear and concrete, as it specifies exactly what information is missing and what needs to be added. The authors know exactly what steps to take to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Arabic climate change QA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of details on the filtering process used to create the dataset and the need for more information on the translation and filtering methodology to assess dataset quality. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"details around the filtering process used to create the Arabic climate change QA dataset are lacking.\" This is a factual observation about the paper, as it highlights a specific area where more information is needed. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is necessary or how it would impact the assessment of the dataset quality. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, namely the lack of details on the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to provide additional details that could enhance the transparency and credibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiment results could be enriched by adding attacks with different strengths and by exploring how different thresholds influence detection performance. While the comment implies that these additions would improve the results, it does not provide specific guidance on how to implement these changes or what specific types of attacks or threshold analyses should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to enhance their results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiment results could be enriched by adding attacks with different strengths and exploring how different thresholds influence detection performance. However, it does not specify which part of the paper these suggestions pertain to, such as specific sections or figures where these additions could be made. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting improvements. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiment results could be enriched by adding attacks with different strengths and exploring how different thresholds influence detection performance. However, the comment lacks specific examples or references to support the claim that these additions would improve the results. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to implement it. Therefore, the claim is considered borderline verifiable, as it provides a general direction but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the experiment results by suggesting the addition of attacks with different strengths and an exploration of how different thresholds influence detection performance. This feedback is clear and actionable, as it provides specific suggestions for enhancing the experimental analysis. However, the comment could be more helpful if it offered additional guidance on how to implement these changes or what specific types of attacks or threshold analyses should be considered. Overall, the comment is mostly helpful as it directs the authors toward meaningful enhancements to their draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. While the action is implicit, it is clear and concrete, as it specifies what additional information is needed to be included in the paper. The authors know exactly what to do to address the comment, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the performance difference resulting from using different image sizes and variations of ResNets. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. However, it does not provide any supporting evidence, reasoning, or references to justify why this information is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by including additional data or analysis. However, the comment lacks depth and does not provide specific guidance on how to present this information or what specific metrics or analyses would be most relevant. While it points out a potential area for improvement, the lack of detailed instructions limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to present and describe the Algorithm in detail, which is helpful for understanding the proposed method. This feedback provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the algorithm is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to present and describe the algorithm in detail, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the clarity and comprehensibility of their work. By addressing this suggestion, the authors can improve the reader\\'s ability to understand and evaluate the proposed method. However, the comment could be more helpful if it provided additional guidance on how to present and describe the algorithm, such as by suggesting specific sections or elements to focus on. Overall, the comment is mostly helpful as it identifies a clear area for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that if FFNs are omitted due to a linear decomposition issue, the authors should consider whether there is existing work that offers a way around this limitation. If not, the comment recommends adding a line or two acknowledging the lack of a solution and describing it as an open (hard) problem. This feedback provides a clear and explicit action for the authors to take, ensuring they know exactly what steps to consider to improve their draft. The suggestion is concrete and specific, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of FFNs being omitted due to a linear decomposition problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering existing work for a way around the issue and proposes adding a line or two to acknowledge the problem as an open (hard) problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that FFNs are omitted due to a linear decomposition issue and questions whether there is existing work that offers a way around this limitation. The comment suggests that if not, a line or two should be added acknowledging the problem as an open (hard) problem. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific references or examples to fully substantiate the claim. The authors might need to conduct additional research to verify the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper regarding the omission of FFNs due to a linear decomposition problem. It suggests that the authors should consider whether there is existing work that offers a way around this limitation, such as an approximation. If not, the comment recommends adding a line or two acknowledging the problem as an open (hard) problem. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the readability and clarity of their paper. By addressing this issue, the authors can enhance the comprehensiveness and rigor of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the impact of the number of images on model performance and suggests that the first appearance of BYOL in the abstract should be explained. While these questions imply that the authors should investigate the effect of image number and provide an explanation for BYOL, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an analysis and provide an explanation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific questions about the cluster structure and the impact of the number of images on model performance. It also suggests that the first appearance of BYOL in the abstract should be explained. However, it does not specify which part of the paper these questions are related to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for an explanation of the impact of image number and the introduction of BYOL, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the impact of the number of images on model performance and suggests that more training images might worsen performance. It also requests an explanation of BYOL in the abstract. While the comment identifies a potential issue with the model performance and suggests an explanation, it lacks specific examples or references to support the claim about the impact of image number. The mention of BYOL in the abstract is a request for clarification, but it does not provide a detailed explanation or evidence to substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the questions but lacks detailed evidence or references to fully support the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the impact of the number of images on model performance and suggests that more training images might worsen performance. It also requests an explanation of BYOL in the abstract, which is a relevant and potentially insightful aspect to explore. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address these issues or conduct the necessary analyses. While it identifies potential areas for improvement, it does not offer actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide stronger arguments or intuitions to explain why the method works, particularly regarding the L_pixel component. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information to clarify the reasoning behind the method's effectiveness. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of understanding the rationale behind the observed effects, specifically regarding the L_pixel component. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that providing stronger arguments or intuitions to explain why the method works would be beneficial. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind the method's effectiveness, particularly regarding the L_pixel component. It suggests that providing stronger arguments or intuitions would be beneficial. However, the comment does not provide specific examples or references to support the claim that the current explanation is insufficient. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the rationale behind the observed effects, particularly regarding the L_pixel component. It suggests that providing stronger arguments or intuitions to explain why the method works would be beneficial. This feedback is somewhat helpful as it points out an area where the authors could enhance their explanation, but it lacks specific guidance on how to develop these arguments or intuitions. The comment highlights a potential weakness in the paper but does not provide detailed suggestions on how to address it, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient and points out that LLMs are typically trained on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to improve the dataset. The action is implicit and somewhat vague, as the authors can infer that they need to consider the size and diversity of their training data but are not given specific instructions on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient and compares them to the typical training data for LLMs, which is typically on trillions of tokens. The comment suggests that the dataset needs to be massive to cover varied domains. However, it does not specify which part of the paper this concern is related to, such as the methodology or results sections. The authors can infer that it relates to the dataset used for training, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing the concern about the training data. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient, comparing them to the typical training data for LLMs, which is typically on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim that 44k dialogues are insufficient. This makes the claim somewhat verifiable, as the authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient, given that LLMs are typically trained on trillions of tokens. The comment suggests that the dataset needs to be massive to cover varied domains, which is a critical consideration for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might improve the dataset or what additional data sources might be considered. While it identifies a potential weakness, the feedback lacks actionable advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses skepticism about the use of binary classification as a baseline metric, questioning its ability to assess models\\' understanding of fine-grained errors like technique errors. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what alternative metrics or approaches might be more suitable. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the use of binary classification as a baseline metric and expresses skepticism about its ability to assess models\\' understanding of fine-grained errors like technique errors. However, it does not specify which part of the paper this concern is related to, such as the methodology or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the binary classification are problematic or how it could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the use of binary classification as a baseline metric, suggesting that it may not be adequate for assessing models\\' understanding of fine-grained errors like technique errors. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to alternative metrics or methods that could be used instead. As a result, the claim is not fully verifiable, making it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the use of binary classification as a baseline metric, suggesting that it may not be adequate for assessing models\\' understanding of fine-grained errors like technique errors. While it acknowledges the importance of the TAL task, it does not provide specific reasoning or suggestions for alternative metrics or approaches that could better assess the models\\' performance. The comment identifies a potential weakness in the methodology but lacks actionable guidance or detailed feedback to help the authors improve their draft. Therefore, it is somewhat helpful, as it points out a potential issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare the SynTextBench metric to other metrics proposed in the literature, specifically mentioning metrics like MMLU and Big Bench for language generation. While the comment does not explicitly instruct the authors to conduct this comparison, it provides a clear direction for how to enhance the evaluation of their metric. The action is implicit but concrete, as it specifies the metrics to compare and the conditions under which SynTextBench should be used. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"large amount of work on LLM evaluation\" and references specific metrics like MMLU and Big Bench, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of SynTextBench to other metrics proposed in the literature and how to use SynTextBench under specific conditions. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that there has been a large amount of work on LLM evaluation and that some of the metrics do not satisfy the proposed desiderata. It also mentions that it would be beneficial to compare SynTextBench to other metrics proposed in the literature, specifically mentioning MMLU and Big Bench for language generation. The comment provides a logical reasoning for why this comparison is important, but it lacks specific examples or references to support the claim that some metrics do not satisfy the desiderata. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to compare their SynTextBench metric to other metrics proposed in the literature, specifically mentioning MMLU and Big Bench for language generation. This feedback is valuable as it guides the authors in demonstrating the strengths and limitations of their metric in the context of existing evaluations. By addressing this suggestion, the authors can enhance the clarity and robustness of their evaluation, which is essential for the credibility and impact of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct the comparison or what specific conditions should be considered. Overall, the comment is mostly helpful as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to the methodology. As a result, the authors are left without any clear direction on how to improve their draft based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this methodology is discussed. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its question about the methodology but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. This feedback prompts the authors to reconsider their experimental setup and potentially explore alternative methods for data selection. However, the comment lacks specific guidance or suggestions on how to address this issue or what specific changes might be necessary. While it identifies a potential weakness, it does not provide actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks a thorough exploration of the upper limits of FedDES's scalability and does not provide a clear discussion of memory requirements or computational complexity. While the comment identifies specific areas that need attention, it does not offer explicit guidance on how to address these issues. The authors are left to infer that they need to provide more detailed discussions of scalability, memory requirements, and computational complexity, but the comment does not provide concrete steps or examples on how to achieve this. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"upper limits of FedDES's scalability\" and \"memory requirements or computational complexity,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a thorough exploration of scalability bounds and the absence of a clear discussion on memory requirements or computational complexity. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a thorough exploration of the upper limits of FedDES's scalability and does not provide a clear discussion of memory requirements or computational complexity. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some indication of a potential issue but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of a thorough exploration of the upper limits of FedDES's scalability and the absence of a clear discussion on memory requirements or computational complexity. This feedback is clear and actionable, as it points out specific areas where the paper could be improved to provide a more comprehensive understanding of the system\\'s scalability and performance. However, the comment could be more helpful if it offered suggestions on how to address these gaps, such as recommending specific metrics or analyses to include. Overall, the comment is mostly helpful as it directs the authors\\' attention to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implications of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It seeks clarification on whether the base node affects the ordering, key nodes for attention, and model performance. While the comment implies that the authors should provide more information or clarification on this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statement \"NodeSort differentially sorts nodes depending on the base node,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the implications of this statement, including whether the base node affects the ordering, key nodes for attention, and model performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the implications of a statement regarding \"NodeSort differentially sorting nodes depending on the base node.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the implications of the statement \"NodeSort differentially sorts nodes depending on the base node,\" seeking clarification on whether the base node affects the ordering, key nodes for attention, and model performance. This is a relevant question that could help the authors better understand the potential impact of their method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it points out a potential area for clarification, it lacks actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the arrow in Figure 2, specifically asking why it goes from a Gaussian space into the latent space rather than the other way around. This question implies that the authors should clarify or correct the arrow direction to better align with the intended purpose of the figure. However, the comment does not explicitly instruct the authors to make this change, leaving it somewhat vague. While the action is implied, the authors can infer that they need to address this issue, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the direction of the arrow in the figure, which is a clear indication of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the direction of the arrow in Figure 2, specifically asking why it goes from a Gaussian space into the latent space rather than the other way around. The reviewer seems to question the logic of the figure, suggesting that the main purpose is to influence n^(i). However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the direction of the arrow in Figure 2, specifically questioning why it goes from a Gaussian space into the latent space rather than the other way around. This feedback highlights a potential inconsistency in the figure, which could be confusing for readers. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the figure. While it identifies a potential problem, it lacks actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that many abbreviations lack definitions and cause confusion, specifically mentioning \"AR\" in Table 5 as an example. It provides a clear and specific action for the authors to take, which is to define these abbreviations in the text or provide a glossary. This guidance is direct and concrete, leaving no ambiguity about what needs to be done to improve the clarity of the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abbreviation \"AR\" in Table 5, noting that it stands for domain adaptation tasks and algorithms. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that many abbreviations lack definitions and cause confusion, specifically mentioning \"AR\" in Table 5 as an example. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that many abbreviations lack definitions and cause confusion. It provides a concrete example by mentioning \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This feedback is valuable as it highlights a clear area for improvement in the clarity and accessibility of the paper. By addressing this issue, the authors can enhance the readability and comprehensibility of their work. However, the comment could be more helpful if it suggested ways to improve the definitions or provided examples of how to clarify the abbreviations. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the technical considerations for conducting the analysis using advantage instead of q value. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific technical considerations should be explored or how to address them. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the technical considerations for conducting the analysis using advantage instead of q value, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine whether it relates to a specific section, table, or figure. Additionally, the comment lacks specificity regarding what technical considerations are being questioned or how they might impact the analysis. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the technical considerations for conducting the analysis using advantage instead of q value. However, it does not present any claims, opinions, or suggestions that require verification. It is a request for clarification, which is not a claim. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the technical considerations for conducting the analysis using advantage instead of q value, which is a relevant point for the authors to address. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might explore or justify their choice of using advantage over q value. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an issue with the performance comparison in Table 1, specifically noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This implies that the comparison is unfair and suggests that the authors should address this issue to ensure fairness in their evaluation. However, the comment does not provide explicit guidance on how to rectify this issue, such as suggesting specific changes to the experimental setup or methodology. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance comparison, noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance comparison in Table 1 is unfair because VINS sets different sample weights while most baselines use a uniform weight of 1. This claim is somewhat verifiable as it provides a logical reasoning for the unfairness, but it lacks specific examples or references to support the claim. The authors might need to infer the impact of this difference in sample weights on the results, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the performance comparison in Table 1, specifically noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This is a relevant observation that could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending a standardized weighting scheme or explaining the impact of this difference on the results. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the time complexity of the system if the reply buffer is too large. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the time complexity or suggestions for adjusting the buffer size. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"reply buffer,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the time complexity being too high if the reply buffer is too large, and it references a specific work, \"PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-based Planning,\" which provides a basis for the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the time complexity will be too high if the reply buffer is too large, referencing a specific work, \"PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-based Planning.\" This reference provides a basis for the claim, as it suggests that the time complexity could be an issue in the context of robotic navigation tasks. However, the comment does not provide detailed reasoning or analysis to fully substantiate the claim, such as explaining why the buffer size is critical or how it affects the time complexity. This makes the claim somewhat verifiable, as it provides a reference but lacks comprehensive justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the time complexity of the system if the reply buffer is too large. It references a specific work, \"PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-based Planning,\" which provides a basis for the claim. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or mitigate the time complexity. While it points out a potential problem, it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it provides some insight but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. While the comment provides a specific direction for improvement, it does not offer concrete guidance on how to implement these changes or which specific baselines to consider. The authors are left to infer the details of execution, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative approaches to consider, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why these alternative perspectives would be beneficial or how they would improve the paper. Without specific examples or detailed explanations, the claim remains unverifiable, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is somewhat helpful as it provides a specific direction for improvement by suggesting alternative approaches to consider. However, the comment lacks detailed guidance on how to implement these changes or which specific baselines to use. To be more helpful, the comment could offer examples of how these alternative perspectives have been applied in similar studies or provide suggestions on how to effectively integrate them into the paper. Overall, the comment provides some insight but could be more actionable with additional guidance. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. This feedback implies that the authors should include this comparison in their paper to enhance the results\\' meaningfulness. While the action is implied, it is clear and concrete, as it specifies the need for a specific comparison and provides a direction for improvement. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a potential comparison that could enhance the results\\' meaningfulness. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. While the comment provides a logical reasoning for why this comparison could enhance the results\\' meaningfulness, it lacks specific examples or references to support the claim that such a comparison is necessary or beneficial. This makes the claim somewhat verifiable, as the authors would need to infer the relevance and potential impact of this comparison themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive suggestion for enhancing the paper\\'s contribution by recommending a comparison with a method designed to defend against multiple attacks. This feedback is actionable as it points out a specific area for improvement that could enhance the paper\\'s impact and relevance. By including this comparison, the authors could demonstrate the effectiveness of their framework against a broader range of attacks, which would be valuable for the field. However, the comment could be more helpful if it provided specific examples of such methods or detailed guidance on how to conduct the comparison. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improving the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to define the bounds for \\tau_i^l, which is important for understanding the time-warp function. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of the bounds for \\tau_i^l, which is important for understanding the time-warp function. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment requests the definition of the bounds for \\tau_i^l, which is important for understanding the time-warp function. However, it does not provide any supporting evidence or reasoning to justify why this definition is necessary or how it would impact the understanding of the function. Without additional context or explanation, the claim is not fully verifiable, as it lacks the necessary justification to be considered fully verifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is specific and actionable, as it directly instructs the authors to define the bounds for \\tau_i^l, which is important for understanding the time-warp function. This feedback is clear and provides a concrete step for the authors to take in order to improve their draft. However, the comment could be more helpful if it explained why defining these bounds is crucial or how it would enhance the clarity of the paper. Despite this, the feedback is mostly helpful as it guides the authors toward a specific improvement that can significantly impact the comprehensibility of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the efficiency of their pairwise matching. There is no guidance on potential solutions, alternative approaches, or specific actions to take. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the efficiency of pairwise matching, which is a specific aspect of the paper. However, it does not explicitly mention which section of the paper discusses this efficiency, making it weakly grounded. The comment is specific in detailing the issue with the low efficiency of pairwise matching, which makes it difficult to use in practical application systems. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the efficiency of pairwise matching, noting that it is very low and difficult to use in practical application systems. This feedback is valuable as it highlights a potential weakness in the paper that could impact its practical applicability. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve the efficiency of their pairwise matching. While it points out a relevant concern, it does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance on how to improve the allocation or what aspects of the figure are considered naive. The comment lacks concrete details on how to address the issue, leaving the authors uncertain about how to apply the feedback. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions \"Figure 1,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity as it does not detail what is considered naive about the allocation of Figure 1 or how it could be improved. Without specific guidance or examples, the authors may struggle to understand the exact issues and how to address them. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the allocation of Figure 1 is \"too naive\" and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance or examples on how the authors could improve the allocation or what aspects of the figure are considered naive. Without detailed feedback or actionable suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the first sentence of the abstract needs to be rewritten. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and provides a concrete action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the first sentence of the abstract, allowing the authors to accurately identify the part of the paper being addressed. However, it does not provide specific details on what is wrong with the sentence or how it should be rewritten. This lack of specificity makes the comment weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the first sentence of the abstract needs to be rewritten. However, it does not provide any reasoning, evidence, or examples to support why this change is necessary or how it would improve the paper. Without additional context or explanation, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the first sentence of the abstract, suggesting that it needs to be rewritten. While this feedback is clear and actionable, it lacks depth and does not provide any further explanation or guidance on what aspects of the sentence need improvement. The authors are given a specific task to address, but without additional context or suggestions, they may struggle to fully understand and implement the necessary changes. Therefore, the comment is somewhat helpful, as it points out a clear area for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to determine what constitutes a significant contribution or how to improve the transferability of the method. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section, method, or result. Without explicit references to sections or elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the method or transferability need improvement. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is the case. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary information to support the assertion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any specific guidance or suggestions on how the authors might improve the transferability of their method or what aspects of the contribution are lacking. Without actionable feedback or detailed reasoning, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it identifies a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the challenges when analyzing Adam under the (L0,L1)-smoothness condition. It suggests that the authors should explain the challenges and the differences between this analysis and that of Zhang et al. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context and explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis of Adam under the (L0,L1)-smoothness condition, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the challenges and differences between this analysis and that of Zhang et al. This provides clear guidance on what the authors need to clarify or improve in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of Adam under the (L0,L1)-smoothness condition is unclear and suggests that the authors should explain the challenges and differences with Zhang et al. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the analysis of Adam under the (L0,L1)-smoothness condition. It points out that the challenges in this analysis are not clearly explained and suggests that the authors should clarify these challenges, especially in comparison to Zhang et al. This feedback is somewhat helpful as it highlights a potential gap in the paper that the authors can address to improve clarity and understanding. However, the comment could be more helpful if it provided specific suggestions on how to clarify these challenges or what aspects of the analysis are unclear. Overall, the comment offers some guidance but lacks depth and actionable details, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a factual statement about the prevalence of person re-ID methods based on pedestrian detectors and mentions a specific reference to an end-to-end method. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how this information should be incorporated into the paper or what specific aspects of the methodology should be addressed. As a result, the authors are left without any actionable steps to improve their draft based on this comment. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a factual statement about the prevalence of person re-ID methods based on pedestrian detectors and mentions a specific reference to an end-to-end method. However, it does not specify which part of the paper this information pertains to, making it weakly grounded. The comment is specific in detailing the types of person re-ID methods and their basis, but without explicit grounding, the authors cannot confidently determine which part of the paper should be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point provides a factual statement about the prevalence of person re-ID methods based on pedestrian detectors and mentions a specific reference to an end-to-end method. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is a factual statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a factual statement about the prevalence of person re-ID methods based on pedestrian detectors and mentions a specific reference to an end-to-end method. While this information is relevant, it does not offer any actionable feedback or suggestions for improvement. It does not guide the authors on how to incorporate this information into their paper or how it might impact their research. As a result, the comment lacks depth and does not provide meaningful assistance to the authors in enhancing their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests adding a first sentence to introduce what Section 3.2 is about. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is specific in detailing what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a first sentence to introduce what the section is about, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment suggests adding a first sentence to introduce what Section 3.2 is about. However, it does not provide any reasoning, evidence, or examples to support why this addition is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding a first sentence to introduce what Section 3.2 is about. This is a clear and actionable suggestion that can help the authors improve the clarity and accessibility of their paper. By providing a specific and direct recommendation, the comment offers a straightforward way for the authors to enhance the organization and flow of their content. However, the comment could be more helpful if it explained why this introduction is important or how it would benefit the reader. Overall, the comment is mostly helpful as it provides a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, it does not provide explicit guidance on what the authors should do to address this issue or how to clarify the statement. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the meaning of the term, but the comment lacks concrete details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this statement is problematic or unclear. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the meaning of the phrase \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. This feedback highlights a potential inconsistency or confusion in the paper, which could be clarified to improve the clarity and coherence of the text. However, the comment does not provide specific suggestions or guidance on how to address this issue or what alternative phrasing might be more appropriate. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the authors experimented with using domain ontologies to avoid placeholder generation in the evaluated responses. It also asks for clarification on the number of questions created for the zero-shot intent classifier and its accuracy. While the comment implies that the authors should provide more information about their experimental setup, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about their experiments. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the usage of domain ontologies to avoid placeholder generation and asks for clarification on the number of questions created for the zero-shot intent classifier and its accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the usage of domain ontologies to avoid placeholder generation and seeks clarification on the number of questions created for the zero-shot intent classifier and its accuracy. However, it does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or how they could impact the paper\\'s findings. Without additional context or explanation, the authors may find it challenging to understand the basis of the questions or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the usage of domain ontologies to avoid placeholder generation in the evaluated responses, which is a relevant and potentially valuable aspect to explore. It also seeks clarification on the number of questions created for the zero-shot intent classifier and its accuracy, which could provide valuable insights into the robustness and performance of the system. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address these questions or improve their work. While it identifies areas for potential enhancement, it does not provide actionable feedback that would help the authors make significant improvements to their draft. Therefore, the comment is somewhat helpful, as it points out areas for further exploration but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper is missing citations to set it in the context of other MARL work, specifically mentioning self-play and population-play with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This feedback is clear and provides concrete actions for the authors to take, including identifying and including relevant citations to enhance the context of their work. The explicit nature of the suggestion and the specific references make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for citations to set the paper in the context of other MARL work, specifically mentioning self-play and population-play with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it clearly details what needs to be addressed by including relevant citations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is missing citations to set it in the context of other MARL work, specifically mentioning self-play and population-play with respect to exploration and coordination. The reviewer provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This provides a clear and concrete basis for the claim, as it offers specific references that can help the authors understand the broader context of their work. Therefore, the claim is fully verifiable, as it is supported by explicit and relevant references.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out that the paper lacks citations to set it in the context of other MARL work, particularly self-play and population-play with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This feedback is clear and actionable, as it directs the authors to include relevant citations to enhance the context and relevance of their work. By addressing this point, the authors can significantly improve the comprehensiveness and impact of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the abstention process, specifically asking for clarification on how it differs from a decision threshold used by the models. While the comment implies that the authors should provide a clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction between the two processes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"abstention process,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how the abstention process differs from a decision threshold used by the models, and it suggests that the authors clarify this distinction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the abstention process, specifically asking for clarification on how it differs from a decision threshold used by the models. The comment does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the abstention process, asking for clarification on how it differs from a decision threshold used by the models. This is a clear and actionable request for the authors to provide additional explanation or clarification in their draft. By addressing this question, the authors can improve the clarity and understanding of their methodology. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. It suggests that the authors should compare their work with a chain-of-thought prompting approach, which is a specific and concrete suggestion for improvement. This feedback provides clear guidance on what the authors need to do to enhance their comparisons and make their work more robust. The explicit nature of the suggestion and the concrete example of a potential baseline make the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of meaningful baselines and the suggestion to compare with a chain-of-thought prompting approach. This provides clear guidance on what the authors need to improve in their comparisons. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. The reviewer suggests that the authors should compare their work with a chain-of-thought prompting approach. While the comment identifies a potential issue with the baselines, it does not provide specific examples or detailed reasoning to support why the current baselines are insufficient. The suggestion to compare with a chain-of-thought prompting approach is logical, but the comment could be strengthened with more detailed justification or examples. Therefore, the claim is somewhat verifiable, as it provides a direction for improvement but lacks comprehensive evidence or explanation.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that despite mentioning various model criticism techniques in Section 2, the authors limit their comparisons to simple naive baselines. The comment suggests that the authors should compare their work with a chain-of-thought prompting approach, which is a more meaningful baseline. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the robustness and credibility of the paper. By addressing this point, the authors can significantly strengthen their comparisons and demonstrate the effectiveness of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also questions how well this generalizes to settings where the associated labels are not available. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification or explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also questions how well this generalizes to settings where the associated labels are not available. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the model is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in its inquiry about the pretraining process and its generalizability. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the pretraining process of the cardiac signal representation learning model. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also questions how well this generalizes to settings where the associated labels are not available. This feedback is somewhat helpful as it prompts the authors to clarify an important aspect of their methodology, which could impact the robustness and generalizability of their results. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to present this information in the paper. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to take to ensure that the observations and design decisions are not dependent on specific hardware or software. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which part of the paper this pertains to. The authors cannot confidently determine which sections or elements of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the observations or design decisions are dependent on hardware or software. Without clear guidance on what needs to be addressed or improved, the authors cannot effectively address the comment. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how it affects their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the paper, suggesting that some observations and design decisions might be hardware and software dependent. While it identifies a potential weakness, it lacks specificity and does not provide actionable guidance on how the authors might address this issue or what specific aspects of the paper might be affected. Without detailed suggestions or examples, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study table. While the comment implies that the authors should address these questions, it does not provide explicit instructions or concrete suggestions on how to do so. The authors can infer that they need to provide more information or analysis to address these concerns, but the comment lacks specific guidance on what aspects to focus on or how to present the information. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study table. However, it does not specify which part of the paper these questions pertain to, such as specific sections or tables. This makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. While the comment is specific in its inquiry, it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study table. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of these questions or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the accuracy and reliability of the results presented in the paper. It questions whether the small differences observed are actually noticeable or due to noise or randomness in the training process. Additionally, it points out a lack of difference between the results reported in the ablation study table. While the comment identifies potential issues, it does not provide specific suggestions or guidance on how the authors might address these concerns or improve their analysis. The feedback is somewhat helpful as it prompts the authors to consider the reliability of their results and the potential sources of variability, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of important experimental details in the main text and the lack of explanations or interpretations in the Appendix. It specifically mentions the PCA experiments in Figures 3, 7, and 8 as examples of missing information. While the comment identifies areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include more detailed explanations and interpretations in the main text and Appendix, but the comment lacks concrete guidance on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures (Figures 3, 7, and 8) and the Appendix, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of explanations or interpretations for the PCA experiments in these figures. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important experimental details are missing or relegated to the Appendix, and that the Appendix lacks explanations or interpretations. The reviewer provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This provides a clear and specific basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that highlight the importance of including explanations and interpretations in the main text. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that important experimental details are missing or relegated to the Appendix, and that the Appendix lacks explanations or interpretations. It provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This feedback is clear and actionable, as it directs the authors to include more detailed explanations and interpretations in the main text and Appendix. However, the comment could be more helpful if it suggested ways to improve the presentation of these details or provided examples of how similar studies have addressed this issue. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of new evaluation metrics and the limited exploration of existing metrics in the experimental analysis section. It explicitly states that there needs to be an in-depth exploration of the reasons for the experimental results. This provides a clear and concrete action for the authors to take, which is to conduct a more thorough analysis of the experimental results and consider proposing new metrics. The comment is specific in detailing what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental analysis section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of new evaluation metrics and the limited exploration of existing metrics. The comment suggests an in-depth exploration of the reasons for the experimental results, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that no new evaluation metrics are proposed and that existing metrics are linearly combined. It suggests that the experimental analysis section needs an in-depth exploration of the reasons for the experimental results. However, the comment does not provide specific examples or references to support the claim that existing metrics are insufficient or that the exploration is lacking. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as the authors may find it challenging to understand the basis of the critique without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting the lack of new evaluation metrics and the limited exploration of existing metrics. It suggests that the experimental analysis section needs an in-depth exploration of the reasons for the experimental results. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by proposing new metrics or conducting a more thorough analysis of the existing ones. However, the comment could be more helpful if it offered examples of how to conduct such an exploration or provided guidance on what specific aspects to focus on. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notation \"K\" is being used inappropriately, as it is used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176). However, it does not provide explicit guidance on how to address this issue or suggest alternative notations. The action is implicit and vague, as the authors are left to infer that they need to clarify or change the notation to avoid confusion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L166\" and \"L176,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the notation \"K,\" which is being used for both a known kernel function and the number of layers, causing confusion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation \"K\" is being used inappropriately, as it is used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176). However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation \"K,\" noting that it is being used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176), which can cause confusion. This feedback is clear and actionable, as it points out a potential source of confusion in the paper and suggests a way to clarify the notation. However, the comment could be more helpful if it provided examples of how the notation is being used inappropriately or suggested alternative notations. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the relevance of connecting human cognition to the problem at hand, given that the authors acknowledge that the problem is reductionist and lacks mechanisms like bargaining and negotiation. The reviewer suggests that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR might have a greater impact on self-organization. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify their argument. The suggestion for more citation is implied but not directly stated, leaving the authors with a vague understanding of what steps to take. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discuss the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unclear connection between human cognition and the problem at hand. The comment suggests that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR might have a greater impact on self-organization than previously appreciated, and it questions the relevance of human cognition. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the relevance of connecting human cognition to the problem at hand, given that the authors acknowledge that the problem is reductionist and lacks mechanisms like bargaining and negotiation. The reviewer suggests that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR might have a greater impact on self-organization than previously appreciated. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the reviewer\\'s point, as the reasoning is not fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid point about the relevance of connecting human cognition to the problem at hand, given that the authors acknowledge that the problem is reductionist and lacks mechanisms like bargaining and negotiation. The reviewer suggests that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR might have a greater impact on self-organization than previously appreciated. This feedback is somewhat helpful as it prompts the authors to reconsider the relevance of human cognition in their analysis and potentially explore alternative perspectives. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue or what additional evidence or analysis might be needed. Overall, the comment offers a valuable insight but lacks detailed guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant in multiple places. However, it does not provide specific guidance on how to tone down the language or suggest alternative phrasing. The comment lacks explicit instructions or concrete examples of what constitutes overly exaggerated or flamboyant language, making it difficult for the authors to know exactly how to address the issue. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the conclusion, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the wording, describing it as overly exaggerated and flamboyant, and suggests that the word choice is a bit flamboyant in multiple places. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant in multiple places. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without specific instances or references to overly exaggerated or flamboyant phrases, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it lacks sufficient evidence or justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and suggests that the word choice is flamboyant in multiple places. This feedback is clear and actionable, as it provides the authors with a concrete example of where the language is excessive and suggests a more appropriate tone. However, the comment could be more helpful if it offered specific suggestions on how to tone down the language or provided examples of more appropriate phrasing. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific direction for the experiments, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the need for ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This provides full grounding as it clearly identifies the part of the paper that needs revision. The comment is also specific because it specifies the exact comparison that needs to be made, which is the number of learnable parameters and GFLOPs. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these comparisons are necessary or how they would benefit the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by conducting additional experiments. By doing so, the authors can demonstrate the effectiveness of their method in comparison to other approaches, which could enhance the paper\\'s contribution and credibility. However, the comment could be more helpful if it included suggestions on how to design these experiments or what specific insights to focus on. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It specifically mentions the use of separate embeddings and positional encoding, but it does not provide explicit guidance on how the embeddings are combined or how they are fed into the CSCM. The comment implies that the authors should provide more detailed explanations or clarifications, but it does not specify exactly what needs to be clarified or how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact details. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"text\" and \"CSCM,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely, how historical observations are combined with inputs known over all time given differences in sequence lengths. The comment provides a clear direction for the authors to address the issue by asking for clarifications on how the embeddings are combined and fed into the CSCM. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It mentions the use of separate embeddings and positional encoding, but it does not provide any supporting evidence, reasoning, or references to justify the claim that clarifications are needed. The comment lacks specific examples or detailed explanations to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the combination of historical observations and inputs known over all time, given differences in sequence lengths. It points out that the text mentions separate embeddings and positional encoding but lacks clarity on how these are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations or clarifications in the paper. However, the comment could be more helpful if it suggested specific ways to clarify these concepts or provided examples of how similar issues have been addressed in related work. Overall, the comment is mostly helpful as it effectively guides the authors toward improving the clarity and comprehensibility of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the sensitivity of hyperparameters such as $m_1$, $m_2$, and $\\\\lambda$ is not discussed in the paper, and their values are not specified. This implies that the authors should include a discussion on the sensitivity of these hyperparameters and specify their values. The comment is explicit in its request for additional information, providing clear guidance on what needs to be added to the paper. However, it does not specify how to present this information, leaving some room for interpretation. Therefore, the comment is mostly actionable, as it identifies a specific area for improvement but lacks detailed instructions on how to implement it.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sensitivity of hyperparameters such as $m_1$, $m_2$, and $\\\\lambda$, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on the sensitivity of these hyperparameters and the absence of their values in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sensitivity of hyperparameters such as $m_1$, $m_2$, and $\\\\lambda$ is not discussed in the paper, and their values are not specified. This is a factual observation that highlights a gap in the paper\\'s content. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this omission is problematic or how it affects the paper\\'s overall quality. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of discussion on the sensitivity of hyperparameters such as $m_1$, $m_2$, and $\\\\lambda$. It highlights that their values are not specified in the paper, which is a critical omission that could impact the validity and reliability of the results. This feedback is clear and actionable, as it directs the authors to include a discussion on the sensitivity of these hyperparameters and their values. However, the comment could be more helpful if it provided suggestions on how to approach this discussion or what specific aspects to consider. Overall, the comment is mostly helpful as it effectively points out a gap in the paper that the authors can address to enhance its rigor and clarity.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more experiments to address the concerns raised. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. However, the comment does not specify which part of the paper discusses the similarity-aware positive sample selection or the experimental results related to generalization. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing the concerns about the model's generalization and the need for additional experiments, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and generalization performance. It suggests that selecting positive samples without introducing perturbation noise could lead to lower generalization performance. The comment is somewhat verifiable as it provides a logical reasoning for the concern, but it lacks specific examples or references to support the claim. The authors might need to conduct additional experiments to validate the claim, making the comment somewhat verifiable. Therefore, the score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. While the comment identifies a critical area for improvement, it lacks specific suggestions or guidance on how to conduct these additional experiments or what specific downstream tasks should be considered. The feedback is somewhat helpful as it points out a potential issue but does not provide detailed guidance on how to resolve it. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the discussion should be expanded. The action is implicit and somewhat vague, as the authors can infer that they need to provide more discussion on the power of different architectures but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the architectures should be discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that fast SMP is less expressive than SMP. Without such evidence or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the architectures should be discussed. The comment is somewhat helpful as it points out a potential gap in the paper, but it does not provide actionable steps for the authors to improve their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the types of situations and social norms mentioned in the paper, such as physical and psychological safety, are not clearly defined. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify these concepts or what specific changes should be made to improve the clarity. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the types of situations and social norms, such as physical and psychological safety, are not clearly defined in the main paper. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of these situations and social norms are unclear or how they could be clarified. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the types of situations and social norms, such as physical and psychological safety, are not clearly defined in the main paper. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a lack of clarity in the paper regarding the types of situations and social norms, such as physical and psychological safety, which are mentioned but not clearly defined. This feedback is somewhat helpful as it points out an area where the authors could improve the clarity and comprehensibility of their work. However, the comment lacks specific suggestions or guidance on how to address this issue, such as providing examples or clarifying definitions. While it highlights a potential weakness, it does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more baselines should be compared and more domains should be tested. It also mentions that the choices of weighting and learning density functions are not strongly motivated, and that stronger empirical results are needed. However, the comment does not provide specific guidance on which baselines to compare or how to test the additional domains. The authors are left to infer that they need to expand their experimental setup, but without concrete suggestions on which baselines or domains to include, the action remains vague. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more baselines should be compared and more domains should be tested, and it mentions the choices of weighting and learning density functions as areas for improvement. However, it does not specify which part of the paper these suggestions pertain to, such as specific sections or experiments where these improvements could be made. Additionally, it lacks specific guidance on which baselines or domains should be included. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that more baselines should be compared and more domains should be tested, and it critiques the choices of weighting and learning density functions as not being strongly motivated. However, the comment lacks specific examples or references to support the claim that these choices are not justified or that the current results are insufficient. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, suggesting that more baselines should be compared and more domains should be tested. It also critiques the choices of weighting and learning density functions as not being strongly motivated, implying that stronger empirical results are needed. However, the comment lacks specific suggestions on which baselines or domains to include, making it somewhat helpful as it points out areas for improvement but does not provide detailed guidance on how to address them. Therefore, the comment is rated as somewhat helpful, as it offers some direction but could be more actionable with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods is questionable. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the comparability of the results or what specific aspects need to be improved. As a result, the authors are left without any clear direction on how to enhance the significance of their work. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods is questionable. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the results are not comparable or how they could be improved. Without clear guidance on where to focus the revision, the authors may struggle to address the issue effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the results are not comparable to existing methods, which suggests that the significance of the proposed methods is questionable. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods may be questionable. However, it does not provide any specific examples or guidance on how the authors might address this issue or improve the comparability of their results. Without actionable feedback or detailed suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of novelty in the paper, specifically noting that it is a straightforward application of existing literature, such as DeCorr, in a specific application domain. It highlights the main contribution as the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment also points out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems. While the comment implies that the authors should provide more insights into these challenges, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the lack of unique insights. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DeCorr [1],\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems, despite being a straightforward application of existing literature. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks novelty and is a straightforward application of existing literature, specifically DeCorr. The reviewer supports this claim by mentioning that the paper's contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment also acknowledges that modifications like different penalty coefficients for users and items are proposed. While the claim is mostly verifiable due to the mention of DeCorr and the transposition of insights, it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it lacks novelty and is a straightforward application of existing literature, specifically DeCorr. It highlights the main contribution as the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment also points out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems. While the comment provides some insight into the paper\\'s limitations, it does not offer specific suggestions or guidance on how the authors might address these issues or enhance the novelty of their work. The feedback is somewhat helpful as it identifies a critical area for improvement, but it lacks actionable advice or detailed guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the paper regarding the assumption that the spectrum of a kernel is sub-gaussian. It acknowledges that this assumption is reasonable for Gaussian kernels but points out that it may be restrictive for other popular classes of kernels, such as Matern kernels. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or expand their results to include other kernel classes. The action is implicit and somewhat vague, as the authors need to infer that they should consider the implications of this limitation and potentially explore other kernel classes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the assumption of the spectrum of a kernel being sub-gaussian, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the assumption is reasonable for Gaussian kernels but may be restrictive for other popular classes of kernels, such as Matern kernels. This provides clear guidance on what needs to be addressed in terms of the limitations of the results. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the assumption of the spectrum of a kernel being sub-gaussian is reasonable for Gaussian kernels but may be restrictive for other popular classes of kernels, such as Matern kernels. The reviewer supports this claim by pointing out that Matern kernels only decay polynomially, which could limit the applicability of the results. However, the comment lacks specific examples or references to Matern kernels or other classes of kernels to fully substantiate the claim. While the reasoning is logical, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper regarding the assumption that the spectrum of a kernel is sub-gaussian. It acknowledges that this assumption is reasonable for Gaussian kernels but points out that it may be restrictive for other popular classes of kernels, such as Matern kernels. This feedback is valuable as it highlights a potential limitation in the applicability of the results, which the authors should consider when interpreting and presenting their findings. However, the comment could be more helpful if it provided suggestions on how the authors might address this limitation or expand their results to include other kernel classes. Overall, the comment is somewhat helpful as it directs the authors to consider a potential limitation in their work, but it lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how to choose an ELM (male/female) and whether this requires knowing the speaker\\'s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not provide explicit guidance or suggestions on how to address this issue. The authors are left to infer that they might need to consider this aspect in their methodology or experimental design, but the comment lacks concrete steps or detailed advice on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the choice of ELM (male/female) and whether this requires knowledge of the speaker\\'s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment. While the authors might have an idea of where this discussion might occur, the comment lacks full grounding. It is specific in its critique of the methodology but does not provide detailed guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of ELM (male/female) and whether this requires knowledge of the speaker\\'s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment lacks specific reasoning or evidence to support why this is a drawback or how it affects the methodology. The claim is somewhat verifiable as it highlights a potential issue but does not provide detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the choice of ELM (male/female) and whether this requires knowledge of the speaker\\'s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline, especially in cases where vocal traits match the speaker\\'s identity. This feedback is somewhat helpful as it identifies a potential issue with the methodology that the authors may not have considered. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what alternative approaches might be considered. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the paper is incremental and lacks technical substance, specifically mentioning that it adds a new loss to [31]. However, it does not provide any guidance on how the authors might address this issue or what specific changes could be made to improve the paper. The lack of explicit or implicit actions makes it difficult for the authors to know how to respond to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper is incremental and lacks technical substance, specifically mentioning that it adds a new loss to [31]. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity in detailing what aspects of the paper are considered incremental or lacking in substance. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is incremental and lacks technical substance, specifically mentioning that it adds a new loss to [31]. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper is incremental and lacks technical substance, specifically mentioning that it adds a new loss to [31]. However, it does not provide any specific feedback or suggestions on how the authors might address this issue or improve the paper. Without actionable guidance or detailed reasoning, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it identifies a potential weakness but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide empirical evidence to demonstrate the applicability of their model to real-world diffusion processes. While the comment implies that the authors should conduct experiments or provide examples to support their claims, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors know they need to provide empirical evidence but may not be entirely sure of the specifics of what is expected. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the applicability of the model to real-world diffusion processes, suggesting that the authors should provide empirical evidence to demonstrate its effectiveness. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for empirical evidence, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the applicability of the model to real-world diffusion processes is a concern, and it provides a logical reasoning by stating that the authors should provide empirical evidence to demonstrate its effectiveness. However, the comment lacks specific examples or references to support the claim that the model captures diffusion phenomena in real-world scenarios. While the suggestion is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the applicability of the proposed model to real-world diffusion processes. It acknowledges the elegance of the solutions presented but suggests that empirical evidence is needed to demonstrate the model's effectiveness in real-world scenarios. This feedback is clear and actionable, as it provides a specific direction for the authors to address the applicability issue by providing empirical evidence. However, the comment could be more helpful if it offered suggestions on how to conduct such experiments or what specific aspects of the diffusion process should be examined. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should provide a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a clear and concrete action that the authors can take to improve their draft. The comment provides a specific direction for visualizing the results, which is a direct and actionable point. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing a plot of how different weights of the model move, specifically after unlearning, to see which layers are affected the most. However, it does not specify which part of the paper this plot should be included in, such as a specific section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular visualization, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a request for additional visualization to support the understanding of the method. However, the comment does not provide any specific reasoning or evidence to support why this plot is necessary or how it would enhance the paper. Without additional context or explanation, the claim is somewhat verifiable, as it requires the authors to make a leap of faith to understand the importance of the suggested plot. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It recommends that the authors include a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a clear and constructive piece of feedback that can help the authors better understand and communicate the impact of their method. By addressing this suggestion, the authors can enhance the clarity and comprehensiveness of their results, making the paper more informative and valuable to the reader. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the paper is limited, particularly regarding the ENCODE part, which is already proposed in a previous work. It points out that the incremental contribution lies in the decomposition part, which only involves factoring M_v into factor D and slicing Phi_v. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue or improve their draft. There is no guidance on how to enhance the novelty or what specific changes could be made to the methodology. As a result, the authors are left without any actionable steps to improve their draft based on this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"methodology aspect\" and \"ENCODE part,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the novelty of the paper is limited, particularly regarding the ENCODE part, which is already proposed in a previous work. The comment further details the incremental contribution as being in the decomposition part, which involves factoring M_v into factor D and slicing Phi_v. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, particularly regarding the ENCODE part, which is already proposed in a previous work. The reviewer supports this claim by referencing the work [10], which provides a basis for the critique. However, the comment does not provide further details or examples from [10] to fully substantiate the claim. While the reference to [10] offers some support, the comment could be strengthened by providing more detailed reasoning or specific examples from the referenced work. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks full justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the novelty of the paper, particularly regarding the ENCODE part, which is already proposed in a previous work. It highlights that the incremental contribution lies in the decomposition part, which involves factoring M_v into factor D and slicing Phi_v. While the comment points out a potential issue with the novelty of the paper, it does not provide specific suggestions or guidance on how the authors might address this limitation or enhance the novelty of their work. The feedback is somewhat helpful as it alerts the authors to a potential weakness, but it lacks actionable advice or detailed insights to help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the presentation is too equation-driven and that the notation in chapter 3 is convoluted and hard to follow. It also recommends the inclusion of an illustrative figure to help clarify the key concepts in section 3. While the comment provides a clear action\u2014adding an illustrative figure\u2014it does not specify which concepts should be illustrated or how the figure should be designed. The authors are given a clear direction to add an illustrative figure but are left to determine the specifics of implementation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the presentation, specifically mentioning that it is too equation-driven and that the notation in chapter 3 is convoluted and hard to follow. It also suggests the inclusion of an illustrative figure to help clarify the key concepts in section 3. While the comment does not explicitly mention a specific section or figure, the authors can infer that it relates to the presentation and notation in chapter 3. The suggestion to include an illustrative figure is specific, providing a clear action for the authors to take. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the presentation is too equation-driven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure would be helpful to clarify the key concepts in section 3. While the comment identifies specific issues with the presentation, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion for an illustrative figure is a logical point, but without further explanation or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation, noting that it is too equation-driven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure would be helpful to clarify the key concepts in section 3. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation by adding an illustrative figure. However, the comment could be more helpful if it offered specific guidance on what elements should be illustrated or how the figure should be designed to enhance clarity. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the comprehensive nature of the data presented in Figure 3 but points out that the visual presentation, specifically the subscripts, could be improved for better readability and aesthetic appeal. While the comment identifies an area for enhancement, it does not provide explicit guidance on how to achieve this improvement. The authors are left to infer that they should make changes to the subscripts, but without specific suggestions or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the visual presentation of the subscripts, for better readability and aesthetic appeal. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the comprehensive nature of the data presented in Figure 3 but suggests that the visual presentation, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. However, the comment does not provide specific examples or detailed reasoning to support why the subscripts are problematic or how they could be improved. Without such examples or references, the claim is not fully verifiable, as it lacks the necessary evidence or justification to substantiate the suggestion. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges the comprehensive nature of the data presented in Figure 3 but points out a specific area for improvement. It suggests that the visual presentation, particularly the subscripts, could be enhanced for better readability and aesthetic appeal. While the comment identifies a clear area for improvement, it lacks detailed guidance or suggestions on how to achieve this enhancement. The authors are left to infer that they should make changes to the subscripts, but without specific instructions or examples, the feedback is somewhat helpful. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the difference between Online Normalization and Batch Normalization, specifically questioning why Online Normalization is unbiased while Batch Normalization is biased. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify their explanation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discuss the problem of gradient bias in Batch Normalization and the potential of Online Normalization. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the difference between Online Normalization and Batch Normalization, asking why Online Normalization is unbiased while Batch Normalization is biased. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that Online Normalization is unbiased and Batch Normalization is biased, suggesting that the authors have not adequately explained this difference. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the difference between Online Normalization and Batch Normalization, specifically questioning why Online Normalization is unbiased while Batch Normalization is biased. This is a relevant point that could help the authors clarify their explanation or provide additional context to readers. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors have reduced whitespace throughout the paper, resulting in cramped equations and captions too close to the figures. This is considered a grounding comment as it clearly identifies the issue with the spacing. However, the comment does not provide any guidance on how to address this issue, such as suggesting specific adjustments or improvements to the spacing. The action is implicit and vague, leaving the authors without clear direction on how to improve the paper in this regard. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of whitespace throughout the paper, specifically mentioning that equations are crammed together and captions are too close to the figures. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the problem of violating the 9-page paper limit due to the reduced whitespace. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper violates the 9-page limit due to the reduced whitespace, specifically mentioning cramped equations and captions too close to the figures. However, the comment does not provide any supporting evidence or reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how it affects the paper\\'s acceptability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s formatting, noting that the reduced whitespace throughout the document results in cramped equations and captions too close to the figures. This is a clear and actionable observation that could impact the paper\\'s readability and adherence to the 9-page limit. However, the comment does not provide suggestions on how to address this issue or improve the spacing, such as recommending adjustments to the margins or spacing between elements. While it highlights a significant problem, the lack of actionable guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical details or formulations, nor are there suggestions for how to better highlight the novelty of the scheme or procedure. As a result, the authors are left without any clear direction on how to enhance their draft based on this feedback. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the technical details or formulations are lacking or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not provide any specific guidance or suggestions on how the authors might improve the technical details or formulations to better highlight the novelty of their work. Without actionable feedback or detailed insights, the authors are left without a clear path for enhancing their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential issue but lacks depth and specificity in its feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the paper\\'s claims regarding the Molecule generation experiment, specifically noting that the proposed constrained method actually yields lower validity and diversity. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or improve their results. The comment lacks actionable details, such as recommending specific analyses or modifications to the methodology, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed constrained method actually yields lower validity and diversity in the Molecule generation experiment. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s results in the Molecule generation experiment are not as expected, specifically that the proposed constrained method actually yields lower validity and diversity. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the paper\\'s claims regarding the Molecule generation experiment, specifically noting that the proposed constrained method actually yields lower validity and diversity. This is a critical observation that could impact the paper\\'s conclusions and credibility. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their results. While it points out a potential problem, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so or provide specific guidance on what details should be included. The action is implicit and somewhat vague, as the authors need to infer that they should add more information about the environment. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper this information should be included in, nor does it provide detailed guidance on what aspects of the environment should be described. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need attention or improvement. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. However, it does not provide any reasoning, evidence, or examples to support why this additional information is necessary or how it would enhance the paper. Without such justification, the claim is unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by providing additional context or background information. However, the comment lacks depth and does not offer specific suggestions on what aspects of the environment should be described or how this information could enhance the paper. While it points out a potential area for improvement, it does not provide actionable guidance or detailed advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that a discussion on the prompt dataset creation for the few-shot case, along with its source, should be included in the paper. This is a clear and direct action for the authors to take, as it provides a specific area for improvement and guidance on what to include in the discussion. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that a discussion on the prompt dataset creation for the few-shot case, along with its source, should be included in the paper. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact location of the discussion. The comment is specific in suggesting what needs to be addressed, but without explicit grounding, it is difficult for the authors to pinpoint the exact part of the paper that requires revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a discussion on the prompt dataset creation for the few-shot case, along with its source, should be included in the paper. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a discussion on the prompt dataset creation for the few-shot case, along with its source, should be included in the paper. This feedback is somewhat helpful as it identifies a specific area for improvement, which is the inclusion of a discussion on the dataset creation process. However, the comment lacks depth and does not provide detailed guidance on how to conduct this discussion or what specific aspects should be covered. While it points out a gap in the paper, it does not offer actionable steps or examples to help the authors effectively address the issue. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the clarity of the motivation or how to differentiate the paper from incremental engineering papers. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the motivation of the paper is difficult to follow and that it appears to be an incremental engineering paper. However, it does not specify which part of the paper is problematic or where the motivation is unclear. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the motivation or the paper are unclear or how they could be clarified. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific details or references, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the motivation of the paper is difficult to follow and that it appears to be an incremental engineering paper. However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity or originality of their work. Without actionable feedback or detailed insights into what aspects of the paper are unclear or lacking, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests an ablation on the weighting method of the cross-entropy loss, specifically mentioning that it would be beneficial to see how it affects the performance of the method in a scenario where the game has repetitive background sounds. The reviewer provides a clear rationale for why this ablation is important, noting that the weighting might have helped remedy the underperformance in such scenarios. However, the comment does not explicitly instruct the authors to conduct this ablation or provide detailed guidance on how to implement it. While the action is implied, the lack of concrete steps makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an ablation on the weighting method of the cross-entropy loss, specifically mentioning the scenario where the game has repetitive background sounds. This provides a clear reference to the section where the authors discuss the performance of their method in Atlantis. However, the comment does not specify which part of the paper should include this ablation, making it weakly grounded. The suggestion is specific, as it clearly identifies what needs to be addressed, namely the weighting method of the cross-entropy loss in the context of repetitive background sounds. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting an ablation on the weighting method of the cross-entropy loss, specifically mentioning that it might help remedy the underperformance of the method in a scenario with repetitive background sounds. This claim is somewhat verifiable as it is based on a logical reasoning that the weighting might improve performance in such scenarios. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests an ablation on the weighting method of the cross-entropy loss, specifically mentioning that it might help remedy the underperformance of the method in a scenario with repetitive background sounds. This is a clear and actionable suggestion that could improve the paper by providing additional insights into the performance of the method in different contexts. However, the comment could be more helpful if it included specific guidance on how to conduct the ablation or what specific aspects of the weighting method should be explored. Overall, the comment is mostly helpful as it identifies a potential area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for Text-to-SQL and notes that the proposed dataset is a different train/test split of an existing dataset, SQUALL. Additionally, the comment mentions a synthetic benchmark paper based on a single question template. While the comment highlights these issues, it does not provide explicit guidance on how the authors should address them. The authors can infer that they need to demonstrate novelty and incremental improvements, but the comment lacks concrete suggestions on how to achieve this. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific issue of the lack of novelty and incremental nature of the work, as well as the problem of column operations in designing semantic parsers for Text-to-SQL. It also mentions the design of a new dataset, which is a different train/test split of an existing dataset, SQUALL. Additionally, it points out a synthetic benchmark paper based on a single question template. This level of detail allows the authors to accurately identify the parts of the paper being addressed. The comment is specific in detailing what needs to be improved, such as demonstrating novelty and incremental improvements, and providing suggestions for addressing the issue of column operations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks novelty and is incremental in nature, specifically addressing a problem of column operations in designing semantic parsers for Text-to-SQL. The reviewer provides some justification by mentioning that the proposed dataset is a different train/test split of an existing dataset, SQUALL, and that the synthetic benchmark paper is based on a single question template. However, the comment could be strengthened by providing more detailed examples or references to support the claim of lack of novelty. As it stands, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification. Therefore, the score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for Text-to-SQL and notes that the proposed dataset is a different train/test split of an existing dataset, SQUALL. Additionally, the comment mentions a synthetic benchmark paper based on a single question template, which further highlights the lack of novelty. This feedback is clear and actionable, as it directs the authors to address the issue of novelty and incremental nature in their work. However, the comment could be more helpful if it provided suggestions on how to demonstrate novelty or incremental improvements, such as by suggesting alternative approaches or datasets. Overall, the comment is mostly helpful as it effectively identifies a critical weakness and offers direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the experiments are limited to one game environment and suggests that more experiments are necessary. This provides a clear and direct action for the authors to take, which is to expand their experimental scope to include additional game environments. The comment is specific in its request for additional experiments, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the experiments are limited to one game environment and recommends conducting more experiments. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to conduct more experiments, but without clear references to specific sections or experiments, the authors may struggle to identify where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments are limited to one game environment and recommends conducting more experiments. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this limitation is problematic or how it affects the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the experiments, noting that they are conducted on only one game environment. It suggests that more experiments are necessary to provide a broader perspective. While this feedback highlights an area for improvement, it lacks specific guidance on which additional environments should be considered or how to conduct these experiments. The comment is somewhat helpful as it points out a potential weakness but does not offer detailed suggestions for improvement, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. This is a clear and direct action for the authors to take, as it specifies the need for a detailed explanation with examples. The comment provides a concrete direction for improvement, ensuring that the authors know exactly what needs to be done to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. This allows the authors to accurately identify the part of the paper being addressed, making it fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for a detailed explanation with examples. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors need to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these assumptions are important or how removing them would contribute to the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors need to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. This feedback is clear and actionable, as it directs the authors to provide a detailed explanation with examples to strengthen their argument. By addressing this point, the authors can enhance the clarity and impact of their paper. However, the comment could be more helpful if it provided specific examples or guidance on how to present these explanations. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the authors\\' claim of implementing ImageNet for the first time and the actual slow speed and low accuracy. It provides specific information about the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet-18, as well as the accuracy, which is around 70%. This explicit comparison and concrete data provide the authors with a clear action to take: they need to address the issue of slow speed and low accuracy by improving their implementation. The comment is explicit and provides concrete details on how to apply the action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the implementation of ImageNet, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of slow speed and low accuracy, providing specific examples of the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet-18, as well as the accuracy, which is around 70%. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' implementation of ImageNet is slow and has low accuracy, citing specific examples of time and accuracy. However, the comment does not provide any supporting evidence or references to substantiate these claims. Without additional context or detailed analysis, the authors may find it challenging to understand the basis of these claims and address them effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the authors\\' claim of implementing ImageNet for the first time and the actual slow speed and low accuracy. It provides specific examples of the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet-18, as well as the accuracy, which is around 70%. This feedback is clear and actionable, as it highlights a critical issue that the authors need to address to improve the credibility and effectiveness of their work. By addressing these points, the authors can enhance the robustness and reliability of their implementation. However, the comment could be more helpful if it offered suggestions on how to improve the speed and accuracy, such as potential optimizations or alternative approaches. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. While it suggests that labeled data might provide effective information for consistency training, it does not offer any explicit guidance or actionable steps for the authors to take. The comment lacks specific instructions or examples on how to incorporate this suggestion into the paper. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in suggesting that labeled data might provide effective information for consistency training and provides examples of relevant works, such as \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation.\" Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. The reviewer supports this suggestion by referencing two external works, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which demonstrate the effectiveness of using labeled data for this purpose. However, the comment lacks detailed reasoning or specific examples from the works to fully substantiate the claim. While the references provide some support, the comment could be strengthened by further elaboration on why labeled data might be beneficial and how it could be integrated into the paper. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. While it suggests that labeled data might provide effective information for consistency training, it does not offer specific guidance or actionable steps for the authors to explore this idea further. The comment references two external works, which could be useful for the authors to consider, but the suggestion is not fully developed or integrated into the review. Overall, the comment provides some insight but lacks depth and actionable advice, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the classification error of the proposed network and suggests reporting the classification accuracy on ImageNet data. It also requests theoretical justifications, if possible. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should report the classification accuracy and provide theoretical justifications. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed classification network, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the classification error of the proposed network and suggests reporting the accuracy on ImageNet data. Additionally, it requests theoretical justifications, which provides clear guidance on what the authors need to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the classification error of the proposed network and questions whether it is as good as the standard softmax network. The comment suggests that building a new model for detecting out-of-distribution samples could lead to loss of classification accuracy. However, the comment lacks specific examples or references to support the claim that the proposed network's classification error is universally inferior to the standard softmax network. Without such evidence or detailed reasoning, the claim is difficult for the authors to verify. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the classification error of the proposed network and its potential impact on detecting out-of-distribution samples. It suggests reporting the classification accuracy on ImageNet data and requests theoretical justifications, if possible. This feedback is actionable as it provides clear guidance on how the authors can address the issue by providing additional data and analysis. However, the comment could be more helpful if it offered specific suggestions on how to improve the classification accuracy or provided examples of theoretical justifications. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement and provides a clear path for addressing it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the practicality of the argument that recognition lists are recalled based on items, particularly in the context of old vs. new judgments. It points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what specific changes could be made to improve the argument or simulations. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific argument related to the practicality of the recognition process, particularly in the context of old vs. new judgments. However, it does not specify which part of the paper this argument is discussed in, making it weakly grounded. The comment is specific in pointing out the issue with the exhaustive list of items and how it relates to concrete predictions through simulations. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the practicality of the argument that recognition lists are recalled based on items, particularly in the context of old vs. new judgments. The reviewer points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. This claim is somewhat verifiable as it provides a logical reasoning for the difficulty in implementing the argument, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the argument presented regarding the recall of recognition lists based on items, particularly in the context of old vs. new judgments. It points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. While the comment highlights an important issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their argument. The feedback is somewhat helpful as it prompts the authors to consider the practicality of their argument, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and clarifies the additional information that CD captures on top of Predictive Uncertainty. It also questions why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples\" (line 115). The reviewer does not provide specific guidance on how to implement these suggestions, leaving the authors to infer the actions needed. The feedback is explicit in identifying the need for clarification and alternate formulations, but it lacks concrete details on how to achieve these improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 113\" and \"line 115,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the additional information captured by Confidence Diversity (CD) and the appropriateness of entropy as a measure. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the additional information captured by Confidence Diversity (CD) and the appropriateness of entropy as a measure. It suggests that the paper should describe possible alternate formulations for CD. However, the comment lacks specific examples or references to support the claim that entropy is not a good measure. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the additional information captured by Confidence Diversity (CD) and the appropriateness of entropy as a measure. It suggests that the paper should describe possible alternate formulations for CD and provides a rationale for why entropy might not be a good measure. This feedback is clear and actionable, as it directs the authors to clarify their work by explaining the additional information captured by CD and potentially exploring alternative formulations. However, the comment could be more helpful if it offered specific suggestions on how to present these formulations or what additional information should be included. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the assumption for termination states of instructions is quite strong, particularly when it comes to labeling a large number of data manually. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the assumption for termination states of instructions, particularly in the context of labeling a large number of data manually. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the issue of the assumption being too strong, but it lacks detailed guidance on how to address this issue or what specific changes could be made. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the assumption for termination states of instructions is \"quite strong,\" particularly when it comes to labeling a large number of data manually. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the assumption for termination states of instructions, particularly when it comes to labeling a large number of data manually. This is a relevant point that could impact the feasibility and cost-effectiveness of the proposed method. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue or improve their approach. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the paper regarding the nature of the contribution with respect to ECE_sweep. It explicitly states that the contribution is not clearly described and suggests that the authors should be more upfront about it. The reviewer provides a concrete example of what is missing, which is the autotuning of a hyperparameter in the estimate, and notes that this is not fundamentally different from the contribution. The comment is explicit in its request for clarification and provides a specific example of what needs to be addressed. Therefore, the comment is highly actionable, as it clearly guides the authors on how to improve the clarity of their contribution.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ECE_sweep\" and the issue with the contribution being unclearly described. It specifies the problem by pointing out that the contribution is not clearly described, particularly regarding the autotuning of a hyperparameter in the estimate. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the contribution with respect to ECE_sweep is not clearly described in the text. It provides a specific example of the issue, which is the autotuning of a hyperparameter in the estimate, and notes that this is not fundamentally different from the contribution. The reviewer acknowledges being confused about the paper\\'s point until they realized this. This provides a logical reasoning for the claim, supported by a concrete example, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to similar works that might have addressed this issue. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the contribution regarding ECE_sweep. It points out that the contribution is not clearly described in the text, particularly regarding the autotuning of a hyperparameter in the estimate. The reviewer acknowledges being confused about the paper\\'s contribution until they realized this, which highlights the need for a clearer explanation. The comment provides a concrete example of what is missing, offering a clear and actionable suggestion for improvement. By addressing this issue, the authors can enhance the clarity and understanding of their contribution, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. However, it does not provide explicit guidance on which methods should be used as a baseline or how to incorporate them into the paper. The action is implicit and vague, as the authors are left to infer that they should consider using these methods as a baseline. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the related work section, noting that it discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This feedback is somewhat helpful as it points out a potential gap in the paper\\'s evaluation, which could be addressed by including these methods as baselines. However, the comment lacks depth and does not provide specific suggestions on how to incorporate these methods or why they are important. To be more helpful, the comment could offer guidance on how to effectively integrate these methods into the evaluation or explain why they are relevant to the paper\\'s goals. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential ambiguity in the authors\\' use of the term \"efficient proxy\" or \"efficient proxies\" in their work. It suggests that the term \"is\" might imply a particular proxy, but the lack of a specific \"Efficient Proxy\" suggests that it might refer to a family of proxies. The reviewer does not provide explicit guidance on how the authors should clarify this ambiguity or what specific actions they should take to address it. However, the comment implies that the authors should clarify the intended meaning of \"efficient proxy\" or \"efficient proxies\" to avoid confusion. While the action is implicit, it is clear that the authors need to make a clarification to improve the draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"efficient proxy\" or \"efficient proxies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ambiguity in the term, suggesting that it might refer to a particular proxy or a family of proxies. This provides clear guidance on what needs to be clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the ambiguity in the term \"efficient proxy\" or \"efficient proxies,\" suggesting that it might refer to a particular proxy or a family of proxies. The reviewer provides logical reasoning by pointing out that the use of \"is\" might imply a particular proxy, but the lack of a specific \"Efficient Proxy\" suggests a broader reference. This reasoning is somewhat verifiable as it highlights a potential issue in the clarity of the paper, but it could be strengthened with additional examples or references to support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the authors\\' use of the term \"efficient proxy\" or \"efficient proxies.\" It suggests that the term might refer to a particular proxy or a family of proxies, based on the use of the word \"is.\" This feedback is somewhat helpful as it points out a potential source of confusion in the paper, which the authors can address to improve clarity. However, the comment could be more helpful if it provided specific suggestions on how to clarify the ambiguity or offered examples of how the term might be clarified. Overall, the comment is somewhat helpful as it highlights an area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the authors stacking methods from Mirzasoleiman et al., 2020 and using a group-learning setting, followed by a classical method like DBSCAN for clustering. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to improve the approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the authors\\' methodology, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the group-learning setting, followed by the use of a classical method like DBSCAN for clustering. However, it does not specify which part of the paper this methodology is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the methodology, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors stack methods from Mirzasoleiman et al., 2020 and use a group-learning setting, followed by a classical method like DBSCAN for clustering. However, the comment lacks any supporting evidence, reasoning, or references to justify why this approach is problematic or inappropriate. Without additional context or explanation, the claim remains unverifiable, as it does not provide sufficient justification for the authors to understand or address the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the authors\\' methodology, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the group-learning setting, followed by the use of a classical method like DBSCAN for clustering. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or detailed advice, the authors are left without a clear path forward. Therefore, the comment is barely helpful, as it identifies a potential weakness but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. It also mentions that the authors might have missed this in the appendix. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the resilience of the metric to the choice of random projection. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the chosen random projection matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. The comment also mentions that the authors might have missed this in the appendix, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. However, the comment lacks specific examples or references to support the claim that such pathological projection matrices are unlikely with random projections. While it highlights a potential concern, the lack of detailed evidence or examples makes the claim somewhat verifiable. The authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the results obtained using the chosen random projection matrix, suggesting that pathological projection matrices could skew the MFTMA capacity and width scores. It also points out that the authors might have missed this in the appendix. While the comment highlights an important area for investigation, it lacks specific guidance or suggestions on how to address this issue or what specific tests could be conducted to verify the resilience of the metric. The feedback is somewhat helpful as it prompts the authors to consider this aspect, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just being limited to the ablation study. While the comment implies that the authors should expand the evaluation to include additional comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden the evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than being limited to the ablation study. However, it does not specify which part of the paper this evaluation is currently limited to, nor does it provide guidance on how to expand the evaluation. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in its suggestion to broaden the evaluation, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of FGT is limited to the ablation study and should be used to evaluate the performance of the proposed method and comparative methods. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation of FGT, noting that it is currently limited to the ablation study and should be used to evaluate the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a direct suggestion for expanding the evaluation to include additional comparisons. However, the comment could be more helpful if it offered specific examples of how to conduct these comparisons or provided guidance on which methods to include. Despite this, the feedback is mostly helpful as it points out a critical area for improvement and provides a clear direction for the authors to enhance their evaluation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to enhance the model's complexity or complexity analysis. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as the model description, results, or analysis. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the model\\'s simplicity are problematic or how it could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the model seems overly simple, which is both a feature and a bug. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the model\\'s complexity. Without actionable feedback or detailed analysis, the comment lacks depth and does not assist the authors in enhancing their draft. Therefore, it is rated as barely helpful, as it identifies a potential weakness but does not offer constructive advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not contribute novelly to the understanding of the winner-take-all property, as it uses extremely simplified settings and reports findings that have been previously reported in other works. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the originality or how to present the findings in a more novel or innovative way. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"winner-take-all property\" and \"Sec 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not contribute novelly to the understanding of this behavior due to the use of extremely simplified settings and the repetition of findings from previous works. This provides clear guidance on what needs to be addressed to improve the originality of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not contribute novelly to the understanding of the winner-take-all property due to the use of extremely simplified settings and the repetition of findings from previous works. However, the comment lacks specific references to these previous works or detailed examples of how the findings have been reported. Without such references or evidence, the claim is difficult for the authors to verify or address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it does not contribute novelly to the understanding of the winner-take-all property due to the use of extremely simplified settings and the repetition of findings from previous works. This is a critical observation that could impact the paper\\'s originality and impact. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or differentiate their work from previous studies. While it points out a potential weakness, it does not provide actionable feedback to help the authors improve their draft. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some run-times in the experiments to help readers understand the method's practicality. While the action is explicit, it is somewhat vague as it does not specify which part of the main paper should include the mention of computational cost or how to present the run-time examples. However, the authors can infer that they need to add this information to the main paper and provide examples, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests mentioning the negligible computational cost of CHR in the main paper and providing a rough example of run-times in the experiments. However, it does not specify which part of the paper should include this information or where the computational cost is discussed in the appendix. The authors can infer that it relates to the main paper, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting the inclusion of computational cost information and providing an example, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests mentioning the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some run-times in the experiments to help readers understand the method's practicality. While the comment provides a logical suggestion for improving the paper, it lacks specific examples or references to support the claim about the computational cost. The recommendation for run-time examples is somewhat verifiable, as it provides a clear direction for improvement but could be strengthened with more detailed guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It recommends mentioning the negligible computational cost of CHR in the main paper, which is currently discussed in the appendix, to help motivate the method. Additionally, it suggests providing a rough example of some run-times in the experiments to help readers understand the method's practicality. This feedback is specific and offers concrete steps for the authors to enhance the clarity and accessibility of their work. By addressing these points, the authors can significantly improve the clarity and appeal of their paper, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should compare their work with existing code completion commercial applications, such as Copilot, as a baseline. It provides a specific suggestion for testing on a smaller subset of RepoEval and highlights the importance of comparing with state-of-the-art code completion systems. This feedback is clear and concrete, giving the authors a direct action to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests comparing the work with existing code completion commercial applications, such as Copilot, as a baseline. It specifies that this comparison should be tested on a smaller subset of RepoEval and is essential for comparing with state-of-the-art code completion systems. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors can infer that it relates to the evaluation or comparison sections, the lack of explicit grounding makes it weakly grounded. The suggestion is specific, as it clearly identifies what needs to be addressed, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the work with existing code completion commercial applications, such as Copilot, as a baseline. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, which is to test the performance of the proposed system against state-of-the-art code completion systems. However, the comment lacks specific examples or references to these existing applications, making it somewhat challenging for the authors to fully understand and implement the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of baselines, specifically comparing the proposed work with existing code completion commercial applications like Copilot. This feedback is valuable as it highlights a potential gap in the evaluation and offers a specific direction for the authors to enhance their work. By including this comparison, the authors can demonstrate the effectiveness of their approach against existing state-of-the-art systems, which is essential for building credibility and understanding the impact of their work. However, the comment could be more helpful if it provided additional guidance on how to implement this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. While the comment implies that the authors should consider expanding their evaluation to include more datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that understanding the criteria behind the selection and exploring other tasks or datasets might yield different insights. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. However, the comment lacks specific examples or references to support the claim that the current evaluation is limited in scope. While it highlights a potential issue, the lack of detailed justification or evidence makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. This feedback is somewhat helpful as it prompts the authors to consider the broader implications of their evaluation approach and how it might impact the generalizability of their findings. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what additional tasks or datasets might be relevant to include. Overall, the comment offers a valuable direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the performance of the shifted-MNIST dataset and suggests that it would be useful to show the model and baselines on test samples from the observational (in) distribution. While the comment implies that the authors should provide additional data or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments or analyses. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"shifted-MNIST,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the performance difference between shift=0 and shift~N (0, \u03c3 2) and suggests showing performance on test samples from the observational (in) distribution. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the performance difference between shift=0 and shift~N (0, \u03c3 2) in the context of the shifted-MNIST dataset. It suggests that both cases incorporate a domain shift, implying that the performance difference is not as significant as claimed. However, the comment does not provide specific reasoning or evidence to support this claim, nor does it offer alternative explanations or comparisons. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to further explore the issue themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the performance difference between shift=0 and shift~N (0, \u03c3 2) in the context of the shifted-MNIST dataset. It suggests that both cases incorporate a domain shift, implying that the performance difference might not be as significant as claimed. The comment also recommends showing the performance of the model and baselines on test samples from the observational (in) distribution, which could provide valuable insights into the robustness of the results. While the comment identifies a potential issue and offers a suggestion for improvement, it lacks specific guidance on how to implement these changes or what specific analyses should be conducted. This limits the comment\\'s helpfulness, as it provides some direction but not enough detail for the authors to fully address the feedback. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of detail in the experimental description, suggesting that increased clarity would be beneficial. It explicitly states that the current state of the manuscript makes it difficult for readers to judge the results. The reviewer provides a reference to \"Questions\" for further details, which implies that the authors should refer to this section for guidance on how to improve the clarity of their experimental description. However, the comment does not specify which aspects of the experimental description are unclear or how to address these issues. While the action is implicit, it is clear that the authors need to improve the clarity of their experimental description, and the reference to \"Questions\" provides a starting point for further exploration. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental details\" and suggests that they need increased clarity to allow the reader to better judge the results. This provides clear guidance on what aspect of the paper is being addressed. However, the comment lacks specificity as it does not detail what specific aspects of the experimental description are unclear or how they could be improved. Without specific examples or detailed feedback, the authors may struggle to identify the exact areas that need attention. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the experimental description lacks detail and clarity, making it difficult for readers to judge the results. This claim is somewhat verifiable as it highlights a specific issue with the manuscript, but it does not provide detailed examples or references to support the claim. The reviewer suggests referring to \"Questions\" for further details, which could be helpful but is not included in the comment. Therefore, the comment is rated as 3: Somewhat Verifiable, as it identifies a potential issue but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, noting that the experimental description lacks detail and clarity, making it difficult for readers to assess the results. It suggests that increased clarity in this area would be beneficial. However, the comment does not provide specific examples or guidance on how to improve the clarity of the experimental description. While it points to a potential area for improvement, the lack of detailed feedback limits its usefulness. Therefore, the comment is somewhat helpful, as it highlights an important area for improvement but does not offer actionable steps for the authors to take.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more explanation to clarify the main contributions of the paper, specifically regarding the optimization strategies and their corresponding results. It suggests discussing different scenarios, such as minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This feedback is clear and concrete, as it specifies exactly what the authors need to address to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the discussion of optimization strategies and their corresponding results, particularly regarding the inter and intra terms in Eq 3. The comment provides a clear direction for the authors to improve their draft by discussing different scenarios and their implications. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should provide more explanation to clarify its main contributions, specifically regarding the optimization strategies and their corresponding results. The reviewer provides a specific example by asking what would happen by minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This suggestion is based on logical reasoning and a clear understanding of the paper\\'s content, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need for more explanation to clarify the main contributions and optimization strategies discussed. It provides a clear example by asking what would happen by minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This feedback is actionable and constructive, as it guides the authors to enhance the clarity and depth of their discussion on optimization strategies and their corresponding results. By addressing these points, the authors can significantly improve the comprehensibility and impact of their paper. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a formal or intuitive definition of treewidth should be included in the paper, as it is central to all the proofs. This is an explicit action, as it clearly instructs the authors to include a definition of treewidth. The comment also provides a specific suggestion for how to improve the paper by including a definition, making it concrete. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including a formal or intuitive definition of treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, methodology, or results sections. The authors can infer that it relates to the proofs, but this inference is not direct. The comment is specific in suggesting the inclusion of a definition, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a formal or intuitive definition of treewidth should be included in the paper, as it is central to all the proofs. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of including a definition of treewidth. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a formal or intuitive definition of treewidth should be included in the paper, as it is central to all the proofs. This is a clear and actionable suggestion that can help the authors improve the clarity and accessibility of their work. By including a definition, the authors can ensure that readers understand the concept and its importance in the context of the paper. However, the comment could be more helpful if it provided additional guidance on how to present the definition or examples of its use in the proofs. Overall, the comment is mostly helpful as it identifies a specific area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the paper is not self-contained and suggests that the supplementary material is necessary to understand large parts of the main paper. It also requests the authors to release the source code of their experiments to allow reproduction of their results. While the comment identifies a specific issue with the self-containment and provides a clear action for the authors to take, it does not offer detailed guidance on how to improve the self-containment or what specific aspects of the supplementary material should be included. The action is explicit but lacks concrete details, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"supplementary\" material, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the self-containment of the paper and the need for the authors to release the source code of their experiments for reproducibility. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not self-contained and suggests that the supplementary material is necessary for understanding the main paper. It also requests the authors to release the source code of their experiments for reproducibility. While the comment identifies a potential issue with the self-containment, it lacks specific examples or detailed reasoning to support the claim. The suggestion to release the source code is logical, but the justification for the need for self-containment is not fully articulated. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the self-containment of the paper, noting that the supplementary material is necessary to understand large parts of the main paper and enable reproducibility. It also requests the authors to release the source code of their experiments to allow for reproduction of their results. This feedback is clear and actionable, as it directly points out a weakness in the paper\\'s self-containment and provides a specific suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to improve the self-containment or what specific aspects of the supplementary material should be included. Overall, the comment is mostly helpful as it provides valuable insights and actionable advice for the authors to enhance the clarity and reproducibility of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of the added complexity in using multiple INs at different speeds in the dynamics predictor. It implies that the authors should consider ablating this feature to determine its impact on the model's performance. However, the comment does not provide explicit instructions or concrete suggestions on how to conduct this ablation or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an ablation study to address the question. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the model, namely the use of multiple INs at different speeds in the dynamics predictor. However, it does not explicitly mention which part of the paper this feature is discussed in, making it weakly grounded. The comment is specific in questioning the importance of the added complexity and suggesting an ablation study to determine whether one IN would suffice. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the importance of the added complexity in using multiple INs at different speeds in the dynamics predictor. It suggests that the authors should consider ablating this feature to determine its impact on the model's performance. However, the comment lacks any supporting evidence, reasoning, or references to justify why this feature is important or whether one IN would suffice. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the importance of the added complexity in using multiple INs at different speeds in the dynamics predictor. It suggests that the authors should consider ablating this feature to determine its impact on the model's performance. This feedback is somewhat helpful as it prompts the authors to consider a potential area for improvement and provides a direction for further exploration. However, the comment could be more helpful if it offered specific suggestions on how to conduct the ablation study or what aspects to focus on. Overall, the comment provides a valuable insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the opponent in the experiments does not aim to maximize the multi-agent payoff proposed by the authors, which is a surprise. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their experimental design. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the opponent does not aim to maximize the multi-agent payoff proposed by the authors, which is a clear and specific critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the opponent in the experiments does not aim to maximize the multi-agent payoff proposed by the authors, which is a surprise. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the experimental setup, noting that the opponent does not aim to maximize the multi-agent payoff proposed by the authors. This observation highlights a potential weakness in the experimental design, as it suggests that the opponent's behavior may not accurately reflect the proposed method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their experimental design. While it identifies a potential problem, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. It implies that the authors should clarify the reasoning behind these choices, specifically mentioning the attention model paper that the algorithm iterates on. While the comment does not explicitly instruct the authors to provide this rationale, it clearly points out what needs to be added to improve the draft. The action is concrete, as it specifies the need for clarification and provides a direction for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"REINFORCE algorithm\" and \"PPO,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors provide a rationale for why certain choices were made, such as the use of REINFORCE versus PPO. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. The reviewer implies that this choice might be related to the attention model paper that the algorithm iterates on, but does not provide specific evidence or references to support this claim. While the suggestion is logical, it lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but requires more detailed reasoning to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the draft. It points out that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. By doing so, the authors can clarify their methodology and provide a more transparent explanation of their decisions. This feedback is clear and constructive, as it directly addresses a potential area of confusion and offers a straightforward way to enhance the clarity and comprehensibility of the paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about a statement in Theorem 5.1, specifically regarding the potential disadvantage of MMD DRO compared to the variance regularized problem. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this confusion or what specific steps to take to clarify the statement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the statement in the theorem, which could indicate a disadvantage of MMD DRO compared to the variance regularized problem. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO compared to the variance regularized problem. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential confusion in the paper regarding a statement in Theorem 5.1, which could be interpreted as a disadvantage of MMD DRO compared to the variance regularized problem. This feedback is somewhat helpful as it points out a specific area that may need clarification or further explanation. However, the comment lacks depth and does not provide suggestions on how to address the confusion or improve the clarity of the statement. While it highlights an area for potential improvement, it does not offer actionable guidance, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should provide more information on how to use morphologic segmentation across domains and how it should be conducted differently for different domains. It also questions whether morphologic segmentation is invariant across domains, given the task of domain adaptation. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information on morphologic segmentation across domains. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"morphologic segmentation\" and \"domain\" aspects, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of morphologic segmentation across domains and how it should differ for different domains. The comment also raises important questions about the assumption of morphologic segmentation invariance across domains, which adds depth to the critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks information on how to use morphologic segmentation across domains and how it should differ for different domains. It questions whether morphologic segmentation is invariant across domains, given the task of domain adaptation. The comment suggests that the paper assumes morphologic segmentation to be invariant, which is a logical claim based on the paper\\'s focus on domain adaptation. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the need for more information on morphologic segmentation across domains, but the lack of detailed evidence or examples makes the claim somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the use of morphologic segmentation across domains and how it should differ for different domains. It questions the assumption of morphologic segmentation invariance across domains, given the task of domain adaptation. This feedback is valuable as it highlights an important area for improvement in the paper, particularly regarding the applicability of morphologic segmentation across different domains. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these questions or how to conduct morphologic segmentation differently for different domains. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical aspect of their work that needs further exploration and clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the object detection-based attention being performed on the image or on some convolutional feature map. It suggests clarifying this point and potentially rescaling based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the object detection-based attention, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on whether the attention is performed on the image or on some convolutional feature map, and whether rescaling is done based on the receptive field. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the object detection-based attention and its application. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the object detection-based attention, specifically asking whether it is performed on the image or on some convolutional feature map. It also suggests that rescaling might be necessary based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how to clarify or address this issue. The feedback is somewhat helpful as it points out a potential area for clarification, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of a discussion about Set Transformer and other related works that use summary tokens. This provides a clear and direct action for the authors to take, which is to include a discussion on these topics. The comment is specific in identifying the missing content and provides a concrete action for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Set Transformer\" and \"other related works that also use summary tokens,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the use of summary tokens and related works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that there is a missing discussion about Set Transformer and other related works that use summary tokens. However, it does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the inclusion of a discussion about Set Transformer and other related works that use summary tokens. This feedback is clear and actionable, as it directs the authors to expand their literature review to include relevant works that could enhance their understanding and analysis. By addressing this suggestion, the authors can improve the comprehensiveness and relevance of their paper. However, the comment could be more helpful if it provided additional context or examples of how these works could be integrated into the paper. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the high-frequency range. It implies that the authors may have overlooked this aspect and suggests that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not provide explicit guidance on how to address this issue or what specific analysis should be conducted. The action is implicit and somewhat vague, as the authors can infer that they need to provide theoretical support but are not given clear instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the high-frequency range. It implies that the authors may have overlooked this aspect and suggests that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not specify which part of the paper this issue is related to, such as a particular section or figure where this analysis is discussed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the high-frequency range. It suggests that the authors may have overlooked this aspect and implies that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the theoretical support for Fourier features in accelerating NTK convergence in the high-frequency range. It suggests that the authors may have overlooked this aspect and implies that it is an essential theoretical foundation for the merits of Fourier features. This feedback is valuable as it prompts the authors to consider a potential gap in their analysis and provides a clear direction for further exploration. However, the comment could be more helpful if it offered specific suggestions on how to address this gap or what kind of analysis should be conducted to support the theoretical foundation. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a direction for the authors to explore further.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the lack of details regarding how the network fits the residual instead of learning the input-output mapping directly. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide more information about the network's training process, but it lacks specific instructions or concrete steps for improvement. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of detail regarding how the network fits the residual instead of learning the input-output mapping directly. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of lacking details regarding the network's training process, but without clear grounding, the authors cannot confidently determine which section or part of the paper needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the lack of details regarding how the network fits the residual instead of learning the input-output mapping directly. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that this is a significant issue or a problem that needs to be addressed. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the lack of details on how the network fits the residual instead of learning the input-output mapping directly. This is a relevant point that could impact the understanding and interpretation of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what additional details might be needed. While it highlights a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the experiment setup in Section 3.3, specifically asking about data augmentation methods and learning rate. While the comment implies that the authors should provide more details about these aspects, it does not explicitly instruct them to do so. The reference to the paper \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" provides some context but does not offer specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the experiment setup. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for details about the experiment setup, such as data augmentation methods and learning rate, and provides a reference to a related paper for context. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the experiment setup in Section 3.3, specifically asking for details on data augmentation methods and learning rate. While it identifies a potential area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. The reference to the paper \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" is helpful in providing context but does not offer actionable advice. Overall, the comment is somewhat helpful as it points out a potential area for improvement but lacks depth and specificity in its guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the authors conducted statistical significance tests for the numbers presented in the paper. While it implies that the authors should consider conducting such tests, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct statistical significance tests. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the statistical significance of the numbers presented in the paper, specifically regarding the comparison between the proposed method and baselines. However, it does not specify which part of the paper this comparison is presented in, making it weakly grounded. The comment is specific in its request for statistical significance tests, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the statistical significance of the numbers presented in the paper, specifically regarding the comparison between the proposed method and baselines. However, it does not provide any supporting evidence, reasoning, or references to justify why this claim is relevant or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the statistical significance of the numbers presented in the paper, specifically regarding the comparison between the proposed method and baselines. This is a valuable point as it highlights a potential area for improvement in the paper, which could enhance the credibility and robustness of the results. However, the comment lacks specific guidance on how to conduct statistical significance tests or what aspects of the comparison should be analyzed. While it identifies an important area for consideration, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a potential weakness but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the paper\\'s focus on learning HMMs with non-parametric emission distributions but questions how these distributions affect inference. It specifically asks about the inference tasks that can be computed with an NP-SPEC-HMM, such as filtering, smoothing, and marginal observation likelihood. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the inference tasks should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the impact of emission distributions on inference tasks. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the focus on learning HMMs with non-parametric emission distributions, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions how these emission distributions affect inference and asks about the inference tasks that can be computed with an NP-SPEC-HMM, such as filtering, smoothing, and marginal observation likelihood. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the impact of non-parametric emission distributions on inference tasks in a discrete HMM. It asks which inference tasks, such as filtering, smoothing, and marginal observation likelihood, can be computed exactly or approximately with an NP-SPEC-HMM. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim that these tasks are affected by the emission distributions. This makes the claim somewhat verifiable, as the authors would need to make a logical deduction to understand the implications of the emission distributions on inference tasks. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the impact of non-parametric emission distributions on inference tasks in a discrete HMM. It specifically questions which inference tasks, such as filtering, smoothing, and marginal observation likelihood, can be computed exactly or approximately with an NP-SPEC-HMM. This feedback is valuable as it prompts the authors to clarify and expand on the implications of their model for inference tasks. However, the comment could be more helpful if it provided suggestions on how to address this gap or examples of how the emission distributions affect inference tasks. Overall, the comment is mostly helpful as it directs the authors to a critical area needing further exploration and explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue with the analysis of experimental results, noting that the authors only mention poor performance of the scope prompting method on GPT-3.5-turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should conduct a more detailed analysis of the experimental results, including identifying the factors contributing to the poor performance. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While the action is implied, it is not as concrete as it could be, leaving some ambiguity about the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis of experimental results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the analysis, noting that the authors only mention poor performance of the scope prompting method on GPT-3.5-turbo without providing any analysis of the underlying reasons. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention poor performance of the scope prompting method on GPT-3.5-turbo without providing any analysis of the underlying reasons. This claim is somewhat verifiable as it highlights a gap in the analysis but lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the need for a more detailed analysis themselves, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention poor performance of the scope prompting method on GPT-3.5-turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it highlights a gap in the paper that needs to be addressed to provide a more comprehensive understanding of the results. By pointing out the lack of analysis, the comment empowers the authors to enhance their draft by including a more detailed explanation of the factors contributing to the poor performance. However, the comment could be more helpful if it suggested specific areas to explore or provided examples of how to conduct a more thorough analysis. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the motivation in the introduction, specifically the low-rank factorization, is unnecessary given that the main result is about polytopes. It also implies that if the result has implications for low-rank matrix factorization, it should be explicitly discussed. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the implications of the low-rank factorization in the context of the main result. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"low-rank factorization\" in the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unnecessary nature of the low-rank factorization and the potential implications for low-rank matrix factorization. This provides clear guidance on what the authors should consider and discuss in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation in the introduction, specifically the low-rank factorization, is unnecessary given that the main result is about polytopes. The reviewer suggests that if the result has implications for low-rank matrix factorization, it should be explicitly discussed. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the need for discussing low-rank matrix factorization based on the comment alone. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the motivation in the introduction, specifically the low-rank factorization, which may not be necessary given the main result about polytopes. It suggests that if the result has implications for low-rank matrix factorization, it should be explicitly discussed. This feedback is somewhat helpful as it points out a potential area for improvement in the paper\\'s motivation and alignment with the main results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what aspects of the low-rank factorization should be discussed in the context of the main result. Overall, the comment offers some guidance but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the specific method used to solve the min-min problem, which is mentioned in passing. However, it does not provide any guidance or suggestions on how the authors should address this issue. The comment lacks explicit instructions or concrete details on what the authors should do to clarify or expand on this aspect of their work. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of an alternating direction method to solve the min-min problem, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what needs to be addressed or improved regarding this method, making it under-specific. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the specific method used to solve the min-min problem. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the specific method used to solve the min-min problem, which is mentioned in passing. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable feedback or detailed advice, leaving the authors without a clear path forward. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the novelty of the paper is limited, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or suggest alternative approaches to explore. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what aspect of the novelty is lacking or how it could be improved. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. This feedback highlights a potential weakness in the paper\\'s contribution, which could be addressed by providing more novel or innovative approaches to model interpretation. However, the comment lacks specific suggestions or guidance on how the authors might enhance the novelty or address this issue. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the scope of the experiments. However, the comment does not provide specific guidance on how to expand the experiments or what additional aspects to consider. The authors are left to infer that they need to make their experiments more comprehensive, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the scope of the experiments. However, the comment does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The suggestion to make the experiments more comprehensive is specific, but without clear grounding, the authors may struggle to identify the exact sections that need improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It highlights the limitation of the model size and the restrictive baselines, which constrain the scope of the experiments. However, the comment does not provide specific examples or references to support why these limitations are problematic or how they impact the results. Without detailed reasoning or evidence, the claim is somewhat verifiable, as it provides a general observation but lacks the necessary justification to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the scope of the experiments. While the comment identifies a potential weakness in the experiments, it lacks specific guidance on how to expand the experiments or what aspects to consider. The authors are left with a general idea of what needs to be improved but without actionable steps or detailed suggestions, making the feedback somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding an optimization-based meta-learning approach, specifically mentioning MAML and implicit-MAML, to Table 1. While the comment implies that the authors should consider adding this information, it does not provide explicit instructions on how to implement this suggestion or what specific details should be included. The action is clear but lacks concrete guidance on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding an optimization-based meta-learning approach, specifically mentioning MAML and implicit-MAML, to Table 1. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this addition would be relevant. The authors can infer that it relates to the table or data presentation, but this inference is not direct. The comment is specific in suggesting the addition of a particular approach, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding an optimization-based meta-learning approach, specifically mentioning MAML and implicit-MAML, to Table 1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how it would enhance their work. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding an optimization-based meta-learning approach, specifically mentioning MAML and implicit-MAML, to Table 1. This is a specific and actionable suggestion that could enhance the paper by providing additional context and comparison to existing methods. However, the comment lacks depth and does not explain why this addition would be beneficial or how it would impact the paper\\'s overall contribution. While it points out a potential area for improvement, it could be more helpful if it included more detailed reasoning or examples of how this addition would enhance the paper. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks an ablation study explaining why the prompt was chosen in a specific way, such as using few-shot examples for CoT. This feedback provides a clear and direct action for the authors to take, which is to include an ablation study to address this issue. The comment is specific and provides concrete guidance on what needs to be added to the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for an ablation study, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of an explanation for why the prompt was chosen in a specific way, such as using few-shot examples for CoT. This provides clear guidance on what the authors need to include in their paper to address the reviewer\\'s concern. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks an ablation study explaining why the prompt was chosen in a specific way, such as using few-shot examples for CoT. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the lack of an ablation study explaining why the prompt was chosen in a particular way, such as using few-shot examples for CoT. This feedback is clear and actionable, as it points out a gap in the paper that could be addressed by including an ablation study. By addressing this issue, the authors could enhance the transparency and robustness of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct the ablation study or suggested specific aspects to consider. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to be careful with the terms \"causal mechanisms\" and \"temporal relationship,\" as they are not interchangeable. This feedback is clear and provides a specific action for the authors to take, ensuring that they use the terms correctly. The comment is concrete, as it specifies the exact issue and offers a direct way to address it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of terms like \"causal mechanisms\" and \"temporal relationship,\" providing guidance on how to avoid confusion and ensure clarity in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the use of terms \"causal mechanisms\" and \"temporal relationship,\" suggesting that they are not interchangeable. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is somewhat helpful as it points out a specific issue with the use of terms like \"causal mechanisms\" and \"temporal relationship\" in the paper. It provides a clear and actionable suggestion to avoid confusion by using these terms carefully. However, the comment could be more helpful if it offered additional guidance on how to effectively use these terms or provided examples of how they might be misused. Overall, the feedback is valuable but could be more comprehensive to fully support the authors in improving their draft. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the claim that \"better than random\" is a strong demonstration of capability, suggesting that it may not be sufficient. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what alternative demonstrations could be used. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific statement \"Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that \"better than random\" is a strong demonstration of capability. However, it does not provide additional details or suggestions on how to address this concern. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the claim that \"better than random\" is a strong demonstration of capability. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations to justify why \"better than random\" might not be a strong demonstration. As a result, the claim is unverifiable, as it does not provide sufficient evidence or justification to support the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the claim that \"better than random\" is a strong demonstration of capability, suggesting that it may not be sufficient. This feedback is somewhat helpful as it points out a potential weakness in the argument, prompting the authors to reconsider the strength of their evidence. However, the comment lacks specific suggestions or guidance on how to strengthen the demonstration or what alternative methods could be used to substantiate the claim. While it identifies an area for improvement, it does not provide detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a desire for a discussion on how the results relate to the lower bounds on kernel learning using low-rank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" While it implies that the authors should include this discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a discussion on this topic. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using low-rank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the results need to be addressed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, it is not specific, as it lacks detailed guidance on what aspects of the results need to be discussed or how they relate to the lower bounds. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using low-rank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using low-rank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" This feedback is somewhat helpful as it identifies a potential area for further exploration and discussion. However, it lacks specific guidance on how to integrate this discussion into the paper or what aspects of the results need to be addressed. While it points out a relevant reference, it does not provide detailed suggestions on how to effectively incorporate this discussion into the paper. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the novelty of using PCA to reduce interaction count and expresses uncertainty about the significance of the paper results. It suggests that the use of PCA is intuitive and raises a question about the assumptions made. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to clarify the assumptions. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more information about the assumptions and the significance of their results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It suggests that the use of PCA is intuitive and raises a question about the assumptions made. However, the comment does not specify which part of the paper discusses the use of PCA or where the assumptions are discussed. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the novelty and significance of the results, but without clear grounding, it lacks full specificity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty and significance of the paper, suggesting that using PCA to reduce interaction count is intuitive and that the assumptions made are unclear. The reviewer provides a reference to a related work by Dombrowski et al. (2022) to support their claim about the use of PCA. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that the use of PCA is not novel or significant. While the reference provides some context, it does not fully address the critique. Therefore, the comment is somewhat verifiable, as it provides some support but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the novelty and significance of the paper, suggesting that using PCA to reduce interaction count is intuitive and that the assumptions made are unclear. It references a related work by Dombrowski et al. (2022) to support its claim. While the comment identifies a potential weakness in the paper, it lacks specific guidance on how the authors might address this issue or what aspects of the assumptions need clarification. The reference to the external work is helpful, but the comment could be more actionable by providing more detailed feedback on how to improve the paper. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the few-shot RC models considered in the paper, noting that they are not state-of-the-art models. It asks a question about how the performance of these models compares to relation extraction/generation models in few-shot settings. While the comment implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the few-shot RC models considered in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the performance of these models compared to relation extraction/generation models in few-shot settings. This provides clear guidance on what aspect of the paper needs further exploration or discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim that the few-shot RC models considered in the paper are not state-of-the-art models. However, it does not provide any specific references or examples to support this claim, nor does it compare the performance of these models to other models in the field. Without such evidence or comparisons, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by noting that the few-shot RC models considered are not state-of-the-art models. It raises a relevant question about how the performance of these models compares to relation extraction/generation models in few-shot settings. This feedback is somewhat helpful as it prompts the authors to consider a potential limitation in their work and to address it by providing a comparison. However, the comment could be more helpful if it offered specific suggestions on how to conduct this comparison or what aspects to focus on. Overall, the comment provides a clear direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to provide results or observations regarding the use of sequential MCB versus a single MCT layer for the decision head. This is a clear and direct request, as it specifies exactly what the authors need to include in their discussion. The action is concrete, as it specifies the exact information that should be added to the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB versus a single MCT layer for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation or results regarding the observed differences between the two approaches. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the discussion of using sequential MCB versus a single MCT layer for the decision head, noting that no results were shown. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is important or how it could be improved. The comment lacks specificity and does not offer a clear direction for the authors to follow, making it difficult for them to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of interest in the paper, namely the discussion of using sequential MCB versus a single MCT layer for the decision head. It points out that while the discussion is interesting, no results or observations are presented, prompting the authors to provide more details. This feedback is somewhat helpful as it highlights a gap in the paper that could be addressed with additional information or analysis. However, it lacks specific guidance on what kind of results or observations would be beneficial, leaving the authors with a general direction but not a clear path forward. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the choice of 20 distribution sets and suggests that the authors might need to control the number of distribution sets for each class. It also asks about the implications of selecting only a few distribution sets. While the comment implies that the authors should consider these aspects, it does not provide explicit instructions or concrete steps on how to address them. The authors can infer that they need to consider these questions, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the choice of 20 distribution sets, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the number of distribution sets for each class can be controlled and what the implications would be if only a few distribution sets are selected. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the choice of 20 distribution sets and suggests that the authors might need to control the number of distribution sets for each class. It also asks about the implications of selecting only a few distribution sets. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the choice of 20 distribution sets is problematic. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the choice of 20 distribution sets and questions whether the authors can control the number of distribution sets for each class. It also inquires about the implications of selecting only a few distribution sets. This feedback is somewhat helpful as it prompts the authors to consider the potential limitations and consequences of their choice. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending a different approach or providing examples of how other studies have handled similar concerns. While it points out a relevant area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should showcase their approach using transformer-based (masked) language models, which are more current and relevant in NLP trends. This is a clear and concrete action for the authors to take, as it provides a specific direction for improvement. The comment also highlights the issue with using obsolete language models, which adds context and guidance for the authors. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"perplexity experiments\" and the specific language models used, such as n-gram HMM and RNN, which are considered obsolete. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly suggests that the authors should showcase their approach using transformer-based (masked) language models, which are more current and relevant in NLP trends. This provides clear guidance on what needs to be addressed to align the paper with current research practices. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the perplexity experiments are carried out on obsolete language models, specifically n-gram HMM and RNN, which are not commonly used nowadays. The reviewer suggests that the authors should showcase their approach using transformer-based (masked) language models, which are more relevant to current NLP trends. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the assertion that these older models are indeed outdated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the perplexity experiments, noting that they are carried out on obsolete language models (n-gram HMM, RNN) that are no longer commonly used in NLP research. It suggests that the authors should showcase their approach using transformer-based (masked) language models, which are more relevant and up-to-date. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that can help the authors align their work with current research trends. However, the comment could be more helpful if it explained why transformer-based models are preferred or how they might be integrated into the existing work. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the discussion on the misestimation of mu, noting that it is the proportion of missing observations, making it unclear how it can be estimated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might clarify this issue or what specific steps they could take to address it. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the discussion on the misestimation of mu, which is a specific part of the paper. However, it does not explicitly mention which section or part of the paper this discussion is located in, making it weakly grounded. The comment is specific in pointing out the issue with the estimation of mu, as it is the proportion of missing observations, and how this affects the clarity of the discussion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of the discussion on the misestimation of mu, noting that it is the proportion of missing observations. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the discussion is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the discussion on the misestimation of mu, noting that it is the proportion of missing observations, which makes it unclear how it can be estimated at all. This feedback highlights a gap in the clarity of the discussion, which could be confusing for readers. However, the comment does not provide specific suggestions or guidance on how the authors might clarify this issue or improve the discussion. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider providing high-probability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to achieve the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should provide high-probability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting the use of ensemble methods and the addition of robustness measures, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should provide high-probability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to ensemble methods or robustness measures that have been successfully used in similar contexts. This makes the claim somewhat verifiable, as the authors would need to infer the specifics of how to implement these suggestions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It recommends adding high-probability bounds by using ensemble methods, as performed in the experiments, and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is specific and constructive, as it guides the authors on how to enhance the robustness and reliability of their results. By addressing these points, the authors can significantly improve the quality and credibility of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the paper's motivation for diversity, noting that the model does not enforce diversity explicitly. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might incorporate diversity into their model or what specific changes could be made to improve the paper. As a result, the comment lacks actionability, leaving the authors without a clear path forward to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s motivation for diversity, specifically mentioning that the model does not enforce diversity explicitly. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the model\\'s lack of diversity enforcement, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper motivates \"diversity\" extensively but does not enforce it explicitly in the model. The reviewer expresses disappointment in this lack of diversity enforcement. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the paper\\'s motivation for diversity, noting that the model does not enforce diversity explicitly. This is a critical issue that could impact the paper\\'s credibility and practical relevance. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve the model\\'s diversity enforcement. While it highlights a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any guidance on how the authors should address this issue or what specific experiments should be included. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the absence of certain experiments, specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments should be included in, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these experiments might fit, the comment lacks full grounding. It is specific in identifying the missing experiments but does not provide detailed guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue by pointing out the absence of certain experiments, such as contrastive learning and adversarial learning. This feedback is somewhat helpful as it highlights a potential gap in the experimental setup, which the authors can address to enhance the comprehensiveness and rigor of their work. However, the comment lacks depth and does not provide suggestions on how to incorporate these experiments or what specific aspects of the paper might benefit from their inclusion. While it directs the authors to a potential area for improvement, it does not offer detailed guidance or actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap between the lower and upper bounds in the paper, specifically mentioning that the independence number may be a better bound for some graphs. It also provides additional remarks about the results on the adaptive adversary and the counterfactual feedback. However, the comment does not offer explicit guidance on how to address this issue or what specific changes should be made to improve the paper. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the use of the independence number and consider its impact on the results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the gap between the lower and upper bounds, specifically mentioning the use of \\u00b2 instead of \\u00b3^{1/3} and the results on the adaptive adversary and counterfactual feedback. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it details the issue with the lower and upper bounds and suggests that the independence number may be a better bound for some graphs. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a gap between the lower and upper bounds in the paper, specifically mentioning the use of \\u00b2 instead of \\u00b3^{1/3}. The reviewer also suggests that the independence number may be a better bound for some graphs, and provides examples of the results on the adaptive adversary and counterfactual feedback. However, the comment lacks specific examples or detailed reasoning to support the claim that the independence number is a better bound. While the suggestion is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap between the lower and upper bounds in the paper, specifically mentioning the use of \\u00b2 instead of \\u00b3^{1/3}. It also suggests that the independence number may be a better bound for some graphs, providing a specific area for improvement. Additionally, the comment highlights issues with the results on the adaptive adversary and counterfactual feedback. While the comment points out a potential problem and offers a suggestion for improvement, it lacks detailed guidance or examples on how to address these issues. The authors are given a clear direction but may need to further explore and develop the suggestions to fully address the feedback. Therefore, the comment is somewhat helpful, as it provides a starting point for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their analysis. The comment lacks explicit instructions or concrete steps for the authors to take, leaving them without a clear path forward. As a result, the action is implicit and vague, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"CUB and SOP datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy in the reported ablation studies, where the complete loss function performed worse than those with missing terms. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. This observation raises a valid concern about the validity of the results and prompts the authors to question why this might be the case. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. While it points out a potential problem, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests conducting an experiment where the image is occluded, which simulates irregularity in neural/behavioral data. It also mentions that this would allow for inspection of the long-range inference capacity of the model. The reviewer explicitly states that these experiments should be included in the final version unless the authors can provide a convincing reason not to. The action is explicit and concrete, as it clearly specifies what the authors need to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting an experiment where the image is occluded, which simulates irregularity in neural/behavioral data. It also mentions the need to inspect the long-range inference capacity of the model. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting the need for the experiment. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting an experiment where the image is occluded to simulate irregularity in neural/behavioral data and to inspect the long-range inference capacity of the model. The reviewer provides a logical reasoning for why this experiment would be beneficial, noting that it would simulate real-world scenarios where keypoint detection may fail. However, the comment lacks specific examples or references to similar experiments in the literature, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a reasonable argument but could be further supported with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending an experiment where the image is occluded to simulate irregularity in neural/behavioral data. This suggestion is relevant as it addresses a potential limitation in the current study and offers a way to test the model's long-range inference capacity. The reviewer also explicitly states that these experiments should be included in the final version unless the authors can provide a convincing reason not to. This feedback is highly helpful as it guides the authors on how to enhance their study with a specific and meaningful addition. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the statement in the abstract is unclear and suggests that it should be revised to be more high-level. It also implies that technical details are not necessary for the abstract. While the comment provides a clear action\u2014to clarify the statement and simplify the abstract\u2014it does not offer specific guidance on how to achieve this clarity or what aspects of the statement are unclear. The authors are left to infer the necessary changes, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statement in the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the statement regarding the low-rank feature subspace, a small number of attacked samples, and other mild assumptions. The comment provides a clear direction for improvement by suggesting that the abstract should be more high-level and that technical details are not necessary. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement in the abstract is unclear and suggests that it should be revised to be more high-level. The reviewer provides a specific example of the unclear statement, \"with a low-rank feature subspace, a small number of attacked samples, and other mild assumptions,\" which is helpful in clarifying the issue. However, the comment lacks detailed reasoning or references to support why this statement is unclear or how it could be clarified. While the example is provided, the lack of further explanation or justification makes the claim somewhat verifiable, as the authors may need to infer the basis for the claim and how to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of a statement in the abstract, noting that it is unclear and suggests that it should be revised to be more high-level. It provides a clear example of the problematic statement, \"with a low-rank feature subspace, a small number of attacked samples, and other mild assumptions,\" which helps the authors understand the exact part of the abstract that needs improvement. The comment also suggests that technical details are not necessary for the abstract, which is a valuable piece of feedback for the authors. However, the comment could be more helpful if it offered suggestions on how to simplify the statement or provided examples of how to achieve a more high-level abstract. Overall, the comment is mostly helpful as it identifies a specific area for improvement and provides some guidance, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be beneficial to include results in other modalities, specifically mentioning language-related tasks. It also implies that expected test loss might not be as meaningful for these tasks. However, the comment does not provide explicit instructions or concrete guidance on how to incorporate these results or what specific aspects of language-related tasks should be addressed. The action is implicit and somewhat vague, as the authors need to infer that they should include results in other modalities and consider the relevance of expected test loss. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including results in other modalities, specifically mentioning language-related tasks. However, it does not specify which part of the paper should include these results or how they should be integrated. Additionally, it mentions the importance of OOD performance for language-related tasks, but does not provide specific guidance on how this relates to the expected test loss. While the authors might infer that the results section is the relevant part, the comment lacks explicit grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that it would be beneficial to include results in other modalities, specifically mentioning language-related tasks. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this would be beneficial or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial to include results in other modalities, specifically mentioning language-related tasks. It also implies that expected test loss might not be as meaningful for these tasks. While the comment identifies a potential area for improvement, it lacks specific guidance on how to incorporate these results or what aspects of language-related tasks should be addressed. The feedback is somewhat helpful as it points out a potential enhancement but does not provide detailed instructions or examples on how to achieve it. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the motivation of the work should be further justified by explaining how the proposed method leverages the concept of \"few-shot\" in graph link prediction. It highlights the need to address how the method can effectively use \"few-shot\" and ensure generalizability to new tasks with 0/few training steps. While the comment implies that the authors should provide more detailed justification for their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"few-shot situation for graph link prediction,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method does not consider how to effectively use \"few-shot\" and how to ensure generalizability to new tasks with 0/few training steps. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation of the work is not adequately justified, specifically regarding the few-shot learning context. It suggests that the paper defines a few-shot situation for graph link prediction but does not consider how to effectively use \"few-shot\" or ensure generalizability to new tasks with 0/few training steps. The comment provides a logical reasoning by highlighting the importance of considering the few-shot aspect in few-shot learning. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further develop the reasoning to fully substantiate the claim, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the motivation of the work, specifically in the context of few-shot learning. It points out that the paper defines a few-shot situation for graph link prediction but does not consider how to effectively use \"few-shot\" or ensure generalizability to new tasks with 0/few training steps. This feedback is valuable as it highlights a key area where the authors need to provide more justification and explanation for their approach. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of how other works have effectively leveraged few-shot learning. Despite this, the comment still provides a clear direction for improvement, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community's work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. However, the comment does not provide explicit guidance or suggestions on how the authors could improve their approach or differentiate it from existing work. The authors are left to infer that they need to make their method more innovative or detailed, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\\'s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. However, the comment does not specify which part of the paper discusses the use of GP, making it weakly grounded. The comment is specific in detailing the issue with the use of GP, but without explicit references to sections or details, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of Gaussian Processes (GP) is straightforward and naive, suggesting that the approach is not novel. The reviewer supports this claim by referencing the community\\'s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. This reference provides a basis for the claim, but it does not offer detailed reasoning or examples to fully substantiate the critique. The authors may need to conduct further research to understand the specific aspects of the approach that are considered straightforward and naive. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\\'s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. While the comment identifies a potential weakness in the paper\\'s contribution, it lacks specific guidance or suggestions on how the authors could address this issue or differentiate their approach from existing work. The feedback is somewhat helpful as it points out a potential area for improvement, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the differential privacy application is currently \"half-baked\" and encourages the authors to think through it more clearly. It also highlights the novelty of the online algorithm and robustness, which should be integrated into the main paper. However, the comment does not provide specific guidance on how to improve the differential privacy application or what aspects need more clarity. The feedback lacks concrete steps or detailed suggestions, leaving the authors uncertain about how to address the issues. As a result, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the differential privacy application is \"half-baked\" and encourages the authors to think through it more clearly. It also mentions the online algorithm and robustness as being interesting and novel, and suggests that the experimental results in the appendix would be better in the main paper. However, the comment does not specify which part of the paper discusses the differential privacy application, making it weakly grounded. The comment is specific in its critique of the differential privacy application and the suggestion to integrate the online algorithm and robustness into the main paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the differential privacy application is \"half-baked\" and encourages the authors to think through it more clearly. However, the comment does not provide specific reasoning or examples to support this claim. It mentions the online algorithm and robustness as being interesting and novel, but this does not address the issue of the differential privacy application being \"half-baked.\" The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors may find it challenging to understand and address the issue without further explanation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a general critique of the differential privacy application, suggesting that it is currently \"half-baked\" and encourages the authors to think through it more clearly. It also highlights the novelty and interest of the online algorithm and robustness, which should be integrated into the main paper. However, the comment lacks specific suggestions or guidance on how to improve the differential privacy application or integrate the online algorithm and robustness into the main paper. While it identifies areas for improvement, the feedback is somewhat helpful as it points out potential weaknesses but does not provide actionable steps for the authors to address them. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, it does not provide explicit guidance on how to implement this change or what specific aspects of the methodology need to be adjusted. The action is implied and somewhat vague, as the authors need to infer that they should consider using robotic manipulation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to use robotic manipulation, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the current methodology is insufficient or why robotic manipulation would be more appropriate. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential weakness in the paper by suggesting that the proposed methodology may not be specific to bimanual manipulation. It recommends using robotic manipulation instead, which could be more appropriate. This feedback is somewhat helpful as it points out a potential limitation in the methodology and provides a suggestion for improvement. However, the comment lacks specific guidance on how to implement this change or what aspects of the methodology need to be adjusted. To be more helpful, the comment could provide examples or detailed reasoning on why robotic manipulation might be more appropriate. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include the METEOR results, which are reported in recent works. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment is specific and provides concrete guidance on how to implement the action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the inclusion of METEOR results, which is a specific aspect of the paper. However, it does not specify which part of the paper should include these results, such as a specific section or table. This makes the comment weakly grounded, as the authors cannot confidently determine the exact location of the METEOR results in the paper. The comment is specific in its request for the inclusion of METEOR results, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include the METEOR results, which are reported in recent works. However, the comment does not provide any supporting evidence, references, or reasoning to justify why this inclusion is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include the METEOR results, which are reported in recent works. This is a clear and actionable suggestion that can help improve the paper by providing additional evidence or comparison to other studies. However, the comment lacks depth and does not explain why the inclusion of these results is important or how they might enhance the paper. While it identifies a specific area for improvement, it could be more helpful if it provided more context or justification for the inclusion of METEOR results. Therefore, the comment is somewhat helpful, as it points out a potential improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a perceived lack of discussion on the potential benefits of using AutoML approaches beyond improving raw performance, specifically mentioning the extraction of hints for future network architecture design. It explicitly suggests that the authors should spend more time discussing these aspects, such as the biggest takeaways from the found architecture. This feedback provides a clear and concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of AutoML approaches and the potential benefits beyond raw performance, such as extracting hints for future network architecture design. It also specifies the issue by pointing out that the authors did not spend much time discussing these aspects, providing clear guidance on what needs to be addressed. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main reason for using AutoML approaches is not just improving raw performance but also extracting hints for future network architecture design. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without concrete evidence or detailed reasoning, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out that the paper does not adequately discuss the potential benefits of using AutoML approaches beyond improving raw performance. It suggests that the authors should spend more time discussing the extraction of hints for future network architecture design, which could be a valuable contribution to the field. While the comment highlights an important aspect that could enhance the paper, it lacks specific suggestions or guidance on how to address this issue. Therefore, it is somewhat helpful, as it provides a direction for improvement but does not offer detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. While the action is implicit, it is clear that the authors need to condense the introduction and include empirical results to enhance the paper. The comment provides a specific direction for improvement, but it lacks detailed guidance on how to achieve this concision or which empirical results should be included. Therefore, the action is somewhat actionable, as the authors know they need to make changes but may not be entirely sure of the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. However, it does not specify which part of the introduction is too long or where empirical results should be included. The authors can infer that the introduction and empirical results sections are being addressed, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in suggesting improvements. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. However, the comment does not provide any specific examples or reasoning to support why the current introduction is too long or how empirical results could enhance it. Without detailed guidance or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. While it identifies a potential area for improvement, it lacks specific guidance on how to achieve this concision or which empirical results would be most relevant. The comment provides a general direction for improvement but does not offer detailed suggestions or examples, making it somewhat helpful. The authors are given an idea of what could be improved but are not provided with actionable steps to achieve it. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the author only conducted experiments on two typical games and did not explore ReBeL's performance on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of input size for value and policy functions. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is concrete, as it specifies the need for testing on more complex games, but it is somewhat vague in detailing how to implement this additional testing. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental setup, specifically mentioning that the author only conducted experiments on two typical games and did not explore ReBeL's performance on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of input size for value and policy functions. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as testing on more complex games, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the author only conducted experiments on two typical games and did not explore ReBeL's performance on more complex problems, specifically mentioning the issue of input size for value and policy functions. However, the comment lacks specific examples or references to support the claim that these complex problems are necessary for ReBeL's performance. Without detailed evidence or reasoning, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the issue without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental setup, noting that the author only conducted experiments on two typical games and did not explore ReBeL's performance on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of input size for value and policy functions. This feedback is somewhat helpful as it points out a potential area for improvement in the experimental setup, but it lacks specific guidance on how to implement this additional testing or what specific complex games should be considered. To be more helpful, the comment could provide examples of complex games or suggest methodologies for conducting the additional testing. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. It implies that adding topic entities is incremental and does not provide a clear direction for improvement. However, the comment does not offer specific guidance on how to address these concerns or what additional aspects could be explored to enhance the novelty of the paper. The lack of explicit suggestions or concrete actions makes it difficult for the authors to know how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. However, it does not specify which datasets or parts of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how the novelty could be enhanced. Without clear guidance on what needs to be addressed, the authors cannot effectively improve their draft. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. It implies that adding topic entities seems incremental and does not provide a clear direction for improvement. However, the comment lacks specific suggestions or examples of how the authors could enhance the novelty or impact of their work. Without actionable feedback or guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential issue but does not offer sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include a discussion on this topic, but it does not specify what aspects of the discussion should be included or how it should be structured. As a result, the action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be done but without concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions the lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspects of the theoretical guarantee are missing or how the authors should address this issue. The comment is specific in identifying the lack of discussion but lacks detailed guidance on how to improve it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks discussion, specifically the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This is a relevant point that could enhance the paper\\'s theoretical foundation and provide additional insights to readers. However, the comment does not offer suggestions or guidance on how the authors might address this gap in the discussion. While it highlights an important area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks a quantitative measure to evaluate the generated VCEs, noting that evaluation is mainly performed with visual inspection. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to incorporate quantitative measures or what specific metrics should be used. The action is implicit and somewhat vague, as the authors need to infer that they should include quantitative measures but are not given concrete suggestions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"generated VCEs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a quantitative measure to evaluate the generated VCEs, and notes that evaluation is mainly performed with visual inspection. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a quantitative measure to evaluate the generated VCEs, noting that evaluation is mainly performed with visual inspection. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper, noting the lack of a quantitative measure to evaluate the generated VCEs. It highlights that evaluation is mainly performed with visual inspection, which is a relevant point for the authors to consider. However, the comment does not provide any suggestions or guidance on how to incorporate quantitative measures or what specific metrics could be used. While it points out an area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the method only provides marginal improvements over baselines, with most improvements within the error bar range. It also notes that the authors claim the method performs better than the baselines, but the error range is high, suggesting that the performance differences are not significant. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the performance of their method. The action is implicit and vague, as the authors are left to infer that they need to improve the performance of their method, but without specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the performance of the method compared to baselines, suggesting that the improvements are marginal and within the error bar range. It also mentions that the authors claim the method performs better than the baselines, but the error range is high, indicating that the performance differences are not significant. However, the comment does not specify which part of the paper discusses these claims or where the performance comparisons are presented, making it weakly grounded. The comment is specific in its critique of the performance improvements and the error range, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method provides only marginal improvements over baselines, with most improvements within the error bar range. The reviewer questions the significance of these improvements, suggesting that the error range is high, indicating that the performance differences between some methods are not very significant. This claim is somewhat verifiable as it provides a logical reasoning for questioning the significance of the improvements, but it lacks specific examples or detailed analysis to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that the method provides only marginal improvements over baselines, with most improvements within the error bar range. It questions the significance of these improvements, suggesting that the error range is high, indicating that the performance differences between some methods are not very significant. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s claims about performance improvements. However, it could be more helpful if it provided specific suggestions on how the authors might address this issue or improve the clarity of their claims. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights issues with the generated videos, specifically noting significant artifacts and questioning the action recognition performance compared to state-of-the-art methods. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it guide the authors on how to address the issues or improve the quality of the videos. As a result, the comment lacks actionable guidance, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the generated videos, specifically mentioning artifacts and the action recognition performance on the UCF dataset. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment does provide some specificity by questioning the action recognition performance compared to state-of-the-art methods, which suggests that the authors should address this aspect. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the generated videos have significant artifacts and questions the action recognition performance compared to state-of-the-art methods. However, it does not provide specific examples or detailed reasoning to support these claims. The mention of artifacts and the comparison to state-of-the-art methods are general statements that lack specificity and do not provide enough evidence or justification for the authors to understand or address the issues. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the generated videos, noting significant artifacts and questioning the action recognition performance compared to state-of-the-art methods. It highlights the need for improvement in both aspects, which is crucial for the paper\\'s credibility and impact. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending improvements in video quality or action recognition algorithms. While it points out areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding how to make the proposed evaluation set more diverse and representative than the previous method and how to select representative images. However, it does not provide any explicit guidance or suggestions on how the authors might address these issues. The comment implies that the authors should provide more details or examples, but it does not specify what those details or examples should be. As a result, the action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of diversity and representation in the proposed evaluation set, specifically mentioning the need for clarity on how to make the set more diverse and representative than the previous method and how to select representative images. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where the evaluation set is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what needs to be clarified regarding diversity and representation, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed evaluation set is unclear in terms of diversity and representation, and how to select representative images. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without such evidence or justification, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the proposed evaluation set, specifically the lack of clarity on how to make it more diverse and representative than the previous method and how to select representative images. This is an important point that could significantly impact the validity and applicability of the evaluation results. However, the comment does not provide specific suggestions or examples on how to address these issues, nor does it offer guidance on how to improve the diversity and representation of the evaluation set. While it highlights a significant area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. It also suggests providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. These actions are clear and concrete, as they specify exactly what needs to be added to the paper to improve clarity and understanding. The authors know exactly what steps to take to address the feedback, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the background section and provides guidance on the overview of the original DPO algorithm. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the context. It also recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. While the comment identifies specific areas that need clarification, it lacks detailed reasoning or examples to fully substantiate the claim. The authors might find it challenging to understand the exact nature of the issues without additional context or examples. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting the inclusion of a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. This suggestion is specific and directly addresses a lack of clarity in the paper, which could significantly improve the authors\\' understanding of the context. Additionally, the comment recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This feedback is highly helpful as it guides the authors on how to enhance the clarity and comprehensibility of their work. By addressing these points, the authors can significantly improve the readability and accessibility of their paper. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed method, specifically that it may not be able to handle continuous addition of new languages due to its limited model capacity. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the method to accommodate continuous language addition. The comment lacks actionable guidance or specific steps for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a potential limitation of the proposed method, specifically the issue of handling continuous addition of new languages due to the limited model capacity. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the potential issue with the method, but without explicit references to sections or details, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method may encounter a limitation due to the limited model capacity when users continuously add new languages. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed method, specifically that it may not be able to handle continuous addition of new languages due to its limited model capacity. This is a relevant concern that could impact the practicality and scalability of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or improve the method to accommodate continuous language addition. Without actionable advice or detailed feedback, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the relevance of the term \"interpretable\" to the work of Doshi-Velez and Kim (2017) regarding the rigorous science of interpretable machine learning. While the comment does not explicitly instruct the authors to make any changes or provide guidance on how to address this question, it implies that the authors should consider the relevance of the term in the context of their work. The action is implicit but clear, as the authors can infer that they need to evaluate the relevance of the term and potentially revise their work accordingly. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the relevance of the term \"interpretable\" to the work of Doshi-Velez and Kim (2017) regarding the rigorous science of interpretable machine learning. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the relevance of the term \"interpretable\" to the work of Doshi-Velez and Kim (2017). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the relevance of the term \"interpretable\" to the work of Doshi-Velez and Kim (2017) regarding the rigorous science of interpretable machine learning. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable feedback or constructive advice, making it barely helpful for the authors in terms of improving their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or differentiate their method from [10]. The comment lacks actionable details, such as recommending specific modifications or discussions to be included in the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"approach in [10],\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning why the approach in [10] cannot use the additional information, such as scoring causal predictions and interventional data. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. It questions why [10] cannot use these side information. While the comment identifies a potential issue with the originality of the proposed method, it lacks specific guidance or suggestions on how the authors might address this concern or differentiate their work from [10]. The feedback is somewhat helpful as it points out a potential problem but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the results from the Atari game are limited to a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or improve the interpretability of their results. There is no guidance on whether they should expand the experiment to include more games or baselines, or how they might present the results in a more clear and accessible manner. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the Atari game result is limited to a single game and a single baseline, making it difficult to interpret. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Atari game result is limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper regarding the interpretation of the Atari game results, specifically noting that the results are limited to a single game and a single baseline. This feedback highlights an area where the authors could improve the clarity and generalizability of their findings. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional experiments or analyses. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the evaluation should include experiments on distributed deployment and a larger model. This provides a clear and direct action for the authors to take, specifying exactly what additional experiments are needed to improve the draft. The comment is specific and concrete, giving the authors a clear path to enhance their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for additional experiments, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not provide any supporting evidence, reasoning, or examples to justify why these experiments are necessary or how they would improve the evaluation. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the evaluation should include experiments on distributed deployment and a larger model. This feedback is somewhat helpful as it identifies a potential area for improvement in the evaluation section. However, it lacks specific guidance on how to implement these experiments or what aspects of the evaluation would be enhanced by including them. The comment does not provide detailed suggestions or examples, which would help the authors understand how to effectively incorporate these changes. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the authors\\' claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. It asks for clarification on whether the proposed model improves with larger word embedding and LSTM parameters. While the comment implies that the authors should provide evidence or experiments to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional experiments or evidence to substantiate their claim. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about superior performance with fewer parameters, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the authors have tested the model with standard parameter settings in the baseline model. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. The reviewer asks for clarification on whether the proposed model improves with larger word embedding and LSTM parameters. While the comment raises a valid point, it lacks specific examples or references to support the claim that the baseline model might have standard parameter settings. This makes the claim somewhat verifiable, as the authors would need to provide additional evidence or experiments to fully substantiate their claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the authors\\' claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. It questions whether the proposed model improves with larger word embedding and LSTM parameters, which is a relevant and important point for the authors to address. The comment provides a clear direction for the authors to substantiate their claim by suggesting additional experiments or evidence to support their findings. However, it could be more helpful if it offered specific suggestions on how to conduct these experiments or what specific metrics to use. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to enhance the robustness of their findings.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure the availability of the environment or a good OPE method. The action is implicit and somewhat vague, as the authors can infer that they need to consider these factors but are not given concrete steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or where the finetuning is mentioned, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these hyperparameters are introduced, the comment lacks full grounding. It is specific about the issue of finetuning and the dependence on the environment or OPE method, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the introduction of two additional hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or evidence, the claim remains unverifiable, as it does not provide sufficient justification for the authors to make improvements. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. This feedback is somewhat helpful as it points out a potential problem that the authors need to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how to ensure the availability of the environment or a good OPE method. Without actionable advice or detailed explanation, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy in the authors\\' approach to regularization, noting that they apply regularization to both LN models and GLMs, while the GLM by Pillow et al. did not crop the image. The reviewer suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. While the comment identifies an issue and provides a suggestion for improvement, it does not offer specific guidance on how to implement this suggestion or what specific features should be reproduced. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"LN model\" and \"GLMs,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy in the application of regularization, suggesting that the authors should try to reproduce the main features of previous models. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors apply regularization to both LN models and GLMs, which is not consistent with the GLM by Pillow et al. The reviewer suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. However, the comment lacks specific examples or references to support the claim that the GLM by Pillow et al. did not crop the image. Without these details, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the authors\\' approach to regularization, noting that they apply regularization to both LN models and GLMs, while the GLM by Pillow et al. did not crop the image but used L1 regularization for the filters and a low-rank approximation to the spatial filter. The reviewer suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. This feedback is somewhat helpful as it points out a potential issue in the paper\\'s methodology and provides a direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to reproduce the main features of previous models or what aspects of the previous models should be replicated. Overall, the comment provides some guidance but lacks detailed instructions, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should study the inference time of their pose estimation method, which is a direct method that does not require detection or keypoint grouping. It also recommends comparing the inference speed of their method to previous top-down and bottom-up pose estimation methods. While the comment implies that the authors should conduct this study, it does not provide explicit instructions or concrete steps on how to conduct the study or what specific aspects to focus on. The action is clear but lacks detailed guidance, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests studying the inference time of the pose estimation method, which is a direct method that does not require detection or keypoint grouping. It also recommends comparing the inference speed to previous top-down and bottom-up pose estimation methods. However, the comment does not specify which part of the paper should include this analysis or where the inference time is currently discussed. While the authors might have an idea of where this information is discussed, the comment lacks full grounding. It is specific about the need for an inference time comparison but does not provide detailed guidance on how to implement this suggestion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks a study of inference time for the pose estimation method, which is a direct method that does not require detection or keypoint grouping. The reviewer provides a logical reasoning by stating that since the method is direct, it should be compared to previous top-down and bottom-up pose estimation methods in terms of inference speed. This claim is somewhat verifiable as it provides a logical basis for the suggestion, but it could be strengthened with specific references or examples to support the comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the paper should include a study of inference time for the pose estimation method. This is a relevant point as it highlights a potential comparison with previous top-down and bottom-up pose estimation methods, which could provide valuable insights into the performance of the direct method. However, the comment lacks depth and does not offer specific guidance on how to conduct this study or what aspects of the inference time should be analyzed. While it points out a potential area for improvement, the feedback could be more actionable with additional details. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the claim about evolutional dropout and its limitations in addressing internal covariate shift. It suggests that the authors should explicitly discuss these limitations, particularly regarding batch normalization. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to discuss these limitations or what aspects should be emphasized. The action is explicit but somewhat vague, as the authors know they need to address the limitations but may not be entirely sure of the exact details to include. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about evolutional dropout and its limitations in addressing internal covariate shift. It also specifies the issue with batch normalization, which standardizes the variance and centers the activation. This provides clear guidance on what needs to be addressed in the paper. However, the comment could be more specific by suggesting how the authors should discuss these limitations or what aspects should be emphasized. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the claim about evolutional dropout addressing internal covariate shift is limited, as it can only increase the variance of some low-variance units. The reviewer supports this claim by comparing it to batch normalization, which standardizes the variance and centers the activation. However, the comment lacks specific examples or references to substantiate the claim fully. While it provides a logical reasoning, it could be strengthened with more detailed evidence or examples to fully support the assertion. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires more detailed evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the claim about evolutional dropout addressing internal covariate shift. It suggests that the claim is limited because it can only increase the variance of some low-variance units, and it contrasts this with batch normalization, which standardizes the variance and centers the activation. The comment provides a clear and actionable suggestion for the authors to explicitly discuss these limitations in their paper. However, it could be more helpful if it offered specific guidance on how to discuss these limitations or what aspects should be emphasized. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include tentative attention maps in the qualitative figures to provide a more comprehensive understanding of the attention mechanism. This feedback is explicit, as it directly instructs the authors to include the tentative attention maps in the figures. The action is concrete, as it specifies exactly what needs to be added to the figures. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including tentative attention maps in the qualitative figures, which implies that it relates to the figures or visualizations presented in the paper. However, it does not explicitly mention which figures or sections these suggestions pertain to, making it weakly grounded. The comment is specific in suggesting the inclusion of tentative attention maps, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including tentative attention maps in the qualitative figures would be beneficial for understanding the attention mechanism. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition would be valuable or how it would enhance the understanding of the attention mechanism. Without such justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including tentative attention maps in the qualitative figures would enhance the understanding of the attention mechanism. This feedback is somewhat helpful as it identifies a potential area for improvement by recommending the inclusion of additional visual information. However, the comment lacks depth and does not provide specific guidance on how to incorporate these maps or why they are important. While it points out a potential enhancement, it does not fully address the authors\\' needs for improving their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the author to add more description about the contribution of the paper. This is a clear and direct action, as it specifies what the authors need to do to improve their draft. The comment provides a specific suggestion for enhancing the paper\\'s clarity by adding more details about the contribution. Therefore, the action is explicit and concrete, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should add more description about the contribution of the paper. However, it does not specify which part of the paper this additional description should be added to, nor does it provide any guidance on what specific aspects of the contribution should be elaborated on. Without explicit references to sections or specific elements of the paper, the authors may struggle to identify where to make these additions. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should add more description about the contribution of the paper. However, it does not provide any reasoning, evidence, or examples to support why this additional description is necessary or how it would enhance the paper. Without specific guidance or justification, the claim is not verifiable, as it lacks the necessary information to help the authors understand and address the feedback. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should add more description about the contribution of the paper. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what aspects of the contribution should be elaborated on or how this additional description would enhance the paper. Without detailed suggestions or examples, the authors may struggle to understand how to effectively address the feedback. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of supervised baselines in the paper and suggests that it is reasonable to assume that full annotation is available for datasets of scale ~100k images. It also notes that even if this is not the case, having an informative baseline would be beneficial to show the performance of self-supervised methods compared to a fully supervised pre-trained network. While the comment implies that the authors should include supervised baselines, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific steps to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the absence of supervised baselines in the paper, specifically mentioning that most experiments are conducted on datasets of scale ~100k images, which implies that full annotation should be available. It suggests that including an informative baseline would be beneficial to show the performance of self-supervised methods compared to a fully supervised pre-trained network. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental setup or results sections. The comment is specific in its suggestion to include supervised baselines, making it fully grounded. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the absence of supervised baselines is a significant issue, as most experiments are conducted on datasets of scale ~100k images, which implies that full annotation should be available. The reviewer suggests that including an informative baseline would be beneficial to show the performance of self-supervised methods compared to a fully supervised pre-trained network. This claim is somewhat verifiable as it provides a logical reasoning for the inclusion of supervised baselines, but it lacks specific examples or references to support the assertion that full annotation is typically available for datasets of this scale. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines, which are crucial for understanding the performance of self-supervised methods. It logically argues that since most experiments are conducted on datasets of scale ~100k images, it is reasonable to assume that full annotation is available. The comment suggests that including an informative baseline would be beneficial to show the performance of self-supervised methods compared to a fully supervised pre-trained network. This feedback is clear and actionable, providing the authors with a specific direction for improvement. However, it could be more helpful if it included examples of suitable supervised baselines or detailed guidance on how to implement them. Overall, the comment is mostly helpful as it effectively highlights a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point. It also notes that the benchmarks used are outdated and likely saturated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of minimal performance differences or how to update the benchmarks. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of performance differences between methods, noting that they are minimal across evaluations and often less than 1 percentage point. It also mentions that the benchmarks used are outdated and likely saturated, referencing specific works. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the issue of minimal performance differences and the need to update the benchmarks. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point, which may be due to random variation. The reviewer supports this claim by referencing the outdated and likely saturated benchmarks used. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides some evidence, it could be strengthened with more detailed analysis or references to specific experiments or studies. Therefore, the comment is somewhat verifiable, as it provides some support but could be more robust with additional evidence or reasoning.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point. This observation suggests that the methods may be overfitting or that the benchmarks are saturated. The comment also points out that the benchmarks used are outdated, which could impact the relevance and applicability of the results. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. Providing more detailed advice or examples on how to update the benchmarks or improve the performance evaluation would make the comment more actionable. Therefore, the comment is somewhat helpful, as it identifies a significant weakness but lacks depth in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the method's effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with non-deterministic dynamics. It also questions the absence of BEAR from baselines and suggests that the method may not have much benefit. While the comment implies that the authors should evaluate their method on different domains and include BEAR in the baselines, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to address the concerns. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the method\\'s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with non-deterministic dynamics. It also questions the absence of BEAR from baselines and suggests that the method may not have much benefit. However, the comment does not specify which part of the paper these questions pertain to, such as specific sections or experiments. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its questions about the method\\'s effectiveness and the inclusion of BEAR in the baselines. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the method\\'s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with non-deterministic dynamics. It also questions the absence of BEAR from baselines and suggests that the method may not have much benefit. However, the comment lacks specific examples or references to support these claims or questions. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claims but lacks sufficient detail to fully substantiate them.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises several questions and suggestions that could help the authors improve their draft. It questions the method\\'s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with non-deterministic dynamics to assess its empirical efficacy. This feedback is valuable as it prompts the authors to broaden the scope of their evaluation, which could enhance the method\\'s applicability. Additionally, the comment questions the absence of BEAR from baselines and suggests that the method may not have much benefit without this comparison. While the comment identifies areas for improvement, it could be more helpful if it provided specific guidance on how to conduct the additional evaluations or included examples of other domains to consider. Overall, the comment is mostly helpful as it directs the authors to consider broader applicability and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide theoretical justification for why co-training and weight averaging can improve results. While the action is explicit, it lacks concrete guidance on how to present this justification or what specific aspects should be addressed. The authors are left to infer that they need to provide theoretical reasoning, but without detailed instructions on how to do so, the comment remains somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide theoretical justification for why co-training and weight averaging can improve results. However, it does not specify which part of the paper this justification should be provided in, nor does it provide details on what aspects of the results need justification. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is specific in its request for theoretical justification but lacks grounding, making it difficult for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide theoretical justification for why co-training and weight averaging can improve results. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide theoretical justification for why co-training and weight averaging can improve results. This is a valid point as these techniques are important for performance, and theoretical justification can help the authors better understand and articulate their contributions. However, the comment lacks specific guidance on how to present this justification or what aspects of the results should be emphasized. While it identifies a potential area for improvement, it does not provide detailed instructions or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the authors\\' derivation for falling into classical learning theory-based bounds, which are not considered realistic without Bayesian considerations. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the derivation. The comment lacks actionable details, such as suggesting alternative methods or approaches to incorporate Bayesian considerations. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' derivation for falling into classical learning theory-based bounds, which are not considered realistic without Bayesian considerations. However, it does not specify which part of the paper this critique pertains to, such as a particular section or equation. The authors can infer that it relates to the derivation or theoretical aspects of the paper, but this inference is not direct. The comment is specific in its critique of the classical learning theory-based bounds and the need for Bayesian considerations, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' derivation falls into classical learning theory-based bounds, which are not considered realistic without Bayesian considerations. The reviewer supports this claim by mentioning Bayesian-PAC based bounds as an example of a more realistic approach. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a general idea of the issue, it does not offer enough evidence or detailed explanation to fully verify the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the authors\\' derivation for falling into classical learning theory-based bounds, which are not considered realistic without Bayesian considerations. It suggests that the authors should consider Bayesian-PAC based bounds as a more realistic approach. While the comment identifies a potential weakness in the derivation, it lacks specific guidance on how the authors might incorporate Bayesian considerations or what specific aspects of the derivation need to be revised. The feedback is somewhat helpful as it points out a potential issue but does not provide actionable steps for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so or offer specific guidance on what details should be included. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details but may not be entirely sure of the exact content or structure of these details. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper these details should be included in, nor does it provide specific guidance on what aspects of the method should be elaborated on. While the authors might have an idea of where these details could be added, the comment lacks full grounding as it does not explicitly mention sections or elements of the paper. The suggestion is specific in terms of what needs to be addressed, but the lack of grounding makes it challenging for the authors to pinpoint the exact location for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these details are necessary or how they would enhance the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, suggesting that more details about the proposed method should be presented, particularly regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their explanation of the methodology. However, the comment could be more helpful if it offered specific examples or guidance on how to present these details, such as which sections or sections to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proposed method's ability to detect hallucinations in open-ended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" The reviewer suggests that the method might struggle to detect hallucinations due to the potential for different responses pertaining to different individuals, making it challenging to identify shared information for consistency checking. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve the method. The action is implicit and somewhat vague, as the authors can infer that they need to consider this issue but are not given detailed instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed method and the specific issue of detecting hallucinations in open-ended responses, such as the prompt \"introduce a sports celebrity to me.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the problem of detecting hallucinations in open-ended responses and the potential challenge of identifying shared information for consistency checking. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method might struggle to detect hallucinations in open-ended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" The reviewer provides a logical reasoning by explaining that the sampled responses could pertain to different individuals, making it challenging to identify shared information for consistency checking. However, the comment lacks specific examples or references to support the claim, such as how the method might fail in detecting hallucinations or how it could be improved. This makes the claim somewhat verifiable, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method\\'s ability to detect hallucinations in open-ended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" This highlights a specific challenge in detecting hallucinations due to the potential for different responses pertaining to different individuals, making it difficult to identify shared information for consistency checking. While the comment points out a potential weakness, it does not provide detailed guidance or suggestions on how the authors might address this issue or improve their method. The feedback is somewhat helpful as it alerts the authors to a potential problem but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors verify the conclusion about label noise and model size on MNIST and CNN, which implies that the authors should conduct additional experiments to test the theoretical findings in a real-world context. While the comment does not explicitly instruct the authors to conduct these experiments, it provides a clear direction for action. The authors know that they need to verify the conclusion, but the comment could be more explicit in suggesting specific experiments or methods to conduct these tests. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests verifying the conclusion about label noise and model size on MNIST and CNN, which implies that the authors should conduct additional experiments to test the theoretical findings in a real-world context. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need for verification on MNIST and CNN, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the theoretical findings are unclear in their relation to real-world deep learning models. It provides a specific suggestion to verify the conclusion about label noise and model size on MNIST and CNN. This claim is somewhat verifiable as it logically suggests that verification is necessary to clarify the theoretical findings. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the theoretical findings and their relation to real-world deep learning models. It suggests that the authors verify the conclusion about label noise and model size on MNIST and CNN, which could provide valuable insights into the practical implications of their theoretical findings. This feedback is clear and actionable, as it directs the authors to conduct specific experiments that could enhance the robustness and generalizability of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the probability distribution p(y|Hf(tn)) should be chosen as Gaussian, as otherwise, Kalman Filtering and Smoothing, and CVI cannot be performed. It also mentions that this assumption is made in the ELBOs later in the paper. This comment provides a clear and direct action for the authors to take, ensuring that the probability distribution is chosen as Gaussian. The explicit nature of the suggestion and the concrete detail on how to implement it make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the probability distribution \"p(y|Hf(tn))\" and the assumption of Gaussian distribution, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the choice of probability distribution and its implications for Kalman Filtering, Smoothing, and CVI. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the probability distribution \"p(y|Hf(tn))\" should be chosen as Gaussian, as otherwise, Kalman Filtering and Smoothing, and CVI cannot be performed. The comment provides a logical reasoning by stating that this assumption is made in the ELBOs later in the paper, which supports the claim. However, the comment lacks specific references or detailed explanations to fully substantiate the claim, such as why this assumption is necessary or how it affects the analysis. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the choice of probability distribution, noting that the probability distribution \"p(y|Hf(tn))\" should be chosen as Gaussian to enable Kalman Filtering, Smoothing, and CVI. This is a clear and actionable point that the authors can address to improve the clarity and feasibility of their analysis. However, the comment could be more helpful if it provided additional context or examples to explain why this choice is important or how it affects the results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the use of suboptimally weight decay across all layers is expected to result in large training losses and suboptimal cosine similarities, especially for large weight decay parameters. It also notes that cosine similarities for such large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the cosine similarities. The action is implicit and somewhat vague, as the authors can infer that they need to report cosine similarities for larger weight decay strengths and possibly adjust the weight decay parameters. However, the lack of concrete details makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of suboptimally weight decay across all layers, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that cosine similarities for large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of suboptimally weight decay across all layers is expected to result in large training losses and suboptimal cosine similarities, especially for large weight decay parameters. The reviewer supports this claim by noting that cosine similarities for such large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. This provides a logical reasoning and specific examples to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed evidence or references to similar studies that have observed similar effects. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the application of suboptimally weight decay across all layers, which is expected to lead to large training losses and suboptimal cosine similarities, especially for large weight decay parameters. It points out that cosine similarities for such large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. This feedback is clear and actionable, as it highlights a potential weakness in the paper that could impact the validity of the results. By addressing this issue, the authors can improve the robustness and credibility of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific analyses or modifications to the experimental setup. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of qualitative experiments to demonstrate the validity of the conditional independence model and suggests providing illustrative experimental results to demonstrate the potential benefits of minimizing HSICcond-i over HSIC_HOOD. It also recommends using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it points out the absence of a correctness test and comparative experiments with other metrics. The comment provides specific actions for the authors to take, such as providing experimental results and visualization or schematic diagrams. These are explicit and concrete suggestions, giving the authors clear guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of qualitative experiments to demonstrate the validity of the conditional independence model, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as providing illustrative experimental results, using a toy dataset to demonstrate separability, and conducting correctness tests and comparative experiments with other metrics. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It suggests providing illustrative experimental results to demonstrate the potential benefits of minimizing HSICcond-i over HSIC_HOOD. The reviewer also recommends using a toy dataset to demonstrate the separability of inlier and outlier features. The comment is somewhat verifiable as it provides a logical reasoning for the need of additional experiments, but it lacks specific examples or references to support the claim. The suggestion to use a toy dataset is a concrete action, but the lack of detailed examples or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of qualitative experiments to demonstrate the validity of the conditional independence model. It provides actionable suggestions for improvement, such as providing illustrative experimental results to demonstrate the potential benefits of minimizing HSICcond-i over HSIC_HOOD. The comment also recommends using a toy dataset to demonstrate the separability of inlier and outlier features, which is a valuable suggestion for clarifying the model's assumptions. Additionally, it points out the absence of a correctness test and comparative experiments with other metrics, which is crucial for validation. The feedback is clear and provides specific guidance on how to enhance the paper\\'s experimental section. However, it could be more helpful if it included examples of what kind of illustrative results or visualization would be beneficial. Overall, the comment is mostly helpful as it offers detailed and actionable suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \\u03b1. The reviewer also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. While the comment provides a clear direction for further analysis, it does not explicitly instruct the authors to conduct this study. The action is implicit but concrete, as it specifies what aspects of the analysis should be explored. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \\u03b1. However, it does not explicitly mention which part of the paper this analysis should be integrated into, making it weakly grounded. The comment is specific in detailing what aspects of the analysis should be explored, such as the roles between \"winners\" and \"cooperators\" and the potential impact of cost on collective return. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \\u03b1. The reviewer also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. While the comment provides logical reasoning and examples, it lacks specific references or detailed evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the suggestion but could be strengthened with additional evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to conduct a systematic analysis of the impact of the cost of incentivization on performance. It offers a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \\u03b1. The comment also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. This feedback is highly valuable as it guides the authors to a specific area for further exploration and analysis, which could significantly enhance the paper. However, the comment could be more helpful if it provided additional details or examples on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is highly helpful as it offers a clear and actionable direction for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the approach description in Section 3 is difficult to follow and suggests revising it. It also suggests using the additional page of the camera-ready version to extend the approach description rather than adding more experiments. This provides clear and concrete guidance on what needs to be done to improve the draft. The authors know exactly what changes to make and how to implement them, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the approach description being difficult to follow and suggests revising it. The comment also provides a clear suggestion to extend the approach description using the additional page of the camera-ready version, rather than adding more experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach description in Section 3 is difficult to follow and suggests revising it. However, the comment does not provide specific examples or detailed reasoning to support why the approach description is challenging or how it could be improved. Without additional context or evidence, the authors may find it difficult to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the approach description in Section 3, noting that it is difficult to follow. It suggests revising the description and provides a clear and actionable suggestion to extend the approach description using the additional page of the camera-ready version. This feedback is valuable as it directs the authors to a specific area needing improvement and offers a concrete way to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional guidance on how to improve the approach description or suggested specific changes to make it more accessible. Overall, the comment is mostly helpful as it effectively points out a weakness and offers a clear path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues with the experimental section: the lack of interpretive insights into why the proposed gyro-structures outperform existing methods and the absence of comparison with other state-of-the-art methods that do not rely on gyro-structures. While the comment highlights these gaps, it does not provide explicit guidance on how to address them. The authors are left to infer that they should include more detailed interpretive insights and comparisons with other methods. However, the comment lacks specific suggestions on how to achieve this, such as which methods to include or how to present the insights. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments part,\" allowing the authors to accurately identify the section being addressed. It also specifies the issue by pointing out the lack of interpretive insights into why the proposed gyro-structures outperform existing methods and the absence of comparison with other state-of-the-art methods that do not rely on gyro-structures. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related discussion lacks interpretive insights and that the paper lacks comparison with other state-of-the-art methods that do not rely on gyro-structures. The comment suggests that this omission makes it unclear whether the proposed approach outperforms simpler or more commonly used techniques in manifold-based learning. While the comment identifies a potential issue with the experimental section, it does not provide specific examples or references to support the claim that the lack of interpretive insights or comparisons significantly impacts the paper\\'s conclusions. The absence of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to make a significant effort to address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two significant issues with the experimental section of the paper. First, it points out the lack of interpretive insights into why the proposed gyro-structures outperform existing methods. This feedback highlights an important area for improvement, as it would help the authors better understand and communicate the strengths of their approach. Second, the comment notes the absence of comparison with other state-of-the-art methods that do not rely on gyro-structures, making it unclear whether the proposed approach actually outperforms simpler or more commonly used techniques. This omission is crucial for the paper\\'s conclusions, and the comment provides a clear direction for the authors to address this gap. By addressing these issues, the authors can significantly enhance the clarity and robustness of their experimental results. Therefore, the comment is highly helpful, as it provides actionable and insightful feedback that can significantly improve the paper.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. While the comment implies that additional analysis is needed, it does not specify what kind of evidence or analysis is required or how it should be presented. The authors are left to infer that they need to provide more detailed information, but the comment lacks concrete guidance on what exactly is needed. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. However, it does not specify which part of the paper this analysis should be included in, such as a particular section or figure. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. The comment is specific in its request for additional evidence or analysis, but it lacks full grounding as it does not explicitly mention the sections where this information should be included. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of evidence or analysis supporting the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. This feedback is clear and actionable, as it points out a critical area where the authors need to provide more detailed information to strengthen their work. However, the comment could be more helpful if it offered specific suggestions on what kind of evidence or analysis would be beneficial or how it could be presented. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. It highlights the need for proper ablation studies to verify this claim. While the comment identifies a specific concern and suggests a potential solution (ablation studies), it does not provide explicit instructions on how to conduct these studies or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. It points out the need for proper ablation studies to verify this claim. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the claim and the need for ablation studies, but without explicit references to sections or details, the authors may struggle to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. The reviewer provides a logical reasoning by pointing out that the fine-tuning without early-stopping can lead to high variances, which could affect the validity of the distillation claim. However, the comment lacks specific examples or references to support the argument, such as data or studies that demonstrate the impact of regularization on teacher performance. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or references to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim that the improvements in teacher performance are due to distillation. It suggests that the improvements might be due to regularization effects instead, given the fine-tuning without early-stopping and the high variances that can occur. The comment highlights the need for proper ablation studies to verify the claim, which is a valuable point for the authors to consider. However, the comment could be more helpful if it provided specific guidance on how to conduct these studies or what aspects to focus on. Overall, the comment is mostly helpful as it points out a critical area for improvement and suggests a clear path for addressing it, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests two specific actions for the authors to take: (i) to include performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, to enhance the credibility of the framework, and (ii) to include morphologically rich languages like Finnish, Hebrew, etc., and low-resource languages in the experiments. These are explicit actions that the authors can directly implement to improve their draft. The second point is a minor suggestion, but it is still clear and actionable. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the addition of performance on word similarity and sentence translation tasks and the inclusion of morphologically rich languages like Finnish, Hebrew, etc., and low-resource languages in the experiments. This provides clear guidance on how to enhance the robustness and effectiveness of the framework. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that adding performance on word similarity and sentence translation tasks would enhance the credibility of the framework, similar to the MUSE paper and others. It also recommends including morphologically rich languages like Finnish, Hebrew, etc., and low-resource languages in the experiments. These suggestions are based on common practices in the field and are logical, but the comment lacks specific examples or references to support the claim fully. The authors might need to infer the importance of these additions themselves, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two specific and actionable suggestions for improving the experiments section of the paper. First, it recommends adding performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, which would enhance the credibility and effectiveness of the framework. This is a clear and concrete suggestion that the authors can easily implement to improve their draft. Second, it suggests including morphologically rich languages like Finnish, Hebrew, etc., and low-resource languages in the experiments, which would further diversify the evaluation and provide more robust results. While the second point is a minor suggestion, it is still actionable and could help the authors expand their experiments. Overall, the comment is mostly helpful as it offers clear and actionable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of node importance in the 1-shot scenario and notes that the experiment part does not include this setting. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes should be made to include the 1-shot setting. The comment lacks actionable details, such as recommending specific experiments or modifications to the paper, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of node importance in the 1-shot scenario and notes that the experiment part does not include this setting. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its critique of the omission of the 1-shot setting in the experiment part, but it lacks grounding as it does not pinpoint the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of node importance in the 1-shot scenario and notes that the experiment part does not include this setting. However, it does not provide any supporting evidence, reasoning, or references to justify why this omission is problematic or how it affects the paper\\'s conclusions. The claim is based on a logical observation but lacks detailed justification or examples, making it somewhat verifiable. The authors would need to infer the importance of addressing this issue themselves, which may not be immediately clear. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid point about the omission of the 1-shot scenario in the experiment part of the paper, noting that related works like RALE have included this setting. This feedback highlights a potential gap in the paper\\'s experimental evaluation, which could impact the authors\\' conclusions. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional experiments could be conducted to fully explore the 1-shot setting. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that there should be more discussions about why LLMs struggle at fine-grained hard constraints and how to address these problems. While the comment implies that additional discussions are needed, it does not provide specific guidance on what aspects of these discussions should be included or how to structure them. The authors are left to infer that they need to expand on the existing discussions, but without concrete instructions on what to focus on or how to implement these changes, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that there should be more discussions about why LLMs struggle at fine-grained hard constraints and how to address these problems. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or section of the results. The authors can infer that it relates to the discussion or results sections, but this inference is not direct. The comment is specific in suggesting the need for more discussions, but it lacks grounding as it does not pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that there should be more discussions about why LLMs struggle at fine-grained hard constraints and how to address these problems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that there should be more discussions about why LLMs struggle at fine-grained hard constraints and how to address these problems. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, specifically regarding the limitations and challenges of LLMs. However, the comment lacks specific guidance on what aspects of these discussions should be included or how to structure them. While it points out a gap in the paper, it does not provide detailed suggestions or examples on how to address the issue, which would make the feedback more actionable. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of insight into the rationale behind the need for self-supervised learning on 360 video data with spatial audio. It implies that the authors should provide more detailed explanations or justifications for this approach. However, the comment does not explicitly instruct the authors to add this information or specify what kind of insights are needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context but may not be entirely sure of the exact details. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental results, suggesting that the authors need to provide more insights into the rationale behind the need for self-supervised learning on 360 video data with spatial audio. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of insights into the rationale behind the approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results suggest the proposed approach is valuable for self-supervised learning on 360 video data with spatial audio but lacks insights into why this is necessary. The comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the rationale behind the need for self-supervised learning on 360 video data with spatial audio. It points out that while the experimental results suggest the approach's value, the paper lacks insights into why this approach is necessary. This feedback is somewhat helpful as it highlights an area where the authors could provide more context or explanation to strengthen their work. However, the comment does not offer specific suggestions or guidance on how to address this issue, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to average their results over multiple runs to determine statistical significance. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific guidance on how to enhance the robustness and reliability of their results, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the results should be averaged over multiple runs to determine statistical significance. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the results are presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to average results over multiple runs, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that results should be averaged over multiple runs to determine statistical significance. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and actionable piece of feedback that can help the authors improve the robustness and reliability of their results. By suggesting a specific method for evaluating statistical significance, the comment provides a concrete step for the authors to take in enhancing the quality of their work. However, the comment could be more helpful if it explained why averaging over multiple runs is necessary or how it would impact the interpretation of the results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the observations and conclusions should be highlighted in the paper, particularly in the experimental section. This feedback implies that the authors should make the observations and conclusions more prominent or accessible to the reader, which is a clear and explicit action. However, the comment does not provide specific guidance on how to achieve this, such as recommending a particular section or method for highlighting the observations. While the action is clear, the lack of concrete details on implementation makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the observations and conclusions are hidden in the experimental section, which implies that the authors should highlight these elements to improve the paper\\'s clarity. However, it does not specify which observations or conclusions are being referred to, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. The comment is weakly grounded because it does not specify the exact sections or elements being addressed, but it is specific in suggesting that the observations and conclusions should be highlighted. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the observations and conclusions are hidden in the experimental section, implying that they are not clearly highlighted or accessible to the reader. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these elements would be beneficial for understanding the trade-offs of annotation effort and corresponding training performance. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper\\'s clarity and accessibility. However, the comment could be more helpful if it offered specific guidance on how to highlight these observations and conclusions, such as recommending a particular section or method for doing so. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the KDE when the classifier space is beyond binary, referencing a previous remark. It suggests comparing the performance on datasets with a decision space beyond binary. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct the comparison themselves. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Remark 1\" and \"Zhang et. al.\" (presumably references to specific sections or figures in the paper), allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed: a comparison of performance on datasets with a decision space beyond binary. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance of the KDE when the classifier space is beyond binary, referencing a previous remark. It suggests comparing the performance on datasets with a decision space beyond binary, referencing Zhang et al. as an example. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would impact the paper\\'s conclusions. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the performance of the KDE when the classifier space is beyond binary, referencing a previous remark. It suggests comparing the performance on datasets with a decision space beyond binary, which could provide valuable insights into the robustness of the approach. However, the comment lacks specific guidance or suggestions on how to conduct this comparison or what specific datasets should be considered. While it identifies an area for potential improvement, the feedback is somewhat vague and does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. While these questions imply that the authors should investigate these aspects, they do not provide explicit instructions or concrete guidance on how to address them. The authors can infer that they need to explore the impact of capacity on FID and consider potential artifacts in the pipeline, but the comment lacks specific details or suggestions on how to conduct these investigations. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not specify which part of the paper these questions pertain to, such as specific sections or experiments where these issues are discussed. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for information about the impact of capacity and artifacts, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The questions themselves are not claims but rather requests for clarification or additional information. Therefore, the comment is classified as \"No\" as it does not contain any claims that require verification.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions that could be valuable for the authors to explore: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. These questions highlight potential areas for further investigation or discussion in the paper. However, the comment lacks specific guidance or suggestions on how to address these questions or what specific aspects of the capacity or artifacts should be examined. While it points out potential areas for improvement, it does not provide detailed or actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, which is to conduct these additional experiments. The comment is specific about the types of experiments that are missing, giving the authors a concrete understanding of what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in detailing the types of experiments that are missing, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, the comment does not provide specific examples or detailed reasoning to support why these experiments are necessary or how they would enhance the paper. Without such evidence or examples, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it directly points out areas where the paper could be strengthened by including these experiments. However, the comment could be more helpful if it provided specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the fairness of the comparison between the proposed method and the state-of-the-art (SOTA) method. It notes that the proposed method only shows an advantage when using prior knowledge, which is not a fair comparison. The reviewer suggests that the extra complexity and cost of requiring two representation models should be considered. While the comment identifies an issue with the comparison, it does not provide explicit guidance on how to address it or suggest specific actions for the authors to take. The authors can infer that they need to consider the extra complexity and cost, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"comparison with the SOTA,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the proposed method only shows an advantage when using prior knowledge, which is unfair due to the extra complexity and cost of requiring two representation models. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method only shows an advantage when using prior knowledge, which is unfair due to the extra complexity and cost of requiring two representation models. The reviewer supports this claim by explaining that the comparison is not fair because the proposed method essentially requires two separate models to be learned for each dataset. This logical reasoning provides a clear justification for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to similar studies that have addressed this issue. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison between the proposed method and the state-of-the-art (SOTA) method. It points out that the proposed method only shows an advantage when using prior knowledge, which is not a fair comparison. The reviewer suggests that the extra complexity and cost of requiring two representation models should be considered, which is a valuable insight for the authors. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending a different comparison method or suggesting ways to reduce the complexity and cost. Overall, the comment is mostly helpful as it highlights a critical aspect of the paper that the authors should consider, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include collaborative games in their experiments to explore how the evaluated methods behave in both collaborative and competitive settings. While the action is explicit, it is somewhat vague as it does not provide specific guidance on how to implement this suggestion or what specific collaborative games should be included. The authors are left to infer the details of how to incorporate collaborative games into their experiments, which could be improved with more concrete instructions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks collaborative games in the experiments and recommends including them to explore the behavior of the evaluated methods in both collaborative and competitive settings. However, it does not specify which part of the paper this issue pertains to, such as the sections where the experiments are described or the methodology section. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting the inclusion of collaborative games, but it is not grounded as it does not explicitly mention which part of the paper should be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks collaborative games in the experiments and recommends including them to explore the behavior of the evaluated methods in both collaborative and competitive settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this addition would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by noting the absence of collaborative games in the experiments. It suggests that including such games would be interesting and could provide valuable insights into the behavior of the evaluated methods in both collaborative and competitive settings. This feedback is clear and actionable, as it directs the authors to consider adding a specific aspect to their experiments that could enhance the understanding and applicability of their work. However, the comment could be more helpful if it provided more detailed guidance on how to implement this suggestion or what specific collaborative games should be considered. Overall, the comment is mostly helpful as it points out a meaningful area for improvement and offers a clear direction for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental settings for figures 1 to 9 are missing, making them difficult to be convincing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific settings to include or suggesting ways to improve the figures. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1 to Figure 9,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the absence of experimental settings for these figures, making them difficult to be convincing. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental settings for figures 1 to 9 are missing, making them difficult to be convincing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the absence of experimental settings for figures 1 to 9. This is a critical observation that could impact the credibility and persuasiveness of the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the figures. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the rationale behind the work, specifically regarding the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. The reviewer suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are specifically tailored to leverage the sparsity exhibited by activation channels in deep networks. While the comment identifies a specific area for clarification, it does not provide explicit instructions on how to address this issue or what specific details should be included in the clarification. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the rationale behind the work, specifically the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are specifically tailored to leverage the sparsity exhibited by activation channels in deep networks. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified regarding the proposed method and its potential impact on task knowledge acquisition. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the rationale behind the work is based on the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. The reviewer suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are specifically tailored to leverage the sparsity exhibited by activation channels in deep networks. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the need for clarification and address it themselves, rather than having a clear rationale provided by the reviewer. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the rationale behind the work, specifically regarding the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are specifically tailored to leverage the sparsity exhibited by activation channels in deep networks. While the comment highlights an important area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or what aspects of the rationale need clarification. The feedback is somewhat helpful as it points out a potential weakness but lacks depth and actionable advice, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the ad-hoc nature of the regularization term and suggests that the authors should provide more theoretical support. It also mentions the possibility of using other statistics, such as the median, to replace the mean and standard deviation in the regularization. While the comment implies that the authors should explore alternative methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative methods to strengthen the theoretical basis of their regularization. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the regularization term, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the ad-hoc nature of the regularization term and suggests the use of alternative statistics, such as the median, to replace the mean and standard deviation. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the ad-hoc nature of the regularization term and suggests that the authors should provide more theoretical support. It also mentions the possibility of using other statistics, such as the median, to replace the mean and standard deviation in the regularization. While the comment provides a logical reasoning for the need for more theoretical support, it lacks specific examples or references to substantiate the claim fully. The suggestion to explore alternative statistics is a valid point, but the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the ad-hoc nature of the regularization term and suggests that the authors should provide more theoretical support. It also provides a specific suggestion to explore the use of alternative statistics, such as the median, to replace the mean and standard deviation in the regularization. This feedback is actionable and constructive, as it offers a clear direction for the authors to enhance the theoretical foundation of their work. However, the comment could be more helpful if it provided examples or references to similar studies that have successfully used alternative statistics in regularization. Overall, the comment is mostly helpful as it guides the authors toward a more robust and defensible approach.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to conduct comparisons with existing fairness algorithms in the experimental section. It clearly states the action needed, which is to integrate benchmark comparisons against state-of-the-art fairness algorithms. This provides a concrete and specific action for the authors to take, ensuring they know exactly what is expected of them to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the lack of comparisons with existing fairness algorithms. The comment provides a clear and actionable suggestion to integrate benchmark comparisons against state-of-the-art fairness algorithms, which would significantly enhance the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that integrating benchmark comparisons with state-of-the-art fairness algorithms would enhance the paper by providing tangible evidence of the proposed method's performance and positioning it within the existing FairML research landscape. This claim is somewhat verifiable as it logically suggests that comparisons with existing algorithms would strengthen the paper, but it lacks specific examples or references to existing fairness algorithms that could be used for comparison. The authors would need to infer the specific algorithms to include, which adds a degree of uncertainty. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental section, noting the absence of comparisons with existing fairness algorithms. It provides a clear and actionable suggestion to integrate benchmark comparisons against state-of-the-art fairness algorithms, which would enhance the paper by offering tangible evidence of the proposed method's performance and positioning it within the existing FairML research landscape. This feedback is highly helpful as it guides the authors on how to strengthen their experimental section and improve the overall quality of their work. By addressing this suggestion, the authors can significantly enhance the credibility and impact of their findings. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the use of supervised pretraining based on the prediction of homo-lumo gap, suggesting that it may lead to negative transfer. It provides an example of Transformer-M performing poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\\'s description of a general-purpose neural network model. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the model. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider the use of supervised pretraining and its potential impact on downstream tasks. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"prediction of homo-lumo gap\" and the \"QM9 in downstream experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the Transformer-M model performs poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\\'s description of a general-purpose neural network model. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that supervised pretraining based on the prediction of homo-lumo gap may lead to negative transfer, as evidenced by Transformer-M\\'s poor performance on most tasks except for homo, lumo, and gap. The reviewer provides an example from downstream experiments on QM9, which supports the claim. However, the comment could be strengthened by providing more detailed analysis or references to similar studies that have observed similar negative transfer effects. As it stands, the claim is mostly verifiable due to the example provided, but it could be further substantiated with additional evidence or references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of supervised pretraining based on the prediction of homo-lumo gap, suggesting that it may lead to negative transfer. It provides an example of Transformer-M performing poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\\'s description of a general-purpose neural network model. This feedback is somewhat helpful as it highlights a potential weakness in the paper\\'s claims and suggests that the authors should reconsider their approach. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue or mitigate negative transfer. Overall, the comment is somewhat helpful as it points out a potential problem but lacks detailed guidance on how to resolve it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the term \"distributional generalization\" may be too strong to accurately represent the empirical phenomenon presented. It points out that the total variation between the test and train distributions of the network's outputs might not be zero, and that this conclusion is difficult to draw from a few test functions where the outputs match. However, the comment does not provide explicit guidance on what term or phrasing would be more appropriate or how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should consider alternative terms or phrasing to better represent the phenomenon. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"distributional generalization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term, explaining that it may be too strong to accurately represent the empirical phenomenon presented. The comment provides a clear rationale for why the term might not be appropriate and suggests an alternative approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the appropriateness of the term \"distributional generalization\" to describe the phenomenon presented, suggesting that it may be too strong. The reviewer provides a logical reasoning by explaining that the term implies a complete vanishing of the total variation between the test and train distributions, which might not be the case. This reasoning is based on the observation that the outputs match in a few test functions, suggesting that the phenomenon is not as idealized as the term suggests. However, the comment lacks specific examples or references to support the claim that the term is inappropriate. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the term \"distributional generalization\" used to describe the phenomenon presented in the paper. It points out that the term might be too strong, as it implies a complete vanishing of the total variation between the test and train distributions, which might not be the case. The reviewer provides a logical reasoning by explaining that the outputs might not match in all test functions, suggesting that the phenomenon is not as idealized as the term suggests. However, the comment could be more helpful if it provided specific suggestions for alternative terms or phrasing that would better capture the empirical phenomenon. While it highlights a potential weakness, the feedback lacks actionable guidance, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the theoretical contribution as \"ok but not particularly strong\" and points out that it is a weak, unpractical bound. It also notes that the proof lacks mathematical novelty. However, the comment does not provide any explicit or implicit actions for the authors to take to improve their draft. It does not suggest specific ways to strengthen the theoretical contribution or offer guidance on how to make the proof more novel. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the theoretical contribution of the paper, specifically mentioning that it is \"ok but not particularly strong\" and that it is a weak, unpractical bound. It also notes that the proof lacks mathematical novelty. However, the comment does not specify which part of the paper this critique is based on, such as a particular section or result. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what is considered weak or unoriginal, but without grounding, it lacks actionable guidance for the authors to improve their draft. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical contribution is \"ok but not particularly strong\" and that it is a weak, unpractical bound. The reviewer also notes that the proof lacks mathematical novelty. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the theoretical contribution as \"ok but not particularly strong,\" which is a subjective assessment. It also points out that the theoretical result is a weak, unpractical bound and that the proof lacks mathematical novelty. While the comment identifies areas for improvement, it does not provide specific suggestions or guidance on how the authors might strengthen their theoretical contribution or make the proof more novel. The feedback is somewhat helpful as it highlights weaknesses but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the phrasing in lines L240 and L428, specifically asking for clarification on what is meant by \"is sufficient.\" The reviewer implies that the authors might be trying to convey that the sum of the \"optimistic\" hoped-for rewards is close to the expected actual rewards. However, the comment does not provide explicit guidance on how to clarify this point or what specific changes should be made to improve the clarity. While the action is implied, it is not directly stated, and the authors are left to infer the necessary changes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines, \"L240\" and \"L428,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the phrasing and suggesting that the authors might be trying to convey that the sum of the \"optimistic\" hoped-for rewards is close to the expected actual rewards. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the phrasing in lines L240 and L428, specifically asking for clarification on what is meant by \"is sufficient.\" The reviewer provides a logical interpretation of what the authors might be trying to convey, suggesting that the sum of the \"optimistic\" hoped-for rewards is close to the expected actual rewards. However, the comment lacks specific examples or references to support this interpretation, making it somewhat verifiable. The authors would need to infer the intended meaning and potentially revise the phrasing to align with the reviewer\\'s suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the phrasing in lines L240 and L428, questioning what is meant by \"is sufficient.\" The reviewer provides a logical interpretation of what the authors might be trying to convey, suggesting that the sum of the \"optimistic\" hoped-for rewards is close to the expected actual rewards. This feedback is somewhat helpful as it points out a potential area for clarification and improvement in the draft. However, it lacks specific suggestions or guidance on how to clarify the phrasing or what changes to make to enhance the clarity. While it provides some insight, the comment could be more actionable with additional details. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the theoretical discussions could benefit from improvements, specifically mentioning the need for sample complexity-type results related to not returning NSF. While the comment implies that the authors should include such results, it does not provide explicit instructions or concrete steps on how to achieve this. The authors are left to infer that they should include these results, but the comment lacks detailed guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the theoretical discussions, specifically mentioning the need for sample complexity-type results related to not returning NSF. However, it does not specify which part of the theoretical discussions needs improvement or which specific results should be included. The authors can infer that it relates to the theoretical sections, but the comment lacks full grounding as it does not explicitly mention the sections or elements being addressed. Additionally, while it suggests a specific area for improvement, it does not provide detailed guidance on how to implement these changes. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the theoretical discussions could benefit from improvements, specifically mentioning the need for sample complexity-type results related to not returning NSF. The reviewer provides a specific expectation, such as \"given confidence levels, what is the sufficient amount of training data points that would not return NSF.\" This suggestion is based on a logical expectation of what should be included in the theoretical discussions, but it lacks specific examples or references to support the claim. Therefore, the comment is somewhat verifiable, as it provides a clear direction for improvement but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the theoretical discussions, suggesting that the current theorems follow directly from the algorithm design and the well-known property of mutual information to $\\\\Delta_{DP}$. It highlights a potential gap in the discussion by pointing out the absence of sample complexity-type results related to not returning NSF. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their theoretical discussions by including specific results or analyses. However, the comment could be more helpful if it offered examples or guidance on how to implement these improvements. Overall, the comment is mostly helpful as it effectively identifies a gap in the paper and provides a clear path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the description of the VAD is puzzling and suggests that the authors should clarify what they mean by \"discarding TF bins with a magnitude of less than epsilon.\" It also highlights that this approach is not consistent with a VAD, which is supposed to look for speech presence and is unlikely to be defined over frequency. The comment implies that the authors should reconsider their definition and approach to VAD. While the action is implicit, it is clear and provides a direction for the authors to take, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the VAD description, pointing out that the current approach discards TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. The comment further explains that a VAD should look for speech presence and is unlikely to be defined over frequency, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the VAD description is puzzling and suggests that the authors are discarding TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. The reviewer argues that a VAD should look for speech presence and is unlikely to be defined over frequency, which is a common understanding in the field. The comment provides a logical reasoning and references common knowledge about VADs, making it mostly verifiable. However, it could be strengthened by providing specific references or examples to support the claim about VADs and their definition. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the description of the VAD, noting that the current approach discards TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. It points out that a VAD should look for speech presence and is unlikely to be defined over frequency, providing a clear understanding of what a VAD should entail. The comment offers a constructive suggestion by suggesting that the authors should reconsider their definition and approach to VAD, which is a valuable piece of feedback for improving the clarity and accuracy of the paper. However, the comment could be more helpful if it provided specific guidance on how to redefine or rephrase the VAD description to align with the expectations of a VAD. Overall, the comment is mostly helpful as it highlights a critical issue and offers actionable advice for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. It also mentions that the experiments have little to hang on to. However, it does not provide any specific guidance on how the authors could improve the clarity or intuition of the paper. There are no explicit suggestions or concrete steps for the authors to take to enhance the readability or understanding of the paper. As a result, the comment is vague and lacks actionable details, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not specify which parts of the paper are particularly challenging or where the lack of intuition is most apparent. Without specific references to sections, figures, or experiments, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment does not provide specific guidance on how to enhance the clarity or intuition of the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, stating that it is not easy to follow and lacks a clear intuition for how the pieces fit together. It also notes that the experiments have little to hang on to, which could impact the paper\\'s impact and clarity. However, the comment does not provide specific suggestions or guidance on how the authors could improve the clarity or intuition of the paper. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance the readability and comprehensibility of their work. Therefore, the comment is rated as barely helpful, as it points out a problem but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of the comparison between the student and refinement networks, suggesting that the teacher network's performance may be improved by training them simultaneously. The reviewer explicitly requests KID/FID metrics for the teacher network, providing a clear and concrete action for the authors to take. This guidance is explicit and specific, leaving no ambiguity about what the authors need to do to address the concern. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the training of the student and refinement networks, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the fairness of the comparison and requests KID/FID metrics for the teacher network. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the fairness of the comparison between the student and refinement networks, suggesting that training them simultaneously may improve the performance of the teacher network. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of the comparison between the student and refinement networks, suggesting that training them simultaneously may improve the performance of the teacher network. It explicitly requests KID/FID metrics for the teacher network, which is a clear and actionable request that can help the authors evaluate and improve their work. However, the comment could be more helpful if it provided additional context or examples of how these metrics could be used to assess the fairness of the comparison. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a concrete action to take, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the refined region vector, specifically questioning whether the attention weight is scaled before being used in the calculation. The reviewer suggests that having a scaling variable before the attention weight might help. While the comment implies that the authors should consider this suggestion, it does not provide explicit instructions or concrete guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding a scaling variable before the attention weight. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the refined region vector and suggests that having a scaling variable before the attention weight might help. The comment provides a clear direction for improvement by asking whether the refined vector scales only the most important regions before global pooling. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the refined region vector, specifically the scaling factor applied to the attention weight before global pooling. The reviewer suggests that having a scaling variable before the attention weight might help. However, the comment lacks specific reasoning or evidence to support why this change would be beneficial or how it would affect the results. Without detailed justification or examples, the claim remains somewhat verifiable, as the authors may find it challenging to understand and address the suggestion without further explanation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the refined region vector, specifically the scaling factor applied to the attention weight before global pooling. It suggests that having a scaling variable before the attention weight might help. This feedback is somewhat helpful as it prompts the authors to consider a potential improvement in their methodology. However, the comment lacks depth and does not provide specific guidance or examples on how to implement this suggestion or what potential benefits it might have. To be more helpful, the comment could offer a rationale or examples of how a scaling variable might affect the results or provide suggestions for testing this hypothesis. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the LLM not accurately recovering the formal goal predicate, especially when faced with ambiguities in human language. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the LLM's accuracy or how to handle ambiguities in human language. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the LLM not accurately recovering the formal goal predicate, especially when faced with ambiguities in human language. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of goal misspecification and the impact on the LLM\\'s performance. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that failures on the ALFRED benchmark often occurred due to goal misspecification, where the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the LLM not accurately recovering the formal goal predicate, especially when faced with ambiguities in human language. This is an important observation that could impact the performance and reliability of the LLM. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their draft. Without specific recommendations or examples, the authors are left without a clear path forward. Therefore, the comment is somewhat helpful, as it points out a potential problem but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. It also raises a concern about the difficulty of Sampling-Gaussian to significantly improve iterative frameworks similar to IGEV. While the comment provides a clear direction for the authors to take, it lacks specific guidance on how to conduct the analysis or what specific aspects of the analysis should be focused on. The action is explicit but somewhat vague in terms of execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"IGEV\" and \"SOTA methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests analyzing the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. Additionally, it raises a concern about the difficulty of Sampling-Gaussian to significantly improve iterative frameworks similar to IGEV. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the improvement of the method over SOTA methods like IGEV is small, and questions whether there is no multi-peak distribution problem in iterative optimization schemes similar to IGEV. The reviewer provides a suggestion to analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. This claim is somewhat verifiable as it logically questions the improvement over IGEV and suggests a potential analysis to address the issue. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. This feedback is valuable as it guides the authors to conduct a specific analysis that could help clarify the limitations of their method compared to SOTA methods. Additionally, the comment raises a concern about the difficulty of Sampling-Gaussian to significantly improve iterative frameworks similar to IGEV, prompting the authors to consider potential limitations or areas for improvement. Overall, the comment is mostly helpful as it offers clear and actionable guidance for the authors to enhance their draft. However, it could be more helpful if it provided additional context or examples to support the analysis suggestion. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should provide model-specific insights by investigating how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. It also recommends presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment provides a clear action to take, it does not specify how to conduct the investigation or what specific aspects of the models should be analyzed. The authors are given a general direction but may need to infer the details of how to implement the suggested changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Model-Specific Insights\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the investigation into how specific models behave differently when ReGuide is applied and the presentation of differences in false positive rates (FPR) between models with and without ReGuide. This provides clear guidance on what the authors need to address to improve their paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper focuses on generic findings across models and recommends a deeper investigation into how specific models behave differently when ReGuide is applied. The reviewer provides a specific example of GPT-4o and InternVL2, suggesting that differences in false positive rates (FPR) should be presented for a better comparison. This claim is somewhat verifiable as it provides a logical suggestion for enhancing the paper\\'s analysis, but it lacks detailed evidence or references to support the claim that these specific models behave differently. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It highlights the current focus on generic findings across models and recommends a deeper investigation into how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. The comment suggests presenting differences in false positive rates (FPR) between models with and without ReGuide for a more nuanced comparison. This feedback is valuable as it directs the authors to a specific area for improvement that could enhance the paper\\'s contribution and clarity. However, the comment could be more helpful if it provided additional guidance on how to conduct this investigation or what specific aspects of the models should be analyzed. Overall, the comment is mostly helpful as it offers a clear and actionable direction for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors clarify whether the Fourier modes are real or complex numbers. This is an explicit request for clarification, providing a clear action for the authors to take. The comment is specific in detailing what needs to be clarified, making it highly actionable. Authors know exactly what needs to be done to improve their draft, ensuring that the action is concrete. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the Fourier modes as numbers,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests clarifying whether these modes are real or complex numbers, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests clarifying whether the Fourier modes are real or complex numbers. However, it does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would impact the understanding of the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors clarify whether the Fourier modes are real or complex numbers. This is a specific and actionable suggestion that can help improve the clarity and precision of the paper. By addressing this point, the authors can ensure that their explanation is accurate and complete, which is beneficial for both the readers and the authors themselves. However, the comment could be more helpful if it provided additional context or examples to guide the clarification process. Overall, the comment is mostly helpful as it identifies a specific area for improvement, but it could be more comprehensive with additional details. Therefore, it is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notations $h, g$ and $\\\\delta$ are introduced without clear input or output domains, and it suggests that this lack of clarity is similar to the issue with $\\\\delta$. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting specific descriptions or examples to include. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context for these notations, but the comment does not offer concrete steps on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the introduction of notations $h, g$, and $\\\\delta$, noting that their input and output domains are not clearly defined. It suggests that this lack of clarity is similar to the issue with $\\\\delta$. However, the comment does not specify which part of the paper these notations are introduced in, making it weakly grounded. The comment is specific in pointing out the issue with the lack of clarity regarding the input and output domains of these notations. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of the notations $h, g$, and $\\\\delta$ and suggests that their input and output domains are not well-defined. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed reasoning or evidence makes the claim borderline verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction of notations $h, g$, and $\\\\delta$, noting that their input and output domains are not clearly defined. It suggests that this lack of clarity is similar to the issue with $\\\\delta$. While the comment highlights a potential problem, it does not provide specific guidance or suggestions on how to address this issue, such as recommending a clearer explanation or examples of the input and output domains. This limits the comment\\'s helpfulness, as it points out a problem but does not offer actionable steps for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper should include results using the GCPG model without pre-trained initializations to clarify the contribution of the task formulation and pre-trained language models. This is a clear and direct action for the authors to take, as it provides a specific step to address the issue of attribution. The comment is specific in detailing what additional results are needed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for results using the GCPG model without pre-trained initializations, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of the contribution of the task formulation and pre-trained language models. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks ablations, specifically the results without pre-trained language models. The reviewer claims that it is unclear how much performance gain is due to the task formulation and how much is because of pre-trained language models. The suggestion to include results using the GCPG model without pre-trained initializations is a logical request to clarify the contribution of the task formulation. However, the comment does not provide specific examples or references to support the claim that the current results are unclear. This makes the claim somewhat verifiable, as the authors would need to make a logical inference to understand the basis of the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the inclusion of ablations to clarify the contribution of the task formulation and pre-trained language models. It suggests using the GCPG model without pre-trained initializations to provide a clearer understanding of the performance gains. This feedback is clear and actionable, as it directs the authors to include additional results that can help clarify their findings. However, the comment could be more helpful if it provided more detailed guidance on how to implement these ablations or why the GCPG model is particularly relevant. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that it is difficult to understand what the axes are for Figure 1. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the axes should be labeled more clearly or if additional explanations are needed. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make to improve the clarity of the figure. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding the axes in Figure 1. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is difficult to understand what the axes are for Figure 1. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the clarity of Figure 1, noting that it is difficult to understand what the axes represent. This feedback is somewhat helpful as it points out a clear area for improvement in the paper, which is the labeling and explanation of the axes. However, the comment lacks depth and does not provide suggestions on how to improve the clarity or offer alternative ways to present the data. While it highlights an important issue, it could be more helpful with additional guidance or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that direct runtime comparisons with existing methods are missing and that the proposed approach is based on implicit differentiation, which requires additional computational costs. This implies that the authors should include direct runtime comparisons to demonstrate the efficiency of their proposed approach. The comment is clear and provides a specific action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for direct runtime comparisons with existing methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of implicit differentiation and its potential impact on runtime efficiency, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that direct runtime comparisons with existing methods are missing and that the proposed approach is based on implicit differentiation, which requires additional computational costs. The comment suggests that these comparisons are necessary to demonstrate the efficiency of the proposed approach. While the reasoning is logical and the claim is based on a common understanding of implicit differentiation and its computational implications, it lacks specific examples or references to support the claim fully. This makes the comment somewhat verifiable, as it provides a clear rationale but requires more detailed evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper, noting the absence of direct runtime comparisons with existing methods. It highlights the importance of these comparisons to demonstrate the efficiency of the proposed approach, which is based on implicit differentiation. This feedback is clear and actionable, as it directs the authors to include these comparisons to strengthen their claims about the efficiency of their method. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or suggested potential methods for doing so. Overall, the comment is mostly helpful as it points out a significant area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the proposed framework is a simple combination of meta-learning and federated learning and does not see any technical contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of the framework need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the proposed framework for being a simple combination of meta-learning and federated learning, indicating a lack of technical contribution. However, it does not specify which part of the paper discusses this framework, making it difficult for the authors to pinpoint the exact section that needs revision. The comment lacks specificity regarding what aspects of the framework are considered unoriginal or lacking in technical contribution. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed framework is a simple combination of meta-learning and federated learning, lacking any technical contribution. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment critiques the proposed framework for being a simple combination of meta-learning and federated learning, indicating a lack of technical contribution. However, it does not provide any specific examples or suggestions for improvement, nor does it explain why the combination is considered unoriginal or insufficient. Without actionable feedback or detailed reasoning, the authors are left without a clear understanding of how to address the critique or enhance their framework. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include case studies and error studies to highlight the effectiveness of each proposed component. It provides an example of a case study from \"Graph pre-training for AMR parsing and generation\" to illustrate the potential benefits of such an approach. While the comment explicitly states the need for case studies and error studies, it does not provide specific guidance on how to implement them or what aspects to focus on. The action is clear but lacks detailed instructions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Element-level Graph Pre-training\" and the \"complex structure\" mentioned in the paper, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of case studies and error studies to highlight the effectiveness of each proposed component. This provides clear guidance on how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that case studies and error studies could be beneficial in demonstrating the effectiveness of each proposed component. It provides an example of a case study from \"Graph pre-training for AMR parsing and generation\" to illustrate the potential benefits. However, the comment lacks specific examples or detailed reasoning to fully substantiate why case studies and error studies are necessary or how they would enhance the paper. While it provides a logical argument, the lack of detailed evidence or references makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of case studies and error studies to demonstrate the effectiveness of each proposed component. It highlights the importance of such studies by referencing an example from \"Graph pre-training for AMR parsing and generation,\" which illustrates the potential benefits of including these analyses. This feedback is valuable as it offers a concrete way for the authors to enhance the persuasiveness and credibility of their work. However, the comment could be more helpful if it provided specific guidance on how to design and conduct these studies, such as what aspects to focus on or how to present the results. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer requests clarification on the rationale for considering these factors as separate evaluations. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for their evaluation criteria. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the traditional DCI framework and questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The comment is specific in its critique of the evaluation criteria and provides a logical explanation of how these factors might be entangled. However, it does not explicitly mention which part of the paper discusses these evaluation criteria, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer provides a logical explanation of how these factors might be entangled, but lacks specific examples or references to support the claim. While the reasoning is clear, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer provides a logical explanation of how these factors might be entangled, but the comment lacks specific suggestions or guidance on how the authors might address this issue. While it identifies a potential weakness in the evaluation criteria, it does not offer actionable advice or detailed feedback to help the authors improve their draft. Therefore, the comment is somewhat helpful, as it provides insight into a potential issue but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could be more interesting if it did not involve manual disentangling and instead demonstrated everything being learned. While the comment implies that the authors should reconsider their approach, it does not provide explicit instructions or concrete steps on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their methodology and potentially revise the paper to include more automated disentangling. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the manual disentangling process and suggests that the paper could be more interesting if it demonstrated everything being learned without manual intervention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. The comment suggests that the paper could be more interesting if it demonstrated everything being learned without manual intervention. However, the comment lacks specific examples or references to support the claim that manual disentangling is not necessary or beneficial. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it provides a logical suggestion but lacks the necessary support to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the manual disentangling process in the paper, questioning why the semantic segmentation network is the first module in the pipeline and suggesting that the paper could be more interesting if it demonstrated everything being learned without manual intervention. This feedback is somewhat helpful as it prompts the authors to consider alternative approaches and potentially enhance the originality and impact of their work. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might achieve this goal. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of connection between the theoretical analysis and the proposed method, specifically regarding the use of self-attention mechanisms in the context of graph neural networks (GNNs). However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to strengthen the connection between the theoretical analysis and the proposed method, or how to enhance the generalization for distant nodes. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the theoretical analysis and the proposed method, specifically mentioning the use of self-attention mechanisms in the context of graph neural networks (GNNs). However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in detailing the issue of a lack of connection between the theoretical analysis and the proposed method, as well as the need for clarity on how the proposed method enhances generalization for distant nodes. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical analysis does not have a strong connection to the proposed method, and that the method seems to simply adopt the self-attention mechanism from transformers. The reviewer questions how the proposed method enhances generalization for distant nodes. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap in the connection between the theoretical analysis and the proposed method, specifically regarding the use of self-attention mechanisms in the context of graph neural networks (GNNs). It points out that the proposed method seems to simply adopt the idea of self-attention from transformers and apply it to graphs, without explaining how it enhances generalization for distant nodes. While the comment highlights an area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or strengthen the connection between the theoretical analysis and the proposed method. The feedback is somewhat helpful as it points out a potential weakness, but it could be more beneficial with additional details or actionable advice. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some of the pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the presentation or clarify the use of existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"equation (12)\" and \"the presentation of these methods,\" which provides some grounding as it refers to specific parts of the paper. However, it does not specify which sections or parts of the paper these references pertain to, making it weakly grounded. The comment is specific in pointing out the issue of vagueness in the presentation of existing methods, such as equation (12), and the need for clarity in understanding these methods. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks specific references or examples to substantiate the claim, making it difficult for the authors to understand the exact issues and address them effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that some pieces rely on existing methods, such as equation (12), and that the presentation of these methods is vague. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s originality and clarity. However, the comment lacks specific suggestions or guidance on how to improve the presentation or clarify the use of existing methods. Without actionable advice or detailed feedback, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the stability definition needs better justification, particularly regarding the left side, which can be arbitrarily small under some construction of tilde{g}. The reviewer recommends making the left side lower bounded. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to justify the stability definition or how to implement the suggested change. The action is concrete, as it specifies the need for a more reasonable treatment, but the lack of detailed guidance on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"stability definition,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the justification of the left side of the stability definition, which can be arbitrarily small under some construction of tilde{g}. The comment provides a clear direction for improvement by suggesting a more reasonable treatment, such as making the left side lower bounded. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the stability definition needs better justification, particularly regarding the left side, which can be arbitrarily small under some construction of tilde{g}. The reviewer proposes a more reasonable treatment by making the left side lower bounded. However, the comment lacks specific examples or references to support the claim that the current justification is inadequate. While the suggestion is logical, the lack of detailed justification or evidence makes the claim somewhat verifiable. The authors would need to further explore the issue to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the stability definition, noting that the left side can be arbitrarily small under some construction of tilde{g}. It suggests a more reasonable treatment by making the left side lower bounded. This feedback is clear and actionable, as it provides a concrete direction for improvement by suggesting a specific change to the definition. However, the comment could be more helpful if it included examples or detailed reasoning on why the current justification is insufficient. Overall, the comment is mostly helpful as it guides the authors on how to enhance the clarity and robustness of their definition.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to compare their methodology against existing methods, such as contrastive decoding, and to address issues mentioned above. It also suggests that if the work does not compare effectively, it should aim for a more application-oriented venue. The comment provides clear and concrete actions for the authors to take, specifying what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Contrastive Response Tuning\" and \"core methodology,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is comparing the effectiveness of the method against existing methods like contrastive decoding and addressing issues mentioned above. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address issues mentioned above. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to existing methods or issues that need to be addressed. This makes the claim somewhat verifiable, as the authors would need to infer the specific methods and issues to be addressed. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address issues mentioned above. It also suggests that if the work does not compare effectively, it should aim for a more application-oriented venue. This feedback is specific and constructive, guiding the authors on how to enhance the rigor and relevance of their work. However, the comment could be more helpful if it provided examples of specific issues or methods to address. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several concerns about the effectiveness and problem of the algorithm, suggesting that it requires access to the entire training dataset and questions how it would operate effectively when the dataset is not fully perceptible. It also points out that the validation experiments are not comprehensive and that the time complexity and efficiency of the computation are not clearly analyzed. Additionally, it suggests that the authors should further elucidate the technical contribution rather than the form of the attack. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, leaving the authors to infer what changes are needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several issues with the paper, including the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. The comment also lacks specificity in terms of what needs to be addressed regarding the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises concerns about the effectiveness and problem of the algorithm, suggesting that it requires access to the entire training dataset and questioning how it would operate effectively when the dataset is not fully perceptible. It also critiques the validation experiments as not comprehensive and points out the lack of analysis on the time complexity and efficiency of the computation. The reviewer expects the authors to further elucidate the technical contribution rather than the form of the attack. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support the claims. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to address the issues raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, including the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. It points out that the algorithm requires access to the entire training dataset and questions how it would operate effectively when the dataset is not fully perceptible. Additionally, it critiques the validation experiments as not comprehensive and suggests that the authors should further elucidate the technical contribution rather than focusing solely on the form of the attack. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how similar problems have been addressed in similar works. Overall, the comment is mostly helpful as it guides the authors toward improving their draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the proposed method is not well-positioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. It suggests that the authors should conduct a thorough literature review to identify other works that use this property. While the comment explicitly states the need for a literature review, it does not provide specific guidance on how to conduct it or what aspects to focus on. The action is clear but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of originality in the proposed method and the need for a thorough literature review to identify other works that use the same property. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not well-positioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. The reviewer supports this claim by referencing specific works, such as the original denoising score matching objective and score-interpolation, which have used this property. This provides a clear and robust justification for the claim, making it fully verifiable. Therefore, the comment is labeled as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed method, noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known in the literature. It provides specific examples of existing works that use this property, such as the original denoising score matching objective and score-interpolation. This feedback is valuable as it highlights a potential gap in originality and suggests a thorough literature review to address it. However, the comment could be more helpful if it offered guidance on how to conduct the literature review or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides actionable feedback on a critical aspect of the paper, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a weakness in the argument that PCC is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. It suggests that the authors should provide a gradient comparison between KL and PCC to substantiate this claim. This feedback is clear and concrete, as it specifies exactly what needs to be done to address the issue. The authors know exactly how to apply this suggestion to improve their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient (PCC),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the assumption that PCC is more relaxed than KL divergence due to its invariance to scale and shift. The comment further provides a rationale for why this assumption is not convincing, suggesting that the constraint strength of a loss function is defined via its gradient distribution. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the assumption that PCC is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. The reviewer provides a logical reasoning by explaining that the constraint strength of a loss function is defined via its gradient distribution, using examples like KL divergence and MSE loss. This reasoning is based on a clear understanding of the concepts and their implications, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a key assumption in the paper regarding the relative relaxation of the Pearson correlation coefficient (PCC) compared to KL divergence. It questions the validity of this assumption by pointing out that the constraint strength of a loss function is defined by its gradient distribution, as exemplified by KL divergence and MSE loss. The comment suggests that a gradient comparison between KL and PCC is necessary to substantiate this claim. This feedback is clear and actionable, providing the authors with a specific direction to address the weakness in their argument. By addressing this point, the authors can enhance the robustness of their analysis and improve the clarity of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the paper regarding the resolution of a debate left open in the previous work. It questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. While the comment identifies an issue, it does not provide explicit guidance on how to address it or what specific experiments should be conducted. The authors are left to infer that they need to clarify this point and potentially conduct additional experiments, but the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the resolution of a debate left open in the paper. The comment questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the resolution of a debate left open in the paper and suggests that the distribution cannot be considered a factor in the results. It also questions whether experiments disentangle changes in distribution from the removal of information. While the comment raises valid points, it lacks specific examples or references to support the claim that the distribution is a significant factor. The reasoning is somewhat verifiable, as it highlights a potential issue but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the paper regarding the resolution of a debate left open in the previous work. It questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. This feedback is somewhat helpful as it points out a potential weakness in the paper that could be clarified or addressed. However, the comment lacks specific suggestions or guidance on how to resolve this issue or what experiments might be needed. While it highlights an area for improvement, it does not provide actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the comparison of methods, noting that the proposed method uses AdamW with cosine lr for training, while the other methods only use Adam with a fixed lr. The reviewer suggests that directly comparing the results is unfair and recommends reproducing the results using the same setting as the other methods, which have their code released. This feedback provides a clear and explicit action for the authors to take, which is to reproduce the results using the same setting as the other methods. The suggestion is concrete and specific, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of AdamW with cosine lr for training and the comparison of methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, suggesting that directly comparing results is unfair due to the different training settings. This provides clear guidance on what needs to be addressed to ensure fair comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that directly comparing results is unfair due to the different training settings used by the proposed method compared to the other methods. The reviewer suggests that reproducing the results using the same setting as the other methods would be more fair. This claim is somewhat verifiable as it logically points out a potential issue with the comparison, but it lacks specific examples or references to support the argument. The authors would need to infer the specific training settings used by the other methods and determine how to reproduce their results. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of methods, noting that the proposed method uses AdamW with cosine lr for training, while the other methods only use Adam with a fixed lr. This observation highlights a potential bias in the comparison, as the results may not be directly comparable due to the different training settings. The comment suggests that reproducing the results using the same setting as the other methods would be more fair, as most recent methods have their code released. This feedback is clear and actionable, providing the authors with a specific direction to improve the fairness and validity of their comparison. However, it could be more helpful if it included examples of how to reproduce the results or suggested specific steps to ensure a fair comparison. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the plots are terrible, providing specific issues with the plot quality. It mentions that the plots are too small, colors are hard to distinguish, axis labels are poorly labeled, and labels are visually similar. The reviewer also points out that these issues are the main presentation of the experimental results, which should be clearer. This feedback is clear and provides concrete actions for the authors to take, such as improving plot size, color contrast, and label clarity. The comment is highly actionable as it directly instructs the authors on how to enhance the clarity and quality of their plots, ensuring that they are more effective in communicating their results.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"plots\" and \"plots are terrible,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the plots, such as their small size, color difficulty, and poorly labeled axis. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the plots are terrible, with specific issues such as small size, color difficulty, and poorly labeled axis. The reviewer also mentions that the labels are visually similar, which contributes to the overall clarity issue. While the comment provides specific examples of problems with the plots, it lacks detailed reasoning or references to support why these issues are problematic or how they impact the clarity of the results. This makes the claim somewhat verifiable, as the authors would need to understand the specific issues and address them to improve the clarity of their plots. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback on the quality of the plots, which are the main presentation of the experimental results. It identifies issues such as the small size of the plots, difficulty in distinguishing colors, poorly labeled axis, and visually similar labels. This feedback is clear and constructive, offering the authors a clear path to improve the clarity and effectiveness of their plots. By addressing these issues, the authors can significantly enhance the clarity and impact of their work, making this comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue with Table 1, noting that it does not show standard deviations. It suggests that this omission would make the submission stronger if the experiments were more extensive. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting which experiments should be included or how to present the standard deviations. The action is implicit and somewhat vague, as the authors can infer that they need to include standard deviations but may not be entirely sure of the specifics. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of standard deviations in Table 1. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 1 does not show standard deviations, which would make the submission stronger if the experiments were more extensive. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this omission is significant or how it affects the overall strength of the submission. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 1, noting that it does not show standard deviations. This is a clear and actionable point that could significantly improve the paper by including this information. However, the comment could be more helpful if it provided suggestions on how to present the standard deviations or which experiments should be included to enhance the submission. While it highlights an important area for improvement, the feedback is somewhat limited in its guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit suggestions for improving the paper\\'s structure and focus. It suggests reordering the sections (introduction->method->experiments) and recommends placing more emphasis on the IEM in Figure 3, which is considered the main figure in the paper. Additionally, it suggests improving the visualization of Figure 7 and Figure. These actions are clear and concrete, providing the authors with specific guidance on how to enhance the clarity and focus of their paper. The comment is highly actionable as it directly instructs the authors on what changes to make to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"introduction,\" \"method,\" and \"experiments,\" allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be improved, such as the structure of the paper and the focus on the IEM in Figure 3. Additionally, it provides specific suggestions for improving the visualization of Figure 7 and Figure. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is hard to follow and suggests improvements to the structure and focus. It provides specific suggestions, such as reordering sections (introduction->method->experiments) and focusing on the IEM in Figure 3. The comment also suggests improving the visualization of Figure 7 and Figure. These suggestions are based on logical reasoning and specific observations, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the structure and organization of the paper, suggesting improvements such as reordering the sections (introduction->method->experiments) and focusing on the IEM in Figure 3, which is considered the main figure in the paper. It also suggests improving the visualization of Figure 7 and Figure. This feedback is clear and constructive, offering the authors a clear path to enhance the clarity and focus of their draft. By addressing these points, the authors can significantly improve the readability and impact of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments should be expanded to include attacks on other architectures and classification tasks beyond neural networks and image classification. While the comment implies that the authors should consider conducting experiments on these additional tasks, it does not provide specific guidance on how to implement these changes or what specific architectures or tasks should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests expanding the experiments to include attacks on other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which parts of the paper these experiments should be added to or which specific architectures or tasks should be considered. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment is not specific about what aspects of the experiments should be expanded or how they should be conducted. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the experiments are limited to neural networks and image classification tasks and recommends expanding them to include attacks on other architectures and classification tasks. However, the comment does not provide any supporting evidence, examples, or references to justify why this expansion is necessary or how it would benefit the paper. Without additional context or reasoning, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests expanding the experiments to include attacks on other architectures and classification tasks beyond neural networks and image classification. This is a valuable suggestion as it could provide a broader understanding of the applicability and effectiveness of the proposed method. However, the comment lacks specificity and does not offer guidance on which architectures or tasks should be considered or how to implement these changes. While it identifies a potential area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses skepticism about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from nearby nodes. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or explain their choice. The comment lacks concrete steps or detailed advice on how to improve the draft, leaving the authors uncertain about what specific actions to take. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of a transformer without locality bias, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the impact of locality bias and the potential consequences of using a transformer without it. However, the comment lacks specificity regarding what aspects of the transformer's design or implementation might be problematic or how the authors could address these concerns. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from nearby nodes. However, the comment lacks specific evidence or reasoning to support this claim. It does not provide examples, references, or detailed explanations to substantiate the argument. As a result, the claim is not fully verifiable, making it difficult for the authors to understand and address the concern effectively. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the choice of using a transformer without locality bias, questioning whether it is indeed the best option given the limited speed of information propagation. It suggests that the neighborhood agents might have more impact on each other compared to far-away nodes. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or explain their choice. While it highlights an important area for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a trade-off between reducing a particular behavior and maintaining high performance. It also points out that if the mitigation strategies significantly impair the model\\'s utility, it could deter their adoption. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to mitigate the potential impact. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the potential impact of their mitigation strategies on performance. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the mitigation strategies aimed at reducing memorization and questions their impact on the overall performance of the model. It suggests that there might be a trade-off between reducing a particular behavior and maintaining high performance, and points out that significant impairment of the model\\'s utility could deter adoption. However, the comment does not specify which part of the paper discusses these mitigation strategies, making it weakly grounded. The comment is specific in its concern about the potential impact on performance, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a trade-off between reducing a particular behavior and maintaining high performance. It also points out that if the mitigation strategies significantly impair the model\\'s utility, it could deter their adoption. However, the comment lacks specific examples or references to support the claim about the potential impact on performance. Without detailed evidence or examples, the claim is somewhat verifiable, as it provides a logical argument but lacks the necessary substantiation to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the mitigation strategies, suggesting that their impact on overall performance might not be fully understood. It raises a concern about a trade-off between reducing a particular behavior and maintaining high performance, and points out that significant impairment of the model\\'s utility could deter adoption. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this issue or what specific mitigation strategies could be explored. The feedback is somewhat helpful as it prompts the authors to consider the potential impact of their mitigation strategies, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the reason for using 6-fold cross-validation in the experiments. It points out that other papers in the field did not use cross-validation, which raises questions about its necessity. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to clarify the rationale behind the cross-validation. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clear explanation for the use of cross-validation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of 6-fold cross-validation and the comparison with other papers that did not use it. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue: the lack of clarity regarding the reason for using 6-fold cross-validation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the reason for using 6-fold cross-validation is unclear because other papers in the field did not use it. However, the comment does not provide any supporting evidence or references to substantiate this claim. Without specific examples or detailed reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the reason for using 6-fold cross-validation. It points out that other papers in the field did not use this validation method, which raises questions about its necessity. This feedback is somewhat helpful as it highlights an area where the authors need to provide more detailed explanation or justification for their methodology. However, the comment could be more helpful if it suggested ways to address this issue, such as explaining the rationale behind the choice of cross-validation or providing a comparison with other validation methods. Overall, the comment provides some insight but lacks actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the paper presents an effective engineering method for ReC but notes that the proposed framework incorporates combinatorial and heuristic aspects. It specifically points out the Non-Ambiguous Query Generation procedure, which relies on a sophisticated filtering template. The reviewer suggests that the authors clarify the impact of these heuristic components. While the comment implies that the authors should provide more information about the heuristic components, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the heuristic components. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Non-Ambiguous Query Generation procedure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the impact of the heuristic components, such as the sophisticated filtering template. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents an effective engineering method for ReC but notes that the framework incorporates combinatorial and heuristic aspects, specifically mentioning the Non-Ambiguous Query Generation procedure. The reviewer suggests that the authors clarify the impact of these heuristic components. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim that these heuristic components are problematic or unclear. The reasoning is somewhat verifiable, as it points out a potential issue but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that the proposed framework incorporates combinatorial and heuristic aspects, such as the Non-Ambiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components, which is a valuable point for improving the paper. However, the comment could be more helpful if it provided specific suggestions on how to clarify these aspects or examples of how they might be addressed. While it highlights an important area for improvement, the feedback could be more actionable with additional guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a doubt about the proposed method's ability to be trained without using camera information, specifically questioning the \"knowledge of CAD model correspondences\" mentioned in Line 223. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what specific steps they could take to clarify or improve their method. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the method\\'s ability to be trained without camera information and the \"knowledge of CAD model correspondences.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the proposed method\\'s ability to be trained without camera information, specifically mentioning the \"knowledge of CAD model correspondences\" (Line 223). However, the comment lacks any supporting evidence, reasoning, or references to substantiate the claim that this knowledge is necessary for training. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the proposed method\\'s ability to be trained without camera information, specifically questioning the \"knowledge of CAD model correspondences\" mentioned in Line 223. It highlights the importance of camera information for performing ray marching and determining the ray\\'s origin. While the comment identifies a potential weakness in the methodology, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. The feedback is somewhat helpful as it points out a potential problem but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper discusses ODA as a method for solving the MOIP problem but does not clearly explain how the presented method improves performance and computation speed over ODA. However, it does not provide specific guidance on how the authors should address this issue or what additional details should be included to clarify the improvement. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the discussion of ODA as a method for solving the MOIP problem and points out that the paper does not clearly explain how the presented method improves performance and computation speed over ODA. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of clarity regarding the improvement over ODA. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not clearly explain how the presented method improves performance and computation speed over ODA, which is a common method for solving the MOIP problem. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it does not clearly explain how the presented method improves performance and computation speed over ODA, which is a common method for solving the MOIP problem. This feedback is somewhat helpful as it points out a gap in the paper\\'s explanation, but it lacks specific suggestions or guidance on how the authors might address this issue. While it highlights an area for improvement, the comment could be more helpful by providing examples or additional details on what aspects of the methodology need clarification or enhancement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of those in the low-resource regime. While the comment explicitly states the need for additional experiments, it does not provide specific guidance on which datasets to use or how to conduct these experiments. The action is clear but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental results, but this inference is not direct. The comment is specific in suggesting additional experiments and encouraging experiments on the full dataset, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. However, it does not provide any supporting evidence, reasoning, or references to justify why additional experiments are necessary or how they would improve the evaluation. The claim is based on a general suggestion, but without specific examples or detailed justification, it lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of those in the low-resource regime. This feedback is clear and actionable, as it directly instructs the authors to expand their experimental scope and improve the comprehensiveness of their evaluation. However, the comment could be more helpful if it provided specific suggestions on which datasets to include or how to conduct these experiments. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the paper regarding the generic argument task and the random argument task, specifically questioning how they prove the authors\\' claims. It also mentions that the dataset transformation and experimental setup feel cumbersome and unclear. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve clarity. The action is implicit and vague, as the authors are left to infer that they need to clarify the tasks and experimental setup. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of clarity in the paper regarding the generic argument task and the random argument task, specifically questioning how they prove the authors\\' claims. It also mentions the cumbersomeness of the dataset transformation and experimental setup. However, the comment does not specify which sections or parts of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing what needs to be clarified, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the generic argument task and the random argument task are unclear in proving the authors\\' claims. It also mentions that the dataset transformation and experimental setup are cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of specificity and detailed evidence or references makes the claim borderline verifiable, as it requires more detailed justification to be fully substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the paper, specifically regarding the generic argument task and the random argument task. It points out that the authors\\' claims are not clearly supported by these tasks, which adds to the overall cumbersomeness of the dataset transformation and experimental setup. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it directs the authors\\' attention to a specific area needing clarification, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be interesting but not necessary to explore how the model works with tabular data, specifically by considering each attribute dimension as a modality. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should explore tabular data but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring how the model works with tabular data, specifically by considering each attribute dimension as a modality. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this exploration could be discussed. The authors can infer that it relates to the model evaluation or methodology sections, but this inference is not direct. The comment is specific in suggesting an area for exploration but lacks grounding as it does not explicitly mention where in the paper this should be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that exploring how the model works with tabular data, specifically by considering each attribute dimension as a modality, would be interesting but not necessary. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this exploration would be beneficial or necessary. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests exploring how the model works with tabular data, specifically by considering each attribute dimension as a modality. This is a valuable suggestion as it could provide insights into the model's applicability to different forms of data. However, the comment lacks specific guidance on how to implement this exploration or what aspects of the model should be considered. While it identifies a potential area for improvement, the lack of detailed instructions or examples limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but requires more detailed guidance for the authors to fully address the suggestion.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include more analysis on the multilingual alignment of entity representations, specifically recommending visualizations or case studies for different types of languages. It also raises a question about the alignment of entities from low-resourced languages with high-resourced ones. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific visualizations or case studies should be included. The action is explicit but somewhat vague in terms of execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the language-agnostic characters of entity representations, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more analysis on the multilingual alignment of entity representations, including visualizations or case studies for different languages. The comment also raises a question about the alignment of entities from low-resourced languages with high-resourced ones. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks analysis on the alignment of entity representations, particularly in the context of multilingual alignment. It recommends adding more analysis, including visualizations or case studies, for different types of languages. The comment also raises a question about the alignment of entities from low-resourced languages with high-resourced ones. While the suggestion for additional analysis is logical, the comment lacks specific examples or references to support the claim that the current analysis is insufficient. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of analysis on the alignment of entity representations, particularly in the context of multilingual alignment. It suggests that the authors should add more analysis, including visualizations or case studies, for different types of languages. Additionally, it raises a question about the alignment of entities from low-resourced languages with high-resourced ones. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their analysis and addressing a gap in their work. However, it could be more helpful if it included specific examples or references to similar studies that have successfully addressed these issues. Overall, the comment is mostly helpful as it guides the authors toward improving their draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the references list contains duplicates and that the publication venues and/or publication years of many of the papers are missing. While it identifies specific issues, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to check for duplicates and ensure the correct publication venues and years are included. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions the references list, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of duplicates and missing publication venues/years, providing clear guidance on what needs to be addressed. However, it does not provide detailed suggestions on how to resolve these issues, such as which specific papers are duplicates or how to ensure accurate publication information. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the references list contains duplicates and that the publication venues and/or publication years of many of the papers are missing. However, it does not provide specific examples or detailed reasoning to support these claims. Without concrete evidence or references, the authors may find it challenging to verify and address the issues. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the references list, noting that it contains duplicates and that the publication venues and/or publication years of many of the papers are missing. This feedback is clear and actionable, as it directs the authors to verify and correct their references list to ensure accuracy and completeness. However, the comment could be more helpful if it provided suggestions on how to identify and resolve duplicates or how to locate missing publication details. Overall, the comment is mostly helpful as it highlights a critical aspect of the paper that needs attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the theoretical analysis in Theorem 1 is unclear and weak, specifically mentioning the lack of clarity regarding the error bound. It suggests that the authors should analyze and compare their theoretical results to those of other comparable methods. This feedback provides a clear and concrete action for the authors to take, which is to clarify the error bound and compare their results with others in the field. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound in Theorem 1 and the need for analysis and comparison with other methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically mentioning the lack of clarity regarding the error bound. The comment suggests that the authors should analyze and compare their theoretical results with those of other comparable methods. While the comment identifies a potential issue with the clarity of the theoretical analysis, it does not provide specific examples or references to support the claim that the error bound is unclear. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that the error bound is unclear and that the authors need to analyze and compare their results with other comparable methods. This feedback is clear and actionable, as it provides a direct suggestion for the authors to improve the clarity and robustness of their theoretical analysis. By addressing this issue, the authors can enhance the rigor and credibility of their work. However, the comment could be more helpful if it offered specific guidance on how to analyze and compare the results, or provided examples of comparable methods to consider. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and points out that the pseudo-code of the proposed method is missing. It also references external works that may be relevant to understanding the performance difference. However, the comment does not provide explicit instructions or suggestions on how the authors should address this issue or what specific aspects of the pseudo-code should be included. The action is implicit and somewhat vague, as the authors need to infer that they should include the missing pseudo-code and possibly explore the performance difference between explicit and implicit methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"locomotion tasks\" and the \"proposed method,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the performance difference between explicit and implicit methods and points out the missing pseudo-code of the proposed method. Additionally, it references external works that could be relevant to understanding the performance difference. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and mentions the missing pseudo-code of the proposed method. It references external works by S\u00f8ren Asmussen and Peter W Glynn and P. Florence et al., which could provide some basis for the claim. However, the comment lacks detailed reasoning or specific examples from the referenced works to fully substantiate the claim. While the references offer some support, the comment is somewhat verifiable as it requires more detailed explanation or examples to fully justify the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the performance of explicit methods compared to implicit methods on locomotion tasks, which is an important aspect of the paper. It also points out the missing pseudo-code of the proposed method, which is a significant oversight. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the pseudo-code should be included. While it identifies a significant gap in the paper, it does not provide actionable feedback or detailed advice on how to improve the draft. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the specific reason for the choice of Gaussian noise in the experiments, noting that the paper claims the model works well for various image noise types. While the comment implies that the authors should address this issue by providing a rationale or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification for the choice of Gaussian noise. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific part of the paper where the authors discuss their model's ability to work well for various image noise types, allowing the authors to accurately identify the relevant section. It is also specific because it questions the choice of Gaussian noise in the experiments and asks for a rationale or explanation. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of Gaussian noise in the experiments, suggesting that there might be a particular reason for this choice. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specificity and does not offer a clear justification or explanation for the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the choice of Gaussian noise in the experiments, noting that the paper claims the model works well for various image noise types. This is an important point as it highlights a potential limitation in the scope of the experiments. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional noise types could be considered. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should visualize the effect of increasing dimensionality on the performance of existing PU learning methods. This is a clear and direct action for the authors to take, as it provides a specific request for visualization that is crucial to the research motivation of the paper. The comment is specific and actionable, as it clearly identifies what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about the performance of existing PU learning methods as the dimensionality of the data increases. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is the visualization of this effect. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the existing PU learning methods will suffer a gradual decline in performance as the dimensionality of the data increases. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of this assertion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper\\'s claim about the performance of existing PU learning methods as the dimensionality of the data increases. It suggests that visualizing this effect is crucial to the research motivation of the paper. This feedback is clear and actionable, as it directs the authors to provide a visualization that can help substantiate their claim. By addressing this suggestion, the authors can enhance the credibility and clarity of their work. However, the comment could be more helpful if it provided specific guidance on how to create the visualization or what aspects to focus on. Overall, the comment is mostly helpful as it highlights an important area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a need for simpler and clearer descriptions of results, specifically mentioning the convoluted nature of some descriptions. It provides a specific suggestion to consider a related idea from [1] and references [2] to check for useful communication. The comment also points out that the differences in figures seem too small, but acknowledges that the topography plots indicate something reasonable. While the comment provides some guidance on what needs to be improved, it lacks explicit instructions on how to simplify the result descriptions or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the need for simpler and clearer descriptions of results, specifically mentioning the convoluted nature of some descriptions. It provides a specific suggestion to consider a related idea from [1] and references [2] to check for useful communication. The comment also points out that the differences in figures seem too small, but acknowledges that the topography plots indicate something reasonable. However, the comment does not explicitly mention which part of the paper these issues pertain to, making it weakly grounded. The suggestions are specific, but without clear grounding, the authors may struggle to identify the exact sections that need improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the result descriptions are needlessly convoluted and suggests that the authors consider a related idea from [1] and check for useful communication in light of [2]. The reviewer provides references to external works, which supports the claim by offering a logical connection to related literature. However, the comment could be strengthened by providing more detailed reasoning or examples of specific instances where the descriptions are convoluted. Despite this, the references provide a solid foundation for the claim, making it mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the complexity and clarity of the result descriptions, noting that some are needlessly convoluted. It provides a constructive suggestion by referencing a related idea from [1] and referencing [2] to check for useful communication. This feedback is actionable as it offers a clear direction for the authors to simplify their descriptions and potentially enhance the clarity of their work. However, the comment could be more helpful if it provided specific examples of convoluted descriptions or detailed guidance on how to simplify them. Overall, the comment is mostly helpful as it offers a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the approximation error should be mathematically characterized, which provides a clear and direct action for the authors to take. This guidance is specific and concrete, as it specifies the exact improvement needed to clarify the approximation error. The authors know exactly what needs to be done to address the issue, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the approximation error, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a mathematical characterization of the approximation error. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approximation error is ambiguous and suggests providing a mathematical characterization. However, the comment does not provide any supporting evidence or reasoning to justify why the current definition is unclear or how a mathematical characterization would improve clarity. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the approximation error definition, noting that it is ambiguous without additional context. It suggests that a mathematical characterization would be beneficial to clarify the concept. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that can enhance the clarity and understanding of the paper. However, the comment could be more helpful if it included examples or additional details on how to implement the suggested mathematical characterization. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, resulting in slow dynamics. It also notes that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. While the comment identifies a specific issue with the model dynamics, it does not provide explicit guidance on how to address this problem or suggest alternative approaches. The action is implicit and somewhat vague, as the authors can infer that they need to consider ways to improve the dynamics and complexity of the model. However, without concrete suggestions or examples, the comment lacks clarity and is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed model\" and the \"evolution model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the model dynamics, noting that the model produces only one node changing cluster per time step and that the evolution model is simplistic, with no other edges changing except those associated with the 1 node changing cluster. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, resulting in slow dynamics. It also notes that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. The comment provides logical reasoning by explaining the consequences of the reassignment probability and the simplicity of the evolution model. However, it lacks specific examples or references to support the claim that this is a significant issue or how it affects the overall performance of the model. Therefore, the comment is somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed model, noting that it produces only one node changing cluster per time step on average due to the reassignment probability being 1/n. This results in slow dynamics, as the model can only change one node at a time. Additionally, the comment points out that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. This feedback is somewhat helpful as it highlights a potential limitation in the model\\'s dynamics and complexity, which the authors could address to improve their draft. However, the comment could be more helpful by suggesting ways to address these issues or providing examples of alternative models or approaches that could be considered. Overall, the comment provides some insight but lacks depth and actionable guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that there are missing details about the division to train and test sets, including numbers and the method used for division (random or other considerations). It clearly instructs the authors to add these details, providing a direct and concrete action for improvement. The comment is specific about what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for details about the division to train and test sets, including numbers and the method used for division. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be added, such as details about the division method and numbers. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are missing details about the division to train and test sets, including numbers and the method used for division. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, namely the absence of details about the division to train and test sets, including numbers and the method used for division. It clearly instructs the authors to add these details, providing a direct and actionable suggestion for improvement. This feedback is valuable as it helps the authors clarify and strengthen their methodology section, ensuring that their experimental results are transparent and replicable. However, the comment could be more helpful if it offered additional guidance on how to present these details or what specific considerations should be taken into account. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the need for human labor in building text descriptions and the potential scalability issue with long-text inputs. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for how to address the human labor issue or how to improve scalability. The comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of human labor in building text descriptions and the scalability of the framework with long-text inputs. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the need for human labor and the scalability issue, but it lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two claims: the need for human labor in building text descriptions and the potential scalability issue with long-text inputs. The first claim is based on the observation that text descriptions still require human labor, which is a factual observation. However, the second claim about scalability is less verifiable as it lacks specific examples or references to support the assertion that long-text inputs restrict scalability. The comment could be strengthened by providing more detailed reasoning or evidence to substantiate the claim about scalability. Therefore, the comment is somewhat verifiable, as it provides some support but lacks full justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main issues: the need for human labor in building text descriptions and the potential scalability issue with long-text inputs. It acknowledges the complexity of determining the optimal textual format for policy learning, which varies across tasks and models. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the scalability of their framework. While it highlights important areas for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out potential weaknesses but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it does not provide any guidance on how the authors might prove these results or what specific theoretical aspects should be addressed. The action is implicit and vague, as the authors are left to infer that they need to provide theoretical evidence or results to substantiate their claims. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the lack of theoretical results, but it is not grounded as it does not reference a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might address this issue or what theoretical results could be explored. Without actionable feedback or detailed insights, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors can provide more evidence to either prove or disprove it. While the comment implies that the authors should provide evidence to support or refute the hypothesis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence to substantiate the hypothesis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. However, it does not specify which part of the paper this hypothesis pertains to, making it weakly grounded. The comment is specific in suggesting that the human test results might support the hypothesis but questions whether the authors can provide more evidence to prove or disprove it. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors could provide more evidence to either prove or disprove it. While the comment provides a logical reasoning for the hypothesis, it lacks specific examples or references to support the claim. The suggestion for additional evidence is a clear indication of what the authors could do to improve the draft, but the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a hypothesis about the two parts of the paper, suggesting that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors could provide more evidence to either prove or disprove it. This feedback is somewhat helpful as it prompts the authors to consider providing additional evidence to substantiate or refute the hypothesis. However, the comment could be more helpful if it offered specific suggestions on how to gather or present this evidence. Overall, the comment provides a direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the testing of the bAbI model, specifically asking whether it was only tested on a single supporting fact dataset (Task 1). While the comment implies that the authors should consider testing the model on other tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should test the model on additional tasks. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"bAbI\" and \"Task 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the testing of the bAbI model, suggesting that it was only tested on a single supporting fact dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking about the testing of the bAbI model on other tasks beyond Task 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a relevant question about the testing of the bAbI model, specifically asking whether it was only tested on a single supporting fact dataset (Task 1). This is a valid point that could impact the robustness and generalizability of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what additional tasks they should consider testing. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should improve Section 3.2 by providing more illustrations and examples. This feedback is clear and direct, giving the authors a specific action to take to enhance the clarity and comprehensibility of their draft. The comment provides a concrete suggestion for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more illustrations and examples to improve the clarity of the section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Section 3.2 is difficult to follow and recommends providing more illustrations and examples to improve clarity. However, the comment does not provide specific examples or detailed reasoning to support why the section is challenging to understand or how additional illustrations and examples would enhance comprehension. Without these details, the authors may find it difficult to address the issue effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Section 3.2, noting that it is difficult to follow. It suggests that the authors might improve the section by providing more illustrations and examples to enhance clarity. While the comment highlights a potential area for improvement, it lacks specific guidance on what types of illustrations or examples would be beneficial or how to effectively integrate them into the section. This limits the comment\\'s helpfulness, as it provides a general direction but does not offer detailed suggestions for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the time complexity of the proposed algorithm, specifically asking about the time required to calculate the hypervolume of different regions in each step of LaMOO. It also mentions that the computation of hypervolume could be time-consuming, especially for problems with many objectives. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete suggestions on how to improve the time complexity or optimize the algorithm. The action is implicit and somewhat vague, as the authors need to infer that they should address the time complexity issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Time Complexity\" and \"LaMOO,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the time complexity of the proposed algorithm, particularly the repeated calculation of hypervolume for promising region selection. The comment raises a concern about the practicality of LaMOO for problems with many objectives, which is a specific and relevant point. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the time complexity of the proposed algorithm, specifically questioning whether the repeated calculation of hypervolume for promising region selection in LaMOO could be time-consuming, especially for problems with many objectives. While the comment highlights a potential issue, it lacks specific examples or references to substantiate the claim that the time complexity is a problem. The authors are left to infer the potential impact on the practicality of the algorithm, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the time complexity of the proposed algorithm, specifically questioning the repeated calculation of hypervolume for promising region selection in LaMOO. It highlights a potential issue with the practicality of the algorithm for problems with many objectives, which could be time-consuming. While the comment identifies a relevant concern, it lacks specific suggestions or guidance on how the authors might address this issue or optimize the algorithm for better performance. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the dataset used in the experiments is small but suggests that results on larger datasets like ImageNet would be more convincing. However, it also states that this is a minor issue and will not affect the overall quality of the paper. While the comment implies that the authors should consider running experiments on larger datasets, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider running experiments on larger datasets. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of the dataset being small, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the suggestion to include results on larger datasets like ImageNet, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the dataset used in the experiments is small and suggests that results on larger datasets like ImageNet would be more convincing. However, the comment does not provide any supporting evidence, reasoning, or references to justify why larger datasets are necessary or how they would impact the paper\\'s conclusions. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the issue of using small datasets in the experiments and suggests that results on larger datasets like ImageNet would be more convincing. However, it also states that this is a minor issue and will not affect the overall quality of the paper. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to address the issue of dataset size. The feedback is somewhat helpful as it points out a potential weakness but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several areas for improvement, including the need to discuss leveraging state, reactiveness, and learning during an episode, as well as the generic and vague title. It suggests being honest and direct in the critique and provides a specific example of what \"brittle convergence properties\" means. Additionally, it mentions that DeepRL methods are widely adopted and suggests considering the landscape 10 years ago. While the comment provides some guidance on what aspects to address, it lacks concrete details on how to implement these suggestions. The authors are given a general direction but may need to infer the specific actions to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several issues, including the limitations of evolutionary methods, the generic and vague title, and the need for more detailed discussion on leveraging state, reactiveness, and learning during an episode. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in suggesting that the title is too generic and vague and that the authors should be more precise in their critique. It also asks for clarification on the term \"brittle convergence properties\" and mentions the widespread adoption of DeepRL methods. Overall, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims and suggestions, including the need to discuss leveraging state, reactiveness, and learning during an episode, the generic and vague title, and the need for more detailed discussion on \"brittle convergence properties.\" The reviewer also questions the widespread adoption of DeepRL methods and suggests considering the landscape 10 years ago. While the comment provides some reasoning and examples, it lacks specific references or detailed explanations to fully substantiate the claims. The authors would need to infer the basis of these claims and potentially conduct additional research to fully understand and address them. Therefore, the comment is somewhat verifiable, as it provides some support but lacks comprehensive evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement, including the need to discuss leveraging state, reactiveness, and learning during an episode, which could enhance the paper\\'s contribution. It also points out that the title is too generic and vague, suggesting that being more precise in the critique would be beneficial. Additionally, the reviewer questions the term \"brittle convergence properties\" and suggests considering the landscape 10 years ago. While the comment provides some actionable feedback, it could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how similar works have tackled these challenges. Overall, the comment is somewhat helpful as it highlights areas for improvement but lacks detailed guidance on implementation.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It asks for clarification on how the defocus map and an image are used to synthesize the defocused image, and how the edges are handled in areas where depth discontinuities occur. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues. The authors know they need to provide more information about the synthesis process, but the comment lacks specific suggestions on how to improve the explanation or what details should be included. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It specifically asks about how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas with depth discontinuities. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections. The comment is specific in detailing what needs to be addressed, providing clear guidance on what aspects of the synthesis process are unclear. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It asks for clarification on how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas where depth discontinuities occur. While the questions are valid, they do not provide specific examples or references to support the claim that the paper lacks clarity or explanation. The comment is somewhat verifiable, as it highlights areas that need further clarification, but it does not offer detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It specifically asks for clarification on how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas where depth discontinuities occur. These questions highlight areas where the paper could be improved by providing more detailed explanations or examples. However, the comment does not offer specific suggestions or guidance on how the authors might address these issues, such as recommending additional experiments or clarifications. While it identifies important areas for improvement, the feedback lacks actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out areas for enhancement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a comparison of the authors\\' approach with other LLMs could be included, specifically mentioning the transferability to other LLMs. Additionally, it points out a minor issue with the jailbreaking percentage being low for certain LLMs. While the comment implies that the authors should include this comparison and address the jailbreaking issue, it does not provide explicit instructions or detailed guidance on how to implement these suggestions. The action is clear but somewhat vague, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"GCG\" and \"their approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison with other LLMs and the issue of low jailbreaking percentages for certain LLMs. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that a comparison with other LLMs could be included, as well as addressing the issue of low jailbreaking percentages for certain LLMs. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the suggestion or the specific aspects that need improvement. The lack of detailed justification or evidence makes the claim borderline verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending the inclusion of a comparison with other LLMs, which could enhance the paper\\'s contribution. It also points out a minor issue with the jailbreaking percentage being low for certain LLMs. While the comment identifies areas for improvement, it lacks detailed guidance or examples on how to conduct the comparison or address the jailbreaking issue. This limits the comment\\'s helpfulness, as it provides some direction but not enough depth to fully support the authors in making these improvements. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the authors\\' explanation of the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. While it acknowledges the novelty of the approach, it explicitly requests a more detailed explanation to better understand the difference. This feedback is clear and provides a specific action for the authors to take, which is to provide a more detailed explanation. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction of unsupervised feature selection from a diffusion perspective, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for a more detailed explanation of the difference between similarity and exit times in nature. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. The reviewer acknowledges the novelty of the approach but expresses difficulty in understanding the distinction. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim that the explanation is unclear. Without additional context or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the explanation of the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It acknowledges the novelty of the approach but expresses a need for a more detailed explanation to better understand the distinction. This feedback is somewhat helpful as it points out a potential gap in the paper\\'s explanation, prompting the authors to provide a clearer explanation. However, the comment could be more helpful if it offered suggestions on how to improve the explanation or provided examples to illustrate the difference. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. While it implies that the authors should address this limitation, it does not provide explicit instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a response to the question. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the limitations of the framework, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the framework is limited in this way. Without such information, the authors may find it challenging to address the question or understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. This is a relevant point that could help the authors identify potential areas for improvement or expansion in their work. However, the comment lacks specific guidance or suggestions on how to address this limitation or what specific aspects of the framework might need improvement. While it points out an important area for consideration, it does not provide actionable feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the creation of the dataset is optional and that the Kialo dataset, which is well-studied in the community, provides pairs of short claims and their counters. The reviewer notes that the Kialo dataset is cleaner and that the authors\\' dataset can be considered extra data to learn from. While the comment implies that the authors should consider using the Kialo dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should use the Kialo dataset rather than being directly told to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is well-studied in the community. It also notes that the Kialo dataset provides pairs of short claims and their counters, and that it is cleaner than the dataset created by the authors. However, the comment does not specify which part of the paper discusses the dataset creation, making it weakly grounded. The comment is specific in suggesting that the Kialo dataset could be used as an alternative, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is well-studied in the community. The reviewer claims that the Kialo dataset provides pairs of short claims and their counters and is cleaner than the dataset created by the authors. However, the comment lacks specific examples or references to support the claim that the Kialo dataset is cleaner or that it provides exactly what the authors need. While the suggestion to use the Kialo dataset is logical, the lack of detailed evidence or comparisons makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is well-studied in the community and provides pairs of short claims and their counters. The reviewer notes that the Kialo dataset is cleaner than the one created by the authors and suggests that the authors\\' dataset can be considered extra data to learn from. While the comment identifies a potential alternative dataset, it lacks detailed guidance on how the authors might incorporate this suggestion into their work or why the Kialo dataset is preferable. The feedback is somewhat helpful as it points out a potential source of data, but it could be more actionable with additional details or suggestions for incorporating the Kialo dataset. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the limited number of tasks in the experiments and suggests that the authors should include more tasks (at least 10) and sequential results in terms of tasks learned rather than epochs. However, it does not provide specific guidance on how to implement these changes or what aspects of the experiments should be revised. The comment implies that the authors should address the weaknesses mentioned, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out the limited number of tasks and suggests that the authors should include more tasks and sequential results in terms of tasks learned rather than epochs. The comment also asks the authors to address the weaknesses mentioned above, providing clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the number of tasks in the experiments is limited and recommends including more tasks (at least 10) and sequential results in terms of tasks learned rather than epochs. However, the comment does not provide any specific reasoning or evidence to support why the current number of tasks is insufficient or how adding more tasks would improve the experiments. The suggestion is based on a general expectation, but without detailed justification or examples, it lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the experiments, specifically the limited number of tasks used. It suggests that the authors should include more tasks (at least 10) and sequential results in terms of tasks learned rather than epochs. This feedback is clear and actionable, as it provides a specific direction for improvement that could enhance the robustness and comprehensiveness of the experiments. However, the comment could be more helpful if it explained why the current number of tasks is insufficient or how adding more tasks would benefit the analysis. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the parameter S remains a problem, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps the authors should consider to improve the parameter setting. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions the issue of setting the parameter S, but it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspect of the parameter S setting is problematic or how it could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The comment states that \"How to set the parameter S remains a problem,\" but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a specific issue with the parameter S, indicating that it remains a problem. However, it does not provide any guidance or suggestions on how to address this issue or improve the parameter setting. Without actionable feedback or detailed insights, the authors are left without a clear path forward to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. While the comment implies that the authors should consider conducting a human evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a human evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, it does not specify which part of the paper discusses the evaluation metrics or the caption generation process, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to include human evaluation, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this suggestion and how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. This feedback is somewhat helpful as it identifies a potential weakness in the paper\\'s evaluation methodology and suggests an alternative approach that could provide a more robust assessment. However, the comment lacks specific guidance on how to conduct a human evaluation or what aspects of the caption generation process should be evaluated by humans. While it points out a potential issue, it does not offer detailed instructions or examples on how to address it, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the experimental setup borrowed from [2] is only semi-real because it involves artificially created multi-node seed cascades by merging single-node seed cascades. This provides a clear and direct action for the authors to take, which is to mention this fact clearly in their paper. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental setup borrowed from [2], allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental setup, namely that it is only semi-real due to the artificial creation of multi-node seed cascades by merging single-node seed cascades. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental setup borrowed from [2] is only semi-real because it involves artificially created multi-node seed cascades by merging single-node seed cascades. This claim is somewhat verifiable as it provides a logical reasoning for the classification, based on the description of the experimental setup. However, it lacks specific examples or references to [2] to fully substantiate the claim. The authors would need to infer the details of the setup from the reference, which could be challenging without direct access to the original work. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that it is only semi-real due to the artificial creation of multi-node seed cascades by merging single-node seed cascades. This is a clear and actionable observation that the authors should address by explicitly mentioning this aspect in their paper. By doing so, the authors can clarify the nature of their experimental setup and provide more transparency to their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how other studies have addressed similar issues. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues: the limited scope of datasets and models used in the study and the lack of assessment of other important biases and datasets. It also points out the absence of assessments on state-of-the-art generative models like GPT. While the comment highlights areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should expand their dataset and model selection and include assessments on additional biases and models like GPT. However, the comment lacks concrete suggestions on how to implement these changes or what specific datasets or models should be considered. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitations of the datasets and models used in the study, specifically mentioning the bias benchmarks and the absence of assessments on state-of-the-art generative models like GPT. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the limitations of the dataset and model selection and the need for additional assessments. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the datasets and models used in the study are limited and that the bias benchmarks only assess gender, race, and religion. It also mentions the absence of assessments on state-of-the-art generative models like GPT. While the comment identifies specific limitations, it lacks detailed justification or examples to fully substantiate the claim. The authors would need to infer the importance of these assessments and the potential impact on the study\\'s conclusions. Therefore, the comment is somewhat verifiable, as it provides some basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the study, noting that the datasets and models used are limited and that the bias benchmarks only assess gender, race, and religion. It also points out the absence of assessments on state-of-the-art generative models like GPT. This feedback is valuable as it highlights areas where the study could be expanded to include a broader range of biases and models, which would enhance its scope and relevance. However, the comment could be more helpful if it provided specific suggestions on which datasets or models to consider or how to incorporate assessments of generative models like GPT. Overall, the comment is mostly helpful as it directs the authors\\' attention to important areas for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the method's sensitivity to hyperparameters, suggesting that careful hyperparameter search is necessary to find the proper value of $\\\\alpha$ for a new problem. However, it does not provide explicit guidance on how to perform this search or what specific steps to take. The action is implied, as the authors can infer that they need to conduct a hyperparameter search, but it remains vague without concrete details on how to execute this task. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the sensitivity of the method to hyperparameters and suggests that careful hyperparameter search is necessary to find the proper value of $\\\\alpha$ for a new problem. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with hyperparameter sensitivity and the need for careful search, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is sensitive to hyperparameters and suggests that careful hyperparameter search is necessary to find the proper value of $\\\\alpha$ for a new problem. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the method, noting its sensitivity to hyperparameters and suggesting that careful hyperparameter search is necessary to find the proper value of $\\\\alpha$ for a new problem. This feedback is somewhat helpful as it points out a potential limitation of the method that the authors may need to address. However, the comment lacks specific guidance on how to conduct the hyperparameter search or what specific aspects of the method are sensitive to hyperparameters. While it highlights an area for improvement, it does not provide detailed instructions or examples to help the authors address the issue effectively. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies issues with Figure 3, including the unclear workflow and captions, as well as the confusing representation of communication modes on the left side. This provides clear and direct guidance on what needs to be improved, namely the clarity and comprehensibility of the figure. The authors are given specific actions to take, such as revising the captions and the representation of communication modes, to enhance the figure\\'s understandability. The feedback is concrete and provides concrete steps for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the unclear workflow and captions and the confusing representation of communication modes on the left side. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, as well as the representation of communication modes on the left side. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks specific references or examples to clarify the issues, making it difficult for the authors to address the feedback effectively. Therefore, the claim is considered borderline verifiable, as it provides some indication of the problem but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific issues with Figure 3, noting that the workflow and captions are unclear and the representation of communication modes on the left side is confusing. This feedback is actionable as it provides the authors with a clear understanding of what needs to be improved in the figure, namely the clarity and comprehensibility of the captions and the representation of communication modes. By addressing these issues, the authors can enhance the figure\\'s utility and accessibility to readers. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of how similar figures have been effectively communicated. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the term \"learned [MASK] embedding\" is unclear in the SSL pre-training stage of the proposed method. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this term or what specific actions they should take to address this issue. The comment lacks actionable details, such as recommending a definition or clarification of the term, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"SSL pre-training stage\" of the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term \"learned [MASK] embedding,\" which is unclear in the context of SSL pre-training. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"learned [MASK] embedding\" is unclear in the SSL pre-training stage of the proposed method. However, it does not provide any supporting evidence, reasoning, or examples to explain why this term is unclear or how it could be clarified. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary justification to support the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the term \"learned [MASK] embedding\" in the SSL pre-training stage of the proposed method. This is a clear and actionable point that can help the authors clarify their terminology and improve the clarity of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the term or offered examples of how it might be defined or explained. Overall, the comment is somewhat helpful as it points out a specific area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the reported results are partially derivative, as they extend to hyper-networks results that have already been presented for standard networks in the literature. However, it does not provide specific guidance on how the authors should address this issue or what changes they should make to improve the originality of their work. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the reported results are partially derivative, as they extend to hyper-networks results that have already been presented for standard networks in the literature. However, it does not specify which part of the paper this issue pertains to, such as specific sections, tables, or figures. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in identifying the issue of derivative results, but without clear grounding, it lacks full specificity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the reported results are partially derivative, as they extend to hyper-networks results that have already been presented for standard networks in the literature. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the originality of the reported results, suggesting that they are partially derivative as they extend to hyper-networks results that have already been presented for standard networks in the literature. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or improve the originality of their work. Without detailed suggestions or examples, the authors are left without a clear path forward, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The comment explicitly states that Figure 3 is difficult to read, providing a clear action for the authors to take. However, it does not specify what aspects of the figure are challenging to read or how the authors might improve the figure to make it more readable. While the action is explicit, the lack of concrete details on how to address the issue makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure, stating that it is difficult to read anything on the figure. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment claims that \"Figure 3 is very hard to read anything on the figure.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with Figure 3, stating that it is difficult to read anything on the figure. This feedback is clear and actionable, as it directs the authors to address a specific visual aspect of their work that may impact the reader\\'s comprehension. However, the comment could be more helpful if it provided suggestions on how to improve the figure\\'s readability, such as recommending font size, color contrast, or layout changes. Despite this, the comment still offers valuable insight into a potential weakness in the paper, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about whether the GAT is trained with the whole model and suggests that the text needs to be reviewed by an English native speaker to improve clarity. While the comment implies that the authors should review the text for clarity, it does not provide specific guidance on how to achieve this or what aspects of the text need to be revised. The action is implicit and somewhat vague, as the authors can infer that they need to review the text but may not be entirely sure of the exact changes required. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"245,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the training of the GAT and suggests that the text needs to be reviewed for clarity. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question and a suggestion for improvement. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the training of the GAT with the whole model, which is a relevant point for clarity. It also suggests that the text needs to be reviewed by an English native speaker to improve clarity. While the comment identifies a potential issue with the clarity of the text, it lacks specific guidance on how to address these concerns. The authors are given a general direction to improve the clarity but are not provided with detailed suggestions or examples of what specific changes might be needed. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not offer actionable steps for the authors to take.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and questions the justification behind using an SGD learning rate of ~0.1. While the comment provides a specific action to take regarding the parameter `lambda`, it does not offer guidance on how to address the issue with the SGD learning rate or what the justification should be. The action is explicit but lacks concrete details on how to implement the change or justify the learning rate. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda` and the use of an SGD learning rate of ~0.1. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes two claims: (1) replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and (2) questioning the justification behind using an SGD learning rate of ~0.1. The first claim is somewhat verifiable as it suggests a change in the mathematical expression but lacks detailed explanation or justification for the proposed change. The second claim is also somewhat verifiable as it questions the justification behind the learning rate but does not provide specific reasoning or examples to support the claim. Overall, the review point is somewhat verifiable, as it provides some basis for the claims but lacks detailed evidence or references to fully substantiate them.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper, such as the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda` and the use of an SGD learning rate of ~0.1. It points out that the justification for these choices is unclear, which is a valuable observation that can help the authors improve their draft. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered alternative justifications for the changes. While it highlights areas for improvement, the feedback is somewhat limited in its guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly encourages the authors to conduct error analysis and provide detailed explanations of the model's performance under different scenarios. This guidance is clear and specific, giving the authors a direct action to take. The comment also highlights the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. Therefore, the action is explicit and concrete, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the importance of error analysis and its role in evaluating model performance and identifying potential issues. It also encourages the authors to conduct error analysis and provide detailed explanations of the model\\'s performance under different scenarios. This provides clear guidance on what needs to be addressed, making the comment fully grounded. The comment is specific because it details the importance of error analysis and its role in guiding subsequent improvements and expansions of the ERC research. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\\'s performance under different scenarios. This claim is somewhat verifiable as it logically supports the importance of error analysis in the context of model evaluation and improvement. However, the comment lacks specific examples or references to substantiate the claim fully. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It highlights the importance of error analysis in evaluating model performance and identifying potential issues, and encourages the authors to conduct such analysis and provide detailed explanations of the model\\'s performance under different scenarios. This feedback is valuable as it guides the authors on how to enhance their draft by incorporating error analysis, which can aid in guiding subsequent improvements and expansions of the ERC research. However, the comment could be more helpful if it included specific examples or suggestions on how to conduct the error analysis or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pre-trained model on synthetic data. While the comment provides a clear direction for the authors to consider, it does not explicitly instruct them to perform these analyses or discussions. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pre-trained model on synthetic data. However, the comment does not specify which part of the paper should include these discussions, making it weakly grounded. The suggestion to analyze the domain gap and discuss the gap between datasets is specific, as it provides clear guidance on what aspects to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pre-trained model on synthetic data. However, the comment lacks specific examples or references to support the claim about the domain gap or the value of the approach. The suggestion is somewhat verifiable, as it provides a logical basis for the claim but requires more detailed evidence or examples to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to analyze the domain gap and discuss the gap between datasets. It highlights the importance of understanding the impact of domain differences on the adaptation process and the potential value of the approach if it can finetune a pre-trained model on synthetic data. This feedback is specific and offers a direction for the authors to enhance their analysis and discussion sections. However, the comment could be more helpful if it provided examples or references to similar studies that have addressed these issues, which would further empower the authors to develop a more comprehensive analysis. Overall, the comment is mostly helpful as it offers valuable guidance for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that at least one NCE-based method should be included for comparison. It provides a specific reference to a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This guidance is clear and concrete, as it specifies the exact action the authors need to take by including a specific method for comparison. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including at least one NCE-based method for comparison, referencing a specific study [1] that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. However, it does not specify which part of the paper should include this comparison or which section would benefit from it. While the authors can infer that it relates to the methodology or results sections, the comment lacks full grounding as it does not explicitly mention the sections. The suggestion is specific, as it clearly identifies the need for a comparison with NCE-based methods. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that at least one NCE-based method should be included for comparison. It references a specific study [1] that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This reference provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how NCE-based methods could enhance the comparison. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that at least one NCE-based method should be included for comparison. It references a specific study [1] that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This feedback is somewhat helpful as it provides a clear direction for the authors to consider adding a relevant comparison. However, the comment could be more helpful if it explained why this comparison is important or how it would enhance the paper\\'s contribution. While it identifies a potential area for improvement, the authors are left to determine the exact impact and relevance of including an NCE-based method. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiment section could be improved by conducting significance tests on the human evaluation results and comparing the proposed method with recent LLMs. While the comment provides a clear direction for improvement, it does not specify which specific tests should be conducted or how to conduct them. Additionally, it does not mention which recent LLMs should be compared. While the action is explicit, the lack of concrete details on how to implement the suggestions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the experiment section, specifically recommending the use of significance tests on human evaluation results and comparing the proposed method with recent LLMs. However, it does not specify which part of the experiment section needs improvement or which specific LLMs should be compared. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting improvements, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiment section could be improved by conducting significance tests on human evaluation results and comparing the proposed method with recent LLMs. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that these changes would significantly enhance the experiment section. The absence of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and implement the suggested improvements.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the experiment section, specifically suggesting the use of significance tests on human evaluation results and comparing the proposed method with recent LLMs. This feedback is clear and actionable, as it provides specific suggestions for enhancing the experiment section. However, the comment could be more helpful if it included examples of which tests should be conducted or which LLMs should be compared. Despite this, the feedback is mostly helpful as it directs the authors to specific areas for improvement, which can significantly enhance the quality of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to discuss a previous work on joint error for UDA, specifically mentioning \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML2019. It also suggests that the authors should illustrate the relationship between this work and their proposed method, and explain why their method is better. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what steps to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the joint error for UDA and references a specific work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML2019. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is the relationship between the proposed method and the previous work, and why the proposed method is better. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' claim about the lack of research on joint error for UDA is incorrect, as it has already been studied in a previous work. The reviewer supports this claim by referencing \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML2019, which provides a specific example of a previous study on this topic. This reference provides a clear and direct justification for the claim, making it fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific claim made by the authors regarding the lack of research on joint error for UDA. It challenges this claim by pointing out that the problem has already been studied in previous works, specifically mentioning \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML2019. The comment suggests that the authors should discuss this previous work and illustrate the relationship between it and their proposed method, as well as explain why their method is better. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft by addressing the critique and demonstrating the novelty of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods, noting that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer suggests that the superiority of the proposed method may be due to the larger-scale datasets. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it. The authors can infer that they should consider the impact of dataset size on performance and potentially adjust the comparison with SOTA methods. However, the comment lacks concrete suggestions on how to conduct this adjustment or what specific aspects of the comparison should be revised. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison with state-of-the-art (SOTA) methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison with state-of-the-art (SOTA) methods may be unfair due to the difference in dataset size. The reviewer provides a logical reasoning by pointing out that the superiority of the proposed method may be due to the larger-scale datasets. However, the comment lacks specific examples or references to support the claim that the dataset size significantly impacts accuracy. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of the proposed method with state-of-the-art (SOTA) methods. It points out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This observation highlights a potential bias in the comparison, as the larger dataset may contribute to the superiority of the proposed method. The comment suggests that the superiority may be due to the larger-scale datasets, which is a valuable insight for the authors to consider when evaluating their method. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending a fairer comparison method or discussing the implications of dataset size on performance. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a logical basis for the concern.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific suggestion for the authors to use powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and compare the efficacy of the transfer parts instead of using the simplest n-gram features. This is an explicit and concrete action that the authors can take to improve their draft. The comment clearly specifies what needs to be done and how it can be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of using the simplest n-gram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular approach to address the domain adaptation problem, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of using the simplest n-gram features. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, based on the common use of these models in domain adaptation tasks in the NLP field. However, the comment lacks specific examples or references to support the claim fully, such as studies or experiments that demonstrate the effectiveness of these models in domain adaptation. This makes the claim somewhat verifiable, as it provides a reasonable basis but could be strengthened with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for the authors to use powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and compare the efficacy of the transfer parts instead of using the simplest n-gram features. This feedback is clear and constructive, as it offers a concrete way to improve the methodology and enhance the results. By following this advice, the authors can potentially improve the robustness and generalizability of their approach. However, the comment could be more helpful if it included additional context or examples to further explain the rationale behind the suggestion. Overall, the comment is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the proposed method, noting that it comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters. The comment suggests that the current version of the ablation study does not provide definitive answers to these questions. While the comment identifies an area for improvement, it does not explicitly instruct the authors on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed analysis or clarification in their ablation study. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed method, which comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters. The comment suggests that the current version of the ablation study does not provide definitive answers to these questions. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology and results sections where the method and its performance are discussed. The comment is specific in its critique of the ablation study, but it lacks grounding as it does not point to a specific part of the paper where the issue is discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method comprises several complicated modules and has more parameters than the baselines, which raises questions about whether the main performance gain is due to a specific module or the increased number of parameters. The reviewer suggests that the current version of the ablation study does not provide definitive answers to these questions. However, the comment lacks specific examples or detailed reasoning to support the claim that the current ablation study is insufficient. While the reviewer highlights a potential issue, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the proposed method, noting that it comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters, and points out that the current version of the ablation study does not provide definitive answers to these questions. This feedback is somewhat helpful as it highlights an area where the authors could improve their analysis and provide more detailed explanations of the method's performance. However, the comment could be more helpful if it suggested specific ways to address the identified issues or provided examples of how other studies have addressed similar concerns. Overall, the comment provides some insight but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of explanation in the paper regarding the two quantities and their relationship to learning settings. It explicitly asks for more explanation, indicating that the authors need to clarify this aspect. However, the comment does not provide specific guidance on how to address this issue or what additional information should be included. While the action is clear\u2014to provide more explanation\u2014the lack of concrete details on how to implement this makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l 196-7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of the two quantities and their relationship to learning settings. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the explanation provided for the two quantities and their relationship to learning settings. It suggests that more explanation is needed, but does not provide specific reasoning or examples to support this claim. The comment lacks detailed justification or references to substantiate the need for more explanation. As a result, the claim is somewhat verifiable, as it points out a potential issue but does not fully support it with evidence or reasoning. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks explanation, specifically regarding the two quantities and their relationship to learning settings. It highlights a gap in the paper that needs to be addressed, which is important for clarity and understanding. However, the comment does not provide detailed guidance or suggestions on how to improve the explanation or what specific aspects need to be clarified. While it points out an area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to discuss the sensitivity of any fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a clear and direct request, providing the authors with a specific action to take. The comment is specific in detailing what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to discuss the sensitivity of fixed tuning parameters in the model, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the strengths and weaknesses of these parameters. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is somewhat helpful as it prompts the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a relevant and important aspect to consider, as it could impact the robustness and generalizability of the model. However, the comment lacks specific guidance or examples on how to approach this discussion or what aspects to focus on. While it points out a potential area for improvement, it does not provide detailed suggestions or examples to help the authors fully understand and address the issue. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed framework should be tested with different policy gradient approaches and provides a specific question about the number of random seeds used for learning the policies (DDPO and IPPG). While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment results. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in its request for information about the random seeds used, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not provide any supporting evidence, reasoning, or references to justify why these changes would be beneficial or necessary. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting the inclusion of additional experiments. However, the comment lacks depth and does not provide specific guidance on how to implement these changes or what specific aspects of the framework would benefit from testing with different policy gradient approaches. While it points out a potential area for enhancement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from evaluating on more datasets and tasks to strengthen the results and conclusions. While it implies that the authors should expand their analysis, it does not provide specific guidance on which datasets or tasks to include or how to conduct the additional evaluations. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to enhance their analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from evaluating on more datasets and tasks to strengthen the results and conclusions. However, it does not specify which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting the need for additional datasets and tasks, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from evaluating on more datasets and tasks to strengthen the results and conclusions. However, it does not provide any specific reasoning or evidence to support why this would be beneficial or how it would impact the paper\\'s conclusions. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s evaluation, noting that it is based on only one dataset and one task. It suggests that expanding the analysis to more datasets and tasks would strengthen the results and conclusions. This feedback is somewhat helpful as it points out an area for improvement, but it lacks specific guidance on which datasets or tasks to consider or how to conduct the additional evaluations. While it highlights a potential enhancement, the comment could be more actionable with more detailed suggestions. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting them in the \"language of kernel interpolation/smoothing.\" However, it does not provide explicit instructions or concrete guidance on how to address this issue. The authors are left to infer that they should consider presenting their considerations in this context, but without specific details on how to do so, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting them in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to present the considerations in the language of kernel interpolation/smoothing, but without explicit grounding, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the applicability of the considerations in the paper to kernel (ridge) regression. It suggests that these considerations should also be applicable to kernel (ridge) regression and proposes presenting them in the \"language of kernel interpolation/smoothing.\" However, the comment lacks specific examples or references to support the claim that these considerations are relevant to kernel (ridge) regression. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression, suggesting that these considerations should also be applicable to kernel (ridge) regression. It proposes presenting them in the \"language of kernel interpolation/smoothing.\" While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to present these considerations in the context of kernel (ridge) regression. The feedback is somewhat helpful as it points out a potential gap in the paper, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add supportive references for the claims made in the paper, specifically mentioning lines 55-64. It provides a specific example of where the authors need to include references, which is helpful. The comment also highlights that many of the factors mentioned have been discussed in existing studies, which adds a level of clarity to the action. However, the comment could be more concrete by suggesting specific references or studies that the authors should consider. Overall, the action is explicit and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 55-64,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to add supportive references for the claims made in the paper. The comment provides a detailed example of the factors that have been discussed in existing studies, which helps the authors understand the need for referencing. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some claims may be inspired from existing studies and suggests that it is critical to add supportive references. The reviewer provides a specific example by referencing lines 55-64, where the authors discuss factors affecting the performance of chain-of-thought prompting. The reviewer mentions that many of these factors have been discussed in existing studies, which supports the claim that references are needed. However, the comment could be strengthened by providing specific references to these studies or explaining how the current claims differ from existing literature. As it stands, the claim is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of supportive references for claims made in the manuscript. It provides a specific example by referencing lines 55-64, where the authors discuss factors affecting the performance of chain-of-thought prompting. The reviewer notes that many of these factors have been discussed in existing studies, which highlights the need for proper citation. This feedback is clear and actionable, as it directs the authors to include relevant references to support their claims. However, it could be more helpful if it suggested specific studies or references to consider, which would enhance the guidance for the authors. Overall, the comment is mostly helpful as it effectively points out a gap in the paper that needs to be addressed.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the tasks are somewhat standard and implies that the authors could have included more unique tasks to showcase the diversity of images/plots. It provides an example of interleaved image-text tasks, such as question answering from images, as a potential area for improvement. While the comment implies that the authors should consider these tasks, it does not explicitly instruct them to do so or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should consider these tasks but may not be entirely sure how to integrate them into their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the tasks are somewhat standard, such as figure captioning and matching figures/sub-figures to appropriate captions. It also mentions the potential for unique tasks that could showcase the diversity of images/plots, such as interleaved image-text tasks like question answering from images. However, the comment does not specify which part of the paper these tasks should be added to or how they would be integrated. While the authors might have an idea of where these tasks could fit, the comment lacks explicit grounding. It is specific about the need for unique tasks but does not provide detailed guidance on how to implement them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the tasks are somewhat standard, such as figure captioning and matching figures/sub-figures to appropriate captions. It also implies that the tasks could be more unique and diverse, such as interleaved image-text tasks like question answering from images. The comment provides a logical reasoning for why the tasks could be more diverse and suggests specific examples of tasks that could be considered. However, it lacks specific examples or references to support the claim that these tasks would be beneficial or necessary. Therefore, the comment is somewhat verifiable, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the tasks are somewhat standard, such as figure captioning and matching figures/sub-figures to appropriate captions. It implies that the authors could have included more unique tasks to showcase the diversity of images/plots, such as interleaved image-text tasks like question answering from images. This feedback is somewhat helpful as it points out a potential area for improvement by suggesting the inclusion of more diverse tasks. However, the comment lacks specific guidance on how to implement these tasks or what specific aspects of the dataset could be leveraged for this purpose. While it provides a general direction, it does not offer detailed steps or examples to help the authors fully understand and address the issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the relevance of the framework to non-convex losses and non-norm type defenses, and it seeks clarification on the implications of the non-vanishing duality gap and difficulty of maximization over non-norm type constraints. It also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the questions themselves do not provide explicit instructions, they imply that the authors should address these issues in their paper. The action is implicit but concrete, as it guides the authors to provide clarification or analysis regarding the framework's applicability and potential limitations. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises questions about the relevance of the framework to non-convex losses and non-norm type defenses, and it specifically references the \"non-vanishing duality gap\" and the difficulty of maximization over non-norm type constraints. It also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the theoretical aspects of the framework or its applicability to non-convex losses. The comment is specific in its inquiry about the relevance and potential limitations of the framework. Therefore, this comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the relevance of the framework to non-convex losses and non-norm type defenses, and it seeks clarification on the implications of the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints. The reviewer also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the questions themselves do not present claims, they imply that the authors should provide more detailed explanations or justifications regarding the framework's applicability and limitations. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the questions. Therefore, the comment is somewhat verifiable, as it provides a basis for the authors to address the concerns but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the relevance and applicability of the framework to non-convex losses and non-norm type defenses. It seeks clarification on the implications of the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints, as well as the potential use of statistics, such as covariance, to design better defenses in binary classification. While the questions themselves do not provide specific guidance on how to address these issues, they prompt the authors to consider the limitations and potential applications of their framework. This feedback is somewhat helpful as it encourages the authors to explore and clarify the implications of their work, but it could be more beneficial with additional suggestions or examples on how to address these questions. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. While the comment implies that the authors should consider this approach, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is clear but lacks concrete details on how to execute the experiment, such as which specific features to select or how to evaluate the results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests an experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. However, it does not provide any supporting evidence, reasoning, or references to justify why this approach would be beneficial or how it would impact the results. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This is a clear and actionable suggestion that could potentially improve the paper by providing additional insights into the performance of the baselines. However, the comment lacks depth and does not explain why this approach might be beneficial or how it could be implemented effectively. While it provides a direction for further exploration, it could be more helpful with additional guidance or rationale. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several areas where the paper lacks detail, specifically regarding the techniques used and the reproducibility of the results. It highlights the importance of understanding the sparsification process, the landmark generation, and the number of landmarks used. Additionally, it questions how to achieve shape invariance. While the comment provides a clear list of specific questions that need to be addressed, it does not offer explicit guidance on how to implement these improvements. The authors are left with a clear understanding of what needs to be added but may need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the techniques and the reproducibility of the results. It provides detailed questions about the sparsification process, landmark generation, and number of landmarks used, as well as how to achieve shape invariance. This level of detail allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be clarified or added to the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the lack of detail in the paper regarding the techniques used and the reproducibility of the results. It highlights specific areas that need clarification, such as the sparsification process, landmark generation, and number of landmarks used. The reviewer also questions how to achieve shape invariance. While the comment identifies specific issues, it does not provide detailed reasoning or examples to support the claim that these areas are crucial for reproducibility. This makes the claim somewhat verifiable, as the authors may need to infer the importance of these details themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas where the paper lacks detail, specifically regarding the techniques used and the reproducibility of the results. It highlights the importance of understanding the sparsification process, the landmark generation, and the number of landmarks used. Additionally, it questions how to achieve shape invariance, among other aspects. This feedback is clear and actionable, as it provides specific questions that the authors need to address to improve the clarity and reproducibility of their work. By addressing these points, the authors can significantly enhance the comprehensibility and robustness of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the utility-based approach used in FIITED, specifically the risk of biases due to temporary high utility scores for recent chunks. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to mitigate the risk of premature evictions. The comment lacks concrete details or suggestions on how to improve the approach or validate its effectiveness. As a result, the authors are left without clear direction on how to address the concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the utility-based approach used in FIITED, specifically the potential for biases due to temporary high utility scores for recent chunks. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential bias issue and the consequences of basing eviction decisions solely on utility scores. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that basing eviction decisions purely on utility scores might introduce biases, specifically mentioning the risk of premature evictions due to temporary high utility for recent chunks. While the comment highlights a potential issue, it lacks specific examples or references to substantiate the claim. The reasoning is logical but could be strengthened with additional evidence or detailed explanation. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but requires more detailed support to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the utility-based approach used in FIITED, specifically the risk of biases due to temporary high utility scores for recent chunks. This is a valuable observation that could lead to premature evictions of other valuable chunks. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the risk of biases. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the performance of the different parts of the framework and their contribution to the final result. It suggests that the paper lacks quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to include quantitative experiments and comparisons, as well as detailed explanations of the algorithms, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not offer specific steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the methodology and the experimental section, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of quantitative experiments and comparisons with other algorithms, as well as the need for more detailed explanations of the presented ones. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks clarity regarding the performance of the different parts of the framework and their contribution to the final result. It suggests that the lack of quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones, makes it unclear what the exact performance of the framework and its individual parts are compared to other solutions. The comment provides a logical reasoning for the need for more detailed information, but it does not include specific examples or references to support the claim. This makes the claim somewhat verifiable, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of clarity regarding the performance of the different parts of the framework and their contribution to the final result. It points out that while the framework yields promising visual stimuli results, it lacks quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones. This feedback is valuable as it highlights a critical area for improvement in the paper, specifically the need for more comprehensive and detailed experimental results. However, the comment could be more helpful if it provided specific suggestions on how to address these gaps, such as which experiments to conduct or how to present the results more effectively. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they should consider to improve the clarity of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where this claim is discussed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the model\\'s ability to generate novel knowledge or testable hypotheses are unclear. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of the model need clarification or how to address this concern. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a simplified version of Theorem 2 could be presented for the general audience, similar to Theorem 1. This implies that the authors should consider simplifying the content of Theorem 2 to make it more accessible to a broader audience. However, the comment does not provide specific guidance on how to achieve this simplification or what aspects of Theorem 2 are particularly challenging for the general reader. While the action is implied, it lacks concrete details on how to implement the suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests simplifying Theorem 2 to make it more accessible to the general audience, similar to Theorem 1. However, it does not specify which part of the paper contains Theorem 2 or where the simplified version should be placed. The authors can infer that it relates to the section containing the theorem, but this inference is not direct. The comment is specific in suggesting a potential simplification but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests simplifying Theorem 2 to make it more accessible to the general audience, similar to Theorem 1. However, it does not provide any supporting evidence, reasoning, or examples to justify why this simplification is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests simplifying Theorem 2 to make it more accessible to the general audience, similar to Theorem 1. This feedback is somewhat helpful as it identifies a potential area for improvement in making the paper more understandable and engaging for a broader audience. However, the comment lacks specific guidance on how to achieve this simplification or what aspects of Theorem 2 are particularly challenging for the general reader. While it points out a potential issue, it does not provide detailed suggestions or examples to help the authors effectively address the problem. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of their model. While the comment implies that the authors should conduct additional experiments, it does not provide explicit instructions on how to implement this suggestion or what specific aspects of the model should be tested at this resolution. The action is clear but lacks concrete details on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a potential improvement by testing the model at a larger resolution, but without explicit grounding, it is difficult for the authors to pinpoint the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or how it would impact the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. This is a valuable suggestion that could provide insights into how the model would perform with different image sizes. However, the comment lacks depth and does not explain why this change would be beneficial or how it might impact the results. Additionally, it does not offer specific guidance on how to implement this suggestion or what aspects of the model should be tested at this resolution. While the suggestion is actionable, the lack of detailed feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the keypoint mask averaged feature vector, specifically asking whether it is calculated by multiplying each feature map element-wise by H_psi. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the calculation of the keypoint mask averaged feature vector, providing clear guidance on what needs to be clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the calculation of the keypoint mask averaged feature vector. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the calculation of the keypoint mask averaged feature vector, specifically asking whether it is calculated by multiplying each feature map element-wise by H_psi. While this question may be relevant to the authors, it does not provide any guidance or suggestions for improvement. It lacks actionable feedback or context that would help the authors understand how to address the issue or improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. While the comment implies that the authors should add this information, it does not explicitly instruct them to do so or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should include this detail. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section, figure, or table. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting what needs to be added, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. However, it does not provide any supporting evidence, reasoning, or examples to justify why this information is important or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. While it identifies a potential area for clarification, it lacks specificity and does not provide guidance on how to effectively integrate this information into the paper. The comment is somewhat helpful as it points out a potential gap in the explanation, but it does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it notes that this paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. While the comment implies that the authors should focus on the collaborative ranking results to derive the lower bound results, it does not provide explicit instructions or concrete steps on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to apply the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of proving lower bounds for round complexity in the context of batched ranking problems. It suggests that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. However, the comment does not specify which part of the paper discusses the lower bound results or the collaborative ranking results, making it weakly grounded. The comment is specific in detailing what the authors need to address, namely, the derivation of lower bound results from collaborative ranking results. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it suggests that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. The comment provides a logical reasoning for why the lower bound results are easier to derive, but it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as it provides a reasonable explanation but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it suggests that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. This feedback is somewhat helpful as it points out a potential area for improvement by suggesting that the authors should focus on the collaborative ranking results to derive the lower bound results. However, the comment could be more helpful if it provided specific guidance on how to effectively utilize the collaborative ranking results or offered examples of how this approach has been successfully applied in similar contexts. Overall, the comment provides some insight but lacks depth and actionable suggestions, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the prompting technique used in the study is basic and fails to leverage the full potentials of LLMs. It recommends using carefully curated prompts to generate better systematic reviews. While the comment implies that the authors should consider using more advanced prompting techniques, it does not provide specific guidance on how to implement this suggestion or what specific prompts might be effective. The action is implicit and somewhat vague, as the authors need to infer the need for more advanced prompting techniques and how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the prompting technique used in the study, suggesting that it is basic and fails to leverage the full potentials of LLMs. It recommends using carefully curated prompts to generate better systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique, making it weakly grounded. The suggestion to use carefully curated prompts is specific, but without clear grounding, the authors may struggle to identify the exact section that needs improvement. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the prompting technique used in the study is basic and fails to leverage the full potentials of LLMs. It suggests that using carefully curated prompts could lead to better results in generating systematic reviews. While the comment provides a logical reasoning for the need to improve the prompting technique, it lacks specific examples or references to support the claim that carefully curated prompts would lead to better results. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the study, namely the basic nature of the prompting technique used and its failure to leverage the full potentials of LLMs. It suggests that using carefully curated prompts could lead to better results in generating systematic reviews. While the comment highlights an important area for improvement, it lacks specific guidance on how to implement this suggestion or what criteria should be used to curate prompts. This limits the comment\\'s helpfulness, as it provides a general direction but does not offer detailed steps for the authors to follow. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed video storyboarding approach lacks novelty, as it relies heavily on frame-wise SDSA, which is similar to the approach used in ConsiStory. The reviewer notes that the only notable difference is the mask source, which uses CLIPseg and OTSU segmentation instead of cross-attention. While the comment identifies a specific area of concern, it does not provide explicit guidance on how the authors should address this issue or improve the novelty of their approach. The action is implicit and somewhat vague, as the authors can infer that they need to explore ways to enhance the innovation of their method. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed video storyboarding approach\" and \"frame-wise SDSA,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty in the approach, noting that it relies heavily on frame-wise SDSA and that the only notable difference is the mask source. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed video storyboarding approach lacks novelty, as it relies heavily on frame-wise SDSA, which is similar to the approach used in ConsiStory. The reviewer notes that the only notable difference is the mask source, which uses CLIPseg and OTSU segmentation rather than cross-attention. This claim is somewhat verifiable as it provides a specific comparison to ConsiStory, which is a well-known approach, and highlights the difference in the mask source. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the novelty of the proposed video storyboarding approach, noting that it relies heavily on frame-wise SDSA, which is similar to the approach used in ConsiStory. The reviewer highlights the only notable difference as the mask source, which uses CLIPseg and OTSU segmentation rather than cross-attention. This feedback is somewhat helpful as it points out a specific area where the paper could be improved by exploring more innovative approaches or techniques. However, the comment lacks detailed suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. To be more helpful, the comment could provide specific suggestions or examples of alternative methods that could be considered. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the zero-shot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability. The reviewer also points out that the manipulation scenario might be challenging due to the complexity of the tasks. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the transferability and complexity of the tasks but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific questions about the zero-shot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability and points out that the manipulation scenario might be challenging due to the complexity of the tasks. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified regarding the transferability and complexity of the tasks. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the zero-shot nature of the work and the transferability of the policy. The reviewer suggests that the difficulty of the source and target tasks might limit the transferability, and provides a logical reasoning by comparing the Walker-run task to the walker-walk task. The reviewer also provides a specific example of the manipulation scenario, which could be challenging due to the complexity of the tasks. However, the comment lacks specific references or detailed evidence to fully substantiate the claim about the difficulty of the tasks or the transferability of the policy. While the reasoning is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the zero-shot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability, and provides a logical reasoning by comparing the Walker-run task to the walker-walk task. The reviewer also offers a specific example of the manipulation scenario, which could be challenging due to the complexity of the tasks. However, the comment could be more helpful if it provided suggestions on how the authors might address these issues or clarify the transferability in the paper. While it identifies areas for improvement, the feedback lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the rigor of the evaluation, given the limited number of datasets for each task (5, 6, and 4). It suggests that having such a small number might not be sufficient, particularly if some datasets are too large for all algorithms to be used. The reviewer provides a specific suggestion to consider using more datasets to ensure rigor. However, the comment does not provide explicit guidance on how to select additional datasets or which datasets to prioritize. While the action is implied, it lacks concrete details on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the rigor of the evaluation, given the limited number of datasets for each task. It suggests that having 5, 6, and 4 datasets for the tasks, respectively, might not be enough, particularly if some datasets are too large for all algorithms to be used. The comment is specific in its critique of the dataset selection and provides a suggestion for additional datasets to ensure rigor. However, it does not explicitly mention which part of the paper discusses the datasets, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not direct. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the rigor of the evaluation, given the limited number of datasets for each task. It suggests that having 5, 6, and 4 datasets for the tasks, respectively, might not be enough, particularly if some datasets are too large for all algorithms to be used. The reviewer provides a logical reasoning by pointing out that having a limited number of datasets could impact the evaluation's thoroughness. However, the comment lacks specific examples or references to support the claim that some datasets are too large for all algorithms. This makes the claim somewhat verifiable, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the rigor of the evaluation, given the limited number of datasets for each task. It suggests that having 5, 6, and 4 datasets for the tasks, respectively, might not be enough, particularly if some datasets are too large for all algorithms to be used. The comment provides a specific suggestion to consider using more datasets to ensure rigor. However, it lacks depth and does not offer detailed guidance on how to select additional datasets or which datasets to prioritize. While it points out a potential weakness, the feedback could be more helpful with additional suggestions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the method addresses sparse reward problems and questions whether it can solve sparse-reward tasks as well as other methods (Qmix). However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, or suggesting ways to improve the method's performance in sparse-reward scenarios. As a result, the authors are left without clear direction on how to address the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the method and the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the method addresses sparse reward problems and whether it can solve sparse-reward tasks as well as other methods (Qmix). The comment provides a clear direction for improvement by asking for clarification on the method's performance in sparse-reward scenarios. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the method\\'s ability to address sparse reward problems and suggests that the experiments do not support this claim. The reviewer provides a logical reasoning by comparing the proposed method to dense reward signals and questioning whether other methods (Qmix) can solve sparse-reward tasks as well. However, the comment lacks specific examples or references to support the claim that the method does not address sparse reward problems effectively. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the method\\'s ability to address sparse reward problems effectively, based on the experiments presented. It suggests that the proposed method requires sub-task-specific rewards, which is similar to dense reward signals, and questions whether other methods (Qmix) can solve sparse-reward tasks as well. The comment also includes minor comments that suggest potential areas for improvement. However, the feedback lacks specific suggestions or guidance on how the authors might address the issue or improve their method. While it identifies a potential weakness, the comment does not provide actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the curated AH36M dataset is used for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide this clarification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"curated AH36M dataset\" and the need for clarification on whether it is used for training. It also raises questions about whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about whether the curated AH36M dataset is used for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the fairness of the comparison. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the use of the curated AH36M dataset for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. This is a clear and actionable point that could help the authors ensure the fairness and transparency of their experimental setup. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending the authors clarify their methodology or provide more detailed information on data access. Overall, the comment is mostly helpful as it identifies a critical area for improvement but lacks depth in its guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the lack of clarity in the motivation for using an adversarial network, the unfairness of the experimental results, and the comparison with a larger model. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The comment lacks concrete details or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses several issues related to the motivation, experimental results, and comparison of the proposed model. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment does provide some specificity by mentioning the addition of CAT and GAN, which could be used to guide the authors in identifying the relevant sections. Overall, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in detailing the issues. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation for using an adversarial network is unclear and that the experimental results are unfair. It also suggests that the proposed model is equipped with newly-added CAT and GAN, which is a larger model than others. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references or detailed explanations to substantiate the claims, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the lack of clarity in the motivation for using an adversarial network, the unfairness of the experimental results, and the comparison with a larger model. It also points out the addition of CAT and GAN, which could be considered a significant change. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the clarity of their motivation or experimental results. While it highlights areas for improvement, the feedback lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the sample-by-sample optimization process. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting specific methods for tuning hyperparameters or discussing potential strategies for managing variation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of hyperparameters that need to be tuned, specifically mentioning step size, N, and $\\\\delta t$. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential variation in optimal hyperparameters due to the sample-by-sample optimization process. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the sample-by-sample optimization process. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the optimization process, specifically the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the sample-by-sample basis. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or mitigate the potential variation. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it highlights a concern but lacks depth and specificity in its feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the limited comparison of performance with only a few methods and the lack of consistent superiority of the proposed method over others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. The reviewer is open to changing their rating based on feedback from the authors and comments from other reviewers. While the comment implies that the authors should provide additional analysis, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific analysis required. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the issue of limited comparison of performance with only a few methods and the lack of consistent superiority of the proposed method over others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion for additional analysis, but without clear grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. The comment provides a logical reasoning by pointing out the limited comparison and the need for analysis to address the issue. However, it lacks specific examples or references to support the claim that the results violate the motivation. This makes the claim somewhat verifiable, as it provides a reasonable basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, namely the limited comparison of performance with only a few methods and the lack of consistent superiority of the proposed method over others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. This feedback is clear and actionable, as it points out a specific area where the authors need to improve their work. However, the comment could be more helpful if it provided examples of the analysis that should be conducted or suggested specific methods for evaluating the performance. Despite this, the feedback is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). It explicitly states that the current experimental comparison only compares ELF (the author\\'s method) with the baseline without MVF, which does not prove that the schema searched by ELF is better than the schema in MVF. This feedback provides a clear and concrete action for the authors to take, which is to include a comparison with the image classification result of MVF to demonstrate the superiority of their method. The comment is highly actionable as it directly instructs the authors on how to enhance their experimental demonstration.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental demonstration of the contribution points\" and the \"experimental comparison between ELF (the author\\'s method) and the baseline without Mid Vision Feedback (MVF),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing: a comparison with the image classification result of Mid Vision Feedback (MVF) to prove the superiority of the schema searched by ELF. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically mentioning the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). The comment highlights a gap in the experimental setup, noting that the current comparison only compares ELF (the author\\'s method) with the baseline without MVF. This critique is somewhat verifiable as it points out a specific issue with the experimental setup, but it could be strengthened by providing more detailed reasoning or examples of how the comparison with MVF could enhance the demonstration of the contribution points. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental demonstration of the paper\\'s contribution points. It points out that the current experimental comparison only compares ELF (the author\\'s method) with the baseline without Mid Vision Feedback (MVF), but not with the image classification result of Mid Vision Feedback (MVF). This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their experimental demonstration by including a comparison with the image classification result of MVF. By addressing this feedback, the authors can better substantiate their claims and provide a more robust demonstration of the contribution points. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should use different notation to avoid confusion between the dimensionality of points and the dilation factor. This is a clear and direct action for the authors to take, as it provides a specific recommendation for improving the clarity of their paper. The comment is concrete, as it specifies the need for different notation, and it is also somewhat vague in that it does not provide detailed guidance on what specific notation should be used. Overall, the comment is highly actionable, as it clearly instructs the authors on how to improve the clarity of their paper.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of \"D\" to represent both dimensionality and dilation factor, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of different notation to avoid confusion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the use of \"D\" to represent both dimensionality and dilation factor can cause confusion. However, it does not provide any supporting evidence or examples to substantiate this claim. The comment lacks specific reasoning or references to justify why using different notation would be beneficial or how it would clarify the paper. As a result, the claim is unverifiable, as it does not provide sufficient evidence or reasoning to support the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of \"D\" to represent both dimensionality and dilation factor, suggesting that it can cause confusion. This is a clear and actionable suggestion that could improve the clarity and readability of the paper. However, the comment could be more helpful if it provided examples of alternative notations or explained why the current notation is problematic. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement, which can enhance the clarity and accessibility of their work. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the concept of \"state\" and questions the equivalence of \"elements\" to \"states\" or \"actions\" in a specific section of the paper. While the comment identifies an area that needs clarification, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to provide more elaboration on the concept of state and its relationship to elements or actions. The action is implicit and somewhat vague, as it lacks concrete steps on how to improve the clarity of the concept. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 186-line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the concept of \"state\" and its relationship to \"elements\" or \"actions.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the concept of \"state\" and its relationship to \"elements\" or \"actions.\" It suggests that more elaboration is needed to clarify this concept. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the concept is unclear. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a lack of clarity in the concept of \"state\" and its relationship to \"elements\" or \"actions.\" It questions the equivalence of these terms and suggests that more elaboration is needed to clarify the concept. This feedback is somewhat helpful as it points out a potential area of confusion that the authors should address to improve the clarity of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify the concept or examples of how it has been misinterpreted. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, it does not provide specific guidance on how the authors should address this issue or what aspects of the FRM should be elaborated upon. The comment implies that the authors should provide more details about the innovative aspects of their model, but it does not offer concrete steps or examples of what these details should include. As a result, the action is implicit and vague, making it difficult for the authors to know exactly how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, it does not specify which part of the paper discusses the FRM, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for more details on the innovative aspects of the FRM, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation. It suggests that the innovative aspects should be detailed, but it does not provide specific guidance on how the authors should address this issue or what aspects of the FRM should be elaborated upon. While the comment highlights a potential weakness, it lacks actionable advice or examples that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a specific reorganization of the sections, proposing to move the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. This provides a clear and concrete action for the authors to take, as it offers a specific way to restructure the sections to potentially improve clarity and coherence. The comment is explicit in its suggestion and provides a concrete implementation, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests a specific reorganization of these sections, proposing to move the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Sections 3 and 4 are redundant and proposes a specific reorganization to improve clarity. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the sections are redundant or how the suggested reorganization would improve clarity. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential redundancy in Sections 3 and 4, suggesting that reorganizing the sections could improve clarity. It provides a specific and actionable suggestion by proposing to move the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. This feedback is clear and offers a concrete way for the authors to enhance the organization and flow of their paper. However, the comment could be more helpful if it explained why the current organization is redundant or how the suggested reorganization would improve the overall structure. Despite this, the feedback is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment implies that these analyses are missing from the paper, it does not explicitly instruct the authors to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these analyses to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"strong empirical results\" of the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the potential contribution of finding out the reasons behind the empirical results through theoretical analyses or extensive experiments. However, the comment lacks specificity regarding what kind of theoretical analyses or experiments would be needed to address the issues raised. It suggests exploring the reasons behind the outperformance of simple greedy selection and deterministic MLP predictors, but does not provide detailed guidance on how to conduct these analyses or what specific aspects to focus on. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. The comment provides a logical reasoning that these analyses could be beneficial, but it lacks specific examples or references to support the claim that these analyses are missing in the paper. The suggestion is somewhat verifiable, as it provides a rationale for the need for additional analyses but does not fully substantiate the claim with concrete evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. This feedback is clear and actionable, as it points out a specific gap in the paper that could enhance its contribution and rigor. However, the comment could be more helpful if it provided examples of what kind of analyses or experiments would be beneficial or how they could be conducted. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for a citation regarding the k-max problem, which is a clear and direct action for the authors to take. The comment provides a specific request for additional information, ensuring that the authors know exactly what is expected of them. The action is concrete, as it specifies the need for a citation, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly asks for a citation regarding the k-max problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a citation regarding the k-max problem. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for a citation regarding the k-max problem. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual request for additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area where additional information or clarification is needed. By asking for a citation regarding the k-max problem, the reviewer prompts the authors to provide more context or references to support their claims. This feedback is actionable and can help the authors enhance the comprehensiveness and credibility of their work. However, the comment could be more helpful if it provided more detailed guidance on how to address the issue or suggested specific sources to consider. Overall, the comment is somewhat helpful as it directs the authors to a specific area for improvement but lacks depth and detailed suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. It specifically points out examples like Figure 1 and the deep-rag algorithm, which are mentioned in the appendix but not in the main sections. The comment suggests that the exact contributions need to be written more clearly in the Introduction and that the material supporting the main contributions should be included in the main sections. While the comment provides a clear action to take, it lacks specific guidance on how to address the issue, such as suggesting a particular section or paragraph where the contributions should be explained. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections, such as Figure 1 and the deep-rag algorithm, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the lack of clear explanation of the contributions in the Introduction and the placement of supporting material in the appendix. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. The reviewer provides specific examples, such as Figure 1 and the deep-rag algorithm, which are mentioned in the appendix but not in the main sections. This provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically the use of forward referencing where material is introduced without proper explanation and is later explained in later sections. It provides specific examples, such as Figure 1 and the deep-rag algorithm, which are mentioned in the appendix but not in the main sections. The comment suggests that the exact contributions need to be written more clearly in the Introduction and that the material supporting the main contributions should be included in the main sections. This feedback is clear and actionable, as it directs the authors to improve the clarity and organization of their paper. However, it could be more helpful if it provided suggestions on how to structure the paper or what specific information should be included in the main sections. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific analyses or methods to ensure privacy protection. As a result, the authors are left without a clear understanding of what steps to take to improve their draft in this area. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, namely the lack of analysis on the security (protection of privacy) of the proposed framework. However, it does not specify which part of the paper this issue pertains to, such as a particular section or subsection where the analysis should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue of security analysis, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a significant gap in the paper, noting that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. This is a critical oversight that could impact the overall robustness and trustworthiness of the work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as recommending particular analyses or methods to ensure privacy protection. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to explain what type of understanding is gained by looking at the PPP maps, which is a clear and direct action. This request is specific and provides a concrete direction for the authors to improve their draft. The comment is highly actionable as it guides the authors on how to enhance the clarity and comprehensiveness of their explanation regarding the importance of PPP metrics.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors state the importance of reliable PPP metrics for understanding PPP effects in different tasks. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely an explanation of the understanding gained by looking at the PPP maps. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the explanation regarding the understanding gained from looking at PPP maps. It does not make a subjective claim or express an opinion but rather seeks clarification on the content. Therefore, it is a factual request for more detailed explanation, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors could improve their paper by explicitly explaining the understanding gained from looking at PPP maps. It highlights a gap in the explanation provided, which is crucial for understanding the effects of PPP in different tasks. By asking for clarification on this point, the comment provides a clear and actionable suggestion for the authors to enhance the comprehensiveness and clarity of their work. This feedback is highly helpful as it directs the authors to a specific area that needs attention and guidance on how to address it. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. It suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. The reviewer also questions the authors\\' choice of baseline and suggests they should provide a stronger baseline to prove the usefulness of FP. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should provide a stronger baseline and consider the impact of rewardless actions on RBI. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"RBI\" and \"Task 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that RBI only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The comment suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone and questions the authors\\' choice of baseline. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that RBI only trains on rewarded actions, which ignores rewardless actions that could provide useful supervision. The reviewer suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. The comment also questions the authors\\' choice of baseline and suggests they should provide a stronger one to prove the usefulness of FP. While the comment provides logical reasoning and a suggestion for improvement, it lacks specific examples or references to support the claim about the impact of rewardless actions on RBI. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the claim themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. This is a significant observation that could impact the effectiveness of RBI. The comment also suggests that this could be a factor in the superiority of FP + RBI over RBI alone and questions the authors\\' choice of baseline. While the comment provides a clear direction for improvement, it lacks specific suggestions on how to address the issue or what specific changes should be made to the training process. This limits the comment\\'s helpfulness, as it points out a potential problem but does not fully guide the authors on how to resolve it. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the multi-scale statement is misleading because the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The reviewer suggests that the only benefit is the reduction of gradient path by the slow RNN. While the comment identifies a potential issue with the statement, it does not provide explicit guidance on how the authors should address this misleading aspect. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the time scales involved and possibly revise the statement to be more accurate. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"multi-scale statement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, explaining that the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The comment further suggests that the only benefit is the reduction of gradient path by the slow RNN. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the multi-scale statement is misleading because the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The reviewer supports this claim by explaining the distinction between physical and logical time scales and the potential benefit of reducing gradient path by the slow RNN. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. As it stands, the comment is mostly verifiable, as it provides a logical explanation but lacks specific references or detailed evidence to fully support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential misleading aspect in the paper regarding the multi-scale statement. It points out that the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. This feedback is valuable as it highlights a potential source of confusion in the paper, which could be clarified to improve the accuracy and understanding of the work. However, the comment could be more helpful if it provided specific suggestions on how the authors might clarify this aspect or address the misleading nature of the statement. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should clarify the distinction between the expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. While the comment implies that the authors should make this distinction clearer upfront, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction, but it is concrete in that it provides a clear direction for improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"formulation in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. The comment provides a clear direction for improvement by suggesting that the distinction should be made clearer upfront. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the expected performance under observation noise is typically used for evaluation because the decision-maker is interested in the true objective function and the noise is assumed to be noise (misleading, not representative). The reviewer suggests that in the current paper, the decision-maker does care about the noise, and the objective function of interest is the stochastic noisy function. The comment provides a logical reasoning for the distinction between the two scenarios, but it lacks specific examples or references to support the claim that the current paper's approach is misleading. Therefore, the claim is somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s approach to evaluation, noting that the expected performance under observation noise is typically used because the decision-maker is interested in the true objective function and the noise is assumed to be noise. However, in the current paper, the decision-maker is interested in the stochastic noisy function, which is a different objective. The comment suggests that the distinction between these two should be clarified upfront to avoid misleading the reader. While the comment provides a clear and actionable suggestion for improvement, it could be more helpful if it offered specific guidance on how to clarify this distinction or provided examples of how other papers have addressed similar issues. Overall, the comment is mostly helpful as it directs the authors to a critical area for clarification, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the long-range modeling ability of DGNs, suggesting that it could be due to oversmoothing, another phenomenon observed in the context of very deep graph networks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to take to improve the modeling ability. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the long-range modeling ability of DGNs and suggests that it could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. However, it does not specify which part of the paper discusses the long-range modeling ability or oversmoothing, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of oversmoothing but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the poor long-range modeling ability of DGNs is due to oversquashing and vanishing/exploding gradients, but also suggests that it could be due to oversmoothing. The reviewer supports this claim by referencing a paper that discusses oversmoothing in the context of very deep graph networks. However, the comment lacks specific examples or detailed explanations of how oversmoothing affects the modeling ability, making it somewhat verifiable. The authors would need to further explore the issue and understand the implications of oversmoothing to fully address the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the long-range modeling ability of DGNs, suggesting that it could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. It does not provide actionable steps or examples of how to mitigate oversmoothing, which would be beneficial for the authors to improve their draft. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific guidance on how to clarify the formulation or what aspects are unclear. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the issue. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the problem formulation is unclear in the statement and introduction examples, but it does not specify which parts of the paper these issues are found in. Without explicit references to sections or examples, the authors cannot confidently determine where to focus their revisions. The comment is specific in identifying the issue of unclear problem formulation, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific examples or detailed reasoning to support this claim. Without specific references or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks specificity and does not provide guidance on how to improve the clarity or what aspects of the formulation are unclear. Without actionable suggestions or examples, the authors are left without a clear path to address the issue. Therefore, the comment is not helpful, as it does not provide the authors with a way to improve their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests conducting experiments with different LLM families, specifically mentioning OPT, BLOOM, or other alternatives. This provides a clear and concrete action for the authors to take, as it specifies the exact models to include in the experiments and the purpose of doing so. The comment is specific and directs the authors on how to enhance their draft by including these additional experiments. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting experiments with different LLM families, specifically mentioning OPT, BLOOM, or other alternatives. This provides a clear direction for the authors to expand their experimental scope. However, the comment does not specify which part of the paper should include these experiments, such as the results or methodology sections. While the authors can infer that it relates to the experimental section, the comment lacks full grounding as it does not explicitly mention the section. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks experiments on different LLM families, specifically mentioning OPT, BLOOM, or other alternatives. This claim is somewhat verifiable as it provides a logical reasoning for why conducting such experiments could be beneficial. However, it lacks specific examples or detailed justification for why these particular models are important or how they would enhance the study. The suggestion is based on a general understanding of the importance of diverse experiments, but it could be strengthened with more detailed reasoning or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of experiments on different LLM families. It suggests conducting trials with models like OPT, BLOOM, or other alternatives to provide valuable insights into the method\\'s applicability and generalizability across various LLM families. This feedback is clear and actionable, as it directly suggests a specific area for improvement and provides a concrete direction for the authors to enhance their work. By addressing this suggestion, the authors can significantly improve the comprehensiveness and relevance of their study. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method only works for generative models that can be fine-tuned as an in/outpainting model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or what specific steps to consider for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method only works for generative models that can be fine-tuned as an in/outpainting model. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the method are limited to fine-tuning or how this limitation could be addressed. Without clear guidance on what needs to be improved or expanded, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the method only works for generative models that can be fine-tuned as an in/outpainting model. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a limitation in the method, suggesting that it only works for generative models that can be fine-tuned as an in/outpainting model. While this observation highlights a potential weakness, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this limitation or what specific aspects of the method need to be revised or expanded. Without actionable advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a perceived weakness in the connections between the curve finding and FGE, suggesting that the process described in the first part does not match the title or the author\\'s imagined process. However, the comment does not provide explicit guidance on how to address this issue or improve the connections. It mentions that the process could work but is computationally demanding, but this is not enough to direct the authors on how to improve their draft. The action is implicit and vague, leaving the authors uncertain about how to apply the feedback to enhance their work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first part and the second part, allowing the authors to accurately identify the sections being addressed. It also specifies the issue by pointing out the perceived weakness in the connections between the curve finding and FGE, and it provides a rationale for the discrepancy between the imagined process and the actual one. However, the comment lacks specific suggestions on how to address this issue or improve the connections. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the connections between the curve finding and FGE are weak, suggesting a discrepancy between the imagined process and the actual one. The reviewer provides a rationale by explaining that the process described in the first part does not match the title or their imagined process, which could work but is computationally demanding. This reasoning is somewhat verifiable as it highlights a potential issue but lacks specific examples or detailed justification to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the connections between the curve finding and FGE, suggesting that the process described in the first part does not match the title or the reviewer\\'s imagined process. It highlights a discrepancy between the imagined and actual processes, noting that the former could work but is computationally demanding. While the comment points out an area for improvement, it lacks specific suggestions or guidance on how to address this issue or improve the connections between the two parts. The feedback is somewhat helpful as it provides insight into a potential problem but does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should discuss the proposed method in relation to existing methods that use generalized Voronoi graphs, semantic maps, or pose graphs for exploration. While the comment implies that the authors should provide a comparison or discussion of their method with these existing methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion of their method in relation to these existing methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"generalized Voronoi graph or semantic maps,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a discussion of the proposed method in relation to existing methods that use similar concepts for exploration. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some of the general ideas in the proposed method are already present in other methods, specifically mentioning the use of generalized Voronoi graphs, semantic maps, and pose graphs for exploration. The reviewer supports this claim by referencing existing methods, such as graph-based SLAM, where loop closure is applied. This provides a clear and specific rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to specific methods or studies where these ideas are already present. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that some of the general ideas presented are already present in other methods, specifically mentioning the use of generalized Voronoi graphs, semantic maps, and pose graphs for exploration. The reviewer suggests that the paper should discuss the proposed method in relation to these existing methods, which could enhance its originality and contribution. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by incorporating a discussion of their method in relation to existing methods. However, the comment could be more helpful if it offered specific examples or references to these existing methods, which would guide the authors in their analysis and comparison. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental setup, tasks, and other details should be moved back into the main text from the appendix to improve interpretability. Additionally, it recommends moving some background information from Section 2 to the appendix. While the comment provides a clear action\u2014moving details back into the main text and reorganizing the appendix\u2014it does not specify which details should be moved or how to structure the reorganization. The authors are left to infer which details are most important to include in the main text and how to integrate them. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental setup, tasks, and other details being moved to the appendix, making it difficult to interpret the paper. It suggests moving some of these details back into the main text and reorganizing the appendix. However, the comment does not specify which details should be moved or how they should be integrated into the main text. This lack of specificity makes it difficult for the authors to pinpoint the exact parts of the paper that need revision. Therefore, the comment is weakly grounded because it does not specify the exact sections or details being addressed, and it is not specific in detailing what needs to be changed. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the experimental setup, tasks, and other details are moved to the appendix, making it difficult to interpret the paper. The reviewer proposes moving some of these details back into the main text and reorganizing the appendix. However, the comment lacks specific examples or detailed reasoning to support why these changes would improve the interpretability of the paper. Without specific examples or references, the claim is somewhat verifiable, as it provides a general suggestion but lacks the necessary detail to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, tasks, and other details being moved to the appendix, making it difficult for readers to interpret the paper. It suggests moving some of these details back into the main text and reorganizing the appendix. This feedback is clear and actionable, as it provides a concrete suggestion for improving the interpretability and accessibility of the paper. However, the comment could be more helpful if it offered specific examples of which details should be moved or how to structure the reorganization. Overall, the comment is mostly helpful as it guides the authors on how to enhance the clarity and readability of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the term \"Memb\" is mentioned as the previous state-of-the-art but no reference is provided. This implies that the authors should include a reference to the work or clarify the context in which \"Memb\" is mentioned. However, the comment does not explicitly instruct the authors to add a reference or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a reference, but it is not explicitly stated. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Memb,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the absence of a reference to the state-of-the-art \"Memb,\" which is a clear issue that needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"Memb\" is mentioned as the previous state-of-the-art but no reference is provided. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the term \"Memb\" is mentioned as the previous state-of-the-art but no reference is provided. This is a clear and actionable point, as it highlights a potential gap in the paper that could impact its credibility and comprehensiveness. By pointing out this oversight, the comment provides the authors with a specific area to address in their draft, ensuring that they include relevant references to support their claims. However, the comment could be more helpful if it suggested specific references or provided guidance on how to incorporate them effectively. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should study the impact of the ratio of unseen classes on the performance of their model. It explicitly recommends conducting experiments to explore how the performance varies with different ratios of unseen classes unlabeled examples. This feedback provides a clear and concrete action for the authors to take, as it specifies the exact aspect to investigate and offers a specific direction for further analysis. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests studying the impact of the ratio of unseen classes on the performance of the model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this analysis could be conducted. The authors can infer that it relates to the model evaluation or results section, but this inference is not direct. The comment is specific in suggesting a particular aspect to investigate, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests studying the impact of the ratio of unseen classes on the performance of the model. However, it does not provide any supporting evidence, reasoning, or references to justify why this is important or how it would benefit the study. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable, as it does not provide sufficient justification for the authors to act on it.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests studying the impact of the ratio of unseen classes on the performance of the model. It provides a specific direction for further analysis by recommending conducting experiments to explore how the performance varies with different ratios of unseen classes unlabeled examples. This feedback is actionable and constructive, as it offers a clear and concrete suggestion for the authors to enhance their study. However, the comment could be more helpful if it provided additional context or examples of how this analysis could be conducted or what specific aspects to focus on. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"epsilon-greedy\" in the context of training, specifically asking whether it is used in addition to the proposed strategy. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"epsilon-greedy\" in the context of training, indicating what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the meaning of \"epsilon-greedy\" in the context of training. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"epsilon-greedy\" in the context of training, specifically asking whether it is used in addition to the proposed strategy. This question highlights a potential area of confusion or misunderstanding in the paper, which could be clarified to enhance the readers\\' comprehension. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable advice, making it somewhat helpful but not comprehensive. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian distribution replaced by a Gaussian mixture distribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the method or what specific aspects need attention. The authors are left without any direction on how to address the comment. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian distribution replaced by a Gaussian mixture distribution. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where this combination is discussed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in detailing the combination of GCN and normalizing flow, but without grounding, it lacks actionable guidance for the authors. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is a combination of GCN and normalizing flow, with a Gaussian distribution replaced by a Gaussian mixture distribution. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian distribution replaced by a Gaussian mixture distribution. However, it lacks depth and does not provide any actionable feedback or suggestions for improvement. It does not explain why this combination is problematic or how it could be improved, nor does it offer guidance on how the authors might address any issues or enhance their work. As a result, the comment is not helpful at all, as it does not provide any meaningful insights or direction for the authors to take. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed invariant learning module could be improved by considering representation learning, which is currently discussed in the appendix. It also points out that the framework seems not to be limited to raw-level selection, as evidenced by the discussion in Section 4. The comment provides a clear direction for the authors to consider incorporating representation learning into the feature selection process in Section 4.2. This feedback is explicit and concrete, as it specifies the exact area that needs improvement and how to address it. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"Line 167-174, Sec. 4,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue with the proposed invariant learning module, suggesting that it could be improved by considering representation learning. Additionally, it provides a rationale for the suggestion by discussing the current framework and its limitations. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed invariant learning module could be improved by considering representation learning, which is currently discussed in the appendix. The reviewer provides a logical reasoning by pointing out that the framework seems not to be limited to raw-level selection, as evidenced by the discussion in Section 4. However, the comment lacks specific examples or references to the appendix or Section 4 to fully substantiate the claim. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable, as it requires further elaboration to fully support the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the proposed invariant learning module by suggesting that it could be enhanced by considering representation learning, which is currently discussed in the appendix. It points out that the framework seems not to be limited to raw-level selection, as evidenced by the discussion in Section 4. This feedback is clear and actionable, as it provides a specific direction for the authors to consider incorporating representation learning into the feature selection process. By addressing this suggestion, the authors could significantly improve the robustness and generalizability of their approach. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some details are missing, specifically mentioning the design of rewards as an example. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific steps to clarify the reward design or suggesting ways to improve the explanation. As a result, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the design of rewards, which is a clear and specific point. However, it does not explicitly mention which part of the paper discusses the rewards, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the lack of understanding of how the rewards are designed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"some details are missing,\" specifically mentioning the design of rewards as an example. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, namely the design of rewards. It points out that the authors need to provide more details on how the rewards are designed, which is a crucial aspect of the paper. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve the clarity of the reward design. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count. This is a clear and direct action for the authors to take, as it provides a specific area for improvement and highlights the importance of runtime as a limitation for ML-based emulators of climate model parametrizations. The comment is concrete, as it specifies what needs to be discussed and why, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Prithvi WxC\" emulator, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the runtime of Prithvi WxC and its potential limitations for applications. This provides clear guidance on what aspect of the paper needs attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count, as it is a limitation for ML-based emulators of climate model parametrizations. However, the comment does not provide any supporting evidence, reasoning, or references to justify why runtime is a critical issue or how it affects the applicability of the emulator. Without additional context or examples, the claim remains somewhat vague and lacks verifiability. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the runtime of Prithvi WxC should be discussed, given its large parameter count. This is a clear and actionable suggestion that could help the authors address a potential limitation of their emulator in the context of ML-based climate model parametrizations. By discussing the runtime, the authors can provide valuable insights into the practicality and applicability of their emulator, which could enhance the overall quality and impact of their work. However, the comment could be more helpful if it provided additional context or examples on how the runtime affects the emulator's performance or applicability. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the quality of paraphrases generated for training data, specifically noting that the paraphrases need to be sufficiently different from the original sentences. It suggests that this impacts the subsequent steps in the process, as the model relies heavily on the quality of these paraphrases. However, the comment does not provide explicit guidance on how to address this issue or what specific steps the authors should take to improve the quality of the paraphrases. While the action is implied, it is not detailed enough for the authors to know exactly how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the process of generating paraphrases for training data, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unclear differences between the paraphrases and the original sentences, which impacts the quality of the final training data. The comment provides a clear rationale for why this issue is important and how it affects the subsequent steps in the process. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paraphrases generated for training data are unclear and that this impacts the quality of the final training data. The reviewer provides a logical reasoning by explaining that if the paraphrases are not sufficiently different from the original sentences, the model will rely on low-quality training data, leading to a low number of pairs added to the new training data. This reasoning is somewhat verifiable as it provides a logical explanation for the impact of the paraphrases on the quality of the training data. However, the comment could be strengthened by providing specific examples or references to studies that demonstrate the importance of paraphrase quality in training data. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the quality of paraphrases generated for training data, noting that the paraphrases need to be sufficiently different from the original sentences to ensure the model's reliability. This is a valuable observation that could significantly impact the quality of the final training data and, in turn, the overall performance of the model. The comment provides a clear and actionable suggestion for improvement, encouraging the authors to address this issue by ensuring that the paraphrases are sufficiently distinct from the original sentences. However, the comment could be more helpful if it offered specific guidance on how to achieve this goal or provided examples of what constitutes an acceptable level of difference. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to take action.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not provide any specific guidance on how to improve the writing or what aspects need attention. The comment lacks concrete suggestions or examples of what changes could be made to enhance the clarity or coherence of the paper. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not specify which parts of the paper are particularly challenging to understand or where the writing could be improved. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the writing could be improved, indicating that it took effort to understand the main idea and theoretical analysis of the paper. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the writing could be improved, indicating that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not provide specific feedback or suggestions on how to improve the writing, such as identifying areas of confusion or offering guidance on clarity or structure. Without actionable advice or detailed insights, the comment lacks depth and does not assist the authors in making meaningful improvements to their draft. Therefore, it is rated as barely helpful, as it provides some direction but not enough detail for the authors to effectively address the feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the comparisons made between the domain-specific model and zero-shot single-image 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative comparisons that might be more fair. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their comparisons, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the domain-specific model being trained on Pix3D and the experiments being conducted on Pix3D, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the comparisons to zero-shot single-image 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparisons between the domain-specific model and zero-shot single-image 3D reconstruction models are unfair due to the use of Pix3D as both the training and testing dataset. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparisons made between the domain-specific model and zero-shot single-image 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. This feedback is somewhat helpful as it points out a potential bias in the experimental setup, which could impact the validity of the results. However, the comment lacks specific suggestions on how to address this issue or alternative comparisons that might be more fair. While it highlights an important consideration, the lack of actionable guidance limits its usefulness for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that additional experiments on realistic noisy datasets like WebVision would provide more support for the C2D method. While the suggestion is clear, it lacks specific guidance on how to conduct these experiments or what specific aspects of the C2D method should be tested on these datasets. The authors are left to infer that they should conduct additional experiments, but without detailed instructions on how to do so, the action remains somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where to look, the comment lacks full grounding. It is specific in suggesting additional experiments but does not provide detailed guidance on how to implement them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that additional experiments on realistic noisy datasets like WebVision would provide more support for the C2D method. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would improve the method. Without detailed justification or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. This is a clear and actionable suggestion that could enhance the robustness and generalizability of the method. However, the comment lacks specific guidance on which aspects of the C2D method should be tested or how these experiments should be designed. While it points to a potential area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but requires further elaboration to be fully beneficial.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It also questions the interpretation of the models' learning and whether simpler tasks would suffice. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve the clarity of their visual reasoning tasks. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It also questions the interpretation of the models' learning and whether simpler tasks would suffice. However, the comment does not specify which part of the paper these tasks are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the tasks and the need for proof that more complex tasks are necessary. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. The reviewer also questions the interpretation of the models' learning and whether simpler tasks would suffice. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim borderline verifiable, as it requires more information to fully substantiate the critique. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions the interpretation of the models' learning and whether simpler tasks would suffice. The comment also asks for proof that more complex tasks are necessary. While the comment identifies a potential issue with the clarity and complexity of the tasks, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the paper. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of essential visualization of intermediate processes and comparisons, which is a clear actionable point. However, it does not provide specific guidance on what visualizations or comparisons are missing or how they should be presented. The authors are left to infer that they need to include visualizations and comparisons, but without concrete details on what is expected, the comment remains somewhat vague. Therefore, the comment is somewhat actionable, as it points out an area for improvement but lacks specific guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of essential visualization of intermediate processes and comparisons, which is a specific issue related to the presentation of the paper. However, it does not specify which parts of the paper should include these visualizations or comparisons, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in identifying the need for visualization and comparison, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, namely the lack of essential visualization of intermediate processes and comparisons. This is a clear and actionable point that the authors can address to enhance the clarity and comprehensiveness of their work. However, the comment does not provide specific guidance on what types of visualizations or comparisons are missing or how they could be incorporated into the paper. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a critical area for enhancement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. However, it does not provide any guidance on how the authors should address this issue or what specific changes need to be made to ensure compliance with the stated condition. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Definition 1\" and \"expected counterfactual,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the expected counterfactual violates a condition stated in Definition 1. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. This is a clear and actionable point that the authors can address to improve the clarity and consistency of their work. However, the comment lacks depth and does not provide suggestions on how to resolve the issue or what specific changes are needed. While it highlights an important area for improvement, it could be more helpful with additional guidance or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the importance of the result, referencing external work that suggests that perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimension-free, which could impact the significance of the result. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve the paper. The authors are left to infer that they might need to reconsider the importance of their result in light of the external work, but without specific instructions on how to do so, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the iteration complexity in Theorem 3 is no longer dimension-free, which is a clear concern. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the result is not surprising due to external work that suggests perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimension-free, which could impact the significance of the result. However, the comment lacks specific references to the external work or detailed reasoning to support the claim that the result is not surprising. The lack of detailed evidence or references makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is somewhat verifiable, as it provides some basis for the claim but requires more detailed evidence or explanation to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the importance of the result, referencing external work that suggests that perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimension-free, which could impact the significance of the result. While the comment identifies potential weaknesses in the paper, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the paper. The feedback is somewhat helpful as it highlights areas for improvement, but it could be more beneficial with additional actionable advice or insights. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the grid search for learning rate, specifically asking whether it is performed on the validation set. It also mentions minor problems, but does not provide further details or suggestions for improvement. The comment implies that the authors should clarify this aspect of their methodology, but it lacks explicit guidance on how to address the issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the grid search process but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"grid search of learning rate,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking whether the grid search is performed on the validation set, providing clear guidance on what needs to be clarified. However, the comment does not provide specific suggestions or examples on how to improve the clarity or execution of the grid search. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point consists of a question asking about the grid search for learning rate, specifically whether it is performed on the validation set. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the grid search for learning rate, specifically asking whether it is performed on the validation set. This is a relevant point that could impact the robustness and generalizability of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it identifies a potential area for clarification, it does not offer actionable advice or detailed feedback that would help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in improving their work.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the diversity of the sample in terms of racial and economic backgrounds, and it asks how well the results might generalize to other groups, including marginalized ones. While the comment implies that the authors should consider this aspect, it does not explicitly instruct them to do so or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors can infer that they need to consider diversity but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the diversity of the sample in terms of racial and economic backgrounds, and it asks how well the results might generalize to other groups, including marginalized ones. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the diversity of the sample in terms of racial and economic backgrounds, and it asks how well the results might generalize to other groups, including marginalized ones. This is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the diversity of the sample in terms of racial and economic backgrounds, and it asks how well the results might generalize to other groups, including marginalized ones. This is a relevant and insightful point that could prompt the authors to consider the broader implications of their findings and ensure that their work is inclusive and applicable to diverse populations. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional analyses or discussions. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the number of images provided in the VioT dataset is small, which may impact the validity of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should increase the number of images, provide additional data, or justify the current number of images. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the VioT dataset, specifically mentioning the number of images provided in each of the four categories. This provides full grounding as it allows the authors to accurately identify the part of the paper being discussed. However, the comment lacks specificity as it does not detail what aspect of the dataset\\'s size is problematic or how it affects the validity of the approach. Without specific guidance on how to address this issue, the authors may find it challenging to understand and implement the suggested improvements. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the number of images in the VioT dataset is small, which may impact the validity of the approach. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the claim and how it affects the validity of the approach. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the VioT dataset, noting that the number of images provided is small, which may impact the validity of the approach. However, it does not provide any specific suggestions or guidance on how the authors might address this issue, such as recommending an increase in the number of images or discussing the implications of the dataset size. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the paper, such as its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It suggests that more intuitive explanations are needed, and provides examples of what could be improved, such as explaining the colors in Fig. 2. Additionally, the reviewer mentions that Fig. 1 and 2 did not contribute much to their understanding, and that they had to read the text multiple times. While the comment provides some guidance on what needs to be improved, it lacks concrete details on how to implement these changes. The authors are given a general idea of what needs to be addressed, but the specific steps for improvement are not fully articulated. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Fig. 1 and 2\" and \"figure captions,\" allowing the authors to accurately identify the areas being addressed. It is also specific because it details the issues with the paper, such as the difficulty in following the mathematical derivations and the lack of explanations in the figure captions. The comment suggests that more intuitive explanations are needed and provides examples of what could be improved, such as explaining the colors in Fig. 2. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is hard to follow and suggests that more intuitive explanations are needed for the mathematical derivations. It also mentions that figure captions are lacking and require additional explanations and legends. The reviewer provides specific examples, such as the need to explain the colors in Fig. 2, which adds a level of detail and specificity to the claim. However, the comment could be strengthened by providing more detailed reasoning or references to similar works that have successfully addressed similar issues. Overall, the claim is mostly verifiable, as it is supported by specific examples and suggestions for improvement, but it could be further substantiated with additional evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper, such as its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It suggests that more intuitive explanations are needed, and provides examples of what could be improved, such as explaining the colors in Fig. 2. The comment also notes that Fig. 1 and 2 did not contribute much to the reviewer\\'s understanding, and that they had to read the text multiple times. This feedback is clear and actionable, as it points out specific areas where the paper could be improved to enhance its clarity and accessibility. However, it could be more helpful if it provided additional guidance on how to improve the explanations or suggested specific techniques for making the paper more intuitive. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the sensitivity of empirical results to hyperparameter choices, noting that incorrect choices could undermine any improvements gained from the method. It explicitly states that resolving this issue would influence the reviewer\\'s rating. While the comment does not provide specific guidance on how to address this issue, it implies that the authors should investigate the robustness of their results to different hyperparameter settings. The action is implicit but concrete, as the authors can infer that they need to assess the sensitivity of their results to hyperparameter choices. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"empirical results\" and the \"hyperparameter choices,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of sensitivity to hyperparameter choices and the potential impact on the method\\'s effectiveness. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the sensitivity of empirical results to hyperparameter choices, noting that incorrect choices could undermine any improvements gained from the method. This claim is somewhat verifiable as it highlights a potential issue with the robustness of the results, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The reviewer suggests that resolving this issue would influence their rating, indicating a need for more detailed analysis or evidence to support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the robustness of the empirical results, specifically the sensitivity to hyperparameter choices. It highlights the potential impact of incorrect choices on the effectiveness of the method, which is a crucial consideration for the authors. The comment explicitly states that resolving this issue would influence the reviewer\\'s rating, providing a clear and actionable suggestion for the authors to address. However, the comment could be more helpful if it offered specific guidance on how to assess the sensitivity or how to make more robust choices for hyperparameters. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a major issue with the paper\\'s motivation, specifically regarding the cross-encoder architecture. It notes that the architecture is not ignoring cross-entity comparison but instead attends to all candidates at once, which may not be as fine-grained as expected. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the motivation or what specific changes should be made to the architecture. As a result, the authors are left without a clear understanding of how to improve their draft in this area. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the motivation of the cross-encoder architecture, noting that it is not ignoring cross-entity comparison but instead attends to all candidates at once. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the motivation, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation for the cross-encoder architecture is poorly explained, specifically stating that it is not ignoring cross-entity comparison but instead attends to all candidates at once. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a major issue with the paper\\'s motivation, specifically regarding the cross-encoder architecture. It points out that the architecture is not ignoring cross-entity comparison but instead attends to all candidates at once, which may not be as fine-grained as expected. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the motivation for their architecture. Without actionable feedback or detailed advice, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is rated as barely helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the work uses an outdated GNN model and method, which affects the performance of the framework. It also mentions that the baseline algorithms/methods are also outdated. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue, such as suggesting newer models or methods to be used. Without actionable guidance, the authors are left without a clear path forward to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the use of an outdated GNN model and method, which affects the performance of the framework. However, it does not specify which part of the paper discusses the GNN model or method, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the GNN model or method are outdated or how they could be improved. Without clear guidance on what needs to be addressed, the authors may find it challenging to make the necessary changes. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work uses an outdated GNN model and method, which impacts the performance of the framework. However, the comment does not provide specific examples or references to support this claim, nor does it explain how the use of outdated methods affects the performance. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the work, noting that it uses an outdated GNN model and method, which impacts the performance of the framework. This is a critical observation that could significantly affect the paper\\'s credibility and relevance. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue, such as suggesting newer models or methods to be used. Without detailed feedback or constructive advice, the authors are left without a clear path forward to improve their draft. Therefore, the comment is somewhat helpful, as it points out a significant weakness but lacks depth and actionable suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that the experiment estimates the quality of uncertainty estimates by comparing the true feature importance to a 95% credible interval. However, the true feature importance is not available, so the experiment relies on pseudo feature importance. The reviewer suggests that the correctness of the pseudo feature importance is based on Proposition 3.2 and a large enough perturbation value. The comment provides two ways to strengthen the experiment: by either using a different method to estimate the true feature importance or by providing a more detailed explanation of the perturbation value. While the comment provides some guidance on how to address the issue, it lacks specific instructions on how to implement these suggestions. The action is explicit but somewhat vague, as the authors need to determine the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiment that estimates the quality of uncertainty estimates, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the experiment, which relies on pseudo feature importance due to the unavailability of true feature importance. The comment provides specific guidance on how to strengthen the experiment by suggesting two ways: using a different method to estimate the true feature importance or providing a more detailed explanation of the perturbation value. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiment to estimate the quality of uncertainty estimates relies on pseudo feature importance due to the unavailability of true feature importance. The reviewer suggests that the correctness of the pseudo feature importance is based on Proposition 3.2 and a large enough perturbation value. The comment provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion about the correctness of the pseudo feature importance. This makes the claim somewhat verifiable, as the authors would need to further explore the basis of the claim to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that the experiment estimates the quality of uncertainty estimates by comparing the true feature importance to a 95% credible interval. However, the true feature importance is not available, so the experiment relies on pseudo feature importance. The reviewer suggests two ways to strengthen the experiment: by using a different method to estimate the true feature importance or by providing a more detailed explanation of the perturbation value. This feedback is clear and actionable, as it guides the authors on how to improve the reliability and robustness of their experiment. By addressing these suggestions, the authors can enhance the credibility and validity of their results. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two issues: the lack of proper experimental settings and the absence of code. It explicitly states that the result reproducibility is critical and that the authors should provide the code. This feedback is clear and direct, giving the authors a clear action to take to improve their draft. The comment is specific about what needs to be added or included, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental settings\" and the \"code,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of proper experimental settings and the absence of code, which are critical for result reproducibility. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental settings are not mentioned properly and that the result reproducibility is critical. It also notes the absence of code, which is a significant concern. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of these issues themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two critical issues with the paper: the lack of proper experimental settings and the absence of code. It highlights the importance of result reproducibility and emphasizes the need for the authors to provide the code. This feedback is clear and actionable, as it directly points out areas where the paper could be improved to enhance its credibility and reliability. However, the comment could be more helpful if it provided specific suggestions on how to address these issues, such as recommending specific experimental settings or code sharing platforms. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, assuming it was auto-generated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent real-life situations. While the comment implies that the authors should consider these options, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these alternatives. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of lexical and syntactic diversity in the teacher feedback, assuming it was auto-generated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent real-life situations. However, the comment does not specify which part of the paper this issue pertains to, such as the methodology or results sections. While the authors might have an idea of where this feedback is relevant, it is not explicitly grounded. The comment is specific in suggesting alternative approaches to improve the diversity of teacher feedback, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, assuming it was auto-generated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent real-life situations. However, the comment does not provide any supporting evidence, examples, or references to justify why this diversity is important or how it would improve the paper. Without additional context or explanation, the claim remains somewhat verifiable, as the authors may find it challenging to understand the significance of this suggestion without further elaboration. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the diversity of teacher feedback, assuming it was auto-generated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent real-life situations. This feedback is somewhat helpful as it points out a specific area for improvement and provides a direction for the authors to explore. However, the comment could be more helpful if it offered more detailed guidance on how to implement these suggestions or provided examples of how other studies have addressed this issue. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. While the comment implies that the authors should include a summary of the supplementary experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a summary of the supplementary experiments. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. However, it does not specify which part of the main text should be revised or where the summary should be placed. The authors can infer that it relates to the sections discussing the experiments or results, but this inference is not direct. The comment is specific in suggesting the need for a summary of supplementary experiments, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. This feedback is somewhat helpful as it identifies a potential gap in the paper\\'s presentation, which could enhance the clarity and comprehensiveness of the main text. However, the comment lacks specific guidance on how to effectively summarize the supplementary experiments or what aspects of the results should be highlighted. While it points out an area for improvement, it does not provide detailed suggestions or examples, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests comparing the performance with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". While the comment implies that these comparisons could provide valuable insights, it does not explicitly instruct the authors to conduct these comparisons or explain why they are necessary. The action is implicit and somewhat vague, as the authors need to infer the importance of these comparisons and how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the performance with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". However, it does not specify which part of the paper these comparisons should be included in, making it weakly grounded. The comment is specific in suggesting the need for these comparisons, as it clearly identifies the potential benefits of including them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the performance with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". However, the comment does not provide any justification or reasoning for why these comparisons are necessary or how they would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the relevance of these comparisons. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the performance of the paper with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". This feedback is somewhat helpful as it provides a clear direction for the authors to consider in terms of benchmarking their work against existing approaches. However, the comment lacks depth and does not explain why these comparisons are important or how they would enhance the paper. Additionally, it does not offer specific guidance on how to conduct these comparisons or what aspects to focus on. While it provides a starting point, the feedback could be more comprehensive and actionable with additional details. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the specificity of the setting and suggests that the approach could be extended to more general settings. However, it does not provide explicit guidance or suggestions on how to achieve this extension. The comment implies that the authors should consider broadening the scope of their work, but it lacks concrete steps or detailed advice on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the specificity of the setting, suggesting that the approach could be extended to more general settings. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the setting and its suggestion for broadening the scope, but without clear references to specific sections or elements, the authors may struggle to identify where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the specificity of the setting and suggests that the approach could be extended to more general settings. However, it does not provide any supporting evidence, reasoning, or references to justify why the current setting is specific or how it could be improved. The comment lacks detailed explanation or examples, making it difficult for the authors to understand and address the critique. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific concern about the specificity of the setting, suggesting that the approach could be extended to more general settings. It questions the need for a generative model and episodic problem structure, which are currently assumed in the paper. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to broaden the scope of the work. The authors are given a direction to consider, but the feedback is not actionable or detailed enough to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the feature extractor used for dimensionality of each region, specifically asking about the feature extractor used in line 201. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the feature extractor. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the feature extractor used for dimensionality, providing clear guidance on what needs to be clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the feature extractor used for dimensionality in line 201. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the feature extractor used for dimensionality in line 201. This is a clear and actionable point, as it prompts the authors to clarify an important detail in their methodology. By addressing this question, the authors can improve the clarity and transparency of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that providing computation/algorithm/implementation details would be helpful for readers. While the comment implies that the authors should include these details, it does not explicitly instruct them to do so or provide specific guidance on how to present this information. The action is implicit and somewhat vague, as the authors need to infer that they should include these details but are not given concrete steps on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that providing computation/algorithm/implementation details would be helpful for readers. However, it does not specify which part of the paper this information should be included in, nor does it provide details on what specific aspects of the computation, algorithm, or implementation should be highlighted. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need to be revised. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that providing computation/algorithm/implementation details would be helpful for readers. However, it does not provide any supporting evidence, reasoning, or examples to justify why these details are necessary or how they would enhance the paper. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that providing computation/algorithm/implementation details would be helpful for readers. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what details should be included or how they could be presented. Without further elaboration or examples, the authors may find it challenging to understand the exact nature of the feedback and how to address it. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of analysis regarding the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing. While the comment implies that the authors should provide more analysis and comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more analysis and comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of analysis regarding the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing. This provides clear guidance on what needs to be addressed in the paper. However, the comment does not specify which sections or parts of the paper should include this analysis or comparison, making it somewhat specific. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that there is insufficient analysis of the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing. The comment provides a logical reasoning by suggesting that such comparisons would clarify the unique advantages of the method. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the claim, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of analysis regarding the effectiveness of data augmentation methods. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing, would clarify the unique advantages of the method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and comparison sections. However, the comment could be more helpful if it offered examples or guidance on how to conduct these comparisons. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement and provides a clear path for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is concrete, as it specifies what the authors should do, but it is somewhat vague in terms of how to implement the ablation study. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting an ablation study and providing examples of alternative approaches. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment lacks specific evidence or detailed reasoning to support the claim that an ablation study is necessary or how it would benefit the paper. The examples given are not fully developed, and the reasoning is not as clear as it could be. Therefore, the comment is somewhat verifiable, as it provides some support but lacks depth and specificity in its justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting an ablation study, which could help the authors better understand the impact of each component. However, the comment could be more helpful if it provided more detailed guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment offers a clear direction for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it does not explicitly instruct the authors to perform a specific action, it implies that they should consider this scenario and its implications for their model. The comment is somewhat actionable as it provides a direction for further exploration, but it lacks concrete guidance on how to implement this exploration or what specific aspects to focus on. Therefore, the authors can infer that they should consider this scenario but may need to infer the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspect of the model's performance is being questioned or how it could be improved. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it highlights an interesting aspect of the model\\'s behavior, it does not provide any guidance or suggestions for improvement. It lacks actionable feedback or insights into how the authors might address this issue or improve their model. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to conduct a quantitative analysis to substantiate the computational gains claimed in the paper. It specifies the types of measurements that would be helpful, such as GPU hours, memory usage, or training time. This provides clear and concrete guidance on what the authors need to do to improve their draft. The action is explicit and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, specifically referring to the claim of computational benefits from replacing the MAE model with a CNN-based data augmentation strategy. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for quantitative analysis to substantiate the computational gains. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks specific measurements or comparisons to substantiate the computational gains from replacing the MAE model with a CNN-based data augmentation strategy. The reviewer suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of the efficiency improvements in DQ V2. This claim is somewhat verifiable as it logically suggests that quantitative analysis would strengthen the paper\\'s claims, but it lacks specific examples or references to similar studies that have used such analyses. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of quantitative analysis to substantiate the computational gains claimed in the paper. It suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of the efficiency improvements in DQ V2. This feedback is clear and actionable, as it directs the authors to conduct a specific type of analysis that would enhance the credibility and robustness of their claims. By addressing this point, the authors can significantly improve the rigor and impact of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the time for COLMAP and scene-by-scene fine-tuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, it does not provide explicit guidance on how the authors should incorporate this consideration into their analysis or what specific changes should be made to account for this time. The action is implied and somewhat vague, as the authors can infer that they need to consider the time aspect but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the time for COLMAP and scene-by-scene fine-tuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to consider the time aspect when comparing methods, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the time for COLMAP and scene-by-scene fine-tuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this time consideration is important or how it affects the efficiency of the method. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be considered fully verifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the efficiency of the method when comparing it to COLMAP and scene-by-scene fine-tuning. It suggests that the time taken for these processes should be considered, which could impact the method\\'s effectiveness for certain scenes. While the comment highlights an important aspect to consider, it lacks specific guidance or suggestions on how the authors should address this issue or what specific changes should be made to improve the efficiency of the method. The feedback is somewhat helpful as it points out a potential weakness, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the \"filter manifold network\" (FMN) and its scalability with the number of filter parameters. It asks if the authors experimented with other architectures for FMN and how adaptive convolutions scale with the number of filter parameters. Additionally, it questions whether FMN can scale well with larger input and output channels, which is common in many CNN architectures. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these questions, but the comment lacks specific guidance on how to do so. Therefore, the comment is somewhat actionable, as it implies actions but does not provide detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"filter manifold network\" (FMN), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the scalability of the FMN with larger input and output channels, and it suggests experimenting with other architectures. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the discussion and analysis of the \"filter manifold network\" (FMN), which is the main part of the technique. It asks if the authors experimented with other architectures for FMN and how adaptive convolutions scale with the number of filter parameters. The reviewer also questions whether FMN can scale well with larger input and output channels, which is common in many CNN architectures. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that the current discussion is insufficient. The authors are left to infer the need for more analysis and discussion, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the discussion and analysis of the \"filter manifold network\" (FMN), which is the main part of the technique. It raises important questions about the scalability of the FMN with larger input and output channels, suggesting that the authors should experiment with other architectures and explore how adaptive convolutions scale with the number of filter parameters. Additionally, the comment questions whether FMN can reasonably scale for larger input and output channels, which is common in many CNN architectures. This feedback is clear and actionable, providing the authors with specific areas to focus on to improve their draft. However, it could be more helpful if it offered suggestions on how to address these questions or provided examples of alternative architectures to consider. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should analyze the contribution of each factor (noise and exponential moving average) separately and compare them to the \\Pi model, which captures only the noise part. This feedback provides a clear and explicit action for the authors to take, as it specifies the need for a detailed analysis of each factor and their contributions. The comment also suggests a specific comparison with the \\Pi model, which further guides the authors on how to conduct their analysis. Therefore, this comment is highly actionable, as it provides concrete steps for the authors to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed model\" and the \"two factors\" that contribute to its benefits, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the analysis of the contribution of each factor separately and a comparison with the \\Pi model. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed model benefits from two factors: noise and keeping an exponential moving average. It suggests that it would be beneficial to analyze the contribution of each factor separately and compare them to the \\Pi model, which captures only the noise part. The comment provides a logical reasoning for this suggestion by highlighting the potential gain from analyzing each factor independently. However, it lacks specific examples or references to support the claim that analyzing each factor would provide significant insights. Therefore, the claim is somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to analyze the contribution of each factor (noise and exponential moving average) separately and compare them to the \\Pi model, which captures only the noise part. This feedback is valuable as it guides the authors to conduct a more detailed analysis of their model, potentially revealing insights into the factors that contribute to its success. By addressing this suggestion, the authors can enhance the clarity and depth of their analysis, which could lead to a more robust understanding of their model and its components. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the results being reported after a significant amount of training has occurred, suggesting that the agent's behavior during learning is also important. The reviewer speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this concern or what specific steps to take to improve the results. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of reporting results after a significant amount of training has occurred, suggesting that the agent's behavior during learning is also important. It raises a concern about early training, where the model parameters might be garbage, and the planning component might hurt more than help. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the training process and the potential impact on the agent's behavior, but without clear grounding, the authors cannot confidently determine which part of the paper needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the results being reported after a significant amount of training has occurred, suggesting that the agent's behavior during learning is also important. The reviewer speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. This is a logical observation but lacks specific evidence or references to support the claim. The comment is somewhat verifiable as it provides a reasonable basis for the concern but could be strengthened with more detailed reasoning or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the results being reported after a significant amount of training has occurred, suggesting that the agent's behavior during learning is also important. It speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. This is a thought-provoking observation that could prompt the authors to consider how their results might be impacted by the agent's behavior during learning. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their results. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it identifies a relevant concern but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the approach taken for handling documents in DocRED, specifically asking whether the documents are considered as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. While the comment identifies a potential gap in the manuscript, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information on their approach but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DocRED\" and \"the documents,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the handling of documents as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. This provides clear guidance on what needs to be addressed in the manuscript. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification about the approach taken in handling documents in DocRED, specifically regarding the consideration of documents as an entire sentence and the handling of concepts involving multiple entity mentions. While the questions themselves do not present a claim, the reviewer is seeking clarification on existing information that is not included in the manuscript. Therefore, the comment is classified as \"No\" as it does not contain a claim.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the approach taken in handling documents in DocRED, particularly regarding the consideration of documents as an entire sentence and the handling of concepts involving multiple entity mentions. This feedback is valuable as it identifies a potential gap in the manuscript that could impact the clarity and completeness of the paper. However, the comment does not provide suggestions or guidance on how the authors might address this issue or what specific information should be included to clarify their approach. While it points out a potential area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the contribution of the paper is marginal because the methods used in different stages are well-designed and demonstrated. It also implies that adding another stream for low-resolution might not be a significant contribution for a top-tier venue like ICLR. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived marginality or how to improve the contribution. As a result, the authors are left without any clear direction on how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the contribution of the paper is marginal because the methods used in different stages are well-designed and demonstrated. However, it does not specify which part of the paper this assessment is based on, such as the methods or the stage where they are used. This lack of specificity makes it difficult for the authors to identify the exact sections that need improvement or clarification. Additionally, the comment does not provide specific guidance on how to address the perceived marginality or what changes could be made to enhance the contribution. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of the paper is marginal because the methods used in different stages are well-designed and demonstrated. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to specific methods or stages where the methods are demonstrated, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the contribution of the paper is marginal, as the methods used in different stages are well-designed and demonstrated. It also implies that adding another stream for low-resolution might not be a significant contribution for a top-tier venue like ICLR. While the comment identifies a potential weakness in the contribution, it lacks specificity and actionable suggestions for improvement. It does not provide guidance on how the authors might enhance the contribution or address the perceived marginality. As a result, the comment is somewhat helpful, as it points out a potential issue but does not offer detailed feedback for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the inclusion of a comprehensive Appendix and appreciates the additional detail it provides. However, it also notes that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. While the comment implies that the authors should consider including more details about these experiments in the main text, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they should provide more information but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment appreciates the inclusion of a comprehensive Appendix and acknowledges the additional detail it provides. However, it does not specify which part of the paper the Appendix is attached to, making it weakly grounded. The comment also mentions the Brusselator as an example of an additional experiment, but it does not specify which part of the Appendix this experiment is discussed in. This lack of specificity makes it difficult for the authors to pinpoint the exact section that needs attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point acknowledges the inclusion of a comprehensive Appendix and appreciates the additional detail it provides. However, it also notes that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This statement is a factual observation about the reviewer\\'s experience and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment appreciates the inclusion of a comprehensive Appendix and acknowledges the additional detail it provides. However, it also notes that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This feedback highlights a potential limitation in the paper, as it suggests that the main text may not fully cover all aspects of the work. While the comment identifies a weakness, it does not provide specific suggestions or guidance on how to address this issue, such as recommending which experiments should be included in the main text or how to prioritize the most important findings. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should demonstrate the scalability of their LFF method by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment somewhat actionable. The authors can infer that they need to conduct additional experiments, but the comment lacks concrete details on how to implement this suggestion.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should demonstrate the scalability of their LFF method by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to demonstrate scalability on more challenging tasks, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that most continuous control experiments are performed on simple and low-dimensional tasks, such as cartpole or mountain car, and that it is important to demonstrate the scalability of LFF by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. The claim is somewhat verifiable as it logically argues that demonstrating scalability on more complex tasks is important. However, it lacks specific examples or references to support the claim that these tasks are indeed more challenging or how LFF could be applied to them. Providing such examples or references would strengthen the claim, making it more fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the current experimental setup, noting that most continuous control experiments are performed on simple and low-dimensional tasks, such as cartpole or mountain car. It suggests that to fully demonstrate the scalability of the LFF method, it is important to show its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental setup and demonstrate the broader applicability of their method. However, the comment could be more helpful if it offered suggestions on how to conduct these additional experiments or what specific aspects of the LFF method should be emphasized in these more complex tasks. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper regards MULT as the only deep learning-based baseline that considers cross-sensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should consider other baselines or update their references to more recent works. As a result, the authors are left without a clear understanding of how to address this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific works, \"MISA,\" \"M2FNet,\" and \"MM-DFN,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper regards MULT as the only deep learning-based baseline that considers cross-sensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper regards MULT as the only deep learning-based baseline that considers cross-sensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. This claim is somewhat verifiable as it provides a specific reference to MULT and its publication year, which supports the assertion that it is outdated. However, the comment lacks detailed reasoning or examples to fully substantiate why MULT is considered out of fashion or how it impacts the current work. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s reference to MULT as the only deep learning-based baseline that considers cross-sensory interaction. It points out that MULT was proposed in 2019 and is therefore out of fashion, which could impact the relevance and credibility of the paper\\'s claims. This feedback is somewhat helpful as it highlights a potential weakness in the paper\\'s references, but it lacks specific suggestions on how the authors might address this issue or update their references accordingly. While it provides some insight, the comment could be more helpful with additional guidance or examples on how to improve the paper. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that W1 and W2 are not defined, and it speculates that they might denote the Encoder and Decoder networks. It also mentions that W and V are not defined in the same context, providing specific references to page 3, line A4, and equation 3. This feedback is clear and directs the authors to define these terms, which is a concrete action for them to take. The comment is highly actionable as it provides specific guidance on what needs to be clarified or defined in the paper.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W1 and W2\" and \"W and V,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that these terms are not defined, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"W1 and W2 are not defined\" and speculates that they might denote the Encoder and Decoder networks. It also mentions that \"W and V are not defined\" and provides specific references to page 3, line A4, and equation 3. This claim is somewhat verifiable as it points out specific sections where the terms are not defined, providing some basis for the assertion. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that W1 and W2 are not defined and speculating that they might denote the Encoder and Decoder networks. It also points out that W and V are not defined in the same context, providing specific references to page 3, line A4, and equation 3. This feedback is clear and actionable, as it directs the authors to clarify these terms to avoid confusion and ensure the paper is understandable. However, the comment could be more helpful if it offered suggestions on how to define these terms or provided examples of how they might be used in the context of the paper. Overall, the comment is mostly helpful as it effectively guides the authors on how to improve the clarity and completeness of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also asks whether this alternating process could help improve performance. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification or analysis regarding the behavior of negative chips and the potential impact of the alternating process. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also asks whether this alternating process could help improve performance. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the behavior of negative chips and the potential impact of the alternating process. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also inquires whether this alternating process could help improve performance. This feedback is valuable as it prompts the authors to clarify their methodology and potentially identify areas for improvement. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or improve performance. Overall, the comment is somewhat helpful as it guides the authors to consider these aspects of their work, but it could be more actionable with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should evaluate their proposed approach on both new and old patients. While the comment implies that the authors should conduct this evaluation, it does not provide specific guidance on how to implement this suggestion or what aspects of the evaluation should be prioritized. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should evaluate their proposed approach on both new and old patients, which is a specific suggestion for improvement. However, it does not specify which part of the paper this evaluation should be included in, such as a particular section or experiment. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for an evaluation on new and old patients, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should evaluate their proposed approach on both new and old patients. However, it does not provide any supporting evidence, reasoning, or examples to justify why this evaluation is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should evaluate their proposed approach on both new and old patients, which is a relevant and actionable suggestion. However, it lacks depth and does not provide specific guidance on how to conduct this evaluation or what aspects of the approach should be tested on each patient group. While the comment identifies a potential area for improvement, it does not offer detailed instructions or examples to help the authors effectively implement this suggestion. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks in-depth analysis and suggests that the authors should provide an explanation for the observed inverse scaling over compute. This feedback is clear and provides a direct action for the authors to take, which is to include an analysis of the training dynamics. The comment is specific in its request for an explanation, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of in-depth analysis and suggests that the authors should provide an explanation for the observed inverse scaling over compute. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely an explanation of the training dynamics. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks in-depth analysis and suggests that the authors should provide an explanation for the observed inverse scaling over compute. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would enhance the paper. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of in-depth analysis and suggesting that the authors provide an explanation for the observed inverse scaling over compute. This feedback is clear and actionable, as it points out a specific area where the paper could be strengthened by including a deeper analysis. However, the comment could be more helpful if it provided examples or suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: whether the authors have any additional insights into modest performance gains on Clothing1M and how the algorithm performs on other real-world datasets like WebVision, evaluated by DivideMix. While these questions imply that the authors should provide additional information or analysis, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more insights or data. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions about the performance of the algorithm on Clothing1M and WebVision, evaluated by DivideMix. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions themselves are specific, as they ask for additional insights or performance evaluations on specific datasets. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions asking for additional insights and performance evaluations on specific datasets. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions that could help the authors gain additional insights into the performance of their algorithm on real-world datasets. By asking about modest performance gains on Clothing1M and the algorithm's performance on WebVision, evaluated by DivideMix, the reviewer encourages the authors to provide more detailed evaluations and comparisons. However, the comment lacks specific guidance or suggestions on how to address these questions or what additional insights would be beneficial. While it points out areas for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it identifies potential areas for enhancement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant gap in the paper, noting that it does not describe the hyperparameters used by each defense nor how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. While the comment identifies a clear area for improvement, it does not provide explicit instructions on how to address this issue. The authors are left to infer that they need to include this information, but the lack of concrete guidance on how to do so makes the action implicit. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of description regarding the hyperparameters used by each defense and how those hyperparameters are derived. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. It is also specific because it clearly specifies what needs to be addressed, namely the description of hyperparameters and their derivation. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a description of the hyperparameters used by each defense and how those hyperparameters are derived. The reviewer suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the importance of including this information and might find it challenging to understand the exact implications without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting that it lacks a description of the hyperparameters used by each defense and how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. This feedback is clear and actionable, as it points out a critical area for improvement in the paper. However, it could be more helpful if it provided specific guidance on how to implement this optimization or how to present the results. Overall, the comment is mostly helpful as it directs the authors to a crucial area for enhancement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the theoretical results do not have immediate practical implications, but acknowledges that this is understandable given the novelty of the work. It also expresses a desire for more practical takeaways for practitioners, specifically mentioning the idea of querying a cluster proportionally to the square root of its size. However, the comment does not provide explicit guidance on how to incorporate this suggestion or what specific aspects of the paper should be revised to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they should focus on making their results more practical and actionable. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the theoretical results and their practical implications, suggesting that the paper could provide more practical takeaways for practitioners. It mentions a specific take-away point regarding querying a cluster proportionally to the square root of its size, but does not specify which part of the paper this relates to. The authors can infer that it pertains to the theoretical results or methodology sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in suggesting that the paper should provide more practical insights, but it does not provide detailed guidance on how to achieve this. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical results do not have immediate practical implications, which is somewhat verifiable. The reviewer acknowledges the novelty of the work and suggests that more practical takeaways for practitioners would be beneficial. However, the comment lacks specific examples or references to support the claim that the theoretical results are not immediately applicable. The suggestion to query a cluster proportionally to the square root of its size is mentioned but not fully developed, leaving the authors to infer the significance of this point. Overall, the comment provides some basis for the claim but lacks detailed evidence or examples to fully substantiate it, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the theoretical results do not have immediate practical implications. It acknowledges the novelty of the work and suggests that more practical takeaways for practitioners would be beneficial. The comment provides a specific take-away point, namely querying a cluster proportionally to the square root of its size, but notes that it is unclear if this is a novel finding in the paper. While the comment highlights an area for improvement, it lacks detailed guidance on how to address this issue or what specific aspects of the paper should be revised to enhance its practical relevance. The feedback is somewhat helpful as it points out a potential weakness and suggests a direction for improvement, but it could be more comprehensive with additional suggestions or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the purpose of separators in section 4, specifically asking for additional information on what they contribute beyond T/I/O. While the comment identifies an area for clarification, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to provide more information or explanation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the purpose of separators and what additional information they provide beyond T/I/O. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the purpose of separators in section 4 and asks for additional information on what they contribute beyond T/I/O. This is a request for clarification and does not make a subjective claim or express an opinion. It is a factual inquiry seeking more information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the purpose of separators in section 4, specifically asking for additional information on what they contribute beyond T/I/O. This feedback is somewhat helpful as it identifies a potential area for clarification or expansion in the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional information could be provided. While it points out a potential gap in the explanation, it does not offer actionable steps for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. While it implies that the authors should consider alternative approaches, it does not explicitly instruct them to do so or provide specific guidance on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative pooling strategies. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. It does not present an opinion, judgment, or suggestion that requires verification. It is a request for clarification and does not contain subjective claims or assertions. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. This is a thought-provoking observation that could lead to a deeper understanding of the methodology and its implications. However, the comment lacks specific guidance or suggestions on how to explore alternative pooling strategies or what specific aspects of mean pooling should be questioned. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the training details of the VQGAN model, specifically inquiring whether it is pre-trained or only trained on a subset of images from the Computer Vision Figures dataset. While the comment implies that the authors should provide more information about the training process, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the training details but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"VQGAN\" and \"Computer Vision Figures dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the training details of the VQGAN model, specifically inquiring whether it is pre-trained or only trained on a subset of images from the dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the training details of the VQGAN model. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the training details of the VQGAN model, specifically inquiring whether it is pre-trained or only trained on a subset of images from the Computer Vision Figures dataset. This is a relevant point as it pertains to the methodology and transparency of the study. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it identifies a potential area for improvement, it does not offer actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include works such as [] Li, Xiujun, et al. \"End-to-end task-completion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and compare them to their work conceptually. Additionally, it recommends discussing how their work differs from other chatbox research works, such as [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015). These suggestions provide clear and explicit actions for the authors to take, including identifying relevant works and discussing their differences. The comment is concrete and provides specific guidance on how to enhance the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including works such as [] Li, Xiujun, et al. \"End-to-end task-completion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and discussing how their work differs from other chatbox research works, such as [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015). However, it does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in suggesting the inclusion of these works and the need for a discussion on differences, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include specific works, such as [] Li, Xiujun, et al. \"End-to-end task-completion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015), to compare their work with. The comment also recommends discussing how their work differs from other chatbox research works. While the suggestion is based on logical reasoning and common knowledge about the importance of including relevant works, it lacks specific examples or detailed justification for why these works are particularly relevant or how they differ from others. This makes the claim somewhat verifiable, as it provides a general direction but lacks detailed evidence or references to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors include relevant works, such as [] Li, Xiujun, et al. \"End-to-end task-completion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015), to compare their work with. It also recommends discussing how their work differs from other chatbox research works. This feedback is mostly helpful as it guides the authors on how to enhance their draft by incorporating relevant references and discussing their unique contributions. However, it could be more helpful if it provided additional context or examples of how these works differ from the current paper. Overall, the comment is mostly helpful as it offers clear and actionable suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed methods, DualIS and DualDIS, in terms of their generic applicability on cross-model retrieval tasks, specifically mentioning the minor improvements in MSVD (Table 3). However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the methods or what specific aspects of the methods need to be addressed. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DualIS and DualDIS,\" allowing the authors to accurately identify the specific methods being discussed. It also specifies the issue by pointing out that the methods are not generic on some cross-model retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some cross-model retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. However, the comment does not provide specific details or references to support this claim, such as data or comparisons with other methods. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the proposed methods, DualIS and DualDIS, by pointing out that they are not generic on some cross-model retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. This feedback is somewhat helpful as it highlights an area where the methods may not be as effective as expected, providing the authors with a specific issue to address. However, the comment could be more helpful if it offered suggestions on how to improve the methods or addressed the issue of generic applicability. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests that a simpler approach could be to run vanilla Adam on the final network with 40 random initial points, which would likely result in finding the global minimum. The comment implies that it is not necessary for each initialization to reach the global minimum, as long as at least one does. While the comment highlights a potential issue with the experimental setup, it does not provide explicit guidance on how to address this concern. The authors are left to infer that they should reconsider their experimental approach, but the lack of specific instructions or suggestions makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. It suggests a simpler approach, which is to run vanilla Adam on the final network with 40 random initial points. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the experimental setup and suggesting a simpler alternative. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the experimental strengths of the approach, specifically the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests that a simpler approach could be to run vanilla Adam on the final network with 40 random initial points, which would likely result in finding the global minimum. The claim is somewhat verifiable as it provides a logical reasoning for the alternative approach, but it lacks specific examples or references to support the claim that running vanilla Adam would be more effective. The authors would need to conduct their own analysis to verify the claim, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. It suggests a simpler alternative, which is to run vanilla Adam on the final network with 40 random initial points, which would likely result in finding the global minimum. This feedback is somewhat helpful as it points out a potential issue with the experimental setup and offers a suggestion for improvement. However, the comment could be more helpful if it provided more detailed reasoning or examples to support the alternative approach. Overall, the comment identifies a weakness but lacks depth and actionable guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the performance of FedSP is not the best in Tables 1 and 2 on some datasets, suggesting that the theme of the paper is mainly about FedSP. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the performance or what specific aspects of FedSP need attention. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the performance of FedSP is not the best in these tables on some datasets. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of FedSP is not the best in Tables 1 and 2 on some datasets. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of FedSP in Tables 1 and 2 on some datasets. It highlights that the theme of the paper is mainly about FedSP, but the performance is not the best. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might improve the performance or address this issue. Without specific recommendations or examples, the feedback does not offer much value to the authors in terms of improving their draft. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the authors should explore the new proposed dataset, DRRI, more thoroughly in the paper. However, it does not provide specific guidance on how to do so or what aspects of the dataset should be highlighted. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their exploration of the dataset but without detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper should have more exploration or what aspects of the dataset should be highlighted. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this exploration is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should explore the new proposed dataset, DRRI, more thoroughly in the paper. However, it lacks specificity and does not provide guidance on how to effectively integrate this exploration into the paper or what aspects of the dataset should be highlighted. Without detailed suggestions or examples, the authors are left with a general direction but without actionable steps to improve their draft. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment states a fact about the limitations of pruning techniques on GPUs, which is not an actionable statement. It does not provide any guidance or suggestions for the authors to improve their draft. As a result, the authors are left without any actionable steps to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it addresses. It is a general statement about the limitations of pruning techniques on GPUs, which does not provide any specific context or guidance for the authors to improve their draft. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"it is not yet possible to realize efficiency gains on GPU\" regarding work on pruning. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment is a general observation about the limitations of pruning techniques on GPUs, which is not particularly helpful to the authors. It does not provide any specific insights or suggestions for improvement, nor does it offer guidance on how to address the issue. Without actionable feedback or constructive criticism, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the impact of the method on insurance costs for men and women. While it does not explicitly instruct the authors to provide this information, the question implies that the authors should include this analysis in their paper. The action is implicit but concrete, as the authors can infer that they need to include this information to address the reviewer\\'s concern. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment poses a question about the impact of the method on insurance costs for men and women, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where this information should be addressed. Additionally, the comment lacks specificity regarding what aspects of the insurance costs should be analyzed or how the method affects them. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the impact of the method on insurance costs for men and women. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a specific question about the impact of the method on insurance costs for men and women. This is a relevant and important question that could help the authors understand the practical implications of their work. However, the comment lacks depth and does not provide any context or explanation about why this information is important or how it could be incorporated into the paper. While it identifies a potential area for improvement, it does not offer detailed guidance or suggestions on how to address this question. Therefore, the comment is somewhat helpful, as it points out a relevant area for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify the difference between the meta solvers and centralized RL, specifically mentioning a reference to Foester et al. (NIPS 2016) as an example. This provides a clear and concrete action for the authors to take, as they are given a specific area to address and a reference to guide their understanding. The comment is highly actionable because it clearly identifies what needs to be clarified and provides a concrete example to follow.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"meta solvers\" and the \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the difference between the meta solvers and centralized RL, and provides a reference to Foester et al. (NIPS 2016) to guide the authors in understanding this difference. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the meta solvers are centralized controllers, and suggests that the authors should clarify the difference between them and centralized RL. The reviewer provides a reference to Foester et al. (NIPS 2016) to support this claim. However, the comment lacks detailed explanation or analysis of why the meta solvers are considered centralized controllers, making it somewhat verifiable. The reference to Foester et al. provides some support, but the authors would need to further explore the context and implications of the claim to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper regarding the classification of the meta solvers as centralized controllers. It suggests that the authors should clarify the difference between the meta solvers and centralized RL, where agents share weights. The comment provides a specific reference to Foester et al. (NIPS 2016) as an example of centralized RL, which is a clear and actionable suggestion for the authors to consider. This feedback is mostly helpful as it guides the authors to clarify a key aspect of their work, which could enhance the understanding and clarity of their paper. However, it could be more helpful if it included additional details or examples on how the authors might address this issue. Overall, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. It provides an example of the BERT paper being available on arxiv in October, suggesting that the authors should consider this issue in their paper. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider the availability of papers on arxiv. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of splitting papers according to their publication years on the ACL anthology, noting that many papers are available on arxiv much earlier. It provides an example of the BERT paper being available on arxiv in October. However, the comment does not specify which part of the paper discusses the splitting of papers, making it weakly grounded. The comment is specific in pointing out the issue of papers being available on arxiv before being published in the ACL anthology. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. The reviewer provides an example of the BERT paper being available on arxiv in October, which supports the claim. However, the comment could be strengthened by providing more examples or detailed reasoning on why this issue is significant. As it stands, the claim is somewhat verifiable, as it relies on a specific example but lacks comprehensive evidence or detailed explanation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s methodology, noting that it splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. This is a relevant observation that could impact the paper\\'s credibility and relevance. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as discussing the implications of this discrepancy or suggesting ways to improve the paper\\'s timeliness. While it points out a potential weakness, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises two concerns: the use of an arbitrary parameter \u03b2 in rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The authors are left to infer that they need to clarify the use of \u03b2 and the difference between QRS and RS, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the proposed relaxation of rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. The comment provides a clear direction for improvement by suggesting that the authors clarify the use of \u03b2 and the difference between QRS and RS. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the use of an arbitrary parameter \u03b2 in rejection sampling and questions the lack of clarity regarding the difference between QRS and RS in Algorithm 1. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the authors should have used Importance sampling instead of rejection sampling. Additionally, the comment lacks specific examples or detailed explanations to support the claim about the difference between QRS and RS. As a result, the claim is not verifiable, as it does not provide sufficient evidence or justification for the authors to understand or address the critique. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the use of an arbitrary parameter \u03b2 in rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. While the comment highlights these areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it points out areas that need attention, but it could be more beneficial if it offered actionable steps or examples to improve the draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the cause of this similarity. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or improve the experimental results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental results on the last two datasets, specifically mentioning the performance being similar to IRM. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the issue with the experimental results, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method. However, it does not provide any specific evidence, reasoning, or examples to support this claim. The mention of \"IRM\" is not sufficient to substantiate the claim, as it does not explain why the performance is similar to IRM or how this relates to the issues mentioned above. Without detailed justification or references, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the effectiveness of the proposed method. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their experimental results. Without detailed guidance or examples, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as barely helpful, as it points out a potential weakness but does not offer sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of detecting both entities in the example of Figure 2, and it asks for clarification on the difference between detecting both entities and just detecting the long one. While the comment implies that the authors should provide a clearer explanation or rationale for this distinction, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of detecting both entities in the example and asking for clarification on the difference between detecting both entities and just detecting the long one. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the necessity of detecting both entities in the example of Figure 2, and it asks for clarification on the difference between detecting both entities and just detecting the long one. While the comment identifies a potential area of confusion or misunderstanding in the paper, it does not provide specific guidance or suggestions on how to address this issue. The authors are left with a vague understanding of what needs to be clarified, which limits the comment\\'s helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the phrase \"non-sequential information such as chunks\" in line 285, suggesting that the term \"chunks\" might be considered sequential information. However, it does not provide any explicit guidance or suggestions on how the authors should address this confusion or clarify their terminology. The action is implicit and vague, as the authors are left to infer that they need to reconsider their terminology. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the phrase \"non-sequential information such as chunks,\" suggesting that the term \"chunks\" might be considered sequential information. This provides clear guidance on what needs to be clarified or revised. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification regarding the phrase \"non-sequential information such as chunks.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the phrase \"non-sequential information such as chunks\" in line 285, suggesting that the term \"chunks\" might be considered sequential information. This question highlights a potential confusion in the paper that could be clarified to improve the clarity and coherence of the text. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their terminology. While it identifies a potential area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the upper bound in Theorem 1, which seems correct but contains an exception. The reviewer asks how to explain this exception, implying that the authors should provide an explanation or clarification. However, the comment does not explicitly instruct the authors to do so, nor does it offer specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the upper bound in Theorem 1 and asks for an explanation of an exception. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the correctness of Theorem 1 and an observation about an exception. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the correctness of Theorem 1 and points out an exception regarding a separate node with 0 neighbors. This question highlights a potential issue in the paper that the authors may need to address. However, the comment does not provide specific guidance or suggestions on how to address this issue or explain the exception. While it identifies a potential weakness, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out a potential problem but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the paper regarding the handling of rumors generated by GPT, specifically questioning the rationale behind why GPT-generated rumors are similar to natural rumors in terms of difficulty to detect. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that further analysis or solutions could be proposed, but it lacks specific details or steps on how to conduct such analysis or propose solutions. As a result, the action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be done but without clear instructions on how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the handling of rumors generated by GPT, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the challenges of detecting rumors generated by GPT and questions why GPT-generated rumors are similar to natural rumors in terms of difficulty to detect. The comment suggests further analysis or solutions could be proposed, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the rationale behind why GPT-generated rumors are similar to natural rumors in terms of difficulty to detect, suggesting that Artificial Rumor should be about the same difficulty as Natural Rumor. The comment provides a logical reasoning by pointing out that Artificial Rumor is also written by humans, which should make it similar in difficulty to Natural Rumor. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further explore the reasoning themselves to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the handling of rumors generated by GPT, specifically questioning the rationale behind why GPT-generated rumors are similar to natural rumors in terms of difficulty to detect. It points out that Artificial Rumor, which is also written by humans, should be about the same difficulty as Natural Rumor, yet the experimental result shows the opposite. This feedback highlights an important area for further analysis or discussion, suggesting that the authors could explore the reasons behind this discrepancy and potentially propose solutions. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Overall, the comment is somewhat helpful as it directs the authors to consider a critical aspect of their work but lacks detailed guidance on how to proceed.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical contribution or what specific changes should be made to Section 4. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the technical contribution, stating that it is limited and not about a formal and principled solution but rather about heuristics. This provides clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the technical contribution of the paper, specifically noting that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. This feedback highlights an area where the paper could be improved by providing a more comprehensive and rigorous approach to the technical contribution. However, the comment lacks specific suggestions or guidance on how to address this issue or what aspects of the heuristics should be improved. While it points out a potential weakness, it does not offer actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the probability mass function (PMF) is not being fully utilized in the experimental setting and recommends considering various PMFs for each learner class. It also mentions that the quasi-uniform distribution used in MixBoost is dependent on a single parameter and suggests that individual consideration of each learner class would add depth to the experimental setting. However, the comment does not provide specific guidance on how to implement this suggestion or which PMFs to consider. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"probability mass function\" and the \"MixBoost\" setting, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the use of a quasi-uniform distribution and suggests considering various probability mass functions for each learner class. This provides clear guidance on what needs to be addressed in the experimental setting. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the probability mass function is not being fully utilized in the experimental setting, specifically mentioning the use of a quasi-uniform distribution in MixBoost. The reviewer suggests that considering various probability mass functions for each learner class would add depth to the experimental setting. However, the comment lacks specific examples or references to support the claim that a quasi-uniform distribution is not ideal. While the reasoning is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setting, noting that the probability mass function is not being fully utilized in the MixBoost setting. It suggests that considering various probability mass functions for each learner class would add depth to the experimental setting. While the comment highlights a potential area for improvement, it lacks specific guidance on how to implement this suggestion or which probability mass functions to consider. The feedback is somewhat helpful as it points out a potential weakness but does not provide detailed instructions on how to address it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should address this issue, provide additional context, or clarify their methodology. As a result, the authors are left without any clear direction on how to respond to this comment. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on how the authors should address this concern. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is not grounded and lacks specificity, making it difficult for the authors to understand and act upon the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is unfair. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a valid point about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. This is an important consideration for the authors to address, as it could impact the interpretation and comparison of results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what specific aspects of the comparison should be considered. While it identifies a potential weakness, it does not provide actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the missing references, specifically mentioning [a], which is relevant to the topic of the paper. It suggests discussing connections with [a], which uses supervised learning in QBF solving, where QBF generalizes SMT. However, the comment does not provide explicit instructions on how to incorporate these references or discuss the connections. While the authors can infer that they need to include these references and discuss the connections, the lack of concrete guidance on how to do so makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific references, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the connections with [a], which uses supervised learning in QBF solving, where QBF generalizes SMT. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper is missing relevant references, specifically mentioning [a], which uses supervised learning in QBF solving. The reviewer provides a specific reference to support the claim that this work is relevant to the paper\\'s topic. However, the comment lacks detailed reasoning or explanation about why this reference is important or how it relates to the paper\\'s content. While the reference is provided, the lack of detailed justification or explanation makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and incorporate the reference. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue by pointing out the missing references, especially [a], which is relevant to the topic of the paper. It suggests discussing connections with [a], which uses supervised learning in QBF solving, where QBF generalizes SMT. This feedback is clear and actionable, as it provides a specific direction for the authors to explore and incorporate relevant references into their work. However, the comment could be more helpful if it offered additional guidance on how to integrate these references or what specific aspects of the work should be discussed. Overall, the comment is mostly helpful as it directs the authors to a relevant area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider whether the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss can be replaced by other relationships. It also suggests that explaining this point may be beneficial. While the comment implies that the authors should explore alternative relationships, it does not provide specific guidance on how to do so or what specific alternative relationships to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the training process and the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests exploring alternative relationships and provides a reference to a related work for further consideration. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss is replaced by other relationships. The reviewer supports this claim by referencing a related work, \"Learning the Pareto Front with Hypernetworks,\" which suggests that the mono tonic relationship can be replaced by other relationships. However, the comment does not provide detailed reasoning or examples from the referenced work to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a reference but lacks comprehensive justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific aspect of the training process that could be improved by exploring alternative relationships to the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss. It suggests that this could lead to a continuous parameterization of the Pareto Front. The comment also references a related work, \"Learning the Pareto Front with Hypernetworks,\" which provides a potential direction for further exploration. While the comment highlights an area for improvement, it lacks specific guidance on how to implement this exploration or what alternative relationships to consider. This limits the comment\\'s helpfulness, as it provides a general direction but does not offer detailed steps for the authors to follow. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the comparison in terms of computation cost or running time. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what aspects of the computation cost or running time should be compared, nor are there suggestions for how to present this information or what specific insights should be drawn from it. As a result, the authors are left without any clear direction on how to address this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the comparison in terms of computation cost or running time, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the computation cost or running time should be compared or how this comparison should be presented. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the comparison in terms of computation cost or running time, but it does not contain any subjective claims, opinions, or suggestions that require verification. It is a request for clarification or additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the comparison in terms of computation cost or running time, which could be an important aspect of the paper. However, it does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the comparison should be considered. Without actionable feedback or context, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it identifies a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address these concerns or improve the paper in response. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the privacy preservation issue and the example of traffic signal control, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control, suggesting that this example is a poor choice for demonstrating federated learning. However, the comment lacks any supporting evidence, reasoning, or references to substantiate these claims. Without detailed justification or examples, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control, suggesting that this example is a poor choice for demonstrating federated learning. While the comment identifies a potential weakness in the paper\\'s argument, it lacks specific guidance or suggestions on how the authors might address this issue or improve the paper. The feedback is somewhat helpful as it points out a potential area for improvement, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the description of the neural network is difficult to understand and recommends starting the section with the final paragraph that clarifies it. While the comment provides a specific suggestion to improve the clarity of the section, it does not offer detailed guidance on how to achieve this clarity or what specific changes should be made to the description. The action is implicit and somewhat vague, as the authors need to infer that they should start the section with the clarifying paragraph. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"528,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of the neural network, suggesting that it is hard to understand and recommending starting the section with the final paragraph that clarifies it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of the neural network is hard to understand and suggests starting the section with the final paragraph that clarifies it. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the description of the neural network, noting that it is hard to understand. It suggests starting the section with the final paragraph that clarifies the description, providing a clear and actionable suggestion for improvement. This feedback is somewhat helpful as it points out a specific area that needs attention and offers a concrete way to address it. However, it could be more helpful if it included additional context or examples to help the authors understand the challenges in the current description. Overall, the comment is somewhat helpful as it provides a clear direction for improvement but lacks depth and detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitations of the model and suggests exploring attention-based encoder-decoder training as an alternative. While it implies that the authors should consider this option, it does not provide explicit instructions or concrete steps on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative approach. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the limitations of the model and suggests exploring attention-based encoder-decoder training as an alternative. However, it does not specify which part of the paper this limitation or suggestion pertains to, making it weakly grounded. The comment is specific in suggesting an alternative approach, but without clear grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the limitations of the model and suggests exploring attention-based encoder-decoder training as an alternative. However, it does not provide any supporting evidence, reasoning, or references to justify why the current approach is limited or how attention-based training might be beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the limitations of the model and suggests exploring attention-based encoder-decoder training as an alternative. While it identifies a potential area for improvement, it lacks depth and does not provide specific guidance or examples on how to implement this change or what benefits it might offer. The comment is somewhat helpful as it points out a potential direction for improvement, but it does not offer actionable steps or detailed reasoning to support the suggestion. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive to be fully beneficial.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the division of tables into three types, specifically questioning the necessity of having three types. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what changes should be made to the tables. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3 (line 247-252),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the division of tables into three types and suggesting that one type (the column header) should work. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the division of tables into three types, specifically questioning the necessity of having three types. However, it does not provide any supporting evidence, reasoning, or references to justify why this division is problematic or how it could be improved. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the division of tables into three types, specifically questioning the necessity of having three types. However, it does not provide any actionable feedback or suggestions for improvement. Without additional context or guidance, the authors are left without a clear understanding of what changes, if any, should be made to address this concern. As a result, the comment is not helpful, as it lacks depth and does not assist the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. It provides specific examples of such methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. However, the comment does not explicitly instruct the authors to use these methods or provide guidance on how to integrate them into their work. While the action is implied, it is not as clear as it could be, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"attack methods\" and \"toy setting with classification tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not consider other classical attack methods in NLP and suggests specific examples from other papers. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. The reviewer provides specific examples of such methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. However, the comment lacks detailed reasoning or evidence to support why these methods are more effective or why the current methods are inadequate. While the examples are provided, the justification for the claim is not fully developed, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the attack methods used are naive and that the paper does not consider other classical attack methods in NLP. It provides specific examples of alternative methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. This feedback is clear and actionable, as it guides the authors to consider a broader range of attack methods that could enhance the robustness and generalizability of their work. However, the comment could be more helpful if it explained why these alternative methods are more effective or how they might be integrated into the paper. Overall, the comment is mostly helpful as it directs the authors to consider a wider range of attack methods, but it could be further improved with additional guidance or rationale.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not provide explicit guidance on how to address these concerns or what specific steps the authors should take to mitigate these risks. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not specify which part of the paper this concern is related to, such as a specific section or experiment where this issue might arise. Without explicit references to sections or experiments, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specific guidance on how to address these concerns or what steps to take to mitigate the risks. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. While the comment identifies a critical issue, it lacks specific guidance or suggestions on how the authors might address this concern or mitigate the risks. The feedback is somewhat helpful as it points out a potential problem but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this observation or what changes they should make to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by expressing surprise about the dominance of function words over content words in a Japanese sentence. However, the comment lacks specificity regarding what aspect of the dominance is surprising or how it might impact the paper. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it lacks any actionable feedback or suggestions for improvement. Without further explanation or context, the authors are left without a clear understanding of what aspect of this observation is relevant to their work or how it might impact their analysis. As a result, the comment does not provide any meaningful guidance for the authors to enhance their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that using the average of multiple k-means objectives with different seeds as a baseline is not ideal and recommends using the minimum k-means objective over multiple seeds instead. The reviewer provides a rationale by referencing two external sources, [1] and [2], which discuss the properties of k-means clustering and its applicability to different datasets. This explicit suggestion and the inclusion of references provide clear guidance on what the authors should consider as a more reasonable baseline for their analysis. The action is explicit and concrete, as the authors know exactly what to change to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of the average of multiple k-means objectives with different seeds as a baseline, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the suggestion to use the minimum k-means objective over multiple seeds instead. This provides clear guidance on what the authors should consider as a more reasonable baseline for their analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that using the average of multiple k-means objectives with different seeds as a baseline is not ideal and recommends using the minimum k-means objective over multiple seeds instead. The reviewer supports this claim by referencing two external sources, [1] and [2], which discuss the properties of k-means clustering and its applicability to different datasets. This provides a logical basis for the claim, as it aligns with established knowledge in the field. However, the comment could be strengthened by providing more detailed explanations or examples from the referenced sources to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to improve the paper by recommending the use of the minimum k-means objective over multiple seeds as a baseline instead of the average. This feedback is based on a logical reasoning that aligns with established knowledge in the field, as evidenced by the references to external sources [1] and [2]. By suggesting a more appropriate baseline, the comment offers a concrete way for the authors to enhance the robustness and generalizability of their results. However, the comment could be more helpful if it explained why the average is not ideal or how the minimum k-means objective might be more beneficial. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be further enhanced with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of an important reference, specifically the paper \"Lista,\" which is relevant to the idea of unrolling. It also highlights the importance of discussing similarities and differences with Lista and placing the paper in appropriate context. This feedback provides a clear and concrete action for the authors to take, which is to include the missing reference and discuss the similarities and differences with Lista. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the missing reference, \"Lista,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the importance of discussing similarities and differences with \"Lista\" and placing the paper in appropriate context. This level of detail provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that an important reference is missing, specifically the paper \"Lista,\" which is relevant to the idea of unrolling. The reviewer suggests that the paper should discuss similarities and differences with \"Lista\" and place itself in appropriate context. While the comment identifies a specific reference, it lacks detailed reasoning or examples to fully substantiate the claim that the paper is missing this reference. The authors would need to infer the importance of including this reference and the potential impact on the paper. Therefore, the comment is somewhat verifiable, as it provides a starting point for the authors to explore but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical omission in the paper, specifically the absence of an important reference, \"Lista,\" which is relevant to the idea of unrolling. It highlights the importance of discussing similarities and differences with \"Lista\" and placing the paper in appropriate context. This feedback is clear and actionable, as it directs the authors to include the missing reference and address the relationship with \"Lista.\" By doing so, the authors can enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided specific guidance on how to discuss the similarities and differences with \"Lista\" or how to contextualize the paper within the literature. Overall, the comment is mostly helpful as it points out a significant oversight and offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for clarification on the definition of the sparsity of the residual term and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. It also recommends showing the advantages of the proposed method compared to existing methods. While the comment provides clear and specific actions for the authors to take, it does not offer detailed guidance on how to present this evidence or what specific aspects should be highlighted. The authors are given a clear direction but may need to infer the exact steps to follow. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"specific definition of the sparsity of the residual term,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the definition and suggests providing evidence to support the sparsity assumption across various noisy cases. Additionally, it recommends comparing the proposed method with existing methods and highlighting its advantages. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the specific definition of the sparsity of the residual term in the paper. It suggests that the authors provide evidence to support the sparsity assumption across various noisy cases and recommends comparing the proposed method with existing methods to highlight its advantages. While the comment identifies a potential issue with the clarity of the definition, it lacks specific examples or references to support the claim that the sparsity assumption is not well-founded. The suggestion to provide evidence is logical, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the definition of the sparsity of the residual term in the paper. It suggests that the authors provide evidence to support the sparsity assumption across various noisy cases and recommends comparing the proposed method with existing methods to highlight its advantages. This feedback is clear and actionable, as it guides the authors to clarify their definition and provide evidence to strengthen their claims. By addressing these points, the authors can improve the clarity and robustness of their work. However, the comment could be more helpful if it provided specific examples or references to existing methods that could be used for comparison. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to the terminology. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"connectivity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is wrong with the term \"connectivity,\" namely that it does not refer to the structural connections between the brain and body. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the term \"connectivity,\" noting that it is misleading as it does not refer to the structural connections between the brain and body. This feedback is valuable as it highlights a potential source of confusion in the paper, which could be clarified to improve the accuracy and precision of the terminology. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue or what specific changes could be made to improve the clarity of the terminology. While it points out a relevant concern, it does not offer actionable guidance, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific guidance on what aspects are missing or how to address these issues. The authors are left to infer that they need to improve the clarity, quality, novelty, and reproducibility of their work, but without concrete suggestions or examples, they may struggle to know exactly what changes to make. The comment is vague and lacks explicit instructions, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not specify which parts of the paper are missing these details, making it difficult for the authors to pinpoint the exact sections that need improvement. Additionally, the comment references \"Clarity, Quality, Novelty And Reproducibility,\" but does not provide specific examples or details from these sections. This lack of specificity and grounding makes it challenging for the authors to understand and address the issues effectively. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests that these are areas of concern, but without further elaboration or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several areas where the paper is lacking, including clarity, quality, novelty, and reproducibility. However, it does not provide specific examples or detailed feedback on what aspects of these categories are missing or how they could be improved. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests that the authors should address these issues, but without further guidance or suggestions, the comment lacks depth and actionable advice. This makes it somewhat helpful, as it points out areas for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit guidance on what the authors should do to improve their draft. It suggests that the authors should study the essentialness of using an orthogonal matrix for the weight matrix in the local window MLP, as it is a crucial part of the validation process. The comment is clear and provides concrete steps for the authors to take, such as conducting additional experiments or analysis to validate the use of orthogonal matrices. Therefore, the comment is highly actionable, as it directly instructs the authors on how to address the issue.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Step 2\" and \"Step 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that Step 3 is the crucial part that requires validation, and it suggests studying the essentialness of using an orthogonal matrix for the weight matrix. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Step 3 is the \"vital part\" that requires validation, as it is only possible with an orthogonal weight matrix. The reviewer suggests that the authors should study the essentialness of using an orthogonal matrix rather than just following the form that connects local and global windows. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the importance of the claim and potentially conduct additional research to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that Step 3 is the \"vital part\" that requires validation, as it is only possible with an orthogonal weight matrix. The reviewer suggests that the authors should study the essentialness of using an orthogonal matrix rather than just following the form that connects local and global windows. This feedback is clear and actionable, as it provides a direction for the authors to explore and validate the use of orthogonal matrices in their work. However, the comment could be more helpful if it offered specific suggestions or examples of how to conduct this validation or what aspects to focus on. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the models and datasets used are too toy-like and recommends using CIFAR100, ResNet 34 or 50, and ViT-tiny or small. It also asks if there are foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\\'s score. While the comment provides specific recommendations for datasets and models, it lacks concrete guidance on how to implement these changes or what specific aspects of the language tasks should be addressed. The action is explicit but somewhat vague, as the authors know what changes to make but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the models and datasets, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the need for CIFAR100, ResNet 34 or 50, and ViT-tiny or small, and raises questions about language tasks. However, the comment does not provide specific guidance on how to address these issues or what aspects of the language tasks should be considered. Therefore, it is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the models and datasets used are \"toy-like\" and suggests that the authors should consider using CIFAR100, ResNet 34 or 50, and ViT-tiny or small. The reviewer also asks about the foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\\'s score. While the comment provides a logical reasoning for the need for more diverse datasets and models, it lacks specific examples or references to support the claim that the current models are too toy-like. The suggestion to use CIFAR100 is a specific example, but the comment could be strengthened by providing more detailed reasoning or examples. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but lacks sufficient evidence or references to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the models and datasets used in the paper, noting that they are too toy-like and suggesting the inclusion of more challenging datasets like CIFAR100, ResNet 34 or 50, and ViT-tiny or small. It also raises a question about the foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\\'s score. While the comment provides clear and actionable feedback on improving the dataset and model selection, it could be more helpful if it offered specific guidance on how to address the language task challenges or provided examples of how other studies have addressed similar issues. Overall, the comment is mostly helpful as it directs the authors to make significant improvements in their work, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of natural ablation studies, specifically mentioning the impact of pretraining on scratchGAN. It suggests that this is a crucial baseline to include, especially given the central argument against pretraining. The comment also includes minor comments and questions, such as the need for more discussion on the results. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to implement these changes or what specific aspects of the ablation studies should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of natural ablation studies, specifically mentioning scratchGAN and the need for a baseline with pretraining. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a baseline with pretraining and the need for more discussion on the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that some natural ablation studies are missing, specifically mentioning the impact of pretraining on scratchGAN. The reviewer claims that this is a crucial baseline to include, as it relates to the central argument against pretraining. However, the comment lacks specific examples or detailed reasoning to support why this baseline is crucial or how it would impact the central argument. The suggestion is somewhat verifiable, as it points to a potential area for improvement but requires more detailed justification to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the inclusion of natural ablation studies, particularly focusing on the impact of pretraining on scratchGAN. This is a crucial baseline that could strengthen the paper\\'s argument against pretraining. Additionally, the comment includes minor comments and questions, such as the need for more discussion on the results. While the comment highlights important areas for improvement, it lacks detailed guidance or suggestions on how to implement these changes. Therefore, the authors are given a clear direction but may need to infer more specific details to fully address the feedback. This makes the comment somewhat helpful, as it provides a starting point for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of comparison against baselines and notes that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering baselines. It suggests that this is a widely-understood binary analysis application and that many papers have developed architecture-agnostic similarity comparison (or codesearch). While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include comparisons against baselines, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not offer specific steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of comparison against baselines and the need for architecture-agnostic similarity comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comparison against baselines and that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering baselines. The reviewer supports this claim by referencing the widely-understood nature of binary analysis applications and the existence of architecture-agnostic similarity comparison (or codesearch) in many papers. This provides a logical basis for the claim, but the comment could be strengthened by providing specific examples or references to these papers. Therefore, the comment is somewhat verifiable, as it provides a logical reasoning but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of comparison against baselines and the limited scope of the functionality similarity comparison study. It highlights that this is a widely-understood binary analysis application and that many papers have developed architecture-agnostic similarity comparison (or codesearch). This feedback is clear and actionable, as it points out a critical area for improvement in the paper. However, it could be more helpful if it provided specific suggestions on how to address this gap, such as which baselines to consider or how to implement the suggested architecture-agnostic similarity comparison. Overall, the comment is mostly helpful as it directs the authors to a crucial area for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to mention that the preprocessing in SI 6.5 is identical to that in Mnih et al. [7], but the evaluation is slightly different due to the absence of human starts. This is a clear and direct action for the authors to take, as it provides a specific point to address in their draft. The comment is concrete, as it specifies the exact part of the paper where the mention should be made and the issue with the evaluation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the mention of preprocessing being identical to Mnih et al. [7] and the evaluation being different due to the absence of human starts. This provides clear guidance on what the authors need to address in this section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation in SI 6.5 is different from that in Mnih et al. [7] due to the absence of human starts. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation in SI 6.5, noting that the preprocessing is identical to that in Mnih et al. [7] but the evaluation is different due to the absence of human starts. This feedback is clear and actionable, as it directs the authors to make a specific mention in the paper to clarify this difference. By addressing this point, the authors can improve the clarity and accuracy of their evaluation. However, the comment could be more helpful if it provided additional context or suggestions on how to effectively communicate this difference. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while the authors claim advantages over previous work in terms of efficiency, the paper does not report any metric to substantiate this claim. This implies that the authors should include metrics to demonstrate the efficiency of their proposed method. However, the comment does not specify which metrics should be used or how they should be presented, leaving the authors with a general direction but without concrete guidance on execution. The action is implicit and somewhat vague, as it highlights a gap in the paper but does not provide detailed instructions on how to address it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discuss advantages over previous work in terms of efficiency. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of metrics to demonstrate the efficiency of the proposed method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks metrics to demonstrate the efficiency of the proposed method. However, it does not provide any supporting evidence or examples to substantiate this claim. Without specific metrics or references to previous work that demonstrate the efficiency of the proposed method, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting that while the authors claim advantages over previous work in terms of efficiency, they do not report any metrics to substantiate this claim. This is a critical point that could impact the credibility of the paper, as it lacks empirical evidence to support the claim. The comment highlights a clear area for improvement, suggesting that the authors should include metrics to demonstrate the efficiency of their proposed method. However, it does not provide specific guidance on which metrics to use or how to present them, leaving some room for interpretation. Overall, the comment is somewhat helpful as it points out a critical issue but could be more actionable with additional details. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to expand the contribution or what specific aspects of the paper could be strengthened. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it does not specify which part of the paper this critique is based on, such as the introduction, methodology, or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention or improvement. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment lacks specific reasoning or evidence to support why the contribution is considered limited. It does not provide examples, comparisons, or references to similar work that might substantiate the claim. As a result, the claim is not fully verifiable, making it difficult for the authors to understand and address the critique. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it does not provide any specific feedback or suggestions on how the authors could enhance the contribution or improve the paper. Without actionable guidance or constructive criticism, the authors are left without a clear path forward to address the perceived limitations. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more details about the state-space, whether it is finite or continuous, and the actions involved. It also questions the space in which theta lies and suggests that the authors should be precise in their explanations. This feedback is clear and concrete, as it specifies exactly what information is missing and how to address it. The authors know exactly what details to include and how to clarify their explanations, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as providing more details about the state-space, whether it is finite or continuous, and the actions involved. The comment also questions the space in which theta lies and suggests that the authors should be precise in their explanations. This level of detail provides clear guidance on what needs to be improved, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for more details about the state-space, whether it is finite or continuous, and the actions involved. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by requesting more details about the state-space, whether it is finite or continuous, and the actions involved. It also questions the space in which theta lies and suggests that the authors should be precise in their explanations. While the comment provides clear guidance on what additional information is needed, it could be more helpful if it offered suggestions on how to present this information or provided examples of what such details might entail. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The reviewer also mentions that the authors acknowledge this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment identifies a problem, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the proof technique and its applicability. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W2.3. Proof Technique\" and \"Appendix A,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The comment further specifies that this issue is acknowledged in Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof technique in Appendix A relies on a special case where a contradiction arises as matrix norms approach infinity, which is acknowledged in Section 3. The reviewer provides a specific reference to Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. This reference provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. This is acknowledged in Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment highlights a potential weakness in the paper, it does not provide actionable suggestions or guidance on how the authors might address this issue or improve the proof technique. The feedback is somewhat helpful as it points out a specific area for improvement, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider using LiDAR-based segmentation as the downstream task instead of object detection. The reviewer provides a rationale for this suggestion, stating that LiDAR-based segmentation is the best choice due to its ability to learn accurate locations and poses, especially in benchmarks using IoU-based metrics like KITTI and Waymo. However, the comment does not provide explicit instructions or concrete steps on how to implement this change or what specific aspects of the current approach need to be adjusted. While the suggestion is clear, the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider using LiDAR-based segmentation as the downstream task instead of object detection. However, it does not specify which part of the paper discusses the downstream task or the current use of object detection. The comment also lacks specificity regarding why LiDAR-based segmentation is considered the best choice or how it would improve the paper. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that LiDAR-based segmentation is a better choice for the downstream task than object detection, citing the ability of LiDAR to learn accurate locations and poses, especially in benchmarks using IoU-based metrics like KITTI and Waymo. However, the comment lacks specific examples or detailed reasoning to support why LiDAR-based segmentation is considered superior to object detection. The claim is somewhat verifiable, as it provides a logical argument but lacks the depth and evidence needed for full verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a subjective opinion on the choice of downstream task, suggesting that LiDAR-based segmentation is a better option than object detection. The reviewer provides a rationale for this suggestion, stating that LiDAR-based segmentation can learn accurate locations and poses, especially in benchmarks using IoU-based metrics like KITTI and Waymo. However, the comment lacks specific guidance or suggestions on how the authors might implement this change or what aspects of the current approach might be improved by using LiDAR-based segmentation. While the feedback provides a direction for improvement, it does not offer actionable steps or detailed reasoning, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential contradiction between the objective of Equation (12) and the Inverse Proportionality Operator (IPO). However, it does not provide any guidance on how the authors should address this issue or suggest specific actions to resolve the contradiction. The comment lacks explicit instructions or concrete details on how to improve the draft, leaving the authors uncertain about what steps to take. As a result, the action is implicit and vague, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the objective of Equation (12) and its relation to the Inverse Proportionality Operator (IPO). However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the contradiction between the objective and IPO, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the objective of Equation (12) is in contradiction with the Inverse Proportionality Operator (IPO). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential contradiction between the objective of Equation (12) and the Inverse Proportionality Operator (IPO). This is a critical observation that could impact the validity and applicability of the work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify the contradiction. Without actionable advice or detailed feedback, the authors are left with a general direction for improvement but no clear path forward. Therefore, the comment is somewhat helpful, as it points out a potential problem but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the adaptation capacity of the proposed visual memory when accommodating ever-growing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve the adaptation capacity. The comment lacks actionable details, such as recommending specific experiments or modifications to the model architecture. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the adaptation capacity of the proposed visual memory in accommodating ever-growing concepts, specifically questioning whether the image encoder can produce meaningful embeddings for new concepts. However, it does not specify which part of the paper this concern is discussed in, making it weakly grounded. The comment is specific in its questioning of the adaptation capacity for different types of concepts, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the adaptation capacity of the proposed visual memory when accommodating ever-growing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. However, the comment lacks specific examples or references to support the claim that the adaptation capacity may be an issue for certain types of concepts. Without detailed evidence or reasoning, the claim remains somewhat verifiable, as it provides a logical basis but lacks the necessary support to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the adaptation capacity of the proposed visual memory when accommodating ever-growing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. While the comment identifies a potential weakness in the model\\'s ability to adapt to new concepts, it lacks specific suggestions or guidance on how the authors might address this concern or improve the adaptation capacity. The feedback is somewhat helpful as it points out a potential issue but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should include a comparison against state-of-the-art loss functions commonly used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This is a clear and concrete action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment provides a specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding a comparison against state-of-the-art loss functions commonly used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. However, it does not specify which part of the paper this comparison should be added to, such as the results or discussion sections. The authors can infer that it relates to the experimental evaluation or comparison sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting what needs to be added. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include a comparison against state-of-the-art loss functions commonly used in face/iris verification. This claim is somewhat verifiable as it provides a logical suggestion for enhancing the paper\\'s contribution by including a comparison with established methods. However, the comment lacks specific examples or references to these state-of-the-art loss functions, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should include a comparison against state-of-the-art loss functions commonly used in face/iris verification. This is a clear and actionable suggestion that could enhance the paper\\'s contribution by demonstrating the effectiveness of the proposed method against established benchmarks. By including this comparison, the authors can provide a more comprehensive evaluation of their work and potentially improve its impact. However, the comment could be more helpful if it specified which loss functions should be included or provided examples of how they might be used in the comparison. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more detailed to be fully comprehensive.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the intent of Section 5.2, indicating that the authors need to clarify or provide more context for this section. However, it does not offer any specific guidance or suggestions on how to address this issue. The action is implicit and vague, as the authors are left to infer that they need to provide more information or clarification about the section. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the intent of this section, indicating that the authors need to clarify or provide more context. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking about the intent of Section 5.2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the intent of Section 5.2, indicating that the authors need to clarify or provide more context for this section. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The comment is somewhat helpful as it points out a potential gap in the paper, but it does not provide actionable advice or detailed feedback to help the authors improve their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly, including the attacker\\'s level of access, capabilities, and the defender\\'s available resources. It also recommends including this information in a dedicated section to enhance clarity. This feedback provides clear and concrete actions for the authors to take, such as creating a new section or expanding the existing one to address the clarity issues. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the threat model, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, including the attacker\\'s level of access, capabilities, and the defender\\'s available resources. Additionally, it suggests including this information in a dedicated section to enhance clarity. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly, including the attacker\\'s level of access, capabilities, and the defender\\'s available resources. This claim is somewhat verifiable as it logically suggests that such clarification would enhance the clarity of the paper, particularly around the assumed white-box access to the victim model. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires further clarification, namely the threat model. It suggests that the authors should define the assumed threat model more explicitly, including the attacker\\'s level of access, capabilities, and the defender\\'s available resources. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the clarity of their work. By addressing these points, the authors can improve the understanding of their threat model and better communicate their results. However, the comment could be more helpful if it included specific examples or references to similar works that have successfully addressed these issues. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the chat-gpt baseline is rudimentary and recommends testing a few-shot approach. It also proposes including discourse relation information in the prompts, which could yield good results. However, the comment does not provide explicit instructions on how to implement these suggestions or what specific changes to make. While the action is implied, it lacks concrete details on execution, making it somewhat actionable. The authors can infer that they need to consider these suggestions but may not know exactly how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the chat-gpt baseline, few-shot approach, and the inclusion of discourse relation information in the prompts. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in suggesting that the chat-gpt baseline is rudimentary and recommends testing a few-shot approach. It also proposes including discourse relation information in the prompts, which could yield good results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the chat-gpt baseline is \"very rudimentary\" and suggests testing a few-shot approach. It also proposes including discourse relation information in the prompts, which could yield good results. However, the comment lacks specific examples or detailed reasoning to support these claims, making it somewhat verifiable. The authors would need to infer the basis of these suggestions and potentially conduct additional research to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a weakness in the chat-gpt baseline, suggesting that it is \"very rudimentary\" and recommends testing a few-shot approach. It also proposes including discourse relation information in the prompts, which could yield good results. While the comment provides some actionable suggestions, it lacks depth and does not explain why the chat-gpt baseline is considered rudimentary or how the few-shot approach would improve the results. Additionally, the comment notes that the proposed changes are extraneous to the current evaluation, which could be a concern for the authors. Overall, the comment is somewhat helpful as it provides some direction for improvement but could be more comprehensive with additional details and justification.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to present the results comparing standard- vs. evolutional dropout on shallow models as a mean over many runs (at least 10) and ideally with error-bars. It also points out that the plotted curves are from single runs, which could be subject to significant fluctuations, and suggests that the models are small, making it unacceptable not to provide statistics. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what changes to make to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the results comparing standard- vs. evolutional dropout on shallow models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely presenting the results as a mean over many runs (at least 10) with error-bars and providing statistics. This level of detail provides clear guidance on how to improve the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10) with error-bars, as the plotted curves are from single runs and might be subject to significant fluctuations. The reviewer also suggests that the models are small, making it unacceptable not to provide statistics. The comment is mostly verifiable as it provides logical reasoning and a clear suggestion for improvement. However, it could be strengthened by providing specific examples or references to similar studies that have used similar methods and presentations. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback on the presentation of results comparing standard- vs. evolutional dropout on shallow models. It suggests that the results should be presented as a mean over many runs (at least 10) with error-bars, which is a standard practice in scientific research. This suggestion is based on the observation that the plotted curves are from single runs, which could be subject to significant fluctuations. Additionally, the reviewer points out that the models are small, making it unacceptable not to provide statistics. This feedback is highly helpful as it guides the authors on how to improve the presentation and robustness of their results, ensuring that they are more reliable and informative. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This is a clear and direct action for the authors to take, as it specifies exactly what additional information is needed to improve the clarity of the experimental setup. The comment is specific and provides concrete guidance on how to implement the suggested improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the impact of different versions of the experimental environment on training and inference speed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors need to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This claim is somewhat verifiable as it logically suggests that different versions of the experimental environment could impact training and inference speed. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of providing this information themselves, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed information about the experimental environment, including the CUDA and PyTorch versions. This feedback is clear and actionable, as it directly addresses a potential issue with the clarity and reproducibility of the experimental setup. By providing this additional information, the authors can ensure that their work is more robust and easily replicable. However, the comment could be more helpful if it included suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is mostly helpful as it effectively guides the authors on how to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It also points out that the expression \"labelled F-measure scores (LF1) (including ROOT arcs)\" was used in a previous work. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and actionable, giving the authors a clear path to enhance the clarity and comparability of their results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (078-079 and 08) and the expression \"labelled F-measure scores (LF1) (including ROOT arcs),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be added, namely the mention of the evaluation metric to clarify the scale of the improvement and for comparability with other works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It references a previous work, Fern\u00e1ndez-Gonz\u00e1lez and G\u00f3mez-Rodr\u00edguez (2020), where a similar expression was used. This claim is somewhat verifiable as it provides a logical reasoning for why clarifying the evaluation metric is important and references a specific example to support the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples of how this clarification would enhance the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It also points out that the expression \"labelled F-measure scores (LF1) (including ROOT arcs)\" was used in a previous work, which is relevant to the current paper. This feedback is valuable as it guides the authors on how to enhance the clarity and comprehensiveness of their results. By addressing these points, the authors can improve the transparency and reproducibility of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they should consider to improve the applicability of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the bounds of the paper, specifically mentioning the o(1) terms and the improvement over previously known results for arbitrarily long inputs. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the potential limitations of the approach due to the large inputs, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the bounds have o(1) terms and improve over previously known results for arbitrarily long inputs, which could limit the applicability of the approach. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper regarding the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs. It raises a valid concern about the applicability of the approach due to the large inputs required. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the approach might be improved. While it points out a potential problem, it does not provide actionable advice or detailed feedback for the authors to enhance their draft. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about the target of the paper, specifically whether it focuses on single-token cloze queries or multi-token ones. It acknowledges that the clarification is provided in the conclusion but does not specify how the authors should address this issue. The comment lacks explicit guidance on how to clarify the target or what specific changes should be made to improve the clarity. As a result, the authors are left without clear instructions on how to improve the draft in this area. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses confusion about the target of the paper, specifically whether it focuses on single-token cloze queries or multi-token ones. However, it does not specify which part of the paper this confusion arises from, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment does not provide specific guidance on how to address this issue, such as suggesting where the clarification should be added or what aspects of the paper are unclear. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses confusion about the target of the paper, specifically whether it focuses on single-token cloze queries or multi-token ones. The reviewer acknowledges that the clarification is provided in the conclusion but does not provide any supporting evidence or reasoning to justify this confusion. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the confusion and how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about the target of the paper, specifically whether it focuses on single-token cloze queries or multi-token ones. It acknowledges that the clarification is provided in the conclusion but does not specify how this affects the paper\\'s focus or what aspects of the paper are unclear. The comment lacks actionable feedback or suggestions for improvement, leaving the authors without guidance on how to address the confusion or enhance the clarity of their work. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks clarity regarding its major contributions, specifically mentioning that analyzing previous work does not constitute a contribution. However, it does not provide any explicit guidance or suggestions on how the authors might clarify or enhance their contributions. The comment implies that the authors should make their contributions more explicit, but it does not offer concrete steps or examples of what these contributions might be. As a result, the action is implicit and vague, leaving the authors uncertain about how to address the issue. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discuss the major contributions of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the major contributions and the issue of analyzing previous work not constituting a contribution. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks clarity regarding its major contributions, specifically mentioning that analyzing previous work does not constitute a contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the major contributions are unclear and that analyzing previous work does not constitute a contribution. This feedback is valuable as it highlights a critical area for improvement, namely clarifying the paper\\'s contributions and distinguishing them from existing work. However, the comment lacks specific guidance or suggestions on how the authors might clarify their contributions or differentiate them from previous work. While it points out a significant weakness, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. While the comment implies that the authors should consider this extension, it does not provide explicit instructions or detailed guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should consider this extension and determine how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to extend the protected feature to a vector form, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this extension would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. This is a somewhat helpful suggestion as it points out a potential way to enhance the paper\\'s contribution by expanding the scope of the protected feature. However, the comment lacks depth and does not provide specific guidance on how to implement this extension or what benefits it might bring. Additionally, it does not address other aspects of the paper, such as its methodology or results. While the suggestion is a starting point, it could be more actionable and comprehensive with additional details and examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the method proposed in the paper, $kNN-ECD$, is similar to $kNN-MT$, which limits the technical contribution of the paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their draft. There is no guidance on how to differentiate the method or what specific aspects could be improved to enhance the technical contribution. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method proposed in the paper, $kNN-ECD$, is similar to $kNN-MT$, which limits the technical contribution of the paper. However, it does not specify which part of the paper discusses $kNN-ECD$ or $kNN-MT$, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the similarity should be addressed or how the authors could differentiate their method. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the method proposed in the paper, $kNN-ECD$, is similar to $kNN-MT$, which limits the technical contribution of the paper. However, the comment does not provide any specific examples, comparisons, or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the method proposed in the paper, $kNN-ECD$, is similar to $kNN-MT$, which limits the technical contribution of the paper. However, it does not provide any specific guidance or suggestions on how the authors could differentiate their method or what aspects of the similarity should be addressed. Without actionable feedback or detailed reasoning, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. This provides a clear and direct action for the authors to take, which is to include these elements in their draft to enhance understanding. The suggestion is concrete, as it specifies exactly what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding an example and a figure to help explain the definition of uniform shattering. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where the definition is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of an example and a figure, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not provide any reasoning or evidence to support why this addition would be beneficial or how it would enhance the understanding of the concept. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to determine the necessity or impact of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by providing visual aids to enhance understanding. However, the comment lacks depth and does not explain why examples or figures would be beneficial or how they could be integrated into the paper. While it points out a potential improvement, it does not offer detailed guidance or suggestions on how to implement this change. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semi-supervised learning. However, it does not provide any specific guidance or suggestions on how the authors might address this concern or improve the novelty of their method. The comment lacks actionable details, such as recommending ways to differentiate the method or suggesting alternative approaches to enhance its originality. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semi-supervised learning. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what aspect of the method is considered common or how it could be improved to enhance its novelty. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed transductive method is not novel because it is related to a common approach in semi-supervised learning, specifically self-training methods. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semi-supervised learning. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The comment lacks actionable feedback or suggestions for improvement, leaving the authors without clear guidance on how to enhance the novelty or impact of their work. Therefore, the comment is rated as barely helpful, as it identifies a potential weakness but does not offer constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the assumption among classes not being practical, but it does not provide any explicit or implicit actions for the authors to take. It mentions that the formulation or definition is trivial but suggests that the optimization and theoretical property analysis could provide insights. However, it does not specify what aspects of the optimization or theoretical property analysis should be addressed or how the authors should incorporate these findings into their work. Without clear guidance or actionable steps, the authors are left without a clear understanding of what changes to make or how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the assumption among classes and suggests that the formulation or definition is trivial but highlights the importance of optimization and theoretical property analysis. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the assumption and the potential value of optimization and theoretical property analysis, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the assumption among classes is not practical, but it does not provide any evidence or reasoning to support this claim. The comment suggests that the formulation or definition is trivial, but it lacks specific examples or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the assumption among classes, suggesting that it may not be practical. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment mentions the importance of optimization and theoretical property analysis, but it lacks actionable advice or detailed feedback on how to incorporate these aspects into the paper. Without specific suggestions or examples, the authors are left without a clear path forward, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a lack of understanding regarding the effectiveness of the multi-view clustering approach and questions the usefulness of the other views. It highlights the dominance of the paraphrase similarity view and suggests that there is a need for a more detailed analysis of the differences and similarities between the views. However, the comment does not provide explicit guidance on how to conduct this analysis or what specific aspects should be explored. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed analysis of the views. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the effectiveness of the multi-view clustering approach and questions the usefulness of the other views. It highlights the dominance of the paraphrase similarity view and suggests a need for a more detailed analysis of the differences and similarities between the views. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its critique of the lack of detailed analysis and the need for more comprehensive exploration of the views. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the effectiveness of the multi-view clustering approach and highlights the dominance of the paraphrase similarity view over other views. It suggests that there is a need for a more detailed analysis of the differences and similarities between the views, except for the task directly. The comment provides a logical reasoning for the need of such an analysis, but it lacks specific examples or references to support the claim about the dominance of the paraphrase similarity view. This makes the claim somewhat verifiable, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the effectiveness of the multi-view clustering approach, specifically the dominance of the paraphrase similarity view over other views and their combination. It questions the usefulness of the other views and suggests that a more detailed analysis of the differences and similarities between them is needed. The comment highlights the lack of such an analysis in the paper and provides a specific example of how the different views help in clustering paraphrases of the word \"slip.\" However, the comment could be more helpful by offering suggestions on how to conduct this analysis or what specific aspects should be explored. Overall, the comment provides valuable insights and actionable feedback, but it could be more comprehensive to fully support the authors in improving their draft. Therefore, it is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide detailed preliminary experimental results on Wikipedia regarding the model size, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. This feedback implies that the authors should include these results to support their claims about model size and performance. However, the comment does not explicitly instruct the authors to include these results or provide specific guidance on how to present them. While the action is implied, it is not as clear as it could be, as the authors may not be entirely sure of the exact details or format required for these results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"preliminary experimental results on Wikipedia about model size,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests providing detailed results from Ni et al. regarding the scaling law and its application to dense retrieval models, which provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is unreasonable to expect that increasing the model size would hurt performance, as recent work by Ni et al. demonstrates that scaling laws apply to dense retrieval models. However, the comment does not provide specific references or examples from the Ni et al. work to support this claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' claims regarding the impact of model size on performance. It suggests that the authors should provide detailed preliminary experimental results on Wikipedia to support their claims, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. This feedback is somewhat helpful as it points out a specific area where the authors could strengthen their argument with empirical evidence. However, the comment could be more helpful if it provided additional guidance on how to present these results or what specific aspects to focus on. Overall, the comment offers a clear direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include related experiments to demonstrate the utility of the information axis tool. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment somewhat actionable. The authors can infer that they need to conduct additional experiments, but the lack of explicit instruction means the action is not as direct as it could be.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the conclusion or discussion, but this inference is not direct. The comment is specific in suggesting the need for related experiments, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not provide any specific examples or references to support this claim. The comment is based on a logical assumption that additional experiments would be beneficial, but without concrete evidence or reasoning, it lacks verifiability. Therefore, the claim is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by suggesting that the authors should include related experiments to demonstrate the utility of the information axis tool. This feedback is somewhat helpful as it points out an area for improvement and encourages the authors to conduct additional experiments. However, the comment lacks specific guidance on what kind of experiments would be beneficial or how they could be designed. While it highlights a potential weakness, it does not provide detailed suggestions or examples to help the authors address it effectively. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they could take to investigate it further. As a result, the comment lacks actionability and does not provide any direction for the authors to improve their draft. Therefore, it is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question pertains to, nor does it provide any context or details about the current setup or the Greek language. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspect of the Greek language might be causing issues in other multilingual setups. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for information about whether other multilingual pretraining setups also struggle with Greek. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. While it raises an interesting question, it does not provide any actionable feedback or suggestions for the authors to address this issue or improve their work. Without further context or guidance, the authors may find it challenging to understand how this information could be relevant to their paper or how to incorporate it into their analysis. Therefore, the comment is rated as barely helpful, as it identifies a potential area of interest but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the text in lines 293-295 makes a particular point unclear, specifically mentioning that it is difficult for readers to understand and evaluate the statement \"we manually observed the generated examples and find the results acceptable.\" The reviewer implies that the authors should clarify this point to improve clarity. However, the comment does not provide specific guidance on how to clarify this point or what aspects need to be addressed. While the action is implicit, it is clear that the authors need to make changes to improve the clarity of the text. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 293-295,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the statement \"we manually observed the generated examples and find the results acceptable.\" This provides clear guidance on what aspect of the text is unclear and needs improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the text in lines 293-295 makes a particular point unclear. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks specificity and does not offer a clear explanation of what makes the text unclear, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the text in lines 293-295, noting that it makes a particular point unclear. It points out that the statement \"we manually observed the generated examples and find the results acceptable\" is difficult for readers to understand and evaluate. While the comment highlights an area for improvement, it does not provide detailed guidance or suggestions on how to clarify the text or what specific aspects need to be addressed. This limits the comment\\'s helpfulness, as it offers some insight but lacks actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a significant issue with the organization and clarity of the proof, noting that it is difficult to follow and lacks clean logic. It specifically points out a problem in Lemma 3, asking whether the result holds for any polynomial function $P(\\\\gamma)$. While the comment highlights a specific area needing improvement, it does not provide explicit guidance on how to address this issue, such as suggesting a reorganization or offering specific suggestions for improving the clarity of the proof. The action is implicit and somewhat vague, as the authors need to infer that they should improve the organization and clarity of the proof. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lemma 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof organization, noting that it is not well-organized and lacks clean logic, making it difficult to follow. The comment also raises a specific question about the applicability of the result to any polynomial function $P(\\\\gamma)$. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof is \"extremely not well organized\" and lacks clean logic, making it difficult to follow and verify the correctness of the proof. The reviewer provides a specific example by questioning the applicability of the result in Lemma 3 to any polynomial function $P(\\\\gamma)$. This claim is somewhat verifiable as it highlights a specific issue with the proof organization and provides a concrete example to illustrate the problem. However, it could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the organization and clarity of the proof, noting that it is extremely difficult to follow due to the lack of clean logic and poor organization. It provides a specific example by questioning the applicability of the result in Lemma 3 to any polynomial function $P(\\\\gamma)$. This feedback is valuable as it highlights a critical area for improvement in the draft, which could significantly enhance the rigor and accessibility of the paper. However, the comment could be more helpful if it offered suggestions on how to improve the organization and clarity of the proof, such as recommending specific changes or improvements. Overall, the comment is mostly helpful as it provides actionable insights for the authors to address the identified weaknesses.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should conduct experiments on real-world datasets instead of synthetic datasets, particularly for the out-of-distribution setting. While the comment implies that the authors should make this change, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment somewhat actionable. The authors can infer that they need to conduct experiments on real-world datasets, but the lack of explicit instruction means the action is not as direct as it could be.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should conduct experiments on real-world datasets instead of synthetic datasets, particularly for the out-of-distribution setting. However, it does not specify which part of the paper discusses the synthetic versus real-world datasets or the out-of-distribution setting. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this suggestion fits, the comment lacks full grounding. It is specific about the need for real-world datasets but does not provide detailed guidance on how to implement this change. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should conduct experiments on real-world datasets instead of synthetic datasets, particularly for the out-of-distribution setting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should conduct experiments on real-world datasets instead of synthetic datasets, particularly for the out-of-distribution setting. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper's experimental setup. However, the comment lacks specific guidance on how to conduct these experiments or what aspects of the synthetic datasets might be problematic. While it points out a potential issue, it does not provide detailed instructions or examples on how to address it, making the feedback somewhat helpful but not fully actionable. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should show the smoothed GT shapes in Figures 3 and 5 to enhance the understanding of the reconstruction quality. This is a clear and direct action for the authors to take, as it provides a specific improvement that can be implemented to improve the clarity of their draft. The comment also mentions a minor concern, which adds context but does not affect the actionability of the main suggestion. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests showing the smoothed GT shapes in Figures 3 and 5 to enhance the understanding of the reconstruction quality. However, it does not specify which part of the paper these figures are located in, making it weakly grounded. The comment is specific in its suggestion to include the smoothed GT shapes, but without explicit references to the figures, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to enhance the understanding of the reconstruction quality. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the clarity of the figures. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion to enhance the clarity of the paper by showing the smoothed GT shapes in Figures 3 and 5. This feedback is clear and direct, offering a concrete way for the authors to improve the presentation of their results. Additionally, the comment acknowledges a minor concern, which adds context but does not detract from the main suggestion. Overall, the comment is highly helpful as it guides the authors toward a clear and meaningful enhancement of their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notations of $\\\\hat{Y}$ and $Y$ are used in a mixed way in Section 2. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue. There is no guidance on whether the notations should be standardized or clarified, or if there are specific parts of the paper where the notation is being used inconsistently. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes are needed to improve the draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notations of $\\\\hat{Y}$ and $Y$ being used in a mixed way. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notations of $\\\\hat{Y}$ and $Y$ are used in a mixed way in Section 2. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of notations in Section 2, noting that the notations of $\\\\hat{Y}$ and $Y$ are used in a mixed way. This is a clear and actionable observation that can help the authors improve the clarity and consistency of their notation usage. However, the comment could be more helpful if it provided suggestions on how to standardize the notation or clarified the context in which these notations are used. Despite this, the feedback is valuable as it directs the authors to a specific area needing attention, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to cite and discuss important references for domain adaptation in the revised manuscript. This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for references and discussions on domain adaptation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, namely references and discussions on domain adaptation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks important references for domain adaptation. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact references that are missing. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of important references for domain adaptation. It explicitly instructs the authors to cite and discuss these references in the revised manuscript. This feedback is clear and actionable, as it provides a direct and specific direction for improvement. By addressing this issue, the authors can enhance the comprehensiveness and relevance of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps to take. It lacks concrete details on how to verify the suspicion or improve the model. As a result, the authors are left without clear instructions on how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the hyperparameters and the potential issue with the model\\'s performance. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment lacks specific evidence or detailed reasoning to support this claim. It does not provide examples, references, or detailed explanations to substantiate the suspicion. As a result, the claim is somewhat verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. This is a relevant observation that could impact the validity of the results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or verify the suspicion. It does not provide actionable steps or detailed feedback on how to improve the presentation or analysis of the results. As a result, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in resolving it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide any specific details or examples of what is unclear or poorly motivated, nor does it offer suggestions on how to clarify or improve these aspects. The comment lacks explicit guidance or concrete steps for the authors to take, leaving them without a clear understanding of what needs to be addressed or how to address it. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"w.r.t. to corpora and datasets,\" indicating that it pertains to the experimental setup. However, it does not specify which part of the paper this pertains to, such as a particular section or table where these aspects are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects are unclear or poorly motivated, making it difficult for the authors to understand the exact issues that need to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"some aspects of the experimental setup were unclear or poorly motivated,\" specifically regarding corpora and datasets. However, the comment does not provide any specific examples or details about what is unclear or poorly motivated, making it difficult for the authors to understand the exact issues that need to be addressed. Without specific examples or references, the claim lacks verifiability, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that some aspects regarding corpora and datasets are unclear or poorly motivated. However, it does not provide any details or examples of what is unclear or poorly motivated, nor does it offer suggestions on how to clarify or improve these aspects. Without specific guidance or actionable feedback, the authors are left without a clear understanding of what needs to be addressed or how to address it. Therefore, the comment is barely helpful, as it points out a potential weakness but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the authors do not provide details on the size of each hourglass module. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the model size. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"size of the model\" and the \"hourglass modules,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of the model size to competing approaches and the details on the size of each hourglass module. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the authors do not provide details on the size of each hourglass module. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the paper\\'s analysis or conclusions. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by questioning the size of the model in terms of depth or number of parameters, noting that the authors do not provide details on the size of each hourglass module. This feedback is clear and actionable, as it prompts the authors to include this information in their paper. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details to include. Overall, the comment is mostly helpful as it directs the authors to a critical aspect of their work that needs clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the metric learning theory in the paper is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or improve the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"metric learning theory\" and \"generalization theory of neural networks,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the metric perspective analysis does not yield better results compared to previous theoretical results, and that the part of metric learning does not seem to work. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metric learning theory in the paper is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, the comment lacks specific references to the theoretical works mentioned, such as Bartlett et al. (2017), which would provide context and support for the claim. Without these references, the authors may find it challenging to verify the claim or understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that the metric learning theory is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. It also points out that the part of metric learning does not seem to work. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their work. Without actionable feedback or detailed advice, the authors are left without a clear path forward. Therefore, the comment is somewhat helpful, as it highlights a potential weakness but does not provide enough direction for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the authors should change the notation, provide additional clarification, or revise the terminology. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems, which is confusing. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the confusion caused by using the same notation for different concepts. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this notation is confusing or how it could be clarified. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential source of confusion in the paper regarding the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. This is a clear and actionable observation that can help the authors clarify their terminology and improve the clarity of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending alternative notations or explaining the context in which these terms are used. Despite this, the feedback is mostly helpful as it points out a specific area for improvement that can enhance the clarity and accessibility of the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether a test example is crucially different, such as a patient being \"British\" versus \"American,\" and whether this can be detected using the corpus residual value. While the comment implies that the authors should consider this issue, it does not provide explicit guidance on how to address it or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should consider this aspect in their analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the detection of crucial differences in test examples, specifically mentioning the example of a patient being \"British\" versus \"American\" and using the corpus residual value. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors can infer that it relates to the analysis or results section, but this inference is not direct. The comment is specific in its question about detecting crucial differences, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the detection of crucial differences in test examples, specifically mentioning the example of a patient being \"British\" versus \"American\" and using the corpus residual value. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is a relevant concern or how it could be addressed. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a thought-provoking question about the detection of crucial differences in test examples, specifically mentioning the example of a patient being \"British\" versus \"American\" and using the corpus residual value. This question highlights an important consideration for the authors regarding the potential impact of different cultural contexts on their analysis. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific steps they could take to ensure the validity of their results. While it prompts the authors to consider a relevant aspect of their analysis, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider using the most popular WebQuestions benchmark set instead of WebQuestionsSP as the testbed. It provides a rationale for this suggestion, noting that using WebQuestions would be more intuitive, straightforward, and could facilitate direct comparison with mainstream QA research. While the comment explicitly states the action to take, it lacks concrete details on how to implement this change or what specific aspects of the WebQuestions benchmark set would be most beneficial. Therefore, the action is explicit but somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"WebQuestionsSP\" dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of dataset and suggesting that using the more popular WebQuestions benchmark set would be more intuitive and straightforward. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP as the testbed. The reviewer provides a logical reasoning by explaining that using WebQuestions would be more intuitive, straightforward, and could facilitate direct comparison with mainstream QA research. However, the comment lacks specific examples or references to support the claim that WebQuestions would be more appropriate for the study. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to consider using a more popular dataset, WebQuestions, instead of WebQuestionsSP as the testbed for their study. It offers a logical reasoning that using WebQuestions would be more intuitive, straightforward, and could facilitate direct comparison with mainstream QA research. This feedback is valuable as it guides the authors to make a simple but impactful change that could enhance the clarity and relevance of their work. However, the comment could be more helpful if it provided specific examples or references to support the argument for using WebQuestions. Overall, the comment is mostly helpful as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the need for making claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It points out that a larger network may perform better without sparsity, and that any potential training speed increases or cost savings must be demonstrated. While the comment implies that the authors should provide evidence or examples to support their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence or examples to substantiate their claims. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It mentions that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. However, the comment does not specify which part of the paper these claims are made in, nor does it provide details on what specific evidence or demonstrations are needed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the claims and the need for evidence, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. The reviewer provides a logical reasoning by pointing out that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. However, the comment lacks specific examples or references to support the claim that sparsity is not beneficial. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It points out that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. While the comment identifies a potential weakness in the paper\\'s claims, it lacks specific suggestions or guidance on how the authors might address this issue or provide evidence to support their claims. The feedback is somewhat helpful as it highlights a potential area for improvement, but it could be more beneficial with additional guidance or examples on how to substantiate the claims. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the model design, specifically mentioning that the architecture and learning details are fragmented or missing. It provides a clear suggestion for the authors to address this issue by either providing a plot of model illustration, pseudo-code table, or code repository. Additionally, it highlights the importance of demonstrating integrated details to facilitate reproducibility, especially considering the novelty of the Neurochaos Learning method. The explicit action and concrete details on how to implement it make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"model design\" and \"model architecture and learning details,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the fragmented or missing details of the model design, and provides a concrete suggestion to address this issue by providing a plot, pseudo-code table, or code repository. Additionally, it highlights the importance of demonstrating integrated details to facilitate reproducibility, especially considering the novelty of the Neurochaos Learning method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model design is unclear due to fragmented or missing details, specifically mentioning the importance of demonstrating integrated details to facilitate reproducibility. The comment suggests providing a plot, pseudo-code table, or code repository to address this issue. However, the comment lacks specific examples or references to support the claim that the model design is unclear or that Neurochaos Learning is not well-known. This makes the claim somewhat verifiable, as the authors would need to infer the importance of these details and the need for demonstration themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the model design, noting that the architecture and learning details are fragmented or missing. It provides a clear and actionable suggestion for the authors to address this by either providing a plot of model illustration, pseudo-code table, or code repository. This feedback is valuable as it guides the authors on how to improve the clarity and reproducibility of their work. However, the comment could be more helpful if it explained why these details are important or provided examples of how they could be presented. Overall, the comment is mostly helpful as it effectively directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should clarify the generalization gaps in their work, specifically regarding the fine-tuning step in DIMES, and provide a comparison of DIMES with other methods on TSP100. While the comment implies that the authors should clarify these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation and comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific issue of generalization to the TSP instances, particularly the fine-tuning step in DIMES. It also specifies what needs to be clarified, namely, the difference between DIMES and other methods on TSP100 in-distribution testing performance with/without meta-learning. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify the generalization gaps in their work, specifically regarding the fine-tuning step in DIMES, and provide a comparison of DIMES with other methods on TSP100. While the comment identifies a potential issue with the generalization of DIMES, it lacks specific examples or references to support the claim that these gaps need clarification. The suggestion to compare DIMES with other methods is somewhat valid, but the lack of detailed reasoning or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the generalization of the fine-tuning step in DIMES, particularly in relation to the TSP instances. It suggests that the authors should clarify the difference between DIMES and other methods on TSP100, including in-distribution testing performance with/without meta-learning. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their work by addressing the generalization gaps and providing a comparison with other methods. However, the comment could be more helpful if it included examples or detailed guidance on how to conduct the comparison. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential inconsistency in the authors\\' claim regarding the readability of RC datasets and its impact on question difficulty. However, it does not provide any explicit or implicit actions for the authors to take. The comment implies that the authors should clarify their methodology or consider alternative methods for answer detection, but it does not specify how to do so or what specific changes should be made. Without concrete guidance or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the readability of RC datasets and its impact on question difficulty. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out the potential inconsistency in the authors\\' claim and suggesting that it depends on the method/features used for answer detection. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim made by the authors regarding the readability of RC datasets and its impact on question difficulty. It suggests that the authors\\' claim is dependent on the method/features used for answer detection, specifically mentioning POS/dependency parse features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the authors\\' claim regarding the readability of RC datasets and its impact on question difficulty. It points out that the authors\\' conclusion may depend on the method or features used for answer detection, specifically mentioning POS/dependency parse features. This feedback is somewhat helpful as it highlights a potential weakness in the authors\\' argument and suggests a direction for clarification or further exploration. However, the comment could be more helpful if it provided specific suggestions on how to address this inconsistency or how to better substantiate the claim. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support the claim that the morphfitting results in a more meaningful space. While the comment implies that the authors should conduct some form of analysis or provide evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional analysis or evidence to address the reviewer\\'s concern. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"vector space where morphological variants are just close together,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the resulting space is meaningful and suggests providing evidence or analysis to support the claim. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support the claim that the morphfitting results in a more meaningful space. The reviewer does not provide specific examples or references to support their claim, making it somewhat verifiable. The authors would need to infer the need for such evidence or analysis themselves, as the comment lacks detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support the claim that the morphfitting results in a more meaningful space. This feedback is valuable as it prompts the authors to consider the significance of their findings beyond just improved embeddings. However, the comment could be more helpful if it provided specific suggestions on how to conduct the analysis or what kind of evidence would be most relevant. While it identifies an important area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing quality of the paper needs improvement, specifically noting that the authors spend too much space on explaining basic memory networks and then the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should focus on improving the writing quality and expanding the related work section, but the comment lacks concrete details on how to achieve these improvements. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the writing quality of the paper needs improvement, specifically mentioning the uneven distribution of space between explaining basic memory networks and the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. However, the comment does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in identifying areas for improvement, such as the uneven distribution of space and the missing related work sections. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the writing quality of the paper needs improvement, specifically mentioning the uneven distribution of space between explaining basic memory networks and the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. However, the comment lacks specific examples or references to support the claim that the writing is uneven or incomplete. Without detailed evidence or examples, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered borderline verifiable, as it provides some indication but lacks sufficient detail to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the writing quality of the paper, noting that the authors spend too much space on explaining basic memory networks and then the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. This feedback is somewhat helpful as it highlights areas where the paper could be improved in terms of balance and comprehensiveness. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending which sections to prioritize or which additional related work to include. While it provides some direction, the lack of detailed advice limits its utility for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of the simulation should be considered. The comment lacks actionable details, such as recommending ways to categorize or analyze the different physical interactions, or suggesting methods for evaluating the simulation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what kind of physical interactions are being considered or how they might impact the simulation. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual inquiry, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation. While it highlights an area of interest, it does not provide any guidance or suggestions on how the authors might address this question or what aspects of the simulation should be considered. Without actionable feedback or context, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a significant issue with the paper\\'s model comparison, specifically the choice of datasets and the lack of categorical features. It points out that the paper claims a thorough comparison on a wide range of datasets but only includes one dataset with categorical features, which may affect the conclusions. Additionally, it notes that the authors do not employ one hot encoding for this dataset, which could negatively impact performance for some models. The comment provides explicit actions for the authors to take: to include more datasets with categorical features and to employ one hot encoding for the dataset with categorical features. These actions are concrete and specific, giving the authors clear guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Model Comparison\" and the \"wide range\" of datasets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the selection of datasets, noting that only one dataset has categorical features and that the authors do not employ one hot encoding for this dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model comparison in the paper is inadequate due to the selection of datasets, which lacks categorical features. The reviewer supports this claim by explaining that categorical features are generally more challenging for deep learning and that the omission of one hot encoding for the dataset with categorical features could negatively affect performance. This reasoning is logical and based on common knowledge, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to studies that support the importance of categorical features in deep learning. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s model comparison, specifically the choice of datasets and the lack of categorical features. It points out that the paper claims a thorough comparison on a wide range of datasets but only includes one dataset with categorical features, which may affect the conclusions. Additionally, it notes that the authors do not employ one hot encoding for this dataset, which could negatively impact performance for some models. This feedback is clear and actionable, as it provides specific guidance on how the authors can improve their model comparison by including more datasets with categorical features and employing one hot encoding for the dataset with categorical features. By addressing these points, the authors can significantly enhance the robustness and credibility of their findings. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the authors\\' approach, noting that pruning majorly works with large networks trained in distributed settings. It suggests that the authors should consider the necessity of finding global top Q values of the metric over the average of gradients, as this could break big portions of acceleration techniques like quantization and sparsification. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider this aspect. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"pruning\" and \"distributed settings,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential need to find global top Q values of the metric over the average of gradients, which could impact acceleration techniques like quantization and sparsification. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that pruning majorly works with large networks trained in distributed settings and suggests that the authors should consider finding global top Q values of the metric over the average of gradients. This is a logical claim based on the observation that pruning is often used with large networks and that distributed settings are common for training. However, the comment lacks specific examples or references to support the claim that finding global top Q values is necessary to avoid breaking acceleration techniques like quantization and sparsification. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' approach, noting that pruning majorly works with large networks trained in distributed settings. It suggests that the authors should consider the necessity of finding global top Q values of the metric over the average of gradients, as this could break big portions of acceleration techniques like quantization and sparsification. This feedback is valuable as it highlights a potential gap in the authors\\' discussion of pruning techniques and their impact on distributed settings. However, the comment could be more helpful if it provided specific examples or references to support the claim about the necessity of global top Q values. Overall, the comment is somewhat helpful as it directs the authors\\' attention to an important aspect of their work that requires further consideration.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether some subfigures in Figures 1 and 2 have been swapped by mistake. While it implies that the authors should check the figures and potentially correct any errors, it does not provide explicit instructions on how to do so or what specific subfigures might be affected. The action is implicit and somewhat vague, as the authors need to infer that they should verify the figures themselves. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about whether some subfigures have been swapped by mistake, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking whether some subfigures in Figures 1 and 2 have been swapped by mistake. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the possibility of subfigures in Figures 1 and 2 being swapped by mistake. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern or verify the accuracy of the figures. The comment lacks actionable feedback or detailed analysis, making it somewhat helpful as it points out a potential problem but does not assist the authors in resolving it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the improvement in sensitivity provided by the dropout probe and its ability to identify a causal role for syntactic representations that previous approaches might have missed. However, it also points out the potential risk of false positives due to the increased sensitivity. The reviewer suggests that this should be a substantial part of the discussion. While the comment implies that the authors should address this issue in their discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on the potential risks of false positives. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"dropout probe\" and its ability to improve sensitivity, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential risk of false positives due to the increased sensitivity. This provides clear guidance on what needs to be addressed in the discussion. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the dropout probe improves sensitivity and identifies a causal role for syntactic representations that previous approaches might have missed. However, the comment suggests that this improvement also increases the risk of false positives, which is a valid concern. The reviewer provides a logical reasoning by pointing out that all other things being equal, this increased sensitivity could lead to false positives. However, the comment lacks specific examples or references to support the claim about the potential risks of false positives. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant improvement in sensitivity provided by the dropout probe, which allows it to find a causal role for syntactic representations that previous approaches might have missed. However, it also points out a potential risk of false positives due to the increased sensitivity. This is a valuable observation that could lead to a substantial part of the discussion. The comment provides a clear and actionable suggestion for the authors to consider the potential risks and discuss them in the context of their findings. By highlighting this aspect, the comment offers a constructive and insightful critique that can help the authors improve their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors claim a regret bound for the proposed mini-batch method but do not provide it in the supplementary material. The reviewer explicitly states that they could not find the regret bound in the supplementary, which implies that the authors should include it. However, the comment does not provide specific guidance on how to present the regret bound or where it should be located in the paper. While the action is clear, the lack of detailed instructions on implementation makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about the regret bound for the proposed mini-batch method being cast to the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the regret bound is not provided in the supplementary material and references a specific work for comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors claim a regret bound for the proposed mini-batch method but do not provide it in the supplementary material. The reviewer references a specific work, \"Online Variance Reduction for Stochastic Optimization,\" by Zalan Borsos, Andreas Krause, and Kfir Y Levy, to support the claim. This reference provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the authors claim a regret bound for the proposed mini-batch method but do not provide it in the supplementary material. The reviewer references a specific work, \"Online Variance Reduction for Stochastic Optimization,\" by Zalan Borsos, Andreas Krause, and Kfir Y Levy, to support their claim. This feedback is clear and actionable, as it directs the authors to include the missing regret bound in the supplementary material. However, the comment could be more helpful if it provided additional guidance on how to present the regret bound or why it is important for the paper. Overall, the comment is mostly helpful as it highlights a critical oversight in the paper, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not discuss or compare exploration methods in RL literature, specifically mentioning count-based methods and intrinsic motivations (RND and ICM). However, it does not provide any explicit guidance on how the authors should address this issue. The comment implies that the authors should include a discussion or comparison of these methods, but it lacks concrete instructions on how to structure this discussion or what specific aspects to cover. The action is implicit and somewhat vague, as the authors can infer that they need to include a discussion but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion and comparison of these methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not sound because it does not discuss or compare exploration methods in RL literature, specifically mentioning count-based methods and intrinsic motivations (RND, ICM). However, the comment lacks specific examples or references to these methods, making it difficult for the authors to understand the exact nature of the issue. Without detailed explanations or references, the claim is not fully verifiable, as it relies on general knowledge of the RL literature. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that it does not discuss or compare exploration methods in RL literature, specifically mentioning count-based methods and intrinsic motivations (RND, ICM). This is a critical observation that could significantly impact the paper\\'s contribution and relevance. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as which methods to discuss or how to structure the comparison. While it points out a significant gap, it does not provide actionable advice, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the paper, but it does not provide explicit or implicit actions for the authors to take. It asks for clarification on the inference process and the coefficient of the p(L, E | X) term in line 307, but it does not instruct the authors on how to address these questions or provide guidance on how to improve the clarity of the writing. The comment also mentions missing hyperparameter details and suggests that ablation studies may not be well-tuned, but it does not provide specific suggestions for improvement. Overall, the comment lacks actionable guidance, leaving the authors uncertain about how to address the issues raised. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises several questions and concerns about the paper, but it does not specify which part of the paper these issues pertain to. It mentions \"line 307\" and \"hyperparameter details,\" but these references are not explicit enough to allow the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity in detailing what is missing or unclear about the inference process, the coefficient of the p(L, E | X) term, or the writing style. Without clear guidance on what needs to be addressed, the authors cannot effectively improve their draft. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises several questions and concerns about the paper, including the inference process, the coefficient of the p(L, E | X) term, and the clarity of the writing. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the claims made. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several concerns about the paper, including the inference process, the coefficient of the p(L, E | X) term, and the clarity of the writing. It questions whether inference is slowed down drastically and whether there is a way to only perform inference. Additionally, it points out missing hyperparameter details and suggests that ablation studies may not be well-tuned. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve the clarity of their writing. While it identifies areas for improvement, the feedback is not actionable and does not provide detailed instructions for the authors to follow. Therefore, the comment is somewhat helpful, as it highlights potential weaknesses but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is identified as the main weakness of the method. However, the comment does not provide any guidance on how the authors should address this issue or suggest specific actions to improve the performance. The authors are left without any concrete steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed compression\" and \"PQ,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the proposed compression performs worse than PQ when a small code length is allowed, which is the main weakness of the method. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, which is identified as the main weakness of the method. However, the comment does not provide any supporting evidence, comparisons, or references to substantiate this claim. Without additional details or justification, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is considered the main weakness of the method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the performance of their method. Without actionable feedback or detailed insights, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is rated as barely helpful, as it points out a problem but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the analysis could be more detailed, specifically mentioning the \"language/nationality\" section. It implies that the authors should explore potential biases in the data and compare them across different languages/nationalities. While the comment does not explicitly instruct the authors to conduct this analysis, it provides a clear direction for improvement by highlighting a specific area that could be expanded upon. The action is implicit but concrete, as it points to a specific aspect of the analysis that could be enhanced. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"language/nationality\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the analysis could be more detailed by exploring potential biases in the data and comparing them across different languages/nationalities. This provides clear guidance on what the authors could address to improve their analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section. It implies that there might be interesting observations to be made about biases towards different languages/nationalities. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that such observations would be interesting or valuable. Without additional context or evidence, the claim remains somewhat vague, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the analysis, suggesting that the \"language/nationality\" section could be more detailed by exploring potential biases across different languages/nationalities. It implies that there might be interesting observations to be made about these biases, which could enhance the analysis and contribute to the paper\\'s overall quality. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how to conduct this analysis or what specific observations might be interesting. This limits the comment\\'s helpfulness, as it points out an area for improvement but does not provide detailed guidance on how to achieve it. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the conservation properties of learning F^\\dagger in the context of physics-related continuous PDEs. It suggests that the authors should consider whether it is possible to train F^\\dagger such that certain conservation properties are maintained. The reviewer also asks for numerical illustrations to demonstrate the conservation properties in Hamiltonian systems. While the comment implies that the authors should address these questions, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"solvers' algorithms\" and \"learning F^\\dagger,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the conservation properties of learning F^\\dagger in the context of physics-related continuous PDEs and suggests that the authors should consider whether it is possible to train F^\\dagger to maintain certain conservation properties. The comment provides a clear direction for the authors to address the issue of conservation properties in their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the conservation properties of learning F^\\dagger in the context of physics-related continuous PDEs. It suggests that solvers' algorithms can maintain certain mathematical properties, such as not losing mass or charge, and asks if it is possible to train F^\\dagger to maintain similar properties. The comment is somewhat verifiable as it provides a logical basis for the question, but it lacks specific examples or references to support the claim that solvers' algorithms maintain these properties. The authors would need to further explore and substantiate the claim themselves, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the conservation properties of learning F^\\dagger in the context of physics-related continuous PDEs. It suggests that solvers' algorithms can maintain certain mathematical properties, such as not losing mass or charge, and asks if it is possible to train F^\\dagger to maintain similar properties. The comment also requests numerical illustrations to demonstrate the conservation properties in Hamiltonian systems. This feedback is somewhat helpful as it prompts the authors to consider the conservation properties of their method and provides a direction for further exploration. However, the comment could be more helpful if it offered specific suggestions on how to address these questions or provided examples of how similar properties have been maintained in other contexts. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not provide any specific guidance on which tasks should be discussed or how to incorporate this information into the paper. The action is implicit and vague, as the authors are left to infer what additional tasks might be relevant and how to address this suggestion. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or discussion where this topic could be addressed. The authors can infer that it relates to the discussion on tasks or applications of PE, but this inference is not direct. The comment is specific in suggesting a topic for expansion, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is expected or necessary. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. While it identifies a potential area for expansion, it lacks specificity and does not provide any guidance on which tasks or aspects of PE should be discussed. The comment is vague and does not offer actionable advice or examples, leaving the authors without clear direction on how to enhance their draft. Therefore, the feedback is barely helpful, as it points out a potential area for improvement but does not provide sufficient guidance for the authors to act upon it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a potential improvement in evaluating the quality of the set of policies, specifically by using the minimum over the set of test MDPs rather than the summation. This feedback provides a clear and explicit action for the authors to consider, as it offers a specific alternative approach to evaluating the performance of the policies. The comment is concrete in its suggestion and provides a clear rationale for the change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the intuitive goal of finding a set of policies that includes an optimal policy for every test MDP in S_{test}. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides a detailed explanation of why the current approach might not be optimal and suggests an alternative method for evaluating the quality of \\u00b1\\u00b7\\u00b7\\u00b7. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a potential improvement in evaluating the quality of a set of policies by using the minimum over the set of test MDPs rather than the summation. The reviewer provides a logical reasoning for this suggestion, explaining that the summation might lead to selecting a subset of policies that are good for most MDPs but poor for the remaining ones, which could be hidden by the summation but highlighted by the minimum. This reasoning is based on a clear understanding of the problem and the potential consequences of the current approach, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to similar approaches in the literature to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed and actionable suggestion for improving the evaluation of the set of policies. It suggests using the minimum over the set of test MDPs rather than the summation, which could reveal a more accurate representation of the performance. The comment explains the potential issue with the current approach, which is that it might select a subset of policies that are good for most MDPs but poor for the remaining ones. This feedback is highly helpful as it offers a clear and specific improvement that could enhance the quality of the work. By addressing this suggestion, the authors can significantly improve the robustness and accuracy of their evaluation. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to reduce the use of footnotes and move important content into the main body of the paper. It provides a specific example by suggesting moving details around parameter settings to the appendix. This feedback is clear and concrete, giving the authors a direct action to take to improve the draft. The suggestion to move content to the appendix is also detailed, providing specific guidance on how to structure the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the extensive use of footnotes in the paper, suggesting that much of the content is important and should be moved into the main body. It provides a specific example by suggesting moving details around parameter settings to the appendix. This allows the authors to identify the section where footnotes are used excessively, making the comment fully grounded. The comment is also specific in detailing what needs to be addressed, such as moving content to the main body and the appendix. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that footnotes are used excessively in the paper, which is distracting. It suggests that much of the content is important and should be moved into the main body of the paper. The reviewer provides a specific example by suggesting moving details around parameter settings to the appendix. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim about the excessive use of footnotes. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the excessive use of footnotes. It suggests that much of the content is important and should be moved into the main body of the paper, which would improve the readability and clarity of the paper. The comment provides a specific example by suggesting moving details around parameter settings to the appendix, which is a clear and actionable suggestion. However, the comment could be more helpful if it provided additional guidance on how to effectively integrate the content into the main body or how to prioritize which content to move. Overall, the comment is mostly helpful as it highlights a significant issue and offers a concrete suggestion for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the inclusion of zero-shot generation results in the paper is somewhat unusual and raises a question about its relevance. However, it does not provide explicit guidance on whether the authors should remove these results or explain their inclusion. The comment lacks concrete instructions on how to address this issue, leaving the authors uncertain about how to proceed. Therefore, the comment is somewhat actionable, as it identifies a potential area for improvement but does not offer specific steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the inclusion of zero-shot generation results in the paper, suggesting that it is somewhat unusual and raises a question about its relevance. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its critique of the inclusion of zero-shot generation results, but without clear guidance on where this discussion should be placed, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the inclusion of zero-shot generation results in the paper is somewhat unusual and raises a question about its relevance. However, it does not provide any specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the inclusion of zero-shot generation results in the paper, suggesting that it might be somewhat unusual and questioning its relevance. While it acknowledges the interesting and relevant experiments, it points out that the inclusion of zero-shot generation results might not be necessary or appropriate. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or justify the inclusion of these results. Without actionable feedback or detailed reasoning, the authors may find it challenging to understand and implement the necessary changes. Therefore, the comment is somewhat helpful, as it highlights a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should acknowledge some of the older works related to supervised, multilingual systems. While the comment implies that the authors should include this acknowledgment, it does not provide specific guidance on which works to mention or how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section on related work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works related to supervised, multilingual systems, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests acknowledging older works related to supervised, multilingual systems. However, it does not provide specific examples or references to these older works, nor does it explain why acknowledging them would be beneficial. Without additional context or reasoning, the claim lacks verifiability, as it does not provide sufficient evidence or justification for the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors acknowledge some of the older works related to supervised, multilingual systems. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by including a broader historical context. However, the comment lacks depth and does not provide specific examples or guidance on which older works to include or how to integrate them into the paper. While it points out a potential enhancement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the time complexity of the proposed method, including the use of an item-oriented autoencoder, the elementwise function, and the number of hidden units. However, it does not provide explicit guidance on how the authors should address these issues or suggest specific actions to improve the time complexity. The comment lacks concrete details on how to implement these improvements, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the time complexity of the proposed method, specifically mentioning the use of an item-oriented autoencoder, the elementwise function, and the number of hidden units. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the time complexity, such as the potential for many users associated with a typical item and the larger number of hidden units compared to matrix factorization-based methods. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the time complexity of the proposed method is high due to the use of an item-oriented autoencoder, the elementwise function, and the number of hidden units. While the comment provides some reasoning by mentioning these factors, it lacks specific examples or detailed explanations to fully substantiate the claim. The authors would need to infer the exact impact of these factors on the time complexity, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the time complexity of the proposed method, specifically mentioning the use of an item-oriented autoencoder, the elementwise function, and the number of hidden units. It highlights that these factors could contribute to a high time complexity. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the time complexity. While it points out a potential weakness, it lacks actionable advice or detailed feedback that would help the authors make meaningful improvements. Therefore, the comment is somewhat helpful, as it provides some insight but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the figures would be clearer if they explicitly mention \"pre-trained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback provides a specific action for the authors to take, which is to add this information to the figures to enhance clarity. The comment is explicit and provides concrete guidance on how to implement the suggested change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that many of the figures would be clearer if they mentioned \"pre-trained solution encoders & solution decoders,\" as there are multiple types of autoencoders. However, it does not specify which figures or sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in suggesting what needs to be clarified, namely the types of autoencoders used in the figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the figures would be clearer if they mentioned \"pre-trained solution encoders & solution decoders,\" as there are multiple types of autoencoders. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the figures. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that many of the figures would be more clear if they explicitly mention \"pre-trained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback is somewhat helpful as it identifies a specific area for improvement in the clarity of the figures, which could enhance the readers\\' understanding of the content. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or why it is important. Additionally, it does not address other aspects of the paper, such as the content or methodology. Therefore, the comment is somewhat helpful, as it points out a specific area for improvement but lacks comprehensive guidance for the authors.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a comparison with a NeRF-based method, specifically mentioning the recent Zero-1-to-3 and point-e. Additionally, it questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment provides explicit actions to include comparisons and question the relevance, it lacks concrete details on how to implement these suggestions. The authors are given a clear direction but may need to infer the specifics of how to conduct these comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including comparisons with NeRF-based methods, specifically mentioning Zero-1-to-3 and point-e. It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. However, the comment does not specify which part of the paper these comparisons should be included in or how the relevance of the occlusion experiment should be addressed. While the authors can infer that the suggestions relate to the experimental section, the comment lacks full grounding as it does not explicitly mention the sections being addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison with NeRF-based methods, specifically mentioning Zero-1-to-3 and point-e, is missing. It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. However, the comment lacks specific examples or detailed reasoning to support these claims. The suggestion to include comparisons is somewhat verifiable, as it provides a direction for improvement, but the critique of the relevance is not fully substantiated. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting the inclusion of comparisons with NeRF-based methods, such as Zero-1-to-3 and point-e. This suggestion is clear and can help the authors improve the comprehensiveness and relevance of their experimental evaluation. Additionally, the comment questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment identifies areas for improvement, it could be more helpful if it provided additional context or examples of how these comparisons could be conducted. Overall, the comment is mostly helpful as it offers clear and actionable suggestions for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It explicitly requests a more detailed analysis of these aspects. While the comment identifies areas for improvement, it does not provide specific guidance on how to conduct the analysis or what aspects should be emphasized. The authors are left to infer that they need to provide more detailed information, but the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p,\" which likely refers to a specific parameter or value used in the paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It requests a more detailed analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It requests a more detailed analysis of these aspects, which could significantly enhance the paper\\'s clarity and rigor. While the comment identifies areas for improvement, it lacks specific guidance on how to conduct the analysis or what aspects should be emphasized. This makes the feedback somewhat helpful, as it points out potential weaknesses but does not provide detailed instructions for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the authors only apply the meta sampler in a decoupled way, specifically when the features are fixed. It also requests more discussion on this aspect and asks for clarification on when the authors start applying the meta sampler. While the comment implies that the authors should provide more information on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more discussion and clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"meta sampler\" and the \"linear classifier,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on whether the meta sampler is applied in a decoupled way and requests more discussion on this topic. Additionally, it asks for clarification on when the meta sampler is applied, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the application of the meta sampler in a decoupled way and requests more discussion on this topic. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the application of the meta sampler in a decoupled way and requests more discussion on this topic. It highlights a potential area for clarification and expansion in the paper, which could enhance the understanding of the methodology. However, the comment does not provide detailed guidance or suggestions on how to address this issue or what specific aspects of the discussion should be expanded. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct more experiments on datasets like COMPAS and Drug Consumption, and encourages them to follow a cited AAAI paper on fairness-aware metrics like Equality Odds (EO). While the comment provides a specific recommendation to conduct more experiments and mentions a relevant paper, it does not explicitly instruct the authors on how to implement these suggestions or what specific aspects of the paper should be revised. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of a vanilla metric and suggests conducting more experiments on datasets like COMPAS and Drug Consumption. It also references a specific paper, \"Exacerbating Algorithmic Bias through Fairness Attacks,\" which provides a clear context for the authors to understand the feedback. However, the comment lacks specificity regarding what aspects of the paper need improvement or how the authors should conduct these experiments. While it provides a clear direction, the lack of detailed guidance on execution makes it fully grounded but under-specific. Therefore, this comment aligns with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the authors should conduct more experiments on datasets like COMPAS and Drug Consumption, and mentions a specific paper for reference. However, the comment does not provide any specific reasoning or evidence to support why these additional experiments are necessary or how they would improve the paper. The mention of the cited paper provides some context, but the claim lacks detailed justification or examples to fully substantiate the suggestion. Therefore, the comment is somewhat verifiable, as it provides a direction but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the authors use their own defined vanilla metric and lack related fairness-aware metrics like Equality Odds (EO). It suggests conducting more experiments on datasets like COMPAS and Drug Consumption, and references a specific paper for guidance. While the comment provides a clear direction for improvement, it lacks detailed guidance on how to conduct these experiments or what specific aspects of the paper should be revised. The feedback is somewhat helpful as it points out a gap in the paper and offers a potential solution, but it could be more comprehensive with additional details. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to either state the content as a remark or move it to a Discussion section, or to remove it altogether. This provides a clear and direct action for the authors to take, ensuring that the content is either revised or removed as needed. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L107-114,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that the content seems speculative or overly opinionated and suggests it should be stated as a remark or moved to a Discussion section. This provides clear guidance on how to revise the content. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"L107-114 seems speculative or overly opinionated.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific section of the paper (L107-114) as potentially being speculative or overly opinionated. It suggests that this content should be stated as a remark or moved to a Discussion section, or removed altogether. This feedback is clear and actionable, as it provides the authors with a concrete suggestion on how to address the issue of potentially overly subjective content. However, the comment could be more helpful if it explained why this section is considered speculative or overly opinionated, which would give the authors a better understanding of the rationale behind the suggestion. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is concrete, as it specifies the baselines to consider, but it is somewhat vague because it does not provide detailed guidance on how to implement this suggestion. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. The authors can infer that it relates to the evaluation or experimental sections, but this inference is not direct. The comment is specific in suggesting the inclusion of these baselines, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these baselines are relevant or how they would impact the evaluation. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting the inclusion of additional baselines. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or why these specific baselines are relevant. While it points out a potential enhancement, it could be more helpful if it included more detailed reasoning or examples of how these baselines could be integrated into the evaluation. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies two missing elements in the paper: the value of the neighborhood size h and an analysis of its influence on the model's performance, and the use of different hyperparameter sets per dataset. It suggests that providing readers with intuitive knowledge of the value of h and the robustness of the method with respect to different neighborhood sizes is essential. Additionally, it questions the use of different hyperparameter sets per dataset and suggests that authors provide insights into how performance varies with a constant set of parameters. The comment is clear and provides specific actions for the authors to take, such as conducting an analysis of h and standardizing hyperparameter sets. The explicit nature of the suggestions and the concrete details on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"value of neighborhood size h\" and the \"analysis of its influence over the model's performance,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for an analysis of the robustness of the method with respect to different neighborhood sizes and the use of different hyperparameter sets per dataset. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the value of neighborhood size h and its influence on the model's performance are missing elements in the paper. It suggests that this is a key parameter of the proposed strategy and that providing readers with intuitive knowledge of the value of h is essential. The reviewer also questions the use of different hyperparameter sets per dataset, suggesting that standardizing these parameters would be beneficial. The comment provides logical reasoning and references the importance of the parameter h, making it mostly verifiable. However, it could be strengthened by providing specific examples or references to support the claim about the influence of h on performance. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two important missing elements in the paper: the value of the neighborhood size h and an analysis of its influence on the model's performance, and the use of different hyperparameter sets per dataset. It suggests that providing readers with intuitive knowledge of the value of h and the robustness of the method with respect to different neighborhood sizes is essential. Additionally, it questions the use of different hyperparameter sets per dataset and recommends standardizing these parameters to improve the robustness of the method. The comment is clear and actionable, offering specific suggestions for improvement that can enhance the clarity and robustness of the paper. However, it could be more helpful if it provided examples or references to similar studies that have addressed these issues. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model's ability to construct higher-order interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. While the comment implies that the authors should consider these questions and potentially address them in their paper, it does not provide explicit instructions or concrete suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these aspects of the model. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model's ability to construct higher-order interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the model's performance or analysis. The comment is specific in its inquiry about the impact of missing modalities and the potential for leveraging additional modalities. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about the impact of imperfect multimodal data on the model, specifically asking whether missing modalities affect the model's ability to construct higher-order interactions and polynomial tensors. The comment does not make a claim or express an opinion but rather seeks clarification or additional information. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model's ability to construct higher-order interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. This feedback is valuable as it prompts the authors to consider a critical aspect of their model's robustness and generalizability. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or explore the impact of missing modalities. Overall, the comment is somewhat helpful as it directs the authors to consider an important aspect of their model but lacks detailed guidance on how to implement the suggested exploration.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. It provides specific examples of what to analyze, such as the frequency of \"nothing\" and its impact on context polarity. This feedback is explicit and provides concrete guidance on what the authors should do to improve their draft. The action is clear and specific, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which are questions and suggestions about the use of the SST dataset and the analysis of negation and intensity words. The comment provides detailed guidance on what statistics to analyze, such as the frequency of \"nothing\" and its impact on context polarity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. It provides specific examples of what to analyze, such as the frequency of \"nothing\" and its impact on context polarity. This claim is somewhat verifiable as it logically suggests that analyzing these statistics could provide valuable insights into the effectiveness of the proposed method. However, the comment lacks detailed justification or references to support the importance of these analyses. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors should analyze the statistics of negation and intensity words in the SST dataset. It offers examples of what to analyze, such as the frequency of the word \"nothing\" and its impact on context polarity. This feedback is clear and provides the authors with a concrete direction for improving their work by demonstrating the potential value of such an analysis. However, the comment could be more helpful if it explained why these statistics are important or how they could enhance the understanding of the method. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors have not verified the stability of the OGE-Aug on out-of-distribution (OOD) benchmarks, specifically mentioning DrugOOD. It suggests that the authors should verify the stability of their model on this benchmark, which is a clear and explicit action. However, the comment does not provide specific guidance on how to conduct this verification or what metrics to use. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific benchmark dataset, DrugOOD, and the work by SPE, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of verification of the stability of the OGE-Aug on OOD benchmarks, such as DrugOOD. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have not verified the stability of the OGE-Aug on out-of-distribution (OOD) benchmarks, specifically mentioning DrugOOD. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors have not verified the stability of their model, the OGE-Aug, on out-of-distribution (OOD) benchmarks such as DrugOOD. It points out that the stability of the model has not been validated on this dataset, despite the fact that SPE has been validated on this dataset. This feedback is clear and actionable, as it directs the authors to verify the stability of their model on OOD benchmarks, which is a crucial aspect of model robustness. However, the comment could be more helpful if it provided additional guidance on how to conduct this verification or what specific metrics to use. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors consider freezing some layers of the model while only training a few layers or using parameter-efficient methods like LoRA. These suggestions are explicit and provide clear actions for the authors to take, such as considering these methods for experimental comparison. The comment also specifies the potential benefits of these approaches, making it clear what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests considering freezing some layers of the model while only training a few layers or using parameter-efficient methods like LoRA. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the model training or parameter efficiency sections, but this inference is not direct. The comment is specific in suggesting alternative methods to consider, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors consider alternative methods, such as freezing some layers of the model or using LoRA, for parameter-efficient model training. While the comment provides a logical reasoning for considering these methods, it lacks specific examples or references to support the claim that these methods are \"natural to think about\" or \"valuable for experimental comparison.\" This makes the claim somewhat verifiable, as the authors would need to infer the benefits and applicability of these methods themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors consider alternative methods for parameter-efficient model training, such as freezing some layers or using LoRA. This feedback is actionable and provides a clear direction for the authors to explore additional approaches that could enhance their experimental comparison. By suggesting these methods, the reviewer highlights a potential area for improvement that could enhance the rigor and comprehensiveness of the study. However, the comment could be more helpful if it provided specific examples or references to these methods, which would guide the authors more directly in implementing these suggestions. Overall, the comment is mostly helpful as it offers a clear and actionable direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to expand the related work section and compare their work to strong baselines that use coordinates. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"related work section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need to expand this section and compare it to strong baselines that use coordinates. This level of detail provides full grounding and specificity, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests expanding the related work section and comparing it to strong baselines that use coordinates. However, it does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for expanding the related work section and comparing it to strong baselines that use coordinates. This feedback is specific and offers a concrete direction for improvement, which can help the authors enhance the comprehensiveness and relevance of their work. By addressing this suggestion, the authors can strengthen their paper by demonstrating the novelty and effectiveness of their approach in comparison to existing methods. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the experiments should be expanded to include multiple seed experiments, which would provide a more robust evaluation. This suggestion is clear and concrete, as it specifies the exact action the authors need to take to improve their draft. The comment provides a specific direction for enhancing the evaluation of the proposed method, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Single Seed Experiments\" and suggests expanding the experiments to include multiple seeds. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for multiple seed experiments to provide a more robust evaluation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experiments are limited to training on a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. This claim is somewhat verifiable as it logically points out the limitation of single-seed experiments and the need for more robust evaluations. However, it lacks specific examples or references to support the claim fully, such as discussing how multiple seed experiments would impact the results or what specific aspects of the method would be better evaluated with multiple seeds. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s experiments, specifically the use of single-seed training, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple-seed experiments would provide a more robust evaluation. This feedback is clear and actionable, as it directly points out a specific area for improvement and offers a concrete suggestion for enhancing the paper\\'s evaluation. However, the comment could be more helpful if it provided additional guidance on how to conduct multiple-seed experiments or discussed the potential benefits of this approach. Overall, the comment is mostly helpful as it effectively directs the authors to a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, asking for clarification on the motivation behind this choice. While the comment implies that the authors should provide a clearer explanation or justification for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for their methodology. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, indicating a lack of clarity in the motivation behind this choice. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification on the motivation behind the choice, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, suggesting that the motivation behind this choice is unclear. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. It highlights a potential lack of clarity in the paper regarding the rationale behind this choice. While the comment identifies an area for improvement, it does not provide specific suggestions or guidance on how the authors might address this issue or clarify their motivation. The feedback is somewhat helpful as it points out a potential weakness, but it could be more beneficial with additional guidance on how to improve the explanation or justification for the methodology. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the proposed method, noting that an entire multi-GPU setup is required for optimizations, making it less accessible for many potential users. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the method more accessible or suggestions for alternative approaches. Without actionable advice or concrete steps, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the proposed method, noting that an entire multi-GPU setup is required for optimizations, which makes it less accessible for many potential users. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on how this requirement affects the accessibility of the method. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment is not grounded and lacks specificity, making it difficult for the authors to address the issue effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed method requires an entire multi-GPU setup for optimizations, making it less accessible for many potential users. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it affects the accessibility of the method. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the accessibility of the proposed method, noting that an entire multi-GPU setup is required for optimizations. This is a relevant point that could impact the practicality and adoption of the method by users who may not have access to such a setup. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending alternative approaches or suggesting ways to make the method more accessible. Without actionable feedback, the authors are left with a clear understanding of the problem but without direction on how to improve their draft. Therefore, the comment is somewhat helpful, as it highlights a potential weakness but does not provide detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests comparing the current system with another system that also captures semantics, potentially using Ref-[2] as a baseline. It provides a clear and concrete action for the authors to take, which is to compare their system with another that captures semantics. However, the comment does not specify which aspects of the current system should be compared or how to implement the comparison. While the action is explicit, the lack of detailed guidance on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the current system with another system that captures semantics, potentially using Ref-[2] as a baseline. However, it does not specify which part of the paper this comparison should be made, such as a specific section or experiment. The authors can infer that it relates to the evaluation or comparison sections, but this inference is not direct. The comment is specific in suggesting a potential baseline and a comparison approach, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the current system with another system that captures semantics, potentially using Ref-[2] as a baseline. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be considered actionable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the current system with another system that also captures semantics, potentially using Ref-[2] as a baseline. This is a constructive suggestion that could help the authors improve the evaluation of their system by providing a more comprehensive comparison. However, the comment lacks specific guidance on how to implement this comparison or which aspects of the current system should be compared. While it identifies a potential area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the model\\'s inability to fully identify the true sources in the triangle dataset. It suggests that one of the assumptions might not be satisfied or that there could be learning difficulties. However, it does not provide specific guidance on how the authors should address these issues or what steps to take to improve the model. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the model\\'s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of model performance and suggesting that assumptions might not be satisfied or that there could be learning difficulties. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the model\\'s inability to fully identify the true sources in the triangle dataset. It suggests that one of the assumptions might not be satisfied or that there could be learning difficulties. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that assumptions are not satisfied or that learning difficulties exist. Without such evidence or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the model\\'s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. It prompts the authors to consider whether these issues are related to assumptions or learning difficulties. While the comment identifies a potential problem, it lacks specific guidance or suggestions on how the authors might address these issues or improve their model. The feedback is somewhat helpful as it points out a potential area for improvement but does not provide detailed guidance or actionable steps. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the metrics used for evaluating continual learning, specifically noting that they are suitable for the datasets provided but may not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to adapt the metrics or suggest alternative approaches. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the metrics used for evaluating continual learning, specifically mentioning the loss after switch and recovery time after switch. However, it does not specify which part of the paper these metrics are discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment also notes that these metrics may not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable, but it does not provide specific guidance on how to address this issue. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the metrics used for evaluating continual learning are suitable for the datasets provided but may not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This claim is somewhat verifiable as it provides a logical reasoning for the limitations of the metrics in certain contexts. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would benefit from more detailed justification or examples to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the metrics used for evaluating continual learning, specifically noting that they are suitable for the datasets provided but may not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This is a relevant observation that highlights a potential weakness in the paper\\'s methodology. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or adapt their metrics accordingly. While it points out a relevant concern, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the user decoder's use of information from the agent decoder, specifically asking why it only uses information up to time step t and does not consider information from all time steps. While the comment identifies an area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they should clarify this aspect of their work, but without specific instructions on how to do so, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"user decoder\" and \"agent decoder,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the user decoder only uses information up to time step t and does not consider information from all time steps. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the rationale behind the user decoder's use of information from only time step t and not from all time steps. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it affects the overall paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the user decoder's use of information from the agent decoder, specifically questioning why it only uses information up to time step t and does not consider information from all time steps. This feedback identifies a potential area of confusion or inconsistency in the paper, prompting the authors to clarify their reasoning or methodology. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it points out a potential weakness, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider a controlled baseline that ablates heads at different locations in the model to address the confounding factor of head \"location\" in the induction and FV heads. This feedback provides a clear and explicit action for the authors to take, which is to implement a controlled baseline that can help isolate the impact of head location on ICL performance. The suggestion is concrete and provides a specific direction for the authors to follow, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of induction heads and FV heads being located at different layers within the model, which could contribute to differences in ICL performance when ablating induction heads versus FV heads. It suggests that a controlled baseline should be considered to isolate the impact of head location on ICL performance. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the discussion or results related to the model architecture and ablation studies. The suggestion is specific, as it provides a clear direction for addressing the issue of head location. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be due to the confounding factor of head \"location\" within the model. The reviewer proposes a controlled baseline that ablates heads at different locations in the model to address this issue. However, the comment lacks specific examples or references to support the claim that head location is a significant contributing factor to the observed differences. While the suggestion is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential confounding factor in the results, specifically the difference in ICL performance when ablating induction heads versus FV heads. It suggests that the location of these heads within the model could be a contributing factor. The comment provides a clear and actionable suggestion by recommending the inclusion of a controlled baseline that ablates heads at different locations in the model. This feedback is valuable as it offers a specific direction for the authors to address the issue and improve the clarity and robustness of their results. However, the comment could be more helpful if it provided additional context or examples of how this controlled baseline might be implemented or what specific locations should be considered. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of a section on synonym identification under similarity measurement, which is a clear and direct action for the authors to take. It specifies the missing section and provides a specific suggestion for what should be included, namely a description of how the multiple-choice task is approached. This level of detail makes the action explicit and concrete, allowing the authors to know exactly what needs to be added to their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section on similarity measurement, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely a section on synonym identification, and provides a clear direction for improvement by suggesting a description of how the multiple-choice task is approached. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a section on synonym identification is missing under similarity measurement, which would describe how the multiple-choice task is approached. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this section is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, namely the absence of a section on synonym identification under similarity measurement. This is a clear and actionable point that the authors can address to improve the clarity and completeness of their draft. By adding this section, the authors can provide a more comprehensive explanation of their approach to the multiple-choice task, which could enhance the understanding and applicability of their work. However, the comment could be more helpful if it offered suggestions on how to structure or present this section, or if it highlighted other areas where similar information might be relevant. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While the action is implicit, it is concrete because it specifies what needs to be added (an overview of the workflow and the model). This provides the authors with a clear direction on how to enhance their draft, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not specify which part of the paper this overview should be included in, nor does it provide details on what aspects of the workflow and model should be covered. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in suggesting the need for an overview but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not provide any specific reasoning or examples to support why this overview is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. This feedback is somewhat helpful as it identifies a potential area for improvement, which could enhance the clarity and accessibility of the paper. However, the comment lacks specific guidance on what aspects of the workflow and model should be covered or how this overview should be structured. While it points out a need for clarity, it does not provide detailed suggestions or examples to help the authors effectively implement this feedback. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the debiasing approach, specifically the need to know the statistical dimension d_lambda of the design matrix A. It also mentions that this information cannot be computed accurately without the same runtime as required for ridge regression. The reviewer suggests that this issue is not discussed in the paper and raises a similar concern regarding the surrogate sketch. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to discuss this issue but are not given clear instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to know the statistical dimension d_lambda of the design matrix A and the issue with computing it accurately without the same runtime as ridge regression. It also mentions a similar issue with the surrogate sketch. This allows the authors to accurately identify the parts of the paper being addressed, such as the sections discussing debiasing and surrogate sketch computation. The comment is specific because it clearly outlines the problem with the approach and suggests that it may not achieve its intended purpose due to the computational requirements. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the debiasing approach requires knowledge of the statistical dimension d_lambda of the design matrix A, which cannot be computed accurately without the same runtime as ridge regression. The reviewer suggests that this issue may defeat the purpose of the approach and points out that it is not discussed in the paper. The comment is somewhat verifiable as it provides a logical reasoning for the claim, but it lacks specific examples or references to substantiate the claim fully. The authors would need to further explore the issue and provide evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the debiasing approach, specifically the need to know the statistical dimension d_lambda of the design matrix A. It points out that this information cannot be computed accurately without the same runtime as required for ridge regression, which could lead to bias and defeat the purpose of the approach. The comment also notes that this issue is not discussed in the paper. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or discuss it in the paper. The feedback is somewhat helpful as it alerts the authors to a potential weakness, but it could be more actionable with additional details or examples. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not provide specific guidance on how to improve the experiment setup or what aspects need to be addressed. The comment lacks explicit instructions or concrete suggestions on how to enhance the experiment setup, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not specify which part of the paper this pertains to, such as the experimental section or a particular figure or table. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in suggesting that the experiment setup should be improved, but without clear grounding, it is difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the ablations deserve better experiment setup due to the many questions that arise. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not provide specific guidance or examples on how to improve the experiment setup or what aspects need to be addressed. Without actionable advice or detailed suggestions, the authors are left with a general idea of what needs to be improved but without clear direction on how to achieve it. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of empirical evidence to support the argument that the proposed models are particularly useful for learning representations for low-frequency words. It suggests that the authors should explore this aspect further by providing empirical evidence to test the hypothesis. While the comment implies that the authors should conduct additional experiments, it does not specify which experiments to conduct or how to conduct them. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the argument about the proposed models being particularly useful for learning representations for low-frequency words, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of empirical evidence to test the hypothesis and suggests exploring this aspect further. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed models are particularly useful for learning representations for low-frequency words but lacks empirical evidence to support this claim. The reviewer suggests that it would be interesting to explore this aspect further, implying that the absence of empirical evidence is a significant issue. However, the comment does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of the empirical evidence themselves, which could be challenging without additional guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of empirical evidence to support the argument that the proposed models are particularly useful for learning representations for low-frequency words. It suggests that the authors should explore this aspect further by providing empirical evidence to test the hypothesis. This feedback is clear and actionable, as it points out a specific area where the paper could be strengthened with additional evidence. However, the comment could be more helpful if it provided suggestions on which experiments or data sets to use for this empirical evaluation. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of an error analysis on the movie dataset and highlights the need for clarity on the cases where the model fails. This provides a clear and direct action for the authors to take, which is to include an error analysis in their draft. The comment is specific and provides concrete guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely an error analysis on the movie dataset, and why it is important for other researchers to understand the cases where the model fails. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the error analysis on the movie dataset is missing, which is a factual observation. However, it does not provide any supporting evidence, reasoning, or examples to substantiate why this is a significant issue or how it affects the paper\\'s contribution. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this omission. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the absence of an error analysis on the movie dataset. It highlights the importance of including this analysis for other researchers who may continue this work. However, the comment does not provide specific guidance on how to conduct the error analysis or what aspects should be covered. While it points out a critical area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide specific guidance on what details are missing or how the authors should address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what actions to take. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions the \"questions section below,\" which implies that it is referring to a specific part of the paper. However, without explicit mention of a section or page number, the authors cannot confidently determine the exact part being addressed. The comment also lacks specificity regarding what details are missing or how they should be addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that \"some details of the proposed method are missing,\" but it does not provide specific examples or reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to identify which details are missing or how they could address this issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide specific details on what these missing details are or how they affect the paper. Without this information, the authors are left without actionable guidance on how to address the issue. The comment lacks depth and specificity, making it barely helpful for the authors in improving their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of ablation analysis in the main paper, which makes it challenging to determine the source of the small performance gain. However, it does not provide explicit guidance on how to include ablation analysis or what specific components should be analyzed. The action is implicit and somewhat vague, as the authors are left to infer that they need to include ablation analysis but without clear instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of ablation analysis in the main paper, which makes it difficult to pinpoint the source of the small performance gain. However, it does not specify which part of the paper lacks this analysis, such as the specific sections or experiments where it should be included. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in identifying the issue of lacking ablation analysis, but without explicit references to sections or experiments, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of ablation analysis makes it difficult to determine the source of the small performance gain. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of ablation analysis, which makes it difficult to pinpoint the source of the small performance gain. This is a critical observation that could significantly impact the authors\\' understanding of their work and its implications. However, the comment does not provide specific guidance on how to address this issue, such as suggesting which components should be analyzed or how to conduct the ablation analysis. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a critical issue but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). However, it does not provide any guidance or suggestions on how the authors should address this observation or what implications it might have for their work. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"2,\" which likely refers to a specific figure or table in the paper. This allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity because it does not detail what aspect of the noise rate of similarity labels compared to class labels is problematic or how it affects the paper\\'s conclusions. Without additional context or suggestions for improvement, the authors may find it challenging to address the issue effectively. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that when the number of classes is large (>8), the noise rate of similarity labels is less than class labels. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand or verify the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). However, it does not provide any actionable feedback or suggestions for improvement. Without additional context or guidance, the authors may not know how to address this observation or what implications it might have for their work. Therefore, the comment is not helpful at all, as it lacks actionable advice or constructive feedback.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the CNN experiments are not fully convincing, but it does not provide any specific details or examples to support this claim. There is no guidance on what aspects of the experiments are lacking or how they could be improved. Without explicit or implicit suggestions for improvement, the authors are left without a clear understanding of what changes are needed to enhance the convincingness of their results. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions the CNN experiments, but it does not specify which part of the paper these experiments are discussed in, making it weakly grounded. It also lacks specificity as it does not detail what aspects of the experiments are not convincing or how they could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively identify and address the issue. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the CNN experiments are not convincing, but it does not provide any specific details or examples to support this claim. Without additional context or evidence, the authors are left without a clear understanding of what aspects of the experiments are lacking or how they could be improved. This makes the claim unverifiable, as it lacks the necessary support to substantiate the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment mentions that the CNN experiments are not convincing, but it does not provide any specific details or examples to support this claim. Without further explanation or guidance, the authors are left without a clear understanding of what aspects of the experiments are lacking or how they could be improved. This lack of actionable feedback limits the usefulness of the comment, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer implies that discussing how to design prompts effectively is crucial. However, the comment does not provide specific guidance on how to achieve this or what aspects of prompt design should be emphasized. The action is implicit and somewhat vague, as the authors can infer that they need to focus on prompt design but may not know exactly how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. However, it does not specify which part of the paper discusses these prompting methods or where the authors should focus their attention. The authors can infer that it relates to sections discussing prompt design, but this inference is not direct. The comment is specific in its suggestion to discuss prompt design effectively, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer argues that different prompts may result in varying performance outcomes, emphasizing the importance of discussing how to design prompts effectively. However, the comment lacks specific examples or references to support the claim that different prompts lead to varying performance outcomes. This makes the claim somewhat verifiable, as the authors would need to infer the importance of prompt design and the potential impact on performance outcomes. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer highlights the importance of discussing how to design prompts effectively, given that different prompts may result in varying performance outcomes. This feedback is clear and actionable, as it directs the authors to focus on a critical aspect of their work that could significantly impact its impact and effectiveness. However, the comment could be more helpful if it provided specific suggestions or examples of effective prompt design strategies. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the use of freezing in MLS selection and suggests that if adaptive is good, it would be better to use an adaptive method for subset selection. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the rationale behind using freezing but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"MLS selection,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of freezing in MLS selection and suggesting that adaptive methods could be used instead. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of freezing in MLS selection and suggests that adaptive methods could be used instead. However, it does not provide any supporting evidence, reasoning, or references to justify why adaptive methods are preferable or how they would improve the selection process. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the use of freezing in MLS selection and suggests that adaptive methods could be a better approach. This feedback prompts the authors to reconsider their methodology and potentially improve their selection process. However, the comment lacks specific guidance or suggestions on how to implement the adaptive method or what aspects of the current methodology might be problematic. While it identifies an area for improvement, it does not provide detailed instructions or examples, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should perform a similar analysis on the proposed knowledge-CLIP model as done in existing work that combines text and KGs. This feedback implies that the authors should conduct a closely-related analysis to test the robustness of their model, specifically by adding negation or changing entities in the text. While the comment does not explicitly instruct the authors to perform this analysis, it provides a clear direction for further exploration and experimentation. The action is explicit and concrete, as it specifies the type of analysis to be conducted, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed knowledge-CLIP model, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting a closely-related analysis to test the robustness of the model, such as adding negation or changing entities in the text. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed knowledge-CLIP model should be tested for robustness by conducting a closely-related analysis, similar to existing work that combines text and KGs. The comment references an external work, providing a specific example of a related analysis. This reference supports the claim that such an analysis would be valuable for understanding the model's robustness. However, the comment does not provide detailed reasoning or evidence to fully substantiate why this analysis is necessary or how it would benefit the paper. While the reference provides some support, the comment could be strengthened by further explanation or examples. Therefore, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the paper by recommending a closely-related analysis on the proposed knowledge-CLIP model. It references existing work that combines text and KGs, suggesting that the authors should perform a similar analysis to test the robustness of their model. This feedback is actionable and offers a clear direction for the authors to enhance their draft, making it more comprehensive and rigorous. By addressing this suggestion, the authors can significantly improve the robustness and generalizability of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify how novel values in the test set are handled for clarity. This is a direct and concrete action, as it specifies a specific area that needs more explanation. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of how novel values in the test set are handled. This provides clear guidance on what the authors need to improve to enhance the clarity of their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment suggests that the authors clarify how novel values in the test set are handled for clarity. However, it does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area where clarity is needed, specifically regarding how novel values in the test set are handled. By pointing out this gap, the comment provides the authors with a clear direction for improving the draft. However, the comment could be more helpful if it offered suggestions on how to explain this aspect more clearly or provided examples of how other studies handle similar issues. Despite this, the feedback is actionable and can guide the authors in enhancing the clarity of their paper. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that similar methods have already been proposed for multi-task learning and were not discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting a discussion of related work or a comparison with existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Similar methods have already been proposed for multi-task learning and has not been discussed in this paper [1],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on similar methods for multi-task learning. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that similar methods have already been proposed for multi-task learning and were not discussed in the paper. However, it does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper regarding the discussion of similar methods for multi-task learning. It points out that similar methods have already been proposed and were not discussed in the paper. However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this issue or incorporate related work into their discussion. Without detailed feedback or constructive advice, the authors are left with a general observation but no clear path for improvement. Therefore, the comment is rated as barely helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the authors have compared the amount of computation required for FedMITR with other methods. While it implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison in their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FedMITR,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the amount of computation required for FedMITR compared to other methods, indicating a potential area for improvement or clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point poses a question about whether the authors have compared the amount of computation required for FedMITR with other methods. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would impact the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment poses a question about the expected computation of FedMITR compared to other methods, suggesting that this might be an area for comparison. While it highlights a potential weakness or area for improvement, it does not provide specific guidance or suggestions on how to address this issue. The comment is somewhat helpful as it points out a potential gap in the paper, but it lacks actionable advice or detailed feedback to help the authors improve their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity, the potential impact of the choice, and whether other influential losses have been considered. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues. The comment implies that the authors should provide more detailed explanations or experiments to justify their choices, but it does not specify exactly what additional information is needed or how to present it. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity, the potential impact of this choice, and whether other influential losses have been considered. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. While the questions are specific, the lack of grounding in the comment makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the methodology used in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity and the potential impact of this choice. It also asks whether other influential losses have been considered, such as replacing the min with a mean or NDCG. These questions are relevant and could prompt the authors to reconsider their methodology and potentially improve the robustness and generalizability of their results. However, the comment lacks specific guidance or suggestions on how to address these issues, such as recommending specific experiments or analyses. While it identifies areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests several actions for the authors to take, including training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines like Resnet50 or DenseNet121 for the feature extraction layer. It also mentions that the current method may not work due to the small number of conv layers. However, the comment does not provide specific guidance on how to implement these suggestions or what specific changes should be made to the method. The action is implicit and somewhat vague, as the authors need to infer the details of how to apply these suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the method of training on labeled data and incorporating input mask explanation annotations, as well as the use of modern backbone baselines like Resnet50 or DenseNet121 for the feature extraction layer. It also mentions the skepticism about the method's effectiveness, based on past attempts at similar interventions. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in detailing what changes are suggested, such as the use of modern baselines and the incorporation of input mask explanation annotations. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed method may not work due to the small number of conv layers and the use of older baselines like Resnet50 or DenseNet121. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the skepticism. The suggestion to use modern baselines is logical, but without further explanation or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several suggestions for improving the methodology, including training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines like Resnet50 or DenseNet121 for the feature extraction layer. These are actionable and specific improvements that could enhance the robustness and effectiveness of the proposed method. However, the comment also acknowledges the skepticism about the method's potential success, given past attempts at similar interventions that have failed. This acknowledgment of potential limitations adds a level of realism to the feedback, but it does not fully address the weaknesses or provide detailed guidance on how to address them. Overall, the comment is mostly helpful as it offers concrete suggestions for improvement but could be more comprehensive with additional details or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method. This implies that the authors should make a comparable effort to optimize the baseline as they do for their proposed method. However, the comment does not provide specific guidance on how to achieve this or what steps to take to ensure a fair comparison. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction of multiple hyperparameters and the extensive hyperparameter search, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the importance of ensuring that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. While the comment highlights the extensive hyperparameter search, it lacks specific examples or references to support the claim that this is necessary. The reasoning is based on a general assumption that a fair comparison requires equal optimization efforts, but it does not provide detailed evidence or examples to substantiate the claim. Therefore, the comment is somewhat verifiable, as it requires further elaboration to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically the extensive hyperparameter search and the need to ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. This is a relevant point that could impact the validity and fairness of the results. However, the comment lacks specific guidance or suggestions on how to achieve this goal, such as recommending specific steps or techniques to optimize the baseline. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the definition of perplexity given in the paper is incorrect and suggests that it should be replaced with the correct definition. Additionally, it notes that the equation mentioned does not resemble perplexity but instead appears to be cross-entropy. While the comment provides explicit guidance on what needs to be corrected, it does not offer specific suggestions on how to revise the definition or equation to ensure accuracy. The action is clear but lacks concrete details on how to implement the correction, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is incorrect about the definition of perplexity and the equation mentioned, providing clear guidance on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the definition of perplexity given in the paper is incorrect and suggests that it should be replaced with the correct definition. The reviewer also notes that the equation mentioned does not resemble perplexity but instead appears to be cross-entropy. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific error in the paper regarding the definition of perplexity, noting that it is not correctly defined. It also points out that the equation mentioned does not resemble perplexity but instead appears to be cross-entropy. This feedback is clear and actionable, as it provides the authors with specific guidance on how to correct the errors in their work. However, the comment could be more helpful if it offered suggestions on how to revise the definition or equation to ensure accuracy. Overall, the comment is mostly helpful as it directs the authors to a critical area needing correction, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern with the evaluation of the proposed strategies, specifically mentioning the need to test the defense against an adversarial attack. It suggests that the defense should be evaluated against adversarial examples that produce minimal structural alterations to the edge map but mislead the model predictions. However, the comment does not provide specific guidance on how to implement this evaluation or what specific adversarial examples should be used. While the action is implied, it is not detailed enough for the authors to know exactly how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"evaluation of the proposed strategies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation, namely the need to test the defense against an adversarial attack that produces minimal structural alterations to the edge map but misleads the model predictions. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation of the proposed strategies is insufficient, specifically mentioning the need to test the defense against an adversarial attack that produces minimal structural alterations to the edge map but misleads the model predictions. The comment provides a logical reasoning by highlighting the potential vulnerability of the defense against such attacks. However, it lacks specific examples or references to support the claim that an adversary could optimize the perturbation to successfully attack the model. This makes the claim somewhat verifiable, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern with the evaluation of the proposed strategies, specifically the need to test the defense against an adversarial attack that produces minimal structural alterations to the edge map but misleads the model predictions. This is a crucial point that could significantly impact the effectiveness of the defense strategies. However, the comment lacks specific guidance on how to implement this evaluation or what specific adversarial examples should be used. While it highlights an important area for improvement, the lack of detailed instructions makes it somewhat helpful, as the authors are given a direction but not a clear path forward. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the experimental results lack standard deviations, making it difficult to assess the significance of the results. This is a clear and direct action for the authors to take, as it instructs them to include standard deviations in their results. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014the inclusion of standard deviations\u2014and why this is important for assessing the significance of the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results lack standard deviations, making it difficult to assess the significance of the results. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why standard deviations are necessary or how their absence affects the interpretation of the results. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting the absence of standard deviations. This is a clear and actionable point that the authors can address to improve the clarity and significance of their findings. By including standard deviations, the authors can provide more robust and interpretable data, which is crucial for assessing the impact of their results. However, the comment could be more helpful if it offered suggestions on how to present the standard deviations or discussed their importance in the context of the study. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the quality of generated images by the proposed method, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the realism of the generated images or suggestions for potential improvements. As a result, the authors are left without any clear direction on how to enhance the quality of their generated images. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the quality of generated images by the proposed method, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. However, it does not specify which part of the paper or supplemental material is being referred to, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the realism of the generated images, but it lacks grounding as it does not identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the quality of generated images by the proposed method is limited, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the quality of generated images by the proposed method, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. This feedback is somewhat helpful as it highlights an area for improvement, but it lacks specific suggestions or guidance on how to address the issue. The authors are informed of a potential weakness but are not provided with actionable steps to enhance the realism of their generated images. Therefore, the comment is somewhat helpful, as it points out a problem but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the statement regarding Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (A-B-A and B-A-B) with two separate standard backpropagation processes. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest how the authors should address this discrepancy or improve their draft. As a result, the authors are left without any guidance on how to respond to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 559-560,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the statement regarding Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (A-B-A and B-A-B) with two separate standard backpropagation processes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement regarding Cycle Consistency loss is not entirely true, as it can iterate between two phases of the reconstructions (A-B-A and B-A-B) with two separate standard backpropagation processes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the paper regarding the Cycle Consistency loss, specifically noting that it can iterate between two phases of the reconstructions (A-B-A and B-A-B) with two separate standard backpropagation processes. This is a clear and actionable point that the authors can address to improve the accuracy and completeness of their work. However, the comment could be more helpful if it provided additional context or examples to explain the implications of this discrepancy or suggested ways to clarify the statement. Overall, the comment is mostly helpful as it points out a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific gaps in the paper regarding the details of the models, particularly the grammar over kernels and the probabilities associated with it. It explicitly asks for clarification on how the grammar is applied in practice, how inference is performed, and what the hypothesis space of kernels consists of. This feedback provides clear and concrete actions for the authors to take, such as expanding on the explanation of the grammar over kernels and the probabilities associated with it. The comment is explicit and provides detailed guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"grammar over kernels\" and the \"probabilities associated with the grammar,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detail in explaining the grammar over kernels and how inference is performed. The comment provides a clear direction for improvement by asking for more detailed explanations of these concepts. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the lack of detail in the explanation of the \"grammar over kernels\" and the probabilities associated with it, which makes it difficult to understand how the approach is applied in practice. The reviewer suggests that there might be probabilities associated with the grammar that define a hypothesis space of kernels, and questions how inference is performed. While the comment identifies specific areas of concern, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to make a significant effort to understand and address the issues raised, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific gaps in the paper regarding the details of the models, particularly the \"grammar over kernels\" and the probabilities associated with it. It points out that these details are not explained in sufficient detail, making it challenging for readers to understand how the approach is applied in practice. The comment raises important questions about the hypothesis space of kernels and inference, prompting the authors to clarify these aspects of their work. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations of these critical components. However, it could be more helpful if it offered suggestions on how to address these gaps or provided examples of how similar concepts have been explained in other works. Overall, the comment is mostly helpful as it highlights important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to include qualitative results, possibly with zoomed-in views, for cases where previous methods failed but were successful with the proposed method. Additionally, it recommends showing some failure cases and analyzing the limitations. While the comment provides a clear direction for improvement, it does not specify which specific qualitative results or failure cases should be included or how to present them. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including qualitative results, possibly with zoomed-in views, for cases where previous methods failed but were successful with the proposed method. It also recommends showing some failure cases and analyzing the limitations. However, the comment does not specify which part of the paper these results should be included in, nor does it provide detailed guidance on how to present them. While the authors might have an idea of where these results could be added, the lack of explicit grounding makes it difficult for them to pinpoint the exact sections that need revision. The suggestion is specific in terms of what is needed, but the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including qualitative results, possibly with zoomed-in views, for cases where previous methods failed but were successful with the proposed method. It also recommends showing some failure cases and analyzing the limitations. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that including these results would be beneficial. The absence of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the value of these additions themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of qualitative results, possibly with zoomed-in views, for cases where previous methods failed but were successful with the proposed method. It also suggests showing some failure cases and analyzing the limitations. This feedback is valuable as it offers a concrete way for the authors to enhance the presentation of their results, which could help demonstrate the effectiveness of their method. However, the comment could be more helpful if it provided specific examples of what qualitative results or failure cases should be included, or if it offered guidance on how to present these results effectively. Overall, the comment is mostly helpful as it provides clear and actionable suggestions for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the title is ambiguous and recommends clarifying that it pertains to machine comprehension of text, not human reading comprehension. This feedback provides a clear and explicit action for the authors to take, which is to clarify the title to avoid confusion. The comment is specific in its suggestion and offers concrete guidance on how to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"title\" and provides a specific suggestion to clarify that it pertains to machine comprehension of text, not human reading comprehension. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be clarified in the title to avoid confusion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the title is ambiguous and recommends clarifying that it pertains to machine comprehension of text, not human reading comprehension. This claim is somewhat verifiable as it provides a logical reasoning for the clarification, but it lacks specific examples or references to support the claim that \"reading comprehension\" and \"readability\" typically refer to human reading comprehension. The authors might find it challenging to fully understand the basis of the claim without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the title of the paper, suggesting that it may be misleading as it pertains to machine comprehension of text, not human reading comprehension. This feedback is clear and actionable, as it provides a specific suggestion for clarification that could help the authors avoid confusion and ensure their title accurately reflects the content of their paper. By addressing this point, the authors can improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided additional context or examples to further explain the issue with the title. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make. The comment lacks concrete suggestions or detailed instructions on how to improve the evaluation, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where the evaluation is discussed, the comment lacks full grounding. It is specific in its critique of the use of an automatic metric, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of an automatic metric (TSS) in the human evaluation, suggesting that it weakens the convincingness of human evaluation. However, the comment does not provide any supporting evidence, reasoning, or references to justify why an automatic metric is less convincing than a human metric. Without such justification, the claim remains unverifiable, as it lacks the necessary information to support the claim. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. This feedback highlights a potential weakness in the evaluation methodology, which could impact the credibility of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what alternative human metrics could be used. While it identifies a potential problem, it lacks depth and actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would be strengthened by including experiments across more diverse domains, specifically mentioning those in TD-MPC 2. While the comment implies that the authors should expand their experiments to include more diverse domains, it does not provide explicit instructions on how to do so or which specific domains to consider. The action is implicit and somewhat vague, as the authors need to infer the need for more diverse domains and determine which ones to include. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments prove the point made by the authors and recommends expanding the experiments to include more diverse domains, specifically mentioning those in TD-MPC 2. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of more diverse domains, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments prove the authors\\' point effectively but recommends expanding the experiments to include more diverse domains, specifically mentioning those in TD-MPC 2. This claim is somewhat verifiable as it provides a logical reasoning for expanding the experiments to enhance the paper\\'s impact. However, it lacks specific examples or detailed justification for why these additional domains are necessary or how they would contribute to the paper. The suggestion is somewhat supported by the mention of TD-MPC 2, but further elaboration would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the experiments effectively prove the authors\\' point but recommends expanding the experiments to include more diverse domains, specifically mentioning those in TD-MPC 2. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting the inclusion of additional experiments to enhance the paper\\'s impact. However, the comment lacks specific guidance on how to implement this suggestion or which specific domains should be considered. While it provides a direction for improvement, it could be more actionable with additional details. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two issues: the lack of confidence intervals for results and the limited evaluation on two datasets. It suggests that the authors should show confidence intervals and evaluate on more datasets, specifically mentioning some standard datasets in the RNP community. The comment provides explicit actions for the authors to take, such as including confidence intervals and expanding the evaluation to more datasets. However, it does not specify which datasets should be used or how to calculate the confidence intervals. While the actions are clear, the lack of detailed guidance on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of confidence intervals for results and the limited evaluation on two datasets, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of not showing confidence intervals and the need to evaluate on more datasets, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not show confidence intervals for their results, which makes it unclear whether performance gains are statistically significant. The reviewer supports this claim by referencing external works that discuss the importance of confidence intervals and the need for more datasets to evaluate robustness. However, the comment could be strengthened by providing specific examples or references to studies that demonstrate the importance of confidence intervals or by explaining why the two datasets used are insufficient. Despite this, the claim is mostly verifiable due to the references to external works, which provide a solid foundation for the critique.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two significant issues with the paper: the lack of confidence intervals for results and the limited evaluation on two datasets. It suggests that the authors should include confidence intervals to demonstrate statistical significance and evaluate on more datasets, specifically mentioning some standard datasets in the RNP community. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the robustness and credibility of their results. However, the comment could be more helpful if it offered suggestions on how to calculate confidence intervals or which datasets to consider. Overall, the comment is mostly helpful as it effectively directs the authors to address these critical areas for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main contribution of the paper is not in proposing novel techniques but rather in demonstrating that a simple combination of existing techniques can achieve surprisingly good accuracy. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. The authors are left without guidance on how to address this feedback or what specific changes could be made to enhance the novelty or contribution of their work. As a result, the comment lacks actionability, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the simplicity of the LUQ design and the standard nature of the approaches presented in Section 5, suggesting that the main contribution is in demonstrating the effectiveness of a simple combination of existing techniques. However, it does not specify which part of the paper this discussion pertains to, such as the sections on the LUQ design or the approaches presented in Section 5. The comment lacks grounding, as it does not specify where in the paper these issues are discussed. Additionally, it is not specific about what needs to be addressed or improved regarding the contribution or the existing techniques. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the LUQ design is straightforward and that the approaches in Section 5 are standard and explored in previous literature. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim unverifiable, as it lacks the necessary support to substantiate the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the straightforward nature of the LUQ design and the standard approaches presented in Section 5, suggesting that the main contribution of the paper is in demonstrating the effectiveness of a simple combination of existing techniques. However, it does not provide specific suggestions or guidance on how the authors could enhance the novelty or contribution of their work. The comment lacks actionable feedback or constructive advice, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as barely helpful, as it identifies a limitation but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. While it implies that the authors should provide evidence or analysis of the training stability, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide training losses to address the concern. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for training losses, but without clear grounding, it is difficult for the authors to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. However, it does not present any claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The authors are left to infer that they should provide evidence or analysis of the training stability, but without detailed instructions or examples, the comment does not fully support the authors in improving their draft. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not offer actionable steps for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed compared to other methods. The reviewer suggests that this could result in unfair comparisons. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their training approach or provide additional context to justify the use of 2x samples per iteration. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"RegMixup\" and \"training,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed and unfair comparisons. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to a slow running speed and unfair comparisons. The reviewer supports this claim by referencing the authors\\' claim of a 1.5x slower running speed compared to other methods. However, the comment lacks specific examples or references to substantiate the claim further, such as detailed comparisons with other methods or specific data to support the claim of a 1.5x slower running speed. This makes the claim somewhat verifiable, as it provides some evidence but could be strengthened with additional details. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed and unfair comparisons. This is a relevant observation that could impact the fairness and validity of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending a different training approach or providing additional context to justify the use of 2x samples per iteration. While it points out a potential problem, the feedback could be more helpful if it included actionable advice for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of scalability should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this issue is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of scalability should be considered or how the authors might address this question. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the scalability of the method as the corpus size or hidden dimension size increases. This is an important consideration for the authors to address, as it could impact the practicality and applicability of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or address this issue. While it points out a potential weakness, it does not offer actionable advice or detailed feedback that could help the authors improve their draft. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about relaxing the need to visit all ball-action pairs with each iteration and suggests exploring partial coverage. However, it does not provide explicit guidance or suggestions on how to address this issue or what specific actions the authors should take. The comment is vague and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"in continuation to the above remark,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how to relax the need to visit all ball-action pairs with each iteration and what would happen if partial coverage is considered. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about relaxing the need to visit all ball-action pairs with each iteration and suggests exploring partial coverage. While it raises an interesting point, it lacks specific guidance or suggestions on how to address this issue or what specific assumptions might be needed. The comment is somewhat helpful as it prompts the authors to consider alternative approaches, but it does not provide actionable steps or detailed analysis to support the authors in making improvements. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the observed improvement could be achieved with a better encoder, specifically mentioning RoBERTa-base instead of BERT. While it does not explicitly instruct the authors to use RoBERTa-base, the implication is clear that they should consider this option. The comment is somewhat actionable as it provides a concrete suggestion for improvement but lacks detailed guidance on how to implement this change or why it might be beneficial.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"encoder\" and compares it to \"RoBERTa-base,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the observed improvement could be achieved with a better encoder, providing a clear direction for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point poses a question about whether the observed improvement could be achieved with a better encoder, specifically mentioning RoBERTa-base instead of BERT. However, it does not provide any supporting evidence, reasoning, or references to justify why RoBERTa-base might be a better choice or how it could lead to improved performance. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the potential improvement in performance with a better encoder, specifically mentioning RoBERTa-base as an alternative to BERT. While it does not provide specific guidance or suggestions for improvement, it does prompt the authors to consider alternative encoders that could enhance their results. This feedback is somewhat helpful as it points out a potential area for exploration, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" While the action is implicit, it is clear that the authors need to provide a method for achieving fair policy learning without negatively impacting the predictive model\\'s performance. However, the comment does not specify how to achieve this or what specific steps to take, leaving some ambiguity. Therefore, the comment is somewhat actionable, as it provides a direction but lacks concrete guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request for a demonstration of fair policy learning without negatively impacting performance, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it could be achieved. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" This feedback is somewhat helpful as it identifies a potential weakness in the paper, specifically the impact of the proposed method on the predictive model\\'s performance. However, the comment lacks specific guidance or examples on how to achieve this balance or what specific steps the authors should take to address this issue. While it points out an area for improvement, it does not provide detailed instructions or suggestions for improvement, making it somewhat helpful but not fully actionable. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the lack of implementation details of the proposed methods is a concern and suggests that these details should be included in Section 4.1. This provides a clear and direct action for the authors to take, specifying where the details should be added and what needs to be included. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of implementation details of the proposed methods. This provides clear guidance on what the authors need to include in the implementation details section to address the reviewer\\'s concerns. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of implementation details of the proposed methods is a concern and suggests that these details should be included in Section 4.1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these details are necessary or how they would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the lack of implementation details of the proposed methods, which is a critical aspect of the paper. It suggests that these details should be included in Section 4.1, providing a clear and actionable suggestion for improvement. This feedback is valuable as it directs the authors to a specific area where their draft could be strengthened, ensuring that the implementation details are transparent and accessible to readers. However, the comment could be more helpful if it offered additional guidance on what specific details should be included or how they could be presented effectively. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the lack of empirical evaluation and comparison with other methods, indicating that the theoretical contributions may be significant but are not adequately demonstrated in the paper. It suggests that the authors should provide empirical evaluation and comparisons with other methods to clarify the practical value of their contributions. The comment is explicit in its request for empirical evaluation and comparison, providing concrete guidance on what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of empirical evaluation and comparison with other methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the theoretical contributions may be significant but are not adequately demonstrated in the paper, and that the theoretical contributions may be valuable but are not presented in a suitable form for publication at NeurIPS. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks empirical evaluation and comparison with other methods, making it unclear what the practical value of the theoretical contributions could be. The reviewer suggests that even a theoretical paper should provide some argument for why it matters. The comment is somewhat verifiable as it highlights a gap in the paper\\'s presentation, but it does not provide specific examples or references to support the claim that empirical evaluation is necessary or how it could be conducted. The lack of detailed justification or examples makes it somewhat challenging for the authors to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting the lack of empirical evaluation and comparison with other methods. It highlights that the theoretical contributions may be significant but are not adequately demonstrated in the paper, making it unclear what the practical value of the contribution could be. The comment suggests that even a theoretical paper should provide some argument for why it matters, which is not the case in this submission. While the comment points out a critical gap in the paper, it does not provide specific suggestions or guidance on how to address this issue. The authors are left with a clear understanding of the problem but without actionable steps to improve their draft. Therefore, the comment is somewhat helpful, as it identifies a significant weakness but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is limited in its application to navigation problems and points out that combining RL and planning has already been discussed in PRM-RL. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or explore more general tasks. The authors are left without any clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper is limited in its application to navigation problems and points out that combining RL and planning has already been discussed in PRM-RL. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the paper\\'s applicability to more general tasks, but it lacks grounding as it does not identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is limited in its application to navigation problems and suggests that combining RL and planning has already been discussed in PRM-RL. However, the comment does not provide any specific references or examples from PRM-RL to support this claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s applicability to navigation problems and suggests that combining RL and planning has already been discussed in PRM-RL. It points out that the paper could be more interesting if it explored more general tasks. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this limitation or expand their work. While it highlights an area for improvement, the feedback is incomplete and does not offer detailed guidance, making it somewhat helpful but not comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the lack of a clear and formal definition for the \"contrastive gap,\" which is central to the work. It acknowledges that an example was provided but finds it less convincing and points out specific issues with the setting. However, the comment does not provide explicit guidance on how to address these concerns or what specific changes should be made to improve the definition. The authors are left to infer that they need to provide a clearer definition, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is central to the work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a clear and formal definition for the contrastive gap. The comment provides detailed feedback on the example given and the setting, which further clarifies the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed \"contrastive gap\" is not clearly defined, despite being central to the work. It acknowledges that an example was provided but finds it less convincing due to the setting. The comment suggests that a clear, formal definition is needed. While the comment provides some reasoning by pointing out the issue with the example setting, it lacks specific examples or references to support the claim that the definition is unclear. This makes the claim somewhat verifiable, as the authors would need to further explore the issue to fully understand and address the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of a clear and formal definition for the \"contrastive gap,\" which is central to the work. It acknowledges that an example was provided but finds it less convincing due to the setting. The comment highlights the need for a clear definition and provides detailed feedback on the example, suggesting that the setting is less idealized than claimed. This feedback is actionable and constructive, as it guides the authors to clarify and strengthen the definition of the contrastive gap. However, the comment could be more helpful if it offered specific suggestions on how to improve the example or provided additional examples to illustrate the concept. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement and provides some guidance on how to address it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include other baselines, such as those mentioned in related work [29, 5, 6]. It also mentions that the authors have addressed the reviewer's weakness points and that all unclear parts have been answered. The reviewer provides a specific suggestion to include the explanation of why the chosen baseline makes the most sense. However, the comment does not explicitly instruct the authors to add this explanation or provide guidance on how to incorporate it into the paper. While the action is implied, it is not as concrete as it could be, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including other baselines, such as those mentioned in related work [29, 5, 6]. It also mentions that the authors have addressed the reviewer\\'s weakness points and that all unclear parts have been answered. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of other baselines and providing a rationale for why they should be included. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that other baselines should be included, such as those mentioned in related work [29, 5, 6]. However, it does not provide any specific reasoning or evidence to support why these baselines should be included or how they would enhance the study. The comment also mentions that the authors have addressed the reviewer\\'s weakness points and that all unclear parts have been answered, but it does not elaborate on these responses. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the importance of including these baselines and the rationale behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include other baselines, such as those mentioned in related work [29, 5, 6]. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting the inclusion of additional baselines. However, the comment lacks specific guidance on how to incorporate these baselines or why they are important for the study. Additionally, the comment mentions that the authors have addressed the reviewer\\'s weakness points and that all unclear parts have been answered, but it does not provide details on what these weakness points were or how they were addressed. Overall, the comment provides some direction for improvement but could be more comprehensive and actionable with additional details. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the uniform setting of \\u03b1_m in line 113, noting that it implies the contributions from all modalities are the same. The reviewer suggests that dynamically weighting the modalities is important, as demonstrated in multimodal fusion works. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors are left to infer that they should consider dynamically weighting the modalities but without detailed instructions on how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 113,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the uniform setting of \\u03b1_m and suggests that dynamically weighting the modalities is important in multimodal fusion. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that setting \\u03b1_m uniformly to 1/M implies that the contributions from all modalities are the same, which is not accurate. The reviewer supports this claim by referencing works in multimodal fusion that demonstrate the importance of dynamically weighting modalities. This reference provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to these works, which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the uniform setting of \\u03b1_m in line 113, noting that it implies the contributions from all modalities are the same. This is a relevant observation that could impact the validity and applicability of the work. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative weighting methods or discussing the implications of this uniform setting. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the pervasive use of the phrase \"to meet\" in the paper, particularly on line 280, which is difficult to understand. However, it does not provide any guidance on how the authors should address this issue or suggest alternative phrasing that might be clearer. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 280,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the pervasive use of the phrase \"to meet\" and how it is difficult to understand. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the pervasive use of the phrase \"to meet\" in the paper is difficult to understand. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the pervasive use of the phrase \"to meet\" in the paper, particularly on line 280, which is difficult to understand. This feedback is clear and actionable, as it points out a specific area where the language could be improved for clarity. However, the comment could be more helpful if it provided suggestions for alternative phrasing or clarified the intended meaning of the phrase. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific aspects of the method should be considered for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the network depth is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the method\\'s limitations should be addressed or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking about the limitations of the method, specifically regarding the depth of the network in the graph case. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. This is a relevant point that could prompt the authors to consider the depth of their network and its implications for the method\\'s effectiveness. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of the method should be considered for improvement. While it identifies a potential area for exploration, it does not offer actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the dropout method used in the paper, specifically asking about the dropping rate and the number of masks generated. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"dropout\" and \"multiple stochastic masks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the dropping rate and the number of masks generated, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the dropout method used in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the dropout method used in the paper, specifically asking about the dropping rate and the number of masks generated. This feedback is valuable as it prompts the authors to clarify and provide more detailed information about their methodology, which could enhance the transparency and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how similar methods have been presented in the literature. Overall, the comment is mostly helpful as it directs the authors to a critical area for clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the effectiveness of the proposed two-stage optimization approach needs further justification. It suggests that comparisons with other single-stage attacks and benchmarks with other state-of-the-art (SOTA) algorithms are necessary to demonstrate the effectiveness. This provides clear and concrete actions for the authors to take, such as including these comparisons and benchmarks to strengthen their claims. The comment is specific in detailing what additional information is needed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed two-stage optimization approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for further justifications, comparisons with other single-stage attacks, and benchmarks with SOTA algorithms to justify the effectiveness of the technical contributions. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the effectiveness of the proposed two-stage optimization approach needs further justification. It suggests that showing only the performance drop on fusion models is insufficient and that comparisons with other single-stage attacks are necessary to demonstrate effectiveness. The comment also implies that without proper benchmarks and comparisons with other state-of-the-art (SOTA) algorithms, it is difficult to justify the technical contributions. However, the comment does not provide specific examples or references to support these claims, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the critique, as the reasoning is not fully articulated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the need for further justification of the proposed two-stage optimization approach. It suggests that showing only the performance drop on fusion models is insufficient and that comparisons with other single-stage attacks and benchmarks with state-of-the-art (SOTA) algorithms are necessary to demonstrate the effectiveness. This feedback is clear and actionable, as it provides specific guidance on what additional information is needed to strengthen the paper\\'s claims. By addressing these points, the authors can significantly improve the clarity and robustness of their technical contributions. However, the comment could be more helpful if it included examples of specific comparisons or benchmarks that would be beneficial. Overall, the comment is mostly helpful as it effectively directs the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the Perceptual Metric in Figure 2, suggesting that it should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. While the comment identifies a specific area of concern, it does not provide explicit instructions on how to address this issue or what changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to make a correction but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the Perceptual Metric, suggesting that it should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the Perceptual Metric in Figure 2, noting that it should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This feedback is clear and actionable, as it points out a potential error in the experimental setup that the authors can address to improve the accuracy of their results. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve this issue, such as explaining why this distinction is important or offering alternative approaches to consider. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether each node can attend to its own lower-level representation, based on the description of N_l^(s) from equation 2. While it highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should clarify or modify the description of N_l^(s) to ensure that each node can attend to its own lower-level representation, but it lacks concrete instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether each node can attend to its own lower-level representation, based on the description of N_l^(s) from equation 2. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether each node can attend to its own lower-level representation, based on the description of N_l^(s) from equation 2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the ability of each node to attend to its own lower-level representation, based on the description of N_l^(s) from equation 2. This is a relevant point that could impact the understanding and interpretation of the model. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify the description. While it identifies a potential area for improvement, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several areas where the paper\\'s main contribution is unclear, specifically regarding the novel properties of the proposed method and how it copes with dynamic large-scale multitasking. It points out that the method\\'s ability and applicability are overstated or not well-supported, and that the automation process is unclear. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to clarify the main contribution. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations or examples to support their claims, but the comment lacks concrete steps or suggestions for improvement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the main contribution of the paper, specifically the novel properties of the proposed method and how it copes with dynamic large-scale multitasking. It points out that the method\\'s ability and applicability are overstated or not well-supported, and that the automation process is unclear. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the clarity of the main idea and the automation process. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the main contribution of the paper is unclear, specifically regarding the novel properties of the proposed method and how it copes with dynamic large-scale multitasking. The reviewer suggests that the method\\'s ability and applicability are overstated or not well-supported, and that the automation process is unclear. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of specific evidence or references makes the claim somewhat verifiable, as the authors would need to make a significant effort to address the issues raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s main contribution, noting that the novel properties of the proposed method and its ability to cope with dynamic large-scale multitasking are unclear. It points out that the method\\'s ability and applicability are overstated or not well-supported, and that the automation process is unclear. This feedback is valuable as it highlights specific areas where the authors need to provide more detailed explanations or evidence to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to clarify these aspects or provided examples of how similar methods have been effectively communicated. Overall, the comment is mostly helpful as it directs the authors to critical areas needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the lack of related work and experimentation with other extract-then-generate methodologies in the paper. It implies that the authors should include a related work section and experiment with other methods to demonstrate the novelty and effectiveness of their proposed system. While the comment does not explicitly instruct the authors to add a related work section or conduct additional experiments, the action is implied and concrete. The authors can infer that they need to address these gaps in their work, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the idea of long document summarization and questions the novelty of the proposed system compared to previous extract-then-generate methodologies. It specifically mentions the absence of a related work section and the lack of experimentation with other extract-then-generate methodologies. However, it does not specify which part of the paper this issue pertains to, such as the introduction, methodology, or results sections. While the authors can infer that it relates to the sections discussing the methodology and results, the comment is not fully grounded as it does not explicitly mention these sections. The comment is specific in identifying the need for a related work section and experimentation with other methods, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the novelty and effectiveness of the proposed system compared to previous extract-then-generate methodologies. It questions the absence of a related work section and the lack of experimentation with other methods. However, the comment does not provide specific examples or references to support the claim that the system does not offer any novelty or improvement over existing approaches. Without such evidence or reasoning, the claim remains unverifiable, as it lacks the necessary justification to be considered fully verifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of a related work section and the lack of experimentation with other extract-then-generate methodologies. This is a critical observation that could impact the paper\\'s credibility and novelty. The comment highlights the need for the authors to address this issue by including a related work section and experimenting with other approaches. While it does not provide specific suggestions on how to conduct these experiments or what specific related work should be included, it points out a clear area for improvement. This feedback is somewhat helpful as it directs the authors to a crucial aspect of their work that needs attention, but it could be more helpful with additional guidance on how to address the identified gaps. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. However, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The authors are left to infer that they should consider these alternatives, but without specific guidance on how to integrate them into their work, the action remains vague. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. However, it does not specify which part of the paper these suggestions pertain to, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment lacks specificity in detailing how these suggestions could be integrated into the paper or what specific aspects of the churn problem they address. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints. However, it does not provide any supporting evidence, reasoning, or references to justify why these directions are more appealing or effective. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. While these suggestions are interesting and could potentially improve the paper, the comment lacks depth and does not provide specific guidance on how to implement these directions or what specific aspects of the churn problem they address. The authors are left with a general idea of potential improvements but without actionable steps or detailed explanations, making the feedback somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, it does not provide any guidance on what specific quantitative measurement should be used or how to implement it. The comment lacks explicit instructions or concrete suggestions for the authors to follow, leaving them without clear direction on how to address this issue. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table where this measurement is discussed. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in identifying the issue of not proposing quantitative measurements, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the lack of quantitative measurement to assess the extent of occupation bias relative to real distributions in society. This is a relevant point that could impact the validity and generalizability of the study\\'s findings. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific quantitative measurements could be used. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly recommends using the real DICOM image as experiment data instead of the PNG image and suggests using the FastMRI challenge dataset for this purpose. It also advises comparing inference speeds between different methods. This feedback provides clear and concrete actions for the authors to take, such as changing the image format and including the FastMRI dataset in their experiments. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"real dicom image\" and suggests using the FastMRI challenge dataset, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be done, which is to use the real DICOM image as experiment data and compare inference speeds between different methods. This provides clear guidance on how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests using the real DICOM image as experiment data instead of the PNG image and recommends using the FastMRI challenge dataset. It also advises comparing inference speeds between different methods. While the comment provides a logical suggestion for improving the experiment setup, it lacks specific examples or references to support the claim that the DICOM image is more appropriate or how the FastMRI dataset would enhance the experiment. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and implement the suggestion fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by recommending the use of the real DICOM image as experiment data instead of the PNG image. It also suggests using the FastMRI challenge dataset for this purpose. Additionally, it advises comparing inference speeds between different methods. This guidance is specific and offers a concrete direction for the authors to improve their draft. By addressing the issue of using the appropriate image format and suggesting a specific dataset, the comment empowers the authors to enhance the quality and relevance of their experiments. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the binder design needs further optimization and validation, specifically mentioning that ProtPainter only provides empirical conformation estimation. However, it does not provide any explicit guidance on how to optimize or validate the binder design, nor does it suggest specific methods or experiments to conduct. The action is implied but lacks concrete details, leaving the authors with a vague understanding of what steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"binder design\" and \"ProtPainter,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for further optimization and validation of the binder design. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that ProtPainter only provides empirical conformation estimation for binder design, suggesting that further optimization and validation are required. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires further optimization and validation, specifically the binder design using ProtPainter. It highlights the need for additional work to ensure the robustness and reliability of the binder design. However, the comment lacks depth and does not provide specific suggestions or examples of how the authors might optimize or validate the binder design. While it points out a potential weakness, it does not offer actionable guidance or detailed advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about what happens if the original CAD model is already associated with spatially-varying (SV) BRDF maps. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this question is relevant to the paper or how it should be addressed. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the implications of having a CAD model associated with spatially-varying (SV) BRDF maps. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the potential consequences of this association, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about the implications of having a CAD model associated with spatially-varying (SV) BRDF maps. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment poses a question about the implications of having a CAD model associated with spatially-varying (SV) BRDF maps. While it highlights an area of interest, it does not provide any guidance or suggestions for the authors to address this question or explore its implications in their work. Without actionable feedback or context, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the statement about initialization, suggesting that it should be more carefully stated. It also references a specific paper, [1] Kunstner et al. (2019), which discusses the limitations of the empirical Fisher approximation for natural gradient descent. While the comment implies that the authors should reconsider their statement about initialization, it does not provide explicit guidance on how to revise the statement or what specific changes should be made. The reference to the external work is helpful but does not fully address the actionability of the comment. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statement about initialization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more careful statement about initialization. The reference to the external work, [1] Kunstner et al. (2019), provides additional context and support for the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that initialization plays a role in natural gradient descent (NGD) and suggests that it should be considered as pre-training. The reviewer supports this claim by referencing [1] Kunstner et al. (2019), which discusses the limitations of the empirical Fisher approximation for natural gradient descent. This reference provides a logical basis for the claim, as it suggests that initialization could be an important factor in the discretization of natural gradient functions. However, the comment could be strengthened by providing more detailed explanations or examples of how initialization affects NGD. Overall, the claim is mostly verifiable, as it is supported by a relevant reference but could benefit from additional justification or explanation.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the statement about initialization, suggesting that it should be more carefully stated. It references a specific paper, [1] Kunstner et al. (2019), which discusses the limitations of the empirical Fisher approximation for natural gradient descent. This reference provides a logical basis for the claim and offers a potential direction for improvement. However, the comment could be more helpful by providing specific suggestions on how to rephrase the statement about initialization or how to incorporate the reference into the paper. While it highlights an important area for clarification, the feedback could be more actionable with additional guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two main issues: the lack of clarity regarding how named entities were extracted from datasets and the need for an English-proofreading to improve the readability of the paper. While the first point is explicit in asking for clarification on the extraction process, the second point is more implicit in suggesting an improvement. However, both points are concrete in their request for clarification and improvement, respectively. The authors know exactly what needs to be done to address both issues, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for clarification on how named entities were extracted from datasets, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for an English-proofreading to improve the readability of the paper. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks clarity regarding how named entities were extracted from datasets and suggests that an English-proofreading would significantly improve the readability of the paper. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement: clarity regarding the extraction of named entities from datasets and the need for an English-proofreading to enhance the readability of the paper. While the comment highlights these issues, it does not provide detailed guidance or suggestions on how to address them. The authors are informed of the need for clarity and readability but are left without specific steps to take to improve their draft. Therefore, the comment is somewhat helpful, as it points out areas for improvement but lacks actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the inversion of matrix determination or the division of the number of samples is being referred to in the context of Eqs. The reviewer does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions on how to clarify or correct the issue. Without any guidance or direction, the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the context of Eqs., specifically whether it is the inversion of matrix determination or the division of the number of samples. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the context of the equations, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the context of Eqs. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the context of Eqs., specifically whether it is the inversion of matrix determination or the division of the number of samples. While this question highlights a potential confusion in the paper, it does not provide any actionable feedback or suggestions for improvement. The authors are left with a vague inquiry that does not guide them on how to address the issue or improve the clarity of their work. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the clarity of the motivation for the task and questions the potential downstream applications or benefits of amodal tracking. It also asks about how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to provide more information about the motivation and potential applications of their work, but the comment lacks specific suggestions on how to do so. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not offer concrete steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the motivation of the task and the potential downstream applications or benefits of amodal tracking. It also asks about how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for clarification on the motivation and potential applications of the work, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the clarity of the motivation for the task and the potential downstream applications or benefits of amodal tracking. It also questions how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas for improvement, it lacks specific examples, references, or detailed reasoning to support the claim that the motivation is unclear or that the potential applications are unclear. The authors are left to infer the need for clarification, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the motivation of the task and the potential downstream applications or benefits of amodal tracking. It highlights the difficulty in predicting the state of an object when it is occluded and questions how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. This feedback is valuable as it prompts the authors to consider the broader implications and potential impact of their work. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or clarify their motivation. Overall, the comment is somewhat helpful as it identifies areas for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include experiments with GPT-3.5, which is a more affordable option than GPT-4, to provide a more comprehensive evaluation of their proposed approach. This feedback is explicit and provides a clear action for the authors to take, which is to include experiments with GPT-3.5. The comment is concrete because it specifies the exact change needed to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including experiments with GPT-3.5, which is a more affordable option than GPT-4, to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of the proposed approach. The authors can infer that it relates to the experimental setup or evaluation, but this inference is not direct. The comment is specific in suggesting the inclusion of GPT-3.5 experiments but lacks grounding as it does not explicitly mention which part of the paper should include this suggestion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include experiments with GPT-3.5, which is a more affordable option than GPT-4, to provide a more comprehensive evaluation of their proposed approach. However, the comment does not provide any supporting evidence or reasoning to justify why GPT-3.5 is a better option or why it would provide a more comprehensive evaluation. Without additional context or comparisons, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include experiments with GPT-3.5, which is a more affordable option than GPT-4, to provide a more comprehensive evaluation of their proposed approach. This feedback is clear and actionable, as it directly advises the authors to include a more cost-effective option in their experiments. However, the comment could be more helpful if it provided additional context or justification for why GPT-3.5 is a better choice or how it might impact the evaluation. Despite this, the suggestion is valuable as it encourages the authors to consider a broader range of options for their experiments. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the word \"confident\" in the sentence is unclear and suggests rephrasing it to clarify whether it pertains to model confidence or human interpretability. While the comment implies that the authors should rephrase the sentence to improve clarity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should revise the sentence to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sentence containing the word \"confident,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the word \"confident\" and suggests rephrasing to clarify whether it pertains to model confidence or human interpretability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the word \"confident\" in the sentence, suggesting that it may refer to model confidence or human interpretability. The reviewer provides a logical reasoning by questioning the word choice and suggesting a rephrasing to clarify the meaning. However, the comment lacks specific examples or references to support the claim that the word is unclear or misleading. While the reasoning is sound, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the word \"confident\" in the sentence, suggesting that it may be unclear whether it pertains to model confidence or human interpretability. While the comment highlights a potential source of confusion, it does not provide specific suggestions for rephrasing or clarifying the sentence. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks actionable guidance on how to address the issue. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of polishing in figures and empirical results, which affects clarity and confidence in empirical findings. It provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on small-scale datasets and a single architecture type. However, the comment does not explicitly instruct the authors on how to address these issues or provide guidance on how to improve the clarity and polish of the figures and results. The action is implicit and somewhat vague, as the authors can infer that they need to improve the presentation of their results, but the comment lacks concrete details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific issues with the figures and empirical results, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the lack of polishing in figures and empirical results, including missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on small-scale datasets and a single architecture type. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks polishing in figures and empirical results, which affects clarity and confidence in empirical findings. The comment provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on small-scale datasets and a single architecture type. These examples provide a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that have addressed these issues. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity and confidence in the empirical findings of the paper. It points out specific problems, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on small-scale datasets and a single architecture type. These observations highlight areas where the paper could be improved in terms of polish and presentation, which are crucial for ensuring the validity and impact of the results. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as recommending specific improvements or examples of how similar studies have handled these challenges. Overall, the comment is mostly helpful as it identifies important areas for improvement, but it lacks detailed guidance on how to achieve them.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the choice of using the number of weight updates as a metric rather than the number of network updates, given that the brain operates in parallel. It implies that the authors should provide additional feedback to explain this choice and potentially justify it. However, the comment does not explicitly instruct the authors to provide this feedback or specify what additional information should be included. While the action is implied, it is not concrete, as the authors are left to infer what specific feedback is needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of using the number of weight updates as a metric rather than the number of network updates, given that the brain operates in parallel. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this metric is discussed. The authors can infer that it relates to the discussion of metrics or experimental results, but this inference is not direct. The comment is specific in its question about the choice of metrics, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of using the number of weight updates as a metric rather than the number of network updates, given that the brain operates in parallel. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the number of weight updates is a better metric. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to substantiate the critique. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the choice of metrics used in the paper, specifically questioning the rationale behind using the number of weight updates as a metric rather than the number of network updates, given that the brain operates in parallel. This is a relevant point that could lead to a deeper understanding of the paper\\'s methodology and its implications. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or provide additional feedback to improve the paper. While it identifies a potential area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of the objective should be clarified. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification on the objective, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. This is a relevant point that could help the authors clarify the purpose and significance of their proposed method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this question or improve their explanation. While it identifies an area for clarification, it does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the contrastive learning framework used in the paper is the same as SimCLR, which is a direct observation. However, it does not provide any guidance or suggestions on how the authors should address this observation or what changes they should make to their framework. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment states that the contrastive learning framework used in the paper is the same as SimCLR, but it does not specify which part of the paper this observation is based on. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what needs to be addressed or improved regarding the comparison to SimCLR. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the contrastive learning framework used in the paper is the same as SimCLR, which could be a potential issue or a point of comparison. However, it does not provide any further context, explanation, or suggestions on how the authors might address this observation or what implications it might have for their work. Without actionable feedback or guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by making the comparisons with the most closely related work more systematic. It specifically recommends comparing the best performance of each method, which provides a clear and concrete action for the authors to take. The comment is explicit in its suggestion and offers a specific improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"most closely related work of Zemel et al. (2013)\" and the present paper, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely making comparisons more systematic with respect to the tuning of each method. This provides clear guidance on how to enhance the originality and comparative analysis of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper could be improved by making comparisons with the most closely related work more systematic, specifically by comparing the best performance of each method. The comment provides a logical reasoning by suggesting that such comparisons would enhance the originality and depth of the paper. However, it lacks specific examples or references to the Zemel et al. (2013) work, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need to make comparisons with the most closely related work more systematic. It suggests that the authors should compare the best performance of each method, which could enhance the originality and depth of the paper. This feedback is clear and actionable, providing the authors with a concrete step to improve their draft. However, the comment could be more helpful if it included specific examples or guidance on how to implement these comparisons. Overall, the comment is mostly helpful as it directs the authors to a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to explicitly estimate the time complexity of the learning algorithm to prove its scalability properties. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete suggestion for how to enhance the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the need to estimate the time complexity of the learning algorithm to prove its scalability properties, providing full grounding as it clearly identifies the part of the paper being addressed. It is specific because it clearly specifies what needs to be addressed, namely the estimation of time complexity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the paper\\'s conclusions. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. This is a clear and actionable suggestion that can help the authors strengthen their claims about the algorithm\\'s performance. By addressing this point, the authors can provide more robust evidence to support their conclusions. However, the comment could be more helpful if it included examples or guidance on how to estimate the time complexity effectively. Overall, the comment is mostly helpful as it directs the authors to a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that there may be a connection between the third point of definition one and properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann. However, it does not provide explicit instructions or guidance on how the authors should explore or incorporate this connection. The comment implies that the authors should investigate the relationship but lacks concrete steps or suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential connection to properties of universal kernels, referencing chapter 4 of Steinwart and Christmann, which discusses the ability of universal kernels to separate an arbitrary finite data set with margin arbitrarily close to one. This provides clear guidance on what aspect of the paper needs attention and how it might be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a potential connection between the third point of definition one and properties of universal kernels, specifically referencing chapter 4 of Steinwart and Christmann. However, the comment does not provide specific examples or detailed reasoning from the referenced work to support the claim. While it points to a relevant source, the lack of detailed explanation or examples makes the claim somewhat verifiable, as the authors would need to follow up on the reference to fully understand the connection. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests a potential connection between the third point of definition one and properties of universal kernels, specifically referencing chapter 4 of Steinwart and Christmann. This is a valuable suggestion that could lead to a deeper understanding and exploration of the topic. However, the comment lacks specific guidance or examples on how the authors might incorporate this connection into their work or what aspects of the connection are most relevant. While it points to a potentially interesting direction, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
