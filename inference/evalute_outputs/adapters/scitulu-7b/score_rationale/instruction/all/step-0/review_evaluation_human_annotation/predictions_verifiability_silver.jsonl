{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting specific theoretical aspects to explore or methods to demonstrate convergence. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not specify which part of the paper this issue pertains to, such as specific sections or figures where these aspects should be addressed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what aspects of the theory profs or convergence properties should be explored or demonstrated. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. This feedback is clear and actionable, as it points out a critical area where the paper could be strengthened by providing more theoretical analysis and experimental evidence. However, the comment could be more helpful if it offered specific suggestions on how to address this gap, such as recommending specific theoretical aspects to explore or methods to demonstrate convergence. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the description of HIERENC is unclear and suggests that it might introduce noise due to the averaging of multiple contextual representations. However, it does not provide explicit guidance on how to clarify the description or address the issue of noise. The authors are left to infer that they need to clarify the description and possibly reconsider the averaging approach. While the comment identifies a potential problem, it lacks concrete instructions on how to resolve it, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of HIERENC, explaining that the averaging of multiple contextual representations might introduce noise and suggesting that only one instantiation is likely correct. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and suggests that averaging multiple contextual representations might introduce noise. The reviewer provides a logical reasoning by explaining that only one instantiation is likely correct and that averaging multiple representations could lead to noise. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and potential consequences to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of HIERENC, noting that the averaging of multiple contextual representations might introduce noise. It provides a logical reasoning that only one instantiation is likely correct, which could lead to noise. This feedback is clear and actionable, as it points out a potential weakness in the description and suggests a possible improvement. However, the comment could be more helpful if it provided specific suggestions on how to clarify the description or address the issue of noise. Overall, the comment is 4 as it directs the authors to a critical area needing clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the selection of only 10 answers from all correct answers and asks if this affects the underestimation of performance. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification or explanation for their choice. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors mention selecting 10 answers from all correct answers, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the potential impact of this selection on the underestimation of performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the selection of only 10 answers from all correct answers and its potential impact on performance underestimation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the selection of only 10 answers from all correct answers and asks if this affects the underestimation of performance. This is a relevant question that could prompt the authors to reconsider their methodology or provide additional context to explain their choice. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a potential area for improvement, it does not provide actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a discrepancy in the description of the data sources, specifically noting that line 226238 suggests the authors selected sentences from raw data, while line 242244 states that these sources already have syntactic information. The reviewer suggests that the description can be revised by mentioning Li et al. (2019a) earlier to clarify and improve the precision of the information. This feedback provides a clear and explicit action for the authors to take, specifying exactly what needs to be revised to improve the clarity of the description. The action is concrete and leaves no ambiguity, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (226238 and 242244) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issue with the description of the data sources, suggesting that the authors should revise the description to mention Li et al. (2019a) earlier to clarify and improve the precision of the information. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a discrepancy in the description of the data sources, specifically noting that line 226238 suggests the authors selected sentences from raw data, while line 242244 states that these sources already have syntactic information. The reviewer suggests that the description can be revised by mentioning Li et al. (2019a) earlier to clarify and improve the precision of the information. This claim is 3 as it provides a logical reasoning for the suggested revision, but it lacks specific examples or references to support the claim fully. The authors would need to make an effort to verify the claim by revisiting the lines in question and considering the suggested revision. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific discrepancy in the description of the data sources, noting that line 226238 suggests the authors selected sentences from raw data, while line 242244 states that these sources already have syntactic information. The reviewer suggests that the description can be revised by mentioning Li et al. (2019a) earlier to clarify and improve the precision of the information. This feedback is clear and actionable, as it provides a concrete suggestion for how the authors can revise their description to avoid confusion and ensure clarity. By addressing this issue, the authors can improve the accuracy and comprehensibility of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and asks for a supporting explanation. It does not provide explicit instructions or suggestions for the authors to follow, but it implies that the authors should clarify the purpose of the reported duration and potentially include information about the time spent by the user waiting for the model to generate a response. While the action is implied, it is clear and concrete, as it guides the authors to provide a more detailed explanation or clarification in their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in Table 1 and requests a supporting explanation, including whether it includes time spent by the user waiting for the model to generate a response. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and requests a supporting explanation. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a request for clarification and does not present an argument or claim that needs justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the purpose of the average duration reported in Table 1, noting the lack of a supporting explanation. It highlights an area where the authors could provide more clarity and context for their readers. While the comment identifies a potential gap in the paper, it does not offer specific suggestions or guidance on how to address this issue. The authors are given a clear direction to provide a more detailed explanation, but the comment could be more helpful with additional advice or examples on how to present this information effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the interpretation of results shown in Table 3, specifically regarding the comparison between NVSB and GT Mel A for Chinese MOSQ and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOSV. While the comment identifies areas of confusion, it does not provide explicit instructions or suggestions on how to address these issues. The authors are left to infer that they need to clarify or explain these points, but without concrete guidance, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the interpretation of results, such as the comparison between NVSB and GT Mel A for Chinese MOSQ and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOSV. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements and observations about the results presented in Table 3. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific issues with the interpretation of results presented in Table 3, particularly regarding the comparison between NVSB and GT Mel A for Chinese MOSQ and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOSV. By pointing out these discrepancies, the comment provides the authors with clear and actionable feedback on areas that need clarification or further explanation. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context or examples to aid in interpretation. Overall, the comment is 4 as it directs the authors to specific areas needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a formatting issue in Tables 2 and 3, specifically noting the inconsistent spacing between accuracy and standard deviation. This is an explicit observation that the authors can directly address by ensuring consistent spacing in their tables. The comment provides a clear and concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of inconsistent spacing between accuracy and standard deviation in these tables, which affects the presentation\"s aesthetics. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that inconsistent spacing between accuracy and standard deviation in Tables 2 and 3 affects the presentation\"s aesthetics. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific formatting issue in Tables 2 and 3, noting inconsistent spacing between accuracy and standard deviation. This is a clear and actionable observation that the authors can address to improve the presentation of their data. By pointing out this inconsistency, the comment provides valuable feedback that can help the authors enhance the aesthetics and readability of their tables. However, the comment could be more helpful if it offered suggestions on how to standardize the spacing or provided examples of how other tables in the field address this issue. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a missing antecedent in the text and suggests checking the references for format issues, such as capitalization and bibliographic details. While the comment explicitly identifies the missing antecedent and provides specific guidance on what to check, it does not offer detailed instructions on how to implement these checks or what specific issues to focus on. The action is clear but somewhat vague in terms of execution, as the authors need to determine the exact details of how to address the formatting issues. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the line number \"781,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the references, suggesting that they should be checked for format, such as capitalization and bibliographic details. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and requests for clarification. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of references, noting that the antecedent is missing and suggesting that the references should be checked for capitalization and bibliographic details. This feedback is clear and actionable, as it provides a concrete step for the authors to take in order to improve the quality of their references. However, the comment could be more helpful if it offered additional guidance on how to ensure proper formatting or provided examples of what constitutes proper capitalization and bibliographic details. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the explanations for features in Section 3.2 are confusing due to their intertwined nature. It provides a clear and concrete suggestion to improve the organization of the section by recommending separate paragraphs for lexical features and sentencelevel features. This explicit guidance offers a direct action for the authors to take, making the comment 5. Authors know exactly what changes to make to improve the clarity and coherence of their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the intertwined explanations for features and the suggestion to organize the section with separate paragraphs for lexical features and sentencelevel features. This provides clear guidance on how to improve the clarity and coherence of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations for features in Section 3.2 are confusing due to their intertwined nature. It suggests that the section would be more coherent with separate paragraphs for lexical features and sentencelevel features. While the comment provides a logical reasoning for the suggested improvement, it lacks specific examples or references to support the claim that the current organization is confusing. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization and clarity of the explanations for features in Section 3.2. It suggests that the section would be more coherent and easier to understand with separate paragraphs dedicated to lexical features and sentencelevel features. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the organization and readability of their draft. By following this advice, the authors can enhance the clarity and comprehensibility of their explanations, which is valuable for improving the overall quality of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper is unclear about how the proposed models compare to models that only consider different senses but not sememes. It implies that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. While the comment identifies a potential area for improvement, it does not provide explicit instructions on how to incorporate these baselines or what specific aspects of the comparison should be addressed. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"MST baseline\" and suggests that it might be an example of a model that only considers different senses but not sememes. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of more baselines based on related work to clarify the comparison between the proposed models and those that only consider different senses. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is unclear about how the proposed models compare to models that only consider different senses but not sememes. The reviewer suggests that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the basis of the claim and potentially conduct additional research to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper regarding the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and proposes that the paper would be strengthened by including more baselines based on related work. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their comparison and analysis. However, the comment could be more helpful if it offered specific examples of related work or baselines that should be considered. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this aspect of their work. The comment lacks actionable details, such as recommending specific ways to present the selection process or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve the clarity of their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper discusses the selection of frame similarity factors and attributes similarity factors. Without explicit references to sections, figures, or specific elements, the authors cannot confidently determine where to address the issue. Additionally, the comment lacks specificity as it does not provide details on what is unclear about the selection process or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential area of confusion regarding the selection of frame similarity factors and attributes similarity factors. However, it does not provide specific guidance or suggestions on how the authors might clarify this aspect of their work. Without actionable feedback or detailed explanations, the authors are left without a clear understanding of what steps to take to improve the clarity of their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that discussions are required on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to clarify how stable points in the probabilistic metric space are obtained. This provides a clear and direct action for the authors to take, which is to include these discussions in their draft. The comment is specific and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"joint learning process\" and the specific models \"RNN\" and \"CopyRNN,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the convergence of the joint learning process and how stable points in the probabilistic metric space are obtained. This provides clear guidance on what the authors need to include in their paper to improve clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that discussions are required on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to clarify how stable points in the probabilistic metric space are obtained. This claim is 3 as it logically suggests that understanding the convergence process is crucial for reproducing results. However, the comment lacks specific examples or references to support the claim, making it somewhat challenging for the authors to fully grasp the importance of this discussion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that discussions on the convergence of the proposed joint learning process are required. This feedback is clear and actionable, as it directs the authors to provide more detailed information on how the stable points in the probabilistic metric space are obtained. By addressing this point, the authors can enhance the clarity and reproducibility of their results. However, the comment could be more helpful if it provided examples or references to similar discussions in related literature, which would further guide the authors in developing their analysis. Overall, the comment is 4 as it effectively points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). Additionally, it mentions that it would be better to use the same terminology for the model in Tables 1 and 2. While the comment provides explicit actions to take, it does not offer concrete guidance on how to implement these suggestions or what specific terminology should be used. The authors are left with a clear understanding of what needs to be done but without detailed instructions on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, \"681\" and \"778,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the results for the task of inferring knowledge on objects and the inclusion of results for model (B). Additionally, it provides a suggestion to use the same terminology for the model in Tables 1 and 2. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). It also mentions that it would be better to use the same terminology for the model in Tables 1 and 2. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that using the same terminology would be beneficial. This makes the claim 3, as the authors would need to make a logical inference to understand the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors discuss the results for the task of inferring knowledge on objects and include results for model (B). It also points out that it would be beneficial to use the same terminology for the model in Tables 1 and 2. This feedback is clear and directs the authors to specific areas for improvement, offering a concrete path for enhancing the clarity and completeness of their draft. However, the comment could be more helpful if it provided additional context or examples on how to implement these suggestions effectively. Overall, the comment is 4 as it guides the authors toward improving their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. While the comment implies that the authors should consider including these baselines, it does not provide explicit instructions or detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should include additional baselines but are not given specific steps on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. However, it does not specify which part of the paper this extension or the baselines should be added to, making it weakly grounded. The comment is specific in suggesting the inclusion of character embeddings as a baseline, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this extension is necessary or how character embeddings would enhance the work. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. While the comment identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how to implement these additional baselines or why they are necessary. The suggestion is 3 as it points out a potential area for enhancement, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper relies on supplemental space to contain the paper, which makes it not truly independent. It specifically mentions the reference to Supplementary Figure 6 in S3.1 and the model comparison and other details of the span vs. sentence investigation as examples of this reliance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the independence of the paper. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their approach to independence but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as S3.1 and the model comparison, allowing the authors to accurately identify the parts being addressed. It also specifies the issue of reliance on supplemental space and the lack of independence in the paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper relies on supplemental space to contain the paper, which makes it not truly independent. It supports this claim by referencing specific sections, such as S3.1 and the model comparison, where the paper references supplementary figures and details of the span vs. sentence investigation. This provides a clear and specific basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it relies heavily on supplemental space to contain the main content. This is a critical observation, as it suggests that the paper may not be truly independent and could benefit from more selfcontained sections. The comment also points out specific examples, such as the reference to Supplementary Figure 6 in S3.1 and the model comparison, where the reliance on supplemental space is evident. While the comment highlights a critical weakness, it does not provide detailed suggestions on how the authors might address this issue or improve the independence of the paper. This limits the comment\"s helpfulness, as it provides insight but lacks actionable guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several weaknesses in the paper, particularly in the experiments, which are limited to an extremely lowresource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks but was not demonstrated. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve the experiments. The feedback is vague and lacks concrete steps for the authors to take, leaving them without clear direction on how to enhance their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the main weaknesses of the paper, specifically the experiments, which are limited to an extremely lowresource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks but was not demonstrated. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the limitations of the experiments and the potential of the proposed augmentation method, but without clear grounding, the authors may struggle to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are the main weaknesses of the paper, as they are limited to an extremely lowresource regime and sentence classification, which are not the only cases for data augmentation in realworld applications. The reviewer also suggests that the proposed augmentation method has potential to be used on more NLP tasks but was not demonstrated. While the comment identifies specific limitations and potential areas for improvement, it lacks detailed reasoning or references to support the claim that the experiments are weak. The suggestion for expanding the scope of the experiments is logical but could be strengthened with more specific examples or references. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies several weaknesses in the paper, particularly in the experiments, which are limited to an extremely lowresource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks but was not demonstrated. This feedback is 3 as it points out specific areas for improvement, such as expanding the scope of the experiments to include more NLP tasks. However, the comment could be more helpful if it provided suggestions on how to address these weaknesses or examples of other tasks that could be considered. Overall, the comment offers some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to describe the traits of the experts and justify why annotation must be carried out by them, outside of its commercial value. It also asks specific questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. These questions provide clear guidance on what the authors need to address to improve their draft. The action is explicit and concrete, as it specifies exactly what needs to be added or clarified. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first point, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the description of the traits of the experts and the justification for why annotation must be carried out by them, outside of its commercial value. The comment also raises questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. This level of detail provides clear guidance on what the authors need to address to improve their draft, making the comment 5.", "verifiability_rationale": "The review point raises questions about the expertise of the annotators and the justification for why annotation must be carried out by them, outside of its commercial value. It suggests that the authors should provide more information about the traits of the experts and the linguistic challenges introduced by the annotation process. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that the annotation process introduces linguistic challenges. This makes the claim 3, as it provides a direction for improvement but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by questioning the authors\" description of the traits of the experts and the justification for why annotation must be carried out by them, outside of its commercial value. It raises important questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. This feedback is clear and provides the authors with a concrete direction for improving their draft by addressing these points. By offering detailed questions and suggestions, the comment empowers the authors to enhance the clarity and robustness of their work. Therefore, it is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. While the action is implied, it is clear and provides a concrete direction for the authors to take. The comment explicitly states what the authors should do, which is to include examples of the system on actual texts. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including examples of the system on actual texts, rather than focusing on other components and models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where examples could be included. Without explicit references, the authors may struggle to identify the exact areas that need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. This feedback is 3 as it points out a potential area for improvement in the paper, which could enhance the reader\"s understanding of the system\"s capabilities. However, the comment lacks specific guidance on how to implement this suggestion or what specific examples would be most effective. While it identifies a potential improvement, it does not provide detailed instructions or examples to fully support the authors in making these changes. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a discrepancy between the paper\"s claims and its actual content. It points out that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not follow through on testing or discussing them. The reviewer suggests that the hypotheses could be tested as given and that the paper should delve deeper into the respective topics. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to test the hypotheses or what aspects of the topics should be explored. The action is explicit but somewhat vague, as the authors know they need to address the issue but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 078086, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not follow through on testing or discussing them. The comment suggests that the hypotheses could be tested as given and that the paper should delve deeper into the respective topics. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not follow through on testing or discussing them. The reviewer suggests that the hypotheses could be tested as given and that the paper should delve deeper into the respective topics. However, the comment lacks specific examples or references to support the claim that the hypotheses are not tested or discussed. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it raises two hypotheses about multilinguality and country/languagespecific bias but does not follow through on testing or discussing them. This is a critical observation, as it misleads readers into thinking that the paper addresses these topics when it does not. The comment suggests that the hypotheses could be tested as given and that the paper should delve deeper into the respective topics, at least to some extent. While the feedback is clear and actionable, it could be more helpful if it provided specific guidance on how to test the hypotheses or what aspects of the topics should be explored. Overall, the comment is 4 as it highlights a significant gap in the paper and offers a direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the use of the Challenge Set (CS) and seeks clarification on its role in the evaluation process. It implies that the authors should provide more information about how the CS is used, whether it is used for augmenting the training material, and the data split used. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the CS. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Challenge Set\" (CS), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how the CS is used, whether it is used for augmenting the training material, and the data split used. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the use of the Challenge Set (CS) in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the use of the Challenge Set (CS) in the paper, specifically inquiring about its role in evaluation and whether it is used for augmenting the training material. It also asks for clarification on the data split used. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential gap in the paper, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the performance of the TWSI model on nouns and questions the generalizability of the clustering approach to all parts of speech. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment implies that the authors should investigate the gap between the oracle GAP for PPDBClus and the performance of the clustering approach, but it does not specify how to conduct this investigation or what specific aspects to focus on. Additionally, it does not offer suggestions on how to improve the uniformity of the performance across all parts of speech. As a result, the comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance of the TWSI model on nouns and the contradiction with the claim of generalizability to all parts of speech. It mentions the oracle GAP for PPDBClus and the fact that the performance is higher than most clustering approaches. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the performance and the contradiction with the claim, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the performance of the TWSI model on nouns and questions the generalizability of the clustering approach to all parts of speech. It mentions the oracle GAP for PPDBClus and the fact that the performance is higher than most clustering approaches, which directly contradicts the claim that the clustering approach is generalizable. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or reasoning makes the claim 3, as it requires further elaboration for the authors to fully understand and address the issue.", "helpfulness_rationale": "The review comment identifies a concern about the performance of the TWSI model on nouns, which is a significant issue. It also points out the contradiction between the claim of generalizability to all parts of speech and the fact that the performance is not uniform across all parts of speech. This feedback is valuable as it highlights a potential weakness in the paper that the authors should address. However, the comment could be more helpful if it provided specific suggestions on how to investigate and understand the gap between the oracle GAP for PPDBClus and the performance of the clustering approach. Additionally, it could offer guidance on how to improve the uniformity of the performance across all parts of speech. Overall, the comment is 3 as it directs the authors to a critical area needing attention, but it could be more actionable with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the discussion in Section 5.2 is too abstract and does not provide insights into why the new model is better than MH. It explicitly requests examples of spurious structures to help clarify the discussion. This feedback is clear and provides a specific action for the authors to take, which is to provide examples of spurious structures to support their claims. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, which is that it is too abstract and does not provide insights into why the new model is better than MH. The comment also requests examples of spurious structures to help clarify the discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion in Section 5.2 is too abstract and does not provide insights into why the new model is better than MH. It suggests that examples of spurious structures could be provided to clarify the discussion. However, the comment lacks specific examples or references to support the claim that the discussion is abstract or unclear. Without these details, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstractness of the discussion in Section 5.2, noting that it does not provide insights into why the new model is better than MH. It suggests that examples of spurious structures could be provided to clarify the discussion. While the comment highlights a clear area for improvement, it lacks depth and does not provide specific guidance on how to address the issue or what kind of examples would be helpful. This limits the comment\"s usefulness, as it points out a problem but does not offer detailed suggestions for improvement. Therefore, the comment is 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. This is a clear and direct action for the authors to take, as it provides a specific and concrete step to enhance the presentation of their results. The comment is 5 because it clearly specifies what needs to be added to the table, making it easy for the authors to implement the suggested change.", "grounding_specificity_rationale": "The comment suggests adding the hard prompt baseline to Table 1 to show the increase in performance of each method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting the inclusion of the hard prompt baseline, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. However, it does not provide any reasoning or evidence to support why this inclusion is necessary or how it would benefit the paper. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. This is a clear and actionable suggestion that could enhance the presentation of the results. By including the hard prompt baseline, the authors can provide a more comprehensive comparison of their methods, allowing readers to better understand the performance improvements. However, the comment could be more helpful if it explained why the inclusion of the hard prompt baseline is important or how it would benefit the paper. Overall, the comment is 4 as it directs the authors to a specific improvement that could enhance the clarity and comprehensiveness of their results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. While it implies that the authors should include numerical results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include numerical results to address the reviewer\"s curiosity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. However, it does not specify which part of the paper lacks numerical results or where the application to popular algorithms should be discussed. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for numerical results and application to popular algorithms, but it is 1 as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of numerical results and expressing curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. This feedback is valuable as it highlights an area where the paper could be strengthened by including numerical results, which would provide more concrete evidence and support for the claims made. However, the comment lacks specific guidance on how to implement this suggestion or what specific comparisons should be made. While it points out a critical area for improvement, it could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experimental comparisons are not sufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2x) and ResNet50 (4x). This feedback provides a clear and explicit action for the authors to take, which is to conduct additional experiments with these wider backbones. The comment is specific in detailing what additional comparisons are needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental comparisons and suggests testing the proposed InvP method with wider backbones like ResNet50 (2x) and ResNet50 (4x). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what additional comparisons are needed and why they are important. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental comparisons are not sufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2x) and ResNet50 (4x). However, the comment does not provide any supporting evidence, reasoning, or references to justify why these additional comparisons are necessary or how they would impact the results. Without such justification, the claim remains 1, as it lacks the necessary information to support the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental comparisons, specifically noting that the proposed InvP method is not tested with wider backbones like ResNet50 (2x) and ResNet50 (4x). This feedback is valuable as it suggests a potential area for improvement in the experimental design, which could enhance the robustness and generalizability of the results. However, the comment could be more helpful if it provided specific guidance on how to implement these additional comparisons or why they are important. Overall, the comment is 4 as it points out a relevant area for improvement but lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the callout to Table 5 should be changed to Table 3 and provides the correct page and section number. Additionally, it points out that the figure 6 callout is not directing properly. This feedback is clear and provides specific actions for the authors to take, ensuring that they know exactly what needs to be corrected. The explicit nature of the instructions and the concrete details on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5\" and \"figure 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the callout to Table 5 and the figure 6 callout, providing detailed guidance on how to correct these issues. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the callout to Table 5 should be changed to Table 3 and that the figure 6 callout is not directing properly. However, the comment does not provide any supporting evidence, reasoning, or examples to justify these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out a mistake in the callout to Table 5, which should be changed to Table 3, and noting that the figure 6 callout is not directing properly. This feedback is clear and directs the authors to correct specific errors in their paper, ensuring that the references are accurate and easy to follow. By addressing these issues, the authors can improve the clarity and accuracy of their work. Therefore, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant concern with the experiments, specifically the lack of comparisons with other models, such as SketchRNN. It explicitly states that the paper should include comparisons with other models to provide a more comprehensive understanding of its results. The comment is clear and provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the lack of comparisons with other models, such as SketchRNN. The comment provides a clear direction for improvement by suggesting that comparisons with other models should be included. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are a significant concern due to the lack of comparisons with other models, specifically SketchRNN. The comment suggests that this lack of comparison adds to the poor motivation problem. However, the comment does not provide specific examples or references to support the claim that the lack of comparisons is a significant issue. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a significant concern with the paper\"s experiments, specifically the lack of comparisons with other models, such as SketchRNN. It points out that the paper\"s selfcomparisons are insufficient and that the absence of comparisons with other models contributes to the poor motivation problem. The comment provides a clear and actionable suggestion for improvement by recommending the inclusion of comparisons with other models. This feedback is valuable as it guides the authors to enhance the comprehensiveness and robustness of their experimental analysis. However, the comment could be more helpful if it explained why comparisons with SketchRNN are particularly important or how they might impact the paper\"s conclusions. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment acknowledges that the paper is not difficult to follow but points out specific areas that may cause confusion. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to improve clarity or what specific changes should be made to avoid confusion. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not specify which sections or parts of the paper these areas are located in, making it difficult for the authors to pinpoint the exact issues. The comment is specific in identifying potential areas of confusion but lacks grounding as it does not specify where these issues are located in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the identified areas of confusion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not provide any detailed guidance or suggestions on how to address these areas of confusion. Without actionable feedback or specific examples, the authors are left without a clear path to improve the clarity of their draft. Therefore, the comment is 2, as it points out an issue but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the claim of \"no corresponding set of tools for the reinforcement learning setting\" is false, providing references to support this claim. This feedback is clear and directs the authors to review the references mentioned to understand the tools available in the reinforcement learning setting. The action is explicit and concrete, as the authors know exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the claim that \"there is no corresponding set of tools for the reinforcement learning setting,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies that this claim is false and provides references to support the assertion. This level of detail and clarity makes the comment 5, as it clearly identifies the issue and provides a basis for the authors to revise their claim. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"there is no corresponding set of tools for the reinforcement learning setting\" is false, providing references to support this claim. This provides a clear and specific justification for the claim, making it 5. The references and logical reasoning offered by the reviewer provide sufficient evidence to support the claim, making the comment 5. Therefore, the comment is labeled as 5.", "helpfulness_rationale": "The review comment challenges a claim made in the paper regarding the availability of tools for the reinforcement learning setting. It provides specific references to support the claim, which is a valuable piece of information for the authors. However, the comment could be more helpful if it offered additional context or analysis on why these references are relevant or how they address the claim. While the feedback is clear and actionable, it could be further enhanced with more detailed guidance. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the results more accessible or how to improve the technical competency required to understand them. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, it does not specify which part of the paper this issue pertains to, such as the results section or a particular technique. The authors cannot confidently determine which part of the paper needs attention, making this comment weakly grounded. The comment is specific in its critique of the technical competency required to understand the results, but without explicit references to sections or techniques, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a potential issue with the results, suggesting that they are not immediately obvious and require a certain level of technical competency. This is a valuable observation that could prompt the authors to reconsider the accessibility and clarity of their results. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending ways to simplify the techniques or improve the presentation of results. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the endtoend system, questioning the conclusion that the direct model is clearly better. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the amount of data used to train the text disambiguation model and compares it to the data used for the endtoend system. It questions the conclusion that the direct model is clearly better, but still acknowledges that both systems are demonstrably superior to the baseline. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the discrepancy in data usage and the conclusion about the direct model. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the amount of data used to train the text disambiguation model is significantly lower than the data used for the endtoend system, which raises questions about the conclusion that the direct model is clearly better. However, the comment does not provide specific data or references to support this claim, making it difficult for the authors to verify the validity of the assertion. The lack of detailed evidence or examples makes the claim 3, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the amount of data used to train the text disambiguation model compared to the endtoend system, which raises questions about the conclusion that the direct model is clearly better. It highlights a potential issue with the validity of the conclusion, but it does not provide specific suggestions or guidance on how the authors might address this concern or improve their analysis. While the comment points out an important area for consideration, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two main issues with the paper: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. While the comment highlights specific areas that need improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they need to provide more detailed explanations and evidence for GaRare\"s advantages over GaLore, as well as clarify the process of updating parameters. However, the comment lacks specific guidance on how to achieve these improvements, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GaRare\" and \"GaLore\" algorithms, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks motivation for GaRare and provides a specific example of the lack of evidence or justification for its advantages over GaLore based on theoretical analysis. It also suggests that a more detailed algorithmic presentation is needed, particularly regarding the process of recovering updated parameters from projected gradients. While the comment identifies specific areas for improvement, it does not provide detailed reasoning or references to support the claim that GaRare lacks motivation or that a more detailed algorithmic presentation is necessary. This makes the claim 3, as the authors would need to further explore and substantiate these claims themselves.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. By pointing out these gaps, the comment provides actionable feedback that can help the authors enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as providing examples or references to similar works that have successfully motivated their algorithms or presented detailed algorithmic explanations. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in realworld datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the model did not consider relevant attention retrieval from the attention memory. While the comment provides explicit actions, it does not offer detailed guidance on how to conduct the ablation study or the specific experiment with ATT(+H). The authors are left with a clear understanding of what needs to be done but may need to infer the exact steps to implement the suggestions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 4 left\" and \"visDial dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely conducting an ablation study on the visDial dataset and conducting an experiment on the performance of ATT(+H) in figure 4 left. The comment provides detailed guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in realworld datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the model did not consider relevant attention retrieval from the attention memory. While the comment provides a logical request for additional experiments, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact experiments and analyses required to address the suggestion. Therefore, the comment is 3, as it provides a clear direction but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in realworld datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the proposed model did not consider relevant attention retrieval from the attention memory. This feedback is clear and offers a concrete direction for the authors to improve their draft by conducting additional experiments and analyses. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4 as it offers valuable suggestions for enhancing the paper, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps to consider. The authors are left without any direction on how to improve their draft in response to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in detailing the potential weakness of using reinforcement learning for a static VQA task, but without clear grounding, it lacks actionable guidance for the authors. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks actionable guidance or suggestions for improvement, leaving the authors without a clear path forward. Without concrete feedback or constructive advice, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback provides clear and concrete actions for the authors to take, making it 5. The comment is specific about what needs to be included and explained, giving the authors a clear path to improve their draft. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the previous question, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the distribution of videos of different lengths within the benchmark and the explanation of how the authors ensured a balanced representation of different video lengths across the 11 categories. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not provide relevant explanations regarding the distribution of videos of different lengths within the benchmark. It suggests that the authors should include a table showing the distribution of video lengths across the dataset and explain how they ensured a balanced representation of different video lengths across the 11 categories. This claim is 3 as it logically points out a gap in the paper\"s explanation and provides a specific suggestion for improvement. However, the comment lacks detailed reasoning or references to support the importance of this explanation or the impact of the distribution on the assessment of reasoning ability and robustness. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of explanation regarding the distribution of videos of different lengths within the benchmark. It suggests that the authors should include a table showing the distribution of video lengths across the dataset and explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback is clear and actionable, providing the authors with a specific and concrete step to improve their draft. By addressing this issue, the authors can enhance the transparency and comprehensiveness of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the availability of the promised dataset, suggesting that a cautious approach should be taken regarding the contribution until the dataset is publicly accessible. However, it does not provide any explicit or implicit actions for the authors to take in response to this concern. There is no guidance on how to address the issue, such as suggesting ways to make the dataset more accessible or how to mitigate the potential impact of this limitation. As a result, the authors are left without any clear direction on how to proceed with this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the availability of the promised dataset, suggesting that a cautious approach should be taken until the dataset is publicly accessible. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its concern about the dataset availability, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the promised dataset has not yet been made publicly available, suggesting that a cautious approach should be taken regarding the contribution until the dataset is accessible. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a significant concern about the availability of the promised dataset, suggesting that a cautious approach should be taken regarding the contribution until the dataset is publicly accessible. This is a relevant and important point, as the availability of the dataset is crucial for the validity and impact of the contribution. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as proposing strategies for making the dataset more accessible or discussing potential alternatives. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should directly illustrate the results of the latter loss term of Eqn 13, as the preactivation values of two networks are the same membrane potentials, resulting in a high cosine similarity. This feedback provides a clear and explicit action for the authors to take, which is to include the illustration of the results in the paper. The comment is specific and provides concrete guidance on how to implement the suggested change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 3 e.\" and \"Eqn 13,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the illustration of the results of the latter loss term of Eqn 13. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results of the latter loss term of Eqn 13 should be illustrated directly, as the preactivation values of two networks are the same membrane potentials, resulting in a high cosine similarity. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this illustration is necessary or how it would enhance the understanding of the results. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in the paper, specifically suggesting that the authors should illustrate the results of the latter loss term of Eqn 13 directly. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and comprehensiveness of the paper. By addressing this point, the authors can enhance the understanding of their results and potentially improve the overall quality of their work. However, the comment could be more helpful if it explained why this illustration is important or how it would benefit the reader. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the paper regarding the lack of comparison with testtime adaptation (TTA) methods, specifically mentioning [AB]. It suggests that a comparison should be made based on experimental results to prove that data processing is superior to model parameter adjustment. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of robustness in video action recognition and the lack of comparison with testtime adaptation (TTA) methods, such as [AB]. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for a comparison with TTA methods to prove the superiority of data processing over model parameter adjustment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison with testtime adaptation (TTA) methods, specifically mentioning [AB]. The reviewer suggests that such a comparison should be made based on experimental results to prove that data processing is superior to model parameter adjustment. However, the comment does not provide specific examples or references to support the claim that TTA methods are relevant or how they could be applied to the paper. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparison with testtime adaptation (TTA) methods, such as [AB], which are relevant to the issue of robustness in video action recognition. It suggests that a comparison with these methods could provide valuable insights into the effectiveness of data processing versus model parameter adjustment. While the comment highlights an important area for improvement, it does not offer specific guidance on how to conduct such a comparison or what specific aspects to focus on. This limits the comment\"s helpfulness, as it provides a clear direction but lacks detailed instructions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a mistake in the first expression for J (\u03b8) and suggests it should be Q (s t 0, \u03c0\u03b8(s t 0)). This provides a clear and direct action for the authors to take, specifying the correct expression to use. The comment is specific and actionable, giving the authors a precise correction to make in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the first expression for J (\u03b8), suggesting that it should be Q (s t 0, \u03c0\u03b8(s t 0)). This provides clear guidance on what needs to be corrected in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first expression for J (\u03b8) is incorrect and should be Q (s t 0, \u03c0\u03b8(s t 0)). However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific mistake in the first expression for J (\u03b8) in Section 3.2.1, noting that it should be Q (s t 0, \u03c0\u03b8(s t 0)). This is a clear and actionable piece of feedback that can help the authors correct an error in their draft. By pointing out the mistake, the reviewer provides the authors with a direct path to improve the accuracy and clarity of their work. However, the comment could be more helpful if it included a brief explanation of why this correction is necessary or how it affects the overall understanding of the paper. Overall, the comment is 4 as it directs the authors to a specific area needing correction, but it could be more comprehensive with additional context."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with capitalization in the paper, including specific references that need capitalization. It also mentions that various words in the references need capitalization. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to correct these issues. The authors are left to infer that they should review and correct the capitalization in the references and in the paper itself. The action is implicit and somewhat vague, as it lacks detailed guidance on how to implement the corrections. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"p. 8\" and \"Various words in many of the references need capitalization,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the capitalization issues in the references and provides examples of specific words that need capitalization, such as \"ai\" and \"Advances in neural information processing systems.\" Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and observations about capitalization issues in the paper and references. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several capitalization errors in the paper and references, which is a clear and actionable piece of feedback. It provides specific examples of words that need capitalization, such as \"ai\" and \"Advances in neural information processing systems,\" and points out capitalization inconsistencies in the references. This feedback is valuable as it helps the authors ensure that their work is presented professionally and adheres to standard academic conventions. However, the comment could be more helpful if it included suggestions on how to address these capitalization issues, such as providing guidance on when to capitalize or offering examples of proper capitalization. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the missing parameter values for task 1 and the Boltzmann policy, specifically asking about the model parameters and the method used to choose them. While it does not explicitly instruct the authors to provide these details, the questions are clear and specific, indicating what information is missing and what the authors should include in their draft. The action is implicit but concrete, as the authors can infer that they need to provide the missing information. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific tasks, such as \"task 1\" and the Boltzmann policy, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for clarification on the model parameters and the method used to choose them, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification on specific parameters and methods used in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific missing information about the model parameters and the method used to choose them, particularly for task 1 and the Boltzmann policy. By asking these questions, the reviewer highlights areas where the authors need to provide more detail or clarification in their draft. However, the comment could be more helpful if it offered suggestions on how to address these gaps or provided examples of how similar information has been presented in other works. While it points out important areas for improvement, the feedback lacks depth and actionable guidance, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to explain why they believe applying Conditional Batch Norm (CBN) to layers 2, 3, and 4 deteriorates performance compared to only applying it to layers 3 and 4. It provides a clear and direct action for the authors to take, which is to provide an explanation or rationale for this observation. The comment is specific and actionable, as it guides the authors on how to address the issue by offering a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the deterioration in performance when Conditional Batch Norm (CBN) is applied to layers 2, 3, and 4 compared to only layers 3 and 4. This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that applying Conditional Batch Norm (CBN) to layers 2, 3, and 4 in Table 2 deteriorates performance compared to only applying it to layers 3 and 4. However, the comment lacks specific details or evidence to support this claim, such as data or analysis that demonstrates the performance difference. Without such supporting information, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the application of Conditional Batch Norm (CBN) to layers 2, 3, and 4 in Table 2, noting that this deteriorates performance compared to only applying it to layers 3 and 4. It prompts the authors to provide an explanation or rationale for this observation, which is a clear and actionable suggestion. By addressing this issue, the authors can improve the clarity and robustness of their results. However, the comment could be more helpful if it included specific suggestions on how to investigate or explain the performance difference. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the proposed method\"s inability to handle headpose and questions why the authors cannot condition the headpose parameters in the NeRF beyond facial expression, similar to a previous work. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method. The comment implies that the authors should consider incorporating headpose control into their method, but it lacks concrete steps or detailed instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"headpose,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the method cannot handle headpose and why it cannot be conditioned like a previous work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, noting that a previous work has already demonstrated control over both facial expression and headpose. The comment suggests that the authors should consider incorporating headpose control into their method, similar to the previous work. However, the comment lacks specific references or detailed reasoning to support why this is a significant issue or how it could be addressed. While it highlights a potential gap in the methodology, the lack of detailed justification makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, noting that it cannot handle headpose while suggesting that a previous work has already demonstrated control over both facial expression and headpose. It questions why the authors cannot condition the headpose parameters in the NeRF beyond facial expression, similar to the previous work. This feedback is 3 as it points out a gap in the methodology and provides a direction for improvement. However, it lacks specific suggestions or guidance on how the authors might address this issue or incorporate headpose control into their method. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that they are artificial patterns that appear only a few times in the training set. It references Chen et al. (2017) and Gu et al. (2019) to provide examples of such triggers. The comment suggests that a few training examples with these triggers could have a significant impact on the trained model. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps to take to mitigate the impact of these triggers. The action is implicit and somewhat vague, as the authors can infer that they need to consider the impact of these spurious features but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the spurious features, comparing them to backdoor triggers and referencing specific examples from Chen et al. (2017) and Gu et al. (2019). This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers, which are artificial patterns that only appear a few times in the training set. The reviewer supports this claim by referencing Chen et al. (2017) and Gu et al. (2019), both of which use random noise patterns and singlepixel triggers, respectively, as examples of backdoor triggers. This provides a solid foundation for the claim, as it references wellknown practices in the field. However, the comment could be strengthened by providing more detailed examples or additional references to further substantiate the claim. Overall, the claim is 4, as it is supported by relevant references but could be improved with more detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper regarding the similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers. It provides a clear and specific comparison to wellknown examples from Chen et al. (2017) and Gu et al. (2019), which helps the authors understand the nature of the issue. The comment suggests that a few training examples with such triggers could have a significant impact on the trained model. However, it lacks actionable suggestions or guidance on how the authors might address this issue or mitigate its impact. While it points out a relevant concern, the feedback could be more helpful with additional advice or recommendations for improvement. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for addressing the issue."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the structural optimization is a main component and that the optimization algorithm seems to be directly from previous works, which can be confusing and reduce the contribution. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific improvements. The comment lacks concrete actions or detailed suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of structural optimization being a main component and the use of an optimization algorithm that seems to be directly from previous works. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the confusion caused by the direct use of an algorithm from previous works and how it affects the contribution of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the structural optimization is a main component and that the optimization algorithm seems to be directly from previous works, which can be confusing and reduce the contribution. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the use of a structural optimization component that seems to be directly from previous works. This observation highlights a potential confusion in the contribution of the paper, as the algorithm\"s direct use from previous works may dilute the novelty. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the contribution of their work. While it points out a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue with the baseline models or how to improve the pipeline style method. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the pipeline style method, which includes two models, and notes that it does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not specify which part of the paper discusses these models or the pipeline style method, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment lacks specificity regarding what needs to be addressed regarding the baseline models or the pipeline style method. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the pipeline style method, which includes two models, not yielding better average results for both XVNLI and MaRVL. It also notes that the baseline models in the experiments are not well introduced. However, the comment lacks specificity and actionable suggestions for improvement. It does not provide guidance on how the authors might address the issue with the pipeline style method or how to improve the introduction of baseline models. Without detailed feedback or constructive advice, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors primarily focus on SSC and do not compare their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should contrast their method with these other methods. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons with other methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on SSC and the need to contrast the method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison with other methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and do not contrast their method with other methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. However, the comment lacks specific examples or references to these methods, making it difficult for the authors to understand the exact nature of the comparison being suggested. Without detailed comparisons or references, the claim is not fully substantiated, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. This feedback is 3 as it points out a gap in the paper\"s comparison with other methods, which could enhance its comprehensiveness and relevance. However, the comment lacks specific suggestions on how to address this issue, such as which methods to include or how to structure the comparison. While it highlights an area for improvement, the lack of detailed guidance limits its utility for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper makes small contributions over previous methods (NCNet [6] and Sparse NCNet [21]) and that it is mostly good engineering. However, it also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. While the comment implies that the authors should address this issue by improving the novelty or differentiating aspects of their work, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should focus on enhancing the novelty or differentiating aspects of their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper makes small contributions over previous methods (NCNet [6] and Sparse NCNet [21]) and that it is mostly good engineering. It also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. However, the comment does not specify which part of the paper discusses these contributions or how they are evaluated. Without explicit references to sections or specific aspects of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper makes small contributions over previous methods (NCNet [6] and Sparse NCNet [21]) and that it is mostly good engineering. However, the comment does not provide specific examples or detailed reasoning to support these claims. It mentions that it is difficult to differentiate the paper from its predecessors, but it does not explain why this is the case or how the paper could be improved in this regard. The lack of specific examples or detailed reasoning makes the claim 3, as the authors would need to infer the basis of the critique and potentially make additional efforts to understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper makes small contributions over previous methods (NCNet [6] and Sparse NCNet [21]) and that it is mostly good engineering. It also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. While the comment identifies a potential issue with the paper\"s novelty, it lacks specific suggestions or guidance on how the authors might address this concern or improve the differentiation of their work. The feedback is 3 as it points out a potential weakness, but it does not provide actionable advice or detailed insights for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to remove the statement about semantic segmentation being a lowlevel cue, as it is not accurate given that categories are specified for each pixel. This feedback is clear and concrete, providing a direct action for the authors to take. The comment is specific and leaves no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the term \"semantic\" segmentation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the statement about semantic segmentation being a lowlevel cue is incorrect, given that categories are specified for each pixel. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement about semantic segmentation being a lowlevel cue is incorrect, as categories are specified for each pixel. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this claim is valid. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper regarding the use of the term \"semantic\" segmentation. It points out that the categories are specified for each pixel, making the statement about semantic segmentation being a lowlevel cue inaccurate. This feedback is clear and actionable, as it directs the authors to remove or revise the statement to avoid misleading the reader. However, the comment could be more helpful if it provided additional context or suggestions on how to rephrase the statement to be more accurate. Overall, the comment is 4 as it effectively guides the authors on how to improve the clarity and accuracy of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the ablation experiment results, noting that the performance without reinforcement learning (RL) dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. While the comment identifies a specific issue with the experimental setup, it does not provide explicit guidance on how to address this issue or what changes should be made to the tables. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or correct the results in the tables, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and the \"two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the discrepancy in performance without reinforcement learning (RL) compared to without dependency tree and notes the missing cases in the tables where dependency tree and RL are not used. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance without reinforcement learning (RL) dropped lower than without dependency tree in the ablation experiment. However, it does not provide any supporting evidence, such as data or comparisons, to substantiate this claim. Additionally, the comment mentions that the two tables do not list the cases where dependency tree and RL are not used, but it does not explain why this is a concern or how it affects the results. Without additional context or evidence, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the ablation experiment results, noting that the performance without reinforcement learning (RL) dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. This feedback is 3 as it highlights a potential discrepancy in the results and suggests that the authors should clarify or correct the tables to provide a more complete picture. However, the comment could be more helpful if it offered suggestions on how to address this issue or what specific changes should be made to the tables. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the vulnerability discovery methodology, specifically questioning the authors\" approach of considering only a single vulnerability at a time. It also questions the ecological validity of such a study and suggests that previous work has considered multiple vulnerabilities simultaneously. The reviewer asks whether the authors argue that identifying one vulnerability at a time is an intended use case. While the comment highlights areas of concern, it does not provide explicit guidance on how the authors should address these issues or improve their methodology. The action is implicit and somewhat vague, as the authors need to infer that they should consider multiple vulnerabilities and justify their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"vulnerability discovery methodology\" and the \"single vulnerability\" approach, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the ecological validity of the study and suggesting that previous work has considered multiple vulnerabilities. The comment further highlights the difficulty in interpreting the results and notes that the improvements may be marginal. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the vulnerability discovery methodology, specifically questioning the authors\" approach of considering only a single vulnerability at a time. The reviewer questions the ecological validity of such a study and suggests that previous work has considered multiple vulnerabilities simultaneously. The comment also points out that the results are difficult to interpret, or at best, marginal improvements. While the comment provides a logical basis for questioning the methodology, it lacks specific references to external works or detailed reasoning to fully substantiate the claim. This makes the comment 3, as it provides a reasonable basis for the critique but requires more detailed evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant issue with the vulnerability discovery methodology, questioning the authors\" approach of considering only a single vulnerability at a time. It highlights the potential problem of ecological validity and suggests that previous work has considered multiple vulnerabilities simultaneously. The reviewer also points out that the results are difficult to interpret, or at best, marginal improvements. This feedback is valuable as it prompts the authors to reconsider their methodology and potentially expand their study to include multiple vulnerabilities. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or improve the study\"s validity. Overall, the comment is 4 as it identifies a critical area for improvement and provides a direction for the authors to consider, but it lacks detailed guidance on implementation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity in understanding the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2. It suggests that additional explanations are needed to address this issue. However, the comment does not provide specific guidance on how to provide these explanations or what aspects of the relationship should be clarified. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations but without concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1 and 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity in understanding the relationship between degree bias and the clearer community structure demonstrated by the theorems. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2 is not intuitive enough. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2. It points out that while the theorems prove conformity to a clearer community structure, the relationship with degree bias is not intuitive. This feedback is valuable as it highlights a potential gap in the paper\"s explanation, which the authors can address to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify this relationship or examples of how it might be explained more effectively. Overall, the comment is 4 as it directs the authors\" attention to an important area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the construction of clean exemplar manifolds for a nonstochastic network, specifically asking about the denominator of Figure 2.c for the ResNet50 and ATResNet50 networks. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this question or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the construction of clean exemplar manifolds and the denominator computation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 182183, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the construction of clean exemplar manifolds for a nonstochastic network and how the denominator of Figure 2.c is computed for the ResNet50 and ATResNet50 networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for a nonstochastic network, specifically asking about the denominator of Figure 2.c for the ResNet50 and ATResNet50 networks. The comment is 3 as it highlights a potential inconsistency in the paper regarding the construction of clean exemplar manifolds. However, it lacks specific examples or references to support the claim, making it somewhat challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the paper regarding the construction of clean exemplar manifolds for a nonstochastic network. It raises a specific question about how the denominator of Figure 2.c is computed for the ResNet50 and ATResNet50 networks, which is a critical aspect of the paper\"s methodology. By pointing out this discrepancy, the comment provides the authors with a clear and actionable step to address a potential weakness in their work. However, the comment could be more helpful if it offered suggestions on how to clarify this issue or provided examples of how similar discrepancies have been addressed in similar works. Overall, the comment is 4 as it directs the authors\" attention to a critical area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the originality of the paper is limited due to the main idea of variable splitting being not new and the algorithm not being new. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or improve the originality of their work. There is no guidance on potential ways to enhance the novelty or creativity of the algorithm or how to present it in a new light. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of originality, specifically mentioning that the main idea of variable splitting is not new and the algorithm is not new. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is considered unoriginal, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the originality of the paper is limited due to the main idea of variable splitting being not new and the algorithm not being new. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the originality of the paper, specifically noting that the main idea of variable splitting is not new and the algorithm is not new. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or enhance the originality of their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the omission of a related work, the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati. It suggests that this paper should be discussed and compared with the current work to provide a better understanding of the stateoftheart. The action is clear and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the omission of this related work and its potential relevance to the current paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati is a related work that should be discussed and compared with the current paper. The reviewer provides a logical reasoning by suggesting that the AAAI15 paper deals with hypergraph data with tensors, which is relevant to the current work. However, the comment lacks specific examples or references to the content of the AAAI15 paper, making it 3. The authors would need to conduct additional research to fully understand the relevance and potential contributions of the AAAI15 paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific related work, the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which is relevant to the current paper but has been overlooked. It suggests that this work should be discussed and compared with the current paper to provide a better understanding of the stateoftheart. This feedback is clear and actionable, as it directs the authors to include a relevant reference and comparison that could enhance the paper\"s comprehensiveness and depth. However, the comment could be more helpful if it provided specific guidance on how to integrate this reference into the paper or what aspects to focus on for comparison. Overall, the comment is 4 as it offers a concrete direction for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the paper is difficult to follow, indicating that the authors need to improve the clarity and accessibility of their experimental procedures and evaluations. However, it does not provide specific guidance on how to achieve this improvement, such as recommending changes to the structure, language, or presentation of the paper. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance the clarity of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the paper is difficult to follow, specifically mentioning the experimental procedures and evaluations. However, it does not specify which sections or parts of the paper are particularly challenging to understand. Without explicit references to sections or details, the authors cannot confidently determine which parts need improvement. The comment is 1 and lacks specificity, making it difficult for the authors to address the issue effectively. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point claims that the paper is \"extremely hard to follow,\" indicating that the reviewer had trouble understanding the experimental procedures and evaluations. However, the comment does not provide specific examples or details about what was difficult to follow, nor does it offer suggestions for improvement. Without these details, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, stating that it is \"extremely hard to follow.\" This feedback highlights a critical weakness in the clarity and accessibility of the experimental procedures and evaluations, which is crucial for readers to understand and replicate the work. However, the comment lacks specificity and does not provide actionable guidance on how the authors might improve the clarity or structure of their paper. Without detailed suggestions or examples, the authors are left without a clear path to enhance the readability and comprehensibility of their draft. Therefore, the comment is 3, as it points out a significant problem but does not offer detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment questions the claim made in section 2 that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what changes should be made to the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. However, the comment does not provide specific guidance on what needs to be addressed or improved in this section. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point questions the claim that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the claim made in section 2 that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. The reviewer points out that a model that can only handle a single time series data is almost useless. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address this concern or what aspects of the claim are misleading. As a result, the comment is not helpful, as it does not provide the authors with a clear path forward to enhance their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to consider introducing specific aspects of their model that are specific to the example model. It provides a clear and concrete action for the authors to take, specifying that they should clarify the model\"s parameters and settings, such as the boundedness of acceleration and scaling parameters. This guidance is direct and specific, leaving no ambiguity about what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l132,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the introduction of specific aspects of the model that are specific to the example model, such as the boundedness of certain parameters. This provides clear guidance on what the authors need to clarify or expand upon in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should introduce specific aspects of their model that are specific to the example model, such as the boundedness of certain parameters. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these aspects are important or how they impact the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors introduce specific aspects of their model that are specific to the example model. It highlights the importance of clarifying the boundedness of certain parameters, such as acceleration and scaling, which are crucial for understanding the context of the model. This guidance is clear and constructive, as it directs the authors to enhance the clarity and comprehensiveness of their paper. By addressing these points, the authors can improve the transparency and effectiveness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a limitation in the experiments, specifically that most of them are limited to RoBERTabase and question whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture. Additionally, it recommends including more analysis and discussion for GPT2, specifically asking for the results of Figure 2 for GPT2. The comment provides explicit actions for the authors to take, such as expanding the experiments to include more models and including additional analysis for GPT2. The suggestions are concrete and provide clear guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1.1\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to investigate whether the results can be generalized to other models and to include more analysis and discussion for GPT2. The comment provides a clear direction for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to RoBERTabase and questions whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture. The reviewer provides a logical reasoning by pointing out that the results might not be generalizable to other models, but the comment lacks specific examples or references to support this claim. While the suggestion is reasonable, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, specifically that most of them are limited to RoBERTabase and question whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture, and recommends including more analysis and discussion for GPT2. The comment provides clear and actionable feedback by suggesting specific areas for improvement, such as expanding the experiments to include more models and including additional analysis for GPT2. This guidance is valuable for the authors to enhance the generalizability and robustness of their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. While the comment implies that the authors should explore these applications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their work to include these other areas. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the model and the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the applicability of the model and experiments to other research areas, such as NLP or simpler models in the image domain (CNNs). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. However, the comment lacks specific examples or references to support the claim that the model and experiments are limited to image data and ViT. Without such evidence or reasoning, the claim remains 3, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. This feedback is valuable as it encourages the authors to expand their work beyond the current focus on image data and ViT, which could enhance the method\"s versatility and broader applicability. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might explore these other areas. Overall, the comment is 4 as it prompts the authors to consider a broader scope for their work, but it could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. The reviewer suggests that this condition is not realistic and may lead to unreasonably large learning rates when learning on largescale datasets. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. There is no guidance on whether the authors should modify the condition, provide a rationale for its use, or explore alternative approaches. As a result, the comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. It provides a clear rationale for why this condition is not realistic and may lead to unreasonably large learning rates when learning on largescale datasets. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue with the learning rate condition and its implications, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the condition on the learning rate is not scalable, as it does not grow with the number of samples in practice. The reviewer provides a logical reasoning by explaining that this condition leads to unreasonably large learning rates when learning on largescale datasets. However, the comment lacks specific examples or references to support the claim that this condition is not realistic. While the reasoning is sound, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. This is a critical observation, as it highlights a potential flaw in the methodology that could lead to unreasonably large learning rates when learning on largescale datasets. The reviewer provides a logical reasoning for why this condition is not realistic and suggests that the authors need a way to precisely characterize the benefit of large learning rates. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or explore alternative approaches. Despite this, the feedback is still valuable as it points out a critical aspect of the methodology that the authors should consider improving. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. This feedback provides clear and concrete actions for the authors to take, such as adding a description of the evaluation process and addressing language issues. The comment is specific and direct, giving the authors a clear understanding of what needs to be added or improved. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. Additionally, it mentions minor language issues on page, providing specific guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that it does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. While the comment highlights an important area for improvement, it does not provide detailed guidance or suggestions on how to address these issues. The authors are given a clear direction to enhance the abstract but are left without specific steps or examples on how to do so. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses skepticism about the experimental results and questions the absence of experiments on a specific setting. It highlights the need for experiments on surveillance in museums with thresholded rewards and privacypreserving data collection. While the comment identifies a specific issue with the experimental section, it does not provide explicit guidance on how to address this concern. The authors are left to infer that they should include experiments on these settings, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it points out an area for improvement but does not offer detailed instructions on how to execute it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results and the specific setting of the POMDP problem with nonconvex value functions. It also specifies the issue with the experiments section, noting the absence of experiments on surveillance in museums with thresholded rewards and privacypreserving data collection. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the experimental results, specifically the absence of experiments on specific settings. It references the examples of surveillance in museums with thresholded rewards and privacypreserving data collection as motivating cases for the paper. However, the comment lacks specific evidence or detailed reasoning to support why these examples are insufficient or why the experiments are not useful. The claim is 3, as it highlights a potential issue but does not provide sufficient justification or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental results of the paper, questioning the relevance and usefulness of the examples used to motivate the solution. It points out the absence of experiments on specific settings, such as surveillance in museums with thresholded rewards and privacypreserving data collection. This feedback is valuable as it highlights a critical gap in the experimental section, which could impact the credibility and applicability of the results. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific experiments or modifications to the existing ones. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it lacks detailed guidance on how to implement the suggested changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that epochwise analysis could be beneficial for understanding the behavior of optimization algorithms, particularly in finite sum settings. It proposes that this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. While the comment provides a clear rationale for why epochwise analysis could be valuable, it does not explicitly instruct the authors on how to implement this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that epochwise analysis could be beneficial for understanding the behavior of optimization algorithms, particularly in finite sum settings. It provides a specific example of how this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. However, the comment does not explicitly mention which part of the paper this analysis should be integrated into, making it weakly grounded. The suggestion is specific, as it clearly outlines the potential benefits of epochwise analysis and how it could be applied to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that epochwise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. It provides a specific example of how this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms. The comment also suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. While the suggestion is logical and provides a clear rationale, it lacks specific examples or references to support the claim fully. Therefore, the comment is 3, as it provides a reasonable basis for the claim but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It suggests that epochwise analysis, particularly in finite sum settings, could be beneficial for understanding the behavior of optimization algorithms. The comment highlights how this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms and aid in comparative analysis of deterministic and stochastic methods. This feedback is clear and provides a concrete direction for the authors to enhance their analysis and improve the paper. By offering a specific and actionable suggestion, the comment is 5 in guiding the authors towards a more comprehensive and insightful analysis. Therefore, it aligns with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a specific issue with the distinction between the three classes of extreme speech, particularly the difficulty in differentiating between derogatory and exclusionary extreme speech. It questions the annotation of a specific instance in the sample data file and seeks clarification on the local regulation over speech that might influence the classification. The reviewer implies that the authors should provide more detailed explanations or examples to clarify this distinction. While the comment does not explicitly instruct the authors to make changes, it implies a clear action for the authors to take, which is to clarify the distinction between the classes and provide additional context for the annotation. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Paper Summary\" and the \"sample data file,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the distinction between derogatory and exclusionary extreme speech, and it provides a specific example from the sample data file to illustrate the confusion. The comment further asks for clarification on the local regulation over speech and its impact on zeroshot crosscountry classification. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the distinction between the three classes of extreme speech, specifically questioning the classification of a specific instance as exclusionary extreme speech. The reviewer provides a specific example from the sample data file to illustrate the confusion, asking for clarification on the local regulation over speech and its impact on zeroshot crosscountry classification. This request for clarification is a logical step in the evaluation process, as it seeks to understand the basis of the classification. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s classification of extreme speech, particularly the difficulty in distinguishing between derogatory and exclusionary extreme speech. It provides a concrete example from the sample data file, questioning the classification of a particular instance as exclusionary extreme speech. The reviewer also seeks clarification on the local regulation over speech and its impact on zeroshot crosscountry classification. This feedback is clear and actionable, as it prompts the authors to clarify their definitions and provide additional context to improve the clarity of their work. By addressing these points, the authors can enhance the comprehensibility and robustness of their classification approach. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be included in the graph and why it is important. The comment also offers a rationale for why this graph is necessary, helping the authors understand the potential sources of performance improvement. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be included in the graph and why it is important to understand the sources of performance improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This claim is 3 as it logically suggests that such a graph would help clarify whether the performance improvement is solely due to the network design or whether it is influenced by the nature of ImageNet. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This is a specific and detailed piece of feedback that can help the authors better understand the performance improvement and its potential sources. By including this graph, the authors can provide a more comprehensive analysis of their results, which could enhance the clarity and robustness of their paper. However, the comment could be more helpful if it explained why this graph is important or how it might influence the interpretation of the results. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper needs to be mathematically correct and provides a specific example by questioning the notation \"L_l\" instead of just \"L.\" It also suggests introducing the notation beforehand. While the comment identifies areas for improvement, it does not provide explicit instructions on how to make these changes or what specific changes should be made. The authors are left to infer that they need to make these corrections, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.\" and \"L_l instead of just L,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the notation \"L_l\" and suggests introducing it beforehand. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper needs to be mathematically correct and questions the notation \"L_l\" instead of \"L.\" It provides a specific example of the notation issue and suggests introducing the notation beforehand. However, the comment lacks detailed reasoning or references to support why this change is necessary or how it would improve the paper. The suggestion is 3 as it identifies a specific issue but does not provide a comprehensive rationale or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"L_l\" instead of \"L\" and suggests that it needs to be corrected for mathematical correctness. It also questions the notation \"L_l\" and suggests introducing it beforehand. This feedback is clear and actionable, as it provides the authors with a concrete step to improve the clarity and correctness of their mathematical notation. However, the comment could be more helpful if it explained why this correction is necessary or how it would enhance the paper\"s understanding. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the method. The action is implicit and somewhat vague, as the authors need to infer that they should consider different timesteps for training and evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The comment suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to infer the relevance of different timesteps and how they might impact the effectiveness of the proposed methods. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the effectiveness of the proposed methods, noting that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep. This observation raises questions about the novelty and impact of the proposed methods. The comment suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. While the comment highlights an important point, it lacks specific suggestions or guidance on how the authors might address this issue or explore different timesteps. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the disentanglement aspect of the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions a limitation related to disentangled latent vectors, it does not provide sufficient detail on how disentanglement is achieved and guaranteed. The reviewer suggests that the authors should clarify this aspect by explaining how disentanglement is realized and what types of bias are involved. This feedback is explicit and provides concrete guidance on what the authors need to address to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Broader Impacts and Limitations\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of how disentanglement is achieved and guaranteed without certain bias types. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that disentanglement is not clearly explained and questions how it is achieved and guaranteed without certain bias types. While the comment references the \"Broader Impacts and Limitations\" section, it does not provide specific examples or detailed reasoning to support the claim that disentanglement is unclear. The reference to the \"Broader Impacts and Limitations\" section suggests that the authors have acknowledged the limitation, but the comment lacks further elaboration or evidence to substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the disentanglement aspect in the paper. It points out that while the \"Broader Impacts and Limitations\" section acknowledges a limitation related to disentangled latent vectors, it does not provide sufficient detail on how disentanglement is achieved and guaranteed without certain bias types. The comment suggests that the authors should clarify this aspect to enhance the clarity and comprehensiveness of their work. This feedback is clear and actionable, as it directs the authors to a specific area that needs further explanation and justification. However, it could be more helpful if it provided examples or additional guidance on how to address this issue. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This is a clear and concrete action for the authors to take, as it provides a specific enhancement to the figure that would help clarify the impact of mean teacher on learning. The suggestion is direct and leaves no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 3\" and \"left graph,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, which is a learning curve for a model without mean teacher or pi regularization. This provides clear guidance on how to enhance the figure and compare the impact of mean teacher on learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This is a request for additional data or analysis, which is a factual observation rather than an opinion or claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This additional information would help clarify the impact of mean teacher on learning, providing valuable insights for the authors. The comment is clear and direct, offering a concrete way to enhance the figure and improve the draft. Therefore, it is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two main concerns: the need to discuss how to handle different types of inputs, such as biomedical signals or speech, and the disorderly citation style. While the first point suggests a specific area for improvement by asking for a discussion on handling different input types, it does not provide explicit guidance on how to structure this discussion or what specific aspects to cover. The second point about the citation style is also vague, as it does not specify which citations are disordered or how they should be organized. Overall, the comment lacks concrete actions or detailed instructions, making it 3. The authors can infer that they need to address the input types and citation issues, but the lack of specific guidance makes it challenging to implement the suggested improvements effectively.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to discuss how to handle different types of inputs, such as biomedical signals or speech, and mentions the disorderly citation style. This allows the authors to accurately identify the parts of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for a discussion on input types and the disorderly citation style. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two claims: the need to discuss how to handle different types of inputs and the disorderly citation style. The first claim is 3 as it suggests a potential area for improvement, but it lacks specific guidance on how to address the issue of input types. The second claim about the citation style is vague, as it does not specify which citations are disordered or how they should be organized. Without detailed examples or references, the authors may find it challenging to understand and address the issue. Therefore, the comment is rated as 3, as it provides some direction but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies two areas for improvement: discussing how to handle different types of inputs, such as biomedical signals or speech, and addressing the disorderly citation style. While the comment highlights these issues, it does not provide specific guidance or examples on how to effectively discuss the input types or organize the citations. The feedback is 3 as it points out areas that could enhance the paper, but it lacks detailed suggestions or actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, specifically mentioning the OfficeHome dataset where the CSAC achieves 64.35 and the proposed solution achieves 64.71, indicating a marginal improvement. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the implications of Eq. 4 and potentially improve the results in Table 5, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the implications of Eq. 4 and noting the lack of significant improvement in the designed solutions in Table 5, particularly on the OfficeHome dataset. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, providing specific examples like the OfficeHome dataset where the CSAC achieves 64.35, and the proposed solution achieves 64.71, indicating a marginal improvement. This claim is 3 as it provides some logical reasoning and specific examples to support the observation. However, it could be strengthened by providing more detailed analysis or references to substantiate the claim further. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, providing specific examples like the OfficeHome dataset where the CSAC achieves 64.35, and the proposed solution achieves 64.71, indicating a marginal improvement. This feedback is 3 as it points out a potential issue with the results and suggests that the authors might need to reconsider their approach. However, it lacks specific suggestions or guidance on how to address the issue or improve the results. To be more helpful, the comment could provide suggestions on how to improve the design solutions or clarify the implications of Eq. 4. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or improve their approach. The comment lacks actionable details, such as recommending alternative methods or suggesting specific modifications to the template mapping process. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the question answering process, particularly the use of template mapping to transform questions into masked statements. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential problem with poor generalization to questions that are not \"Whtypes\" or transformable. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the question answering process, specifically the use of template mapping, may lead to poor generalization to questions that are not \"Whtypes\" or transformable. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or examples to substantiate the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It points out that this approach might lead to poor generalization to questions that are not \"Whtypes\" or transformable. While the comment highlights a relevant concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. The feedback is 3 as it directs the authors\" attention to a potential weakness, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"VolumeDeform [1],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what the issue is: the use of a volumetric representation in the deformation field is not novel, as it has been proposed by VolumeDeform [1]. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, the comment does not provide any further explanation or justification for why this is not novel or how it relates to the paper under review. Without additional context or references, the claim lacks verifiability, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, it does not provide any constructive feedback or suggestions for improvement. It lacks depth and actionable guidance, leaving the authors without a clear understanding of how to address the issue or enhance their work. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant issue with the ICLHAR, noting that it improves consistency and verifiability but significantly impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. The reviewer suggests that this issue should be discussed or acknowledged in the main text in more detail. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is concrete, as it points out the need to discuss or acknowledge the impact on accuracy, but it is somewhat vague in terms of how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the ICLHAR, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ICLHAR, noting that it improves consistency and verifiability but significantly impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. This provides clear guidance on what needs to be addressed in the paper, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the ICLHAR improves consistency and verifiability but significantly impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. This claim is 3 as it provides a specific numerical example (70.4 to 55.6) to support the assertion of a significant impact on accuracy. However, the comment lacks detailed reasoning or explanation of why this impact occurs or how it could be addressed. Additionally, it does not provide references to external works or studies that might substantiate the claim further. Therefore, the comment is rated as 3, as it provides some support but lacks depth and detailed evidence.", "helpfulness_rationale": "The review comment identifies a significant issue with the ICLHAR, noting that while it improves consistency and verifiability, it significantly impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. This is a critical observation that the authors should address, as it affects the overall quality and reliability of their results. The comment suggests that this issue should be discussed or acknowledged in the main text in more detail, providing a clear direction for the authors to improve their draft. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or what aspects of the ICLHAR might be contributing to the accuracy drop. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to take action."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the innovations in network architecture design and constraint embedding are limited and that the performance is constrained by the performance of the oracle expert. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the innovations or how to mitigate the constraints. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the innovations in network architecture design and constraint embedding are limited, and that the performance is constrained by the performance of the oracle expert. However, it does not specify which part of the paper discusses these innovations or the performance constraints, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in identifying the issue of limited innovation and the constraint on performance, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the innovations in network architecture design and constraint embedding are limited and that the performance is constrained by the performance of the oracle expert. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the innovations of network architecture design and constraint embedding, suggesting that the performance is constrained by the performance of the oracle expert. However, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. The comment lacks actionable feedback or detailed insights into potential improvements, leaving the authors without a clear path forward. As a result, the comment is 2, as it points out a weakness but does not offer constructive advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. It also encourages the authors to discuss the difference between their method and traditional methods. While the comment provides a clear action to take, it lacks specific guidance on how to conduct the calibration curves or what aspects of the traditional method should be discussed. The authors are given a general direction but may need to infer the exact steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the model AUC and its ability to assess model discriminant ability, as well as the consistency between predicted scores and actual risks. It suggests conducting calibration curves to demonstrate this consistency, which is crucial for the clinical scoring system. The comment also mentions the difference between the traditional method and the authors\" method, which could be discussed in the paper. However, the comment does not explicitly mention which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as conducting calibration curves and discussing the difference between traditional and novel methods. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the model AUC can assess the model discriminant ability but may not demonstrate consistency between predicted scores and actual risks. It suggests that this consistency is crucial for the clinical scoring system and recommends conducting calibration curves to show the agreement. The comment also mentions the importance of discussing the difference between the traditional method and the authors\" method. While the comment provides a logical reasoning for the need to demonstrate consistency, it lacks specific examples or references to support the claim about the importance of calibration curves. Therefore, the comment is 3, as it provides a reasonable argument but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It highlights the importance of demonstrating consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. The comment suggests conducting calibration curves to show this consistency, offering a specific and concrete step for the authors to take. Additionally, it encourages the authors to discuss the difference between their method and traditional methods, providing a direction for further exploration and comparison. While the comment could be more helpful by offering examples of how to conduct calibration curves or suggesting specific aspects of the traditional method to discuss, it still provides valuable guidance for improving the draft. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the lack of discussion on how to ensure that the conditions for DICE are met, and the observation that the range of ID and OOD does not change much with sparsification. While the comment identifies specific areas that need attention, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they need to discuss these conditions and consider how sparsification affects them, but the comment lacks detailed guidance on how to implement these improvements. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by pointing out the lack of discussion on how to ensure DICE meets certain conditions, particularly regarding the mean and the range of ID and OOD with sparsification. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD does not change much with sparsification and that Lemma 2 requires an identical mean. These claims are based on observations from Figure 4 and the text, respectively. However, the comment lacks specific examples or detailed reasoning to support these claims, making it 3. The authors would need to infer the significance of these observations and the implications for DICE, which may not be immediately clear. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the lack of discussion on how to ensure that the conditions for DICE are met, and the observation that the range of ID and OOD does not change much with sparsification. It points out that Lemma 2 requires an identical mean, which is crucial for DICE. By highlighting these areas, the comment provides the authors with clear and actionable feedback on what needs to be discussed and explored in the paper. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar conditions have been discussed in other works. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several concerns about the experiments, including the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these issues, but without specific guidance on how to do so, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues related to the experiments, including the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides some specific concerns, it lacks grounding as it does not specify where these issues are addressed in the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises concerns about the strength and fairness of the experiments, questioning the use of position kernels and the absence of certain baselines. It also suggests that the paper lacks discussion on limitations and societal impacts. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the strength and fairness of the experiments, the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. It provides specific suggestions for addressing these issues, such as using default settings of baselines in the literature and comparing the proposed approach with other baselines. However, the comment could be more helpful if it offered more detailed guidance on how to implement these suggestions or provided examples of how similar studies have addressed these concerns. Overall, the comment is 4 as it provides actionable feedback that can help the authors improve their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a drop in correlation after a short period of training, which increases with more training iterations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps to take to improve the correlation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions a drop in correlation after a short period of training, which increases with more training iterations. However, it does not specify which part of the paper this observation is based on, such as a specific section, table, or figure. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspect of the correlation drop needs to be addressed or improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is a drop in correlation after a short period of training, which increases with more training iterations. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific observation about the correlation drop after a short period of training, which increases with more training iterations. This is a valuable insight that could be relevant to the authors, as it may indicate a potential issue with the model or training process. However, the comment lacks depth and does not provide actionable suggestions or guidance on how to address this issue or improve the model. Without further explanation or specific recommendations, the authors are left with only a general observation, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that all sparsity patterns seem to perform equally well and questions whether this is unique to the sparsity detection problem or applies to GNNs in general. It also notes a discrepancy in the presentation of \"bits\" in Section 4.3. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should provide more insight into the results and clarify the presentation of \"bits.\" The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the uniqueness of the results and suggesting that the authors provide more insight into the sparsity patterns. The comment is specific because it clearly identifies what needs to be addressed, namely the lack of insight into the results and the discrepancy in the presentation of \"bits.\" Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the uniqueness of the results and suggests that all sparsity patterns perform equally well. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific examples or data to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, as it does not provide sufficient evidence or justification to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the results, noting that all sparsity patterns seem to perform equally well and questioning whether this is unique to the sparsity detection problem or applies to GNNs in general. It also points out a discrepancy in the presentation of \"bits\" in Section 4.3. While the comment highlights areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or provide more insight into the results. The feedback is 3 as it prompts the authors to consider the generalizability of their findings and the presentation of their work, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the derivation from Equation 3 to Equation 4 is missing the temperature parameter, \u03c4. It suggests that either the temperature should be shown in a rigorous way or that the paper should mention it. This provides a clear and concrete action for the authors to take, as they are directly instructed to either include the temperature or mention it in the paper. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqn. 3 to Eqn. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the missing temperature parameter, \u03c4, and suggests that it should be shown in a rigorous way or mentioned in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the derivation from Equation 3 to Equation 4 is missing the temperature parameter, \u03c4. The reviewer suggests that either the temperature should be shown in a rigorous way or that the paper should mention it. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the temperature should be included or how it affects the derivation. This lack of explanation makes the claim 1, as it does not provide sufficient justification for the authors to understand or address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the derivation from Equation 3 to Equation 4, noting that the temperature parameter, \u03c4, is missing. It suggests that either the temperature should be shown in a rigorous way or that the paper should mention it. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to address the issue. However, the comment could be more helpful if it explained why the inclusion of \u03c4 is important or how it affects the derivation. Despite this, the feedback is 4 as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should add a citation on differential privacy, specifically mentioning a standard work like [2]. This is a clear and direct action for the authors to take, as it provides a specific reference to include in the paper. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the addition of a citation on differential privacy, providing a specific example like [2]. This level of detail provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a citation on differential privacy, specifically mentioning a standard work like [2]. This is a factual suggestion that does not involve an opinion, judgment, or claim that requires verification. It is a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by suggesting the addition of a citation on differential privacy. By providing a specific example like [2], the comment offers clear guidance on how to enhance the paper\"s credibility and comprehensiveness. However, the comment could be more helpful if it explained why this citation is important or how it would benefit the reader. Overall, the feedback is actionable and provides a clear direction for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment questions the claim made in the first paragraph of Section 3.2 that \"this methodology requires significant additional assumptions.\" It suggests that the only additional assumption is that the test set be drawn from the same distribution as the query set, which is a common assumption in machine learning settings. The reviewer also points out a mistake in the inequality on line 310, suggesting that it has the wrong sign. While the comment identifies specific issues with the claim and the inequality, it does not provide explicit guidance on how to address these issues or improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the claim and correct the inequality. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of Section 3.2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the claim that \"this methodology requires significant additional assumptions,\" suggesting that the only additional assumption is that the test set be drawn from the same distribution as the query set, which is a common assumption in machine learning settings. The comment also points out a mistake in the inequality on line 310, providing specific guidance on how to correct it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that \"this methodology requires significant additional assumptions,\" suggesting that the only additional assumption is that the test set be drawn from the same distribution as the query set, which is a common assumption in machine learning settings. The reviewer provides a logical reasoning by pointing out that this assumption is natural and not extreme. However, the comment lacks specific examples or references to support the claim that this assumption is common in machine learning settings. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific critique of the claim made in the first paragraph of Section 3.2, suggesting that it is too extreme by implying that the methodology requires significant additional assumptions. The reviewer points out that the only additional assumption is that the test set be drawn from the same distribution as the query set, which is a common assumption in machine learning settings. This feedback is valuable as it challenges the authors to reconsider their claim and potentially revise it to be more accurate and grounded in reality. Additionally, the comment identifies a mistake in the inequality on line 310, which is helpful for the authors to correct. However, the comment could be more helpful if it provided suggestions on how to address the issue or improve the clarity of the claim. Overall, the comment is 4 as it offers actionable feedback on the claim and the inequality, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values over other methods. Additionally, it recommends including a significant discussion on the advantages and disadvantages of each of the three ways of transforming highdimensional data to lowdimensional latent space. While the comment provides explicit actions, it does not specify which specific comparisons or discussions should be included, leaving some ambiguity. However, the authors can infer that they need to provide experimental comparisons and a detailed discussion on the advantages and disadvantages of the methods. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of Shapely values over other methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for experimental comparisons with other methods and a discussion on the advantages and disadvantages of the three ways of transforming highdimensional data to lowdimensional latent space. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors need to provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values over other methods. It also recommends including a significant discussion on the advantages and disadvantages of each of the three ways of transforming highdimensional data to lowdimensional latent space. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that Shapely values are superior to other methods. This makes the claim 3, as the authors would need to make a significant effort to understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values over other methods. It also recommends including a significant discussion on the advantages and disadvantages of each of the three ways of transforming highdimensional data to lowdimensional latent space. This feedback is valuable as it guides the authors to enhance the robustness and credibility of their argument by providing empirical evidence and a comprehensive analysis of the methods. However, the comment could be more helpful if it provided specific examples or references to similar studies that have successfully employed these comparisons or discussions. Overall, the comment is 4 as it directs the authors to make significant improvements in their draft, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that Appendix A.2 does not illustrate the state space representation of the environment clearly. This provides a direct and concrete action for the authors to take, which is to improve the clarity of the illustration in Appendix A.2. The comment is specific about what needs to be addressed, making it 5. Authors know exactly what needs to be done to enhance the clarity of their illustration, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be improved in the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the state space representation in Appendix A.2. It points out that the illustration is not clear, which is a critical aspect of the paper\"s presentation. This feedback is actionable as it directs the authors to improve the clarity of the illustration, ensuring that readers can better understand the environment\"s state space. However, the comment could be more helpful if it provided suggestions on how to enhance the clarity or offered examples of how similar illustrations have been effectively presented. Despite this, the comment is 4 as it highlights a specific area for improvement, which is valuable for the authors to address."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors\" approach is only applicable to small or mediumscale problems, suggesting that it may not be effective for truly large problems. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to adapt the approach for larger problems or what specific steps to consider. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the authors\" approach is only applicable to small or mediumscale problems, implying that it may not be effective for truly large problems. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the applicability of the approach to large problems, but without clear references to sections or details, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors\" approach is only applicable to small or mediumscale problems, suggesting that it may not be effective for truly large problems. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation in the applicability of the authors\" approach, suggesting that it is only applicable to small or mediumscale problems. This is a relevant observation that could impact the scope and impact of the work. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this limitation or expand their approach to larger problems. Without detailed feedback or constructive advice, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the motivation for using characteristic function regularization is not clear. However, it does not provide any explicit or implicit suggestions for how the authors might clarify this motivation or what specific aspects of the motivation are unclear. Without guidance on how to address this issue, the authors are left without a clear action to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the motivation for using characteristic function regularization is not clear, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine whether it relates to the introduction, methodology, or results sections. Additionally, the comment lacks specificity regarding what aspects of the motivation are unclear or how they could be clarified. Without explicit references or detailed guidance, the authors cannot effectively address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the motivation for using characteristic function regularization is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a lack of clarity in the motivation for using characteristic function regularization, which is an important aspect of the paper. However, it does not provide specific guidance or suggestions on how the authors might clarify this motivation or what aspects of the methodology are unclear. Without actionable feedback or detailed insights, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as 2, as it points out an area for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper appears to be limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It suggests that the contribution is incremental because these techniques are not novel. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the contribution or suggest new directions for the work. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific techniques used in the paper, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is problematic: the contribution appears to be incremental due to the combination of existing techniques. This provides clear guidance on what needs to be addressed or improved in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that these results are not surprising and that the contribution is therefore incremental. However, the comment lacks specific examples or references to these existing techniques, making it difficult for the authors to understand the basis of the claim. Additionally, the comment does not provide detailed reasoning or evidence to support why these techniques are not novel or how they contribute to the paper. As a result, the claim is 3, as it provides some context but lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it appears to be limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that these results are not surprising and that the contribution is therefore incremental. While the comment highlights a potential issue with the novelty of the work, it does not provide specific suggestions or guidance on how the authors might address this limitation or enhance the contribution. The feedback lacks actionable advice or detailed critique, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies specific issues with the writing quality of the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide any explicit guidance or suggestions on how to address these issues. The authors are left to infer that they need to improve their writing quality, but without concrete steps or examples, they may struggle to know exactly what changes to make. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment identifies specific issues with the writing quality of the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity in detailing what exactly is unclear or needs improvement in the writing. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, the comment does not provide specific examples or detailed explanations of these issues, making it difficult for the authors to understand and address them effectively. Without specific examples or references, the claim lacks verifiability, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies significant writing issues in the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. While it highlights these problems, it does not provide specific examples or guidance on how to address them. The comment lacks actionable advice or suggestions for improvement, leaving the authors without a clear path to enhance the quality of their draft. Therefore, the feedback is 3 as it points out areas for improvement but does not offer detailed guidance or suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It explicitly instructs them to run the corresponding experiments and add the results to the figures and Table 1. It also clarifies specific aspects of the figures, such as whether the network was trained on random data or unaltered data, and whether the data was normalized. The comment also suggests adding examples of random data in the appendix. These actions are clear and specific, leaving no ambiguity about what the authors need to do to address the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 3c\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as running the corresponding experiments and adding the results to the figures and Table 1. The comment also clarifies specific aspects of the figures, such as whether the network was trained on random data or unaltered data, and whether the data was normalized. Additionally, it suggests adding examples of random data in the appendix. This level of detail provides clear guidance for the authors to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of requests for clarification and additional experiments. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas where the paper could be improved. It points out that the figures do not show results for untrained networks and suggests running the corresponding experiments and adding them to the figures and Table 1. Additionally, it clarifies some aspects of the figures, such as whether the network was trained on random data or unaltered data, and whether the data was normalized. The comment also suggests adding examples of random data in the appendix. While the feedback is clear and actionable, it could be more helpful if it provided more detailed guidance on how to conduct the additional experiments or how to present the results. Overall, the comment is valuable in directing the authors to address specific weaknesses and improve the clarity of their work, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should repeat the experiments and conduct statistical significance analysis on the numbers to determine whether the results are statistically significant. This feedback is explicit and provides a clear action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is also concrete, as it specifies the need for statistical analysis and the need to repeat the experiments. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the improvement over previous methods, specifically mentioning the results in Table 1 and Fig. 5. It also suggests repeating the experiments and conducting statistical significance analysis on the numbers. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in suggesting the need for statistical analysis and repeating the experiments, but without clear grounding, the authors may struggle to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvement over previous methods is small, about 0.2%1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation. Additionally, it suggests that determining statistical significance is difficult due to the limited novelty and marginal improvement. The comment provides some logical reasoning by pointing out the lack of detailed reporting and statistical analysis, but it lacks specific examples or references to support the claim about the size of the improvement. This makes the claim 3, as the authors would need to further investigate and substantiate the claim themselves.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the limited improvement over previous methods and the lack of detailed reporting in the results. It suggests that the authors should repeat the experiments and conduct statistical significance analysis on the numbers to determine whether the results are statistically significant. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. However, the comment could be more helpful if it explained why the current results are insufficient or what specific aspects of the analysis need improvement. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the absence of the approach section in the main paper and suggests that the supplementary material should be used as additional information rather than an extension to the paper. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the approach section. The comment implies that the authors should include the approach section in the main paper, but it lacks concrete details on how to integrate it or what specific content should be included. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach section\" and the \"supplementary material,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the approach section in the main paper and the use of supplementary material as additional information rather than an extension to the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach section is missing in the main paper and suggests that the supplementary material should be used as additional information rather than an extension to the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the approach section should be included or how the supplementary material should be used. Without additional context or explanation, the claim remains 1, as it lacks the necessary justification to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the absence of the approach section in the main paper. It suggests that the supplementary material should be used as additional information rather than an extension to the paper. While the comment highlights a critical oversight, it lacks specific guidance on how to address this issue or what content should be included in the approach section. The feedback is 3 as it points out a gap in the paper, but it could be more beneficial with additional details or suggestions for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the statement regarding the biological plausibility of backpropagation in the introduction may be too weak and points out that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to strengthen the statement. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the statement and provide more robust evidence or reasoning to support it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement in the introduction regarding the biological plausibility of backpropagation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the weakness of the statement and the need to provide more robust evidence or reasoning to support it. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement regarding the biological plausibility of backpropagation in the introduction is too weak, as it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without specific examples or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the introduction regarding the biological plausibility of backpropagation. It points out that the statement is too weak and that it is widely accepted that backpropagation is biologically implausible. This feedback is 3 as it highlights an area where the authors may need to provide more robust evidence or reasoning to support their claims. However, the comment could be more helpful if it suggested specific ways to strengthen the statement or provided examples of alternative perspectives or evidence that could be considered. Overall, the comment provides some guidance but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the paper, noting that it does not explore the implications of the proposed method for other NLP tasks. However, it does not provide specific guidance on how the authors should address this issue or what additional exploration is needed. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to enhance the generalizability of their results. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s exploration of the implications of the proposed method for other NLP tasks, suggesting that the paper\"s generalizability is somewhat limited due to this lack of exploration. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of limited generalizability, but without explicit references to sections or details, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which somewhat limits its generalizability. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it provides a logical argument but lacks the necessary support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it does not explore the implications of the proposed method for other NLP tasks. This observation highlights a potential weakness in the generalizability of the results, which is an important consideration for broader impact and applicability. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional exploration could be conducted. While it points out a relevant area for improvement, the feedback lacks actionable details, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiments are limited to toy data and recommends expanding the scope to include real data. It explicitly states that there is a range of problems with real data where barycenters can be used and suggests that the method\"s performance should be demonstrated in those settings. This feedback provides a clear and concrete action for the authors to take, as it specifies the need to include real data experiments and the potential benefits of doing so. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests expanding the scope of the experiments to include real data, which implies that the current experiments are limited to toy data. However, it does not specify which part of the paper discusses the experiments or where the limitation is mentioned, making it weakly grounded. The comment is specific in suggesting that real data experiments could be beneficial and highlighting the potential use of barycenters in realworld scenarios. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are limited to toy data and recommends expanding the scope to include real data. However, the comment does not provide any specific examples or references to support the claim that real data experiments would be beneficial or necessary. Without such evidence or reasoning, the authors may find it challenging to understand the basis of the suggestion and how it could improve their work. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully substantiate the recommendation.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are currently limited to toy data. It suggests expanding the scope to include real data, which could provide a more comprehensive understanding of the method\"s performance in various settings. This feedback is actionable and constructive, as it points out a potential gap in the experimental design and suggests a way to enhance the paper\"s contribution. However, the comment could be more helpful if it provided specific examples or guidance on how to implement real data experiments or what aspects of realworld data would be most relevant. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more detailed to be fully comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. While the comment implies that additional experiments are necessary, it does not provide specific guidance on how to conduct these experiments or what aspects to focus on. The references provided are relevant but do not offer detailed instructions on how to implement the suggested experiments. The action is implicit and somewhat vague, as the authors need to infer the specific details of how to proceed with the additional experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results discussion. The references provided are relevant but do not directly address the comment\"s suggestion. Therefore, the comment is weakly grounded because it does not specify where in the paper these experiments should be conducted, and it is not specific in detailing what aspects need to be addressed. This aligns with a score of 2.", "verifiability_rationale": "The review point suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. The reviewer provides references to relevant works, which supports the claim that these experiments could enhance the paper. However, the comment lacks detailed reasoning or specific examples of how these additional experiments would benefit the paper. While the references provide some context, the claim could be strengthened with more detailed justification or examples of how these experiments would contribute to the paper. Therefore, the comment is 3, as it provides some support but lacks full justification.", "helpfulness_rationale": "The review comment suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific guidance on which aspects of the paper would benefit from these additional experiments or how they should be conducted. The references provided are relevant but do not offer detailed instructions or suggestions for the authors to follow. Therefore, the comment is 3 as it points out a potential area for improvement but does not provide actionable steps for the authors to take."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed sample selection mechanism is not clearly explained in terms of how it preserves the label distribution. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific ways to clarify the mechanism or suggesting alternative explanations. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed sample selection mechanism, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding how the mechanism preserves the label distribution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the proposed sample selection mechanism in preserving the label distribution. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the proposed sample selection mechanism, noting that it is not clear how it preserves the label distribution. This feedback is 3 as it points out a potential weakness in the paper that the authors should address to improve clarity and understanding. However, the comment lacks depth and does not provide specific suggestions or examples on how to clarify the mechanism or what aspects of the explanation are unclear. While it highlights an area for improvement, it does not fully guide the authors on how to address the issue. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results and analysis are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not provide any explicit or implicit suggestions for improvement or additional models to consider. The authors are left without guidance on how to enhance the scope or relevance of their evaluation. As a result, the comment lacks actionable advice, leaving the authors uncertain about how to address the issue. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the results and analysis, noting that they are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not specify which part of the paper this critique pertains to, such as the results or analysis sections. Without explicit references to sections or figures, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the evaluation are limited by the choice of models. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results and analysis are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to other models or studies that could be considered, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a limitation in the evaluation of results and analysis, noting that only two relatively old and small models are considered. This feedback highlights an area where the authors could potentially expand the scope and relevance of their work by including more diverse models. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional models or methods to consider. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS, particularly when specific conditions are met. However, it does not provide any explicit or implicit actions for the authors to take based on this observation. There is no guidance on how to apply this insight or what specific conditions should be considered for equivalence. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS under certain conditions. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion that LS and KD are equivalent under certain conditions, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that KD can be considered a special form of LS under certain conditions, specifically when the teacher network is uniformly distributed and the temperature is set at 1. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without additional context or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS under certain conditions. It provides a specific example of when this equivalence occurs, which is when the teacher network is uniformly distributed and the temperature is set at 1. This feedback is 3 as it offers a potential insight into the relationship between KD and LS, which could be useful for the authors to explore further. However, the comment could be more helpful if it provided additional context or suggestions on how to apply this insight to improve the paper. Overall, the comment is 3 as it provides a direction for further exploration but lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to provide an explanation for why the performance degrades when using additional information about missing, wrong, or redundant information. This is a clear and direct request, giving the authors a specific action to take. The comment is specific in its request for an explanation, which provides a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation of why the performance degrades when using additional information about missing, wrong, or redundant information. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance degradation when using additional information about missing, wrong, or redundant information. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance degradation when using additional information about missing, wrong, or redundant information. This is a clear and actionable request for the authors to provide an explanation or analysis of this phenomenon. By addressing this question, the authors can improve the clarity and robustness of their results. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided examples of similar cases where performance degradation was observed. Overall, the comment is 3 as it directs the authors to a specific area for improvement but lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a discrepancy in the paper\"s argument regarding the flatness of the minima found by the proposed method. It points out that while the authors claim that the method finds the flat minima, the analysis about flatness is missing. The reviewer suggests that the authors should provide an analysis of the losses of the noiseinjected models after training to substantiate their claim. This feedback is explicit and provides a clear action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the analysis about flatness\" and \"the loss used for training base model,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis of the losses of the noiseinjected models after training to substantiate the claim about the flatness of the minima found by the proposed method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis about the flatness of the minima is missing, and it suggests that minimizing the averaged loss across the noiseinjected models does not ensure the flatness of the minima. The reviewer provides a logical reasoning by explaining that the loss used for training the base model is the averaged loss for the noiseinjected models, and that the convergence analysis on this loss does not guarantee the flatness of the minima. However, the comment lacks specific examples or references to support the claim that the analysis on the losses of the noiseinjected models after training is necessary to substantiate the claim about the flatness of the minima. This makes the claim 3, as it provides a logical argument but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s argument regarding the flatness of the minima found by the proposed method. It points out that while the authors claim that the method finds the flat minima, the analysis about flatness is missing. The reviewer provides a logical explanation, noting that minimizing the averaged loss across the noiseinjected models does not ensure the flatness of the minima. This feedback is 5 as it directs the authors to a specific area where the paper\"s argument is flawed and suggests a clear and actionable solution: providing an analysis of the losses of the noiseinjected models after training to substantiate the claim about the flatness of the minima. By addressing this issue, the authors can significantly improve the clarity and robustness of their argument. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to make the text inside the figure and labels roughly the same size as the manuscript text. This is a clear and direct action that the authors can take to improve the readability of their figures. The comment provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"text inside the figure and the labels,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the size of the text compared to the manuscript text. This provides clear guidance on how to improve the readability of the figures. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text inside the figure and labels is too small to read without zooming, suggesting that it should be roughly the same size as the manuscript text. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change is necessary or how it would improve the readability of the figures. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the readability of the figures, noting that the text inside the figure and the labels are too small to read without zooming. It provides a clear and actionable suggestion to make the text roughly the same size as the manuscript text. This feedback is valuable as it directly addresses a usability concern that could impact the accessibility and comprehension of the figures. However, the comment could be more helpful if it included examples or additional guidance on how to achieve this improvement. Overall, the comment is 4 as it effectively points out a specific issue and offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that using multiple local prompts can be beneficial but notes that the features and their positions differ across categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improving the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the use of multiple local prompts and notes that the features and their positions differ across categories. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the features or positions are problematic or how they could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges that using multiple local prompts can be beneficial but notes that the features and their positions differ across categories. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment acknowledges the use of multiple local prompts and notes that the features and their positions differ across categories. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model is somewhat complicated and recommends improving its presentation in Section 4, possibly by referring to the supplement. It also provides specific suggestions for enhancing the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate the attention mechanisms. These actions are explicit and concrete, providing clear guidance on how to improve the presentation of the model. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved, such as suggesting the use of notation and breakout diagrams to enhance the presentation of the model. This level of detail provides the authors with a clear understanding of what changes are needed to improve the presentation. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model is somewhat complicated and recommends improving its presentation in Section 4. It provides a specific suggestion to replace natural language descriptions with notation and adds breakout diagrams to illustrate the attention mechanisms. This claim is 3 as it offers a logical suggestion for improving the presentation, but it lacks detailed justification or examples to fully substantiate the claim. The authors might need to explore the specific benefits of using notation and diagrams, which are not explicitly explained. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of the model in Section 4, noting that it is somewhat complicated and requires careful reading. It provides specific suggestions for improving the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate the attention mechanisms. These suggestions are actionable and can help the authors enhance the clarity and accessibility of their presentation. However, the comment could be more helpful if it explained why these changes are necessary or provided examples of how they might be implemented. Overall, the comment is 4 as it offers clear and constructive guidance for improving the draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or expand their experiments to include more molecules. The action is implicit and vague, as the authors are left to infer that they need to consider expanding their experiments to include more molecules. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the limited scope of the experiments conducted in the paper, specifically mentioning that only a few molecules are tested and that indistribution testing is provided for these samples. However, it does not specify which sections of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its critique of the limited scope of the experiments and the potential limitations of the method if it requires training for each molecule individually. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically noting that the experiments are conducted on a limited number of molecules and only provide indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. This feedback is 3 as it points out a potential weakness in the paper\"s scope and suggests an area for improvement. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this limitation or expand their experiments to include more molecules. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment suggests that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the symbols or how to make them more accessible to the reader. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not specify which symbols or parts of the paper are causing this issue, making it difficult for the authors to pinpoint the exact areas that need improvement. Without specific references to sections, figures, or symbols, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not provide any specific examples or reasoning to support this claim. Without detailed evidence or references, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not provide any specific examples or guidance on how to simplify these symbols or make them more accessible to the reader. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the origin of the red line in Figure 3 and whether there is a ground truth for the test data. While it identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The comment implies that the authors should clarify the source of the red line and the ground truth, but it lacks specific instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the red line in the figure and asks for clarification on the origin of the test data and the existence of a ground truth. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions about the origin of the red line in Figure 3 and the existence of a ground truth for the test data. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the origin of the red line in Figure 3 and the existence of a ground truth for the test data. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern. The comment lacks depth and actionable advice, leaving the authors without a clear path forward. Therefore, it is rated as 2, as it points out a potential weakness but does not offer constructive feedback for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment does not provide explicit instructions or concrete steps for the authors to take. It lacks actionable details, such as recommending specific modifications or experiments to address this concern. As a result, the authors are left without a clear path forward, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment does not specify which part of the paper this question pertains to, such as specific experiments or sections where the results are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the role of periodicity in the results, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment lacks specific evidence or examples to support this claim. It does not provide detailed reasoning or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides a logical basis for the question but lacks sufficient evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment raises a pertinent question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. This is a valuable observation that could prompt the authors to reconsider their approach and potentially improve their results. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending experiments or modifications to the method. While it provides a thoughtprovoking insight, it could be more helpful with additional actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: why the results of Table 6 are not aligned with Table 1 (MCTpair) and what about the ablation studies of MCT without the adaptive metrics. While these questions imply that the authors should address these issues, they do not provide explicit instructions or concrete guidance on how to do so. The authors can infer that they need to clarify the discrepancy in the results and potentially include ablation studies, but the comment lacks specific details on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6\" and \"Table 1 (MCTpair),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the alignment of results and asking about the ablation studies of MCT without adaptive metrics. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises two questions that are relevant to the paper\"s content and methodology. First, it questions the alignment of results between Table 6 and Table 1 (MCTpair), which could indicate a discrepancy or inconsistency in the data. Second, it asks about the ablation studies of MCT without the adaptive metrics, suggesting that this could be a valuable addition to the paper. While the questions are valid, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve their work. It provides some direction but could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the 10 subtasks are simplistic for bAbi and that more discussions are required. However, it does not provide any specific guidance on what kind of discussions are needed or how the authors should address this issue. The comment lacks actionable details, such as recommending additional analyses or discussions that could be included to enhance the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the 10 subtasks are simplistic for bAbi and that more discussions are required. However, it does not specify which part of the paper these subtasks are discussed in or where the discussions are lacking. Without explicit references to sections or specific subtasks, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what kind of discussions are needed or how they could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the 10 subtasks are simplistic for bAbi and suggests that more discussions are required. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanation or examples of how the subtasks are simplistic or how they could be improved with additional discussions. Without such support, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the 10 subtasks presented in the paper, suggesting that they may be simplistic for bAbi and that more discussions are required. However, the comment lacks specificity and does not provide any guidance on what kind of discussions or analyses would be beneficial. It does not offer suggestions on how the authors might address this issue or improve the paper. As a result, the feedback is not actionable and does not provide the authors with a clear path forward for enhancing their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It asks whether this limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. While the comment implies that the authors should consider this limitation and potentially explore alternatives, it does not provide explicit instructions or concrete suggestions on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should consider extending their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in its inquiry about whether the limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It does not present an opinion, judgment, or suggestion that requires verification. It is a factual observation seeking clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a valid concern about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It questions whether this limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. This feedback prompts the authors to consider whether their approach is limited by the specific windowing method or if it can be extended to accommodate different windowing methods. While the comment identifies a potential weakness, it lacks specific suggestions or guidance on how to address this limitation or explore alternative approaches. Therefore, the comment is 3, as it points out an area for improvement but does not provide detailed guidance for the authors to act upon."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the definition of \"sequence of episodes\" in the context of the paper and suggests that related work might be relevant but not necessarily detrimental to the novelty of the paper. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions to take. The comment lacks concrete steps or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the definition of \"sequence of episodes\" and suggesting that related work might be relevant but not detrimental to the novelty of the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and observations about the definition of \"sequence of episodes\" and the relevance of related work. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of \"sequence of episodes\" in the context of the paper, which is a relevant point for clarity. It also suggests that related work might be relevant but not detrimental to the novelty of the paper. While the comment identifies a potential area for improvement by suggesting the inclusion of related work, it lacks specific guidance or suggestions on how to address this issue or incorporate related work. The feedback is 3 as it points out a potential gap in the paper, but it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the classification of the study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what changes should be made to the study. The comment lacks actionable advice or suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the study\"s classification but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the study about different subdomain sizes is not an \"ablation\" study because it does not involve removing a component of the method. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. While it identifies a potential issue with the study\"s designation, it lacks depth and does not provide specific suggestions or guidance on how the authors might clarify or reframe their study. The feedback is 3 as it points out a potential misclassification but does not offer actionable advice for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific steps to consider. The authors are left without any direction on how to incorporate this suggestion into their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the inclusion of AccNet in a larger predictor. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation. It suggests that it might make sense to learn AccNet as part of a larger predictor, which could be beneficial for the paper. However, the comment lacks depth and does not provide specific guidance or suggestions on how to incorporate this idea into the paper. While it identifies a potential area for improvement, it does not offer actionable steps or detailed reasoning to support the authors in making this change. Therefore, the comment is 3, as it points out a potential area for enhancement but does not fully guide the authors on how to implement it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed metric is only tested on a single dataset, which is a limitation. However, it does not provide any guidance on how the authors should address this issue or suggest ways to expand the testing to other datasets. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment points out that the proposed metric is only tested on a single dataset, which is a specific issue. However, it does not specify which dataset or which part of the paper discusses the metric testing. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue of testing on a single dataset, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed metric is only tested on a single dataset. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it affects the paper\"s validity. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a limitation in the paper, specifically that the proposed metric is only tested on a single dataset. This is a relevant observation that could impact the generalizability and applicability of the metric. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue, such as recommending additional datasets for testing or discussing the implications of this limitation. While it identifies a potential weakness, the feedback does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6. It also mentions that the lack of definitions hindered understanding in an initial read. The reviewer provides specific references to similar works that have defined these terms, which offers a clear direction for the authors to address these issues. By explicitly mentioning the undefined terms and providing examples of how they have been defined in other works, the comment offers concrete guidance on how to improve the clarity and accessibility of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"L73\" and \"L166,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue of undefined abbreviations and the lack of definition for superscript notation in Equation 6, which hindered understanding. Additionally, it provides examples of similar works that have defined these terms, offering clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6, which hindered understanding in an initial read. The reviewer provides references to similar works that have defined these terms, offering a logical basis for the claim. This provides a clear and robust justification for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6, which hindered understanding in an initial read. It provides examples of similar works that have defined these terms, offering clear guidance on how the authors can improve the clarity and accessibility of their paper. By pointing out these specific issues and providing references to similar works, the comment offers actionable feedback that can help the authors enhance the readability and comprehensibility of their draft. However, the comment could be more helpful if it included suggestions on how to address these issues, such as recommending specific definitions or approaches. Overall, the comment is 4 as it provides clear and actionable feedback, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue. There is no guidance on what specific changes or improvements could be made to the evaluation or baselines. Without actionable advice or concrete steps, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions the \"evaluation\" and \"baselines used in the paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the evaluation being weak and the baselines not being designed for fair classification. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation, noting that the baselines used in the paper are not designed for fair classification. This is a critical observation that highlights a potential weakness in the paper\"s methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the evaluation. Without actionable advice or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. It suggests that the authors are trying to present something in greater generality than what is actually presented, which muddles the exposition. However, the comment does not provide specific guidance on how to clarify the setting or what aspects need to be clarified. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the setting but may not be entirely sure of the exact details to address. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first three paragraphs of section 2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting needs to be spelled out more clearly and suggesting that the authors may be trying to present something in greater generality than what is actually presented, which muddles the exposition. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. The reviewer suggests that the authors are trying to present something in greater generality than what is actually presented, which muddles the exposition. However, the comment lacks specific examples or references to support this claim, making it 3. The authors may find it challenging to understand the exact issue without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of section 2. It suggests that the authors may be presenting something in greater generality than what is actually shown, which muddles the exposition. This feedback is clear and actionable, as it points out a specific area where the authors need to clarify their work to improve the reader\"s understanding. However, the comment could be more helpful if it provided suggestions on how to clarify the setting or what specific aspects need to be addressed. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the convincing nature of the experiments and questions the choice of the old baseline, R3D and C3D. It suggests that the authors should consider whether their proposed method works on other 3D CNNs, such as X3D, SlowFast, etc., and compare its advantages to those approaches. While the comment implies that the authors should conduct additional experiments or comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments or comparisons to address the concerns raised. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of the old baseline and suggesting that the proposed method should be evaluated against other 3D CNNs. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the convincing nature of the experiments and suggests that the authors should consider whether their proposed method works on other 3D CNNs, such as X3D, SlowFast, etc. The comment also raises a logical question about the advantage of the proposed method compared to these approaches. However, the comment lacks specific examples or references to support the claim that the baseline is outdated or that the proposed method is not convincing. This makes the claim 3, as the authors would need to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experiments, questioning the choice of the old baseline and suggesting that the proposed method should be evaluated against other 3D CNNs. It also raises a logical question about the advantage of the proposed method compared to existing approaches. While the comment provides a clear direction for improvement, it lacks specific suggestions or examples on how to address these issues. The authors are given a general idea of what needs to be improved but are not provided with detailed guidance on how to implement these improvements. Therefore, the comment is 3, as it points out areas for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly asks the authors to clarify how the attention module is attached to the backbone ResNet20 architecture, including the number of attention modules used, their placement (after each block or stage), and how they are integrated into the overall architecture. This feedback provides clear and specific guidance on what needs to be clarified in the paper, making it 5. The authors know exactly what information is missing and how to address it, ensuring that they can effectively improve the clarity of their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"attention module attached to the backbone ResNet20 architecture\" and the need to clarify how many attention modules are used, where they are placed, and after which stages. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be clarified, such as the number of attention modules, their placement, and how they are integrated into the architecture. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of how the attention module is attached to the backbone ResNet20 architecture, specifically asking about the number of attention modules, their placement, and how they are integrated into the overall architecture. This is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the integration of the attention module with the backbone ResNet20 architecture. It asks for clarification on the number of attention modules used, their placement, and how they are integrated into the overall architecture. This feedback is clear and actionable, as it provides the authors with specific questions to address in order to improve the clarity of their draft. By addressing these points, the authors can enhance the understanding of their method and its implementation, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the proposed method\"s performance at low bitrates, suggesting that it is close to the baselines in this range. It also asks for clarification on the precise bitrate range used for BDrate comparison and suggests discussing a related work on implementing contentadaptive algorithms in learned video compression. While the comment provides a clear direction for improvement by suggesting a specific area for comparison and a related work to consider, it does not explicitly instruct the authors on how to implement these suggestions. The action is implicit but concrete, as the authors can infer that they need to clarify the bitrate range and consider the related work for discussion. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"BDrate comparison,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the bitrate range used for comparison and the suggestion to discuss a related work on contentadaptive algorithms in learned video compression. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s performance at low bitrates, suggesting that it is close to the baselines in this range. The reviewer provides a specific suggestion to clarify the bitrate range used for BDrate comparison and mentions a related work for discussion or comparison. This provides a logical basis for the claim, as it highlights a potential issue with the method\"s performance and offers a direction for improvement. However, the comment could be strengthened by providing more detailed reasoning or examples to support the claim fully. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that it performs stronger at high bitrates but is close to the baselines at low bitrates. This is a valuable observation that prompts the authors to reconsider the method\"s performance at different bitrates. Additionally, the comment suggests clarifying the bitrate range used for BDrate comparison and provides a specific reference to a related work on contentadaptive algorithms in learned video compression. This feedback is actionable and constructive, as it guides the authors to address a critical aspect of their methodology and provides a relevant literature reference for further exploration. However, the comment could be more helpful if it included additional suggestions or insights on how to improve the method at low bitrates. Overall, the comment is 4 as it directs the authors to a specific area for improvement and provides a relevant reference for further exploration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. While the comment implies that the authors should make this distinction, it does not provide explicit instructions on how to do so or what specific aspects of the paper need to be revised. The action is implicit and somewhat vague, as the authors need to infer that they need to make a distinction but are not given specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, it does not specify which part of the paper this distinction should be made in, nor does it provide detailed guidance on how to make this distinction. The authors can infer that it relates to the discussion or analysis of the results, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a distinction needs to be made. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or how it would benefit the paper. Without additional context or examples, the claim remains 1, as it lacks the necessary support to guide the authors in making the suggested distinction. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. While this feedback identifies a potential area for clarification and differentiation, it lacks specific guidance on how to achieve this distinction or what aspects of the paper need to be revised. The comment highlights a potential issue but does not provide actionable steps for the authors to address it, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or what additional analysis should be conducted. The comment lacks concrete details or specific actions for the authors to take, leaving them uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not specify which tasks, previous works, or selfimplemented baselines are being referred to, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment lacks specificity regarding what additional analysis should be conducted or how it could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, the comment does not provide any specific examples, comparisons, or references to support these claims. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not provide specific examples or details on what aspects of the analysis are lacking or how the authors could improve it. The comment lacks actionable guidance or suggestions for enhancing the analysis, leaving the authors without clear direction on how to address the critique. As a result, the feedback is not helpful, as it does not provide the authors with a path to improve their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that all the linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should make the proof clearer or relocate Theorem 8 to a more accessible location, but it lacks specific instructions on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should make the proof more accessible, but it is not detailed enough to be fully actionable. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the linear convergence rates relying on Theorem 8, which is buried in the appendix and whose proof is unclear. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that all linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that all linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. This is a clear and actionable point that the authors can address to improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to improve the proof or relocate Theorem 8 to a more prominent location in the paper. Overall, the comment is 4 as it directs the authors to a critical area needing attention and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This is a clear and explicit action for the authors to take, as it provides a specific direction for improving the presentation of results. The comment is concrete in its guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the presentation of average results on the test set with clearly defined error bars under different random seeds. This provides clear guidance on how to improve the paper\"s presentation of results. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s results are not convincing because they are based on the best results on the development set with hyperparameter search and model selection on the development set. The reviewer suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This claim is 3 as it provides a logical reasoning for why the current presentation of results is insufficient, but it lacks specific examples or references to support the claim. The suggestion for presenting results on the test set is a reasonable one, but the comment could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in the paper, noting that the authors report the best results on the development set with hyperparameter search and model selection on the development set, which is not enough to be convincing. The comment suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This feedback is clear and actionable, providing a concrete suggestion for improving the presentation of results. By addressing this issue, the authors can enhance the credibility and persuasiveness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the dataset used in the paper, including the number of topics, the method for obtaining topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the questions are explicit, the comment lacks concrete guidance on how to address these issues. The authors are left to infer that they need to provide more detailed information about the dataset, but the specific actions to take are not clearly stated. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions about the dataset used in the paper, including the number of topics, the method for obtaining topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the dataset and methodology sections. The comment is specific in detailing what needs to be addressed, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the dataset used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the dataset used in the paper, including the number of topics, the method for obtaining topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the questions are relevant and could guide the authors in improving their draft, the comment lacks specific suggestions or actionable advice on how to address these issues. The authors are left with a clear understanding of what needs to be clarified but without detailed guidance on how to implement these improvements. Therefore, the comment is 3, as it identifies areas for improvement but does not provide comprehensive guidance for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis on BRPNAS is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. This feedback implies that the authors should expand their analysis to include more comparisons and consider additional NAS approaches. However, the comment does not explicitly instruct the authors to do so, nor does it provide specific guidance on which NAS approaches to include or how to conduct the analysis. While the action is implied, it is not as clear as it could be, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis on BRPNAS, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the analysis is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. This provides clear guidance on what needs to be addressed in the analysis section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis on BRPNAS is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. However, the comment does not provide specific examples or references to these other NAS approaches, nor does it explain why they are important or how they would enhance the analysis. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the analysis section of the paper, specifically noting that the BRPNAS analysis only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. This feedback highlights an area where the paper could be expanded to provide a more comprehensive analysis. However, the comment does not offer specific suggestions on how to address this issue or which NAS approaches to consider, leaving the authors with a general direction but without detailed guidance on how to improve their draft. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a subjective opinion about the zeroshot version and its connection to density estimation, stating that it distracts from the main point of the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes, if any, should be made to the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the zeroshot version and its connection to density estimation, suggesting that these elements are distracting from the main point of the paper. However, it does not specify which part of the paper these elements are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the distraction but lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the zeroshot version and its connection to density estimation are distracting from the main point of the paper, which is about learning effective prototypes for fewshot learning. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a subjective opinion about the zeroshot version and its connection to density estimation, suggesting that these elements are distracting from the main point of the paper. However, it does not provide any specific guidance or suggestions for improvement, nor does it offer actionable feedback on how to address this issue. Without detailed feedback or constructive advice, the authors are left without a clear understanding of how to enhance their draft. Therefore, the comment is rated as 2, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiment results could be enriched by adding attacks with different strengths and by exploring how different thresholds influence detection performance. While the comment implies that these additions would improve the results, it does not provide specific guidance on how to implement these changes or what specific types of attacks or threshold analyses should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to enhance their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results could be enriched by adding attacks with different strengths and exploring how different thresholds influence detection performance. However, it does not specify which part of the paper these suggestions pertain to, such as specific sections or figures where these additions could be made. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting improvements. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the experiment results could be enriched by adding attacks with different strengths and exploring how different thresholds influence detection performance. However, the comment lacks specific examples or references to support the claim that these additions would improve the results. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to implement it. Therefore, the claim is considered 2, as it provides a general direction but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the experiment results by suggesting the addition of attacks with different strengths and an exploration of how different thresholds influence detection performance. This feedback is clear and actionable, as it provides specific suggestions for enhancing the experimental analysis. However, the comment could be more helpful if it offered additional guidance on how to implement these changes or what specific types of attacks or threshold analyses should be considered. Overall, the comment is 4 as it directs the authors toward meaningful enhancements to their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate their claim of reducing exposure bias by training a discriminator on generations from the learned model, similar to Figure 1. The reviewer notes that this is different from Figure 4, as the discriminator is coadapting with the generator, which could lead to getting stuck at a local optimum. While the comment provides a clear action\u2014to evaluate the claim by training a discriminator\u2014it does not offer specific guidance on how to implement this evaluation or what metrics to use. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of the claim to reduce exposure bias and the need to train a discriminator on generations from the learned model. The comment provides a clear direction for the authors to follow, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should evaluate their claim of reducing exposure bias by training a discriminator on generations from the learned model, similar to Figure 1. The reviewer explains that this is different from Figure 4, as the discriminator is coadapting with the generator, which could lead to getting stuck at a local optimum. This claim is 3 as it provides a logical reasoning for the need to evaluate the claim and explains the difference between Figure 1 and Figure 4. However, the comment lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for evaluating the claim of the paper, which is to train a discriminator on generations from the learned model to confirm if the paper successfully reduces exposure bias. The reviewer explains the difference between Figure 1 and Figure 4, noting that the former involves coadaptation between the discriminator and generator, while the latter is a static representation. This feedback is valuable as it guides the authors on how to test their claim and provides a specific method for evaluation. However, the comment could be more helpful if it offered additional insights or examples on how to implement this evaluation or what metrics to use. Overall, the comment is 4 as it provides a clear direction for the authors to improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. While the action is implicit, it is clear and concrete, as it specifies what additional information is needed to be included in the paper. The authors know exactly what to do to address the comment, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the performance difference resulting from using different image sizes and variations of ResNets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. However, it does not provide any supporting evidence, reasoning, or references to justify why this information is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically regarding the impact of the experimental setup on performance. However, the comment lacks depth and does not provide specific guidance on how to present this information or what specific metrics or analyses would be most relevant. While it points out a potential gap in the paper, it does not offer detailed suggestions for addressing it, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a runtime comparison at test time would be interesting to include in the paper. While it implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a runtime comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that a runtime comparison at test time would be interesting to include in the paper, as it mentions the possibility of using Chebyshev polynomials to achieve a speedup. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where the comparison could be included. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential addition. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that a runtime comparison at test time would be interesting to include in the paper, as it mentions the possibility of using Chebyshev polynomials to achieve a speedup. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that a runtime comparison at test time would be interesting to include in the paper, as it mentions the possibility of using Chebyshev polynomials to achieve a speedup. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific comparison that could enhance the paper\"s contribution. However, the comment lacks depth and does not provide detailed guidance on how to conduct the comparison or what specific aspects to focus on. While it points out a potential improvement, it does not fully support the authors in making that enhancement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or suggestions on how to address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should consider the applicability of their method to natural images. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. However, it does not specify which part of the paper this question pertains to, such as the methodology or results sections. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its question about the applicability of the method to natural images, but without explicit grounding, it is difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. However, the comment lacks any supporting evidence, reasoning, or references to justify why the method might not be applicable to natural images. Without such information, the claim remains 1, as it does not provide a clear basis for the authors to address the concern. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a valid question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. This is an important consideration for the authors, as natural images have wider applications in the real world. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or expand the applicability of their method. While it identifies a potential limitation, it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relation between subfigures is unclear. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to improve the clarity of the figures and label the modules, but the lack of concrete steps or suggestions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"CMAF, L_BT, VoLTA,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the clarity of the figures, particularly the confusion regarding the relation between subfigures in Figure 2 and the lack of labeling for certain modules. This provides clear guidance on what needs to be addressed to improve the clarity of the figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning Figure 2 and the confusion regarding the relation between subfigures. It also notes that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the exact nature of the confusion and the importance of labeling the modules. Therefore, the comment is 3, as it provides some evidence but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relation between subfigures is confusing. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. This feedback is clear and actionable, as it provides the authors with specific areas to improve the clarity and labeling of their figures. By addressing these issues, the authors can enhance the readability and comprehensibility of their paper. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of how similar issues have been addressed in other works. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. However, it does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to control domain drift. The comment lacks actionable details, such as suggesting alternative measures or methods for controlling domain drift. As a result, the authors are left without a clear understanding of what changes they need to make to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a concern about the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. However, it does not specify which part of the paper this concern is related to, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the use of perplexity and the need to control domain drift, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. However, the comment does not provide specific examples or references to support the claim that perplexity is an inappropriate measure or that domain drift is a significant issue. Without detailed reasoning or evidence, the claim remains 3, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. This is an important point that could impact the accuracy and generalizability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or control domain drift. While it identifies a potential weakness, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the impact of the number of images on model performance and suggests that the first appearance of BYOL in the abstract should be explained. While these questions imply that the authors should investigate the effect of image number and provide an explanation for BYOL, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an analysis and provide an explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific questions about the cluster structure and its impact on model performance, as well as the first appearance of BYOL in the abstract. However, it does not explicitly mention which part of the paper these questions pertain to, such as specific sections or figures. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for an explanation of the impact of the number of images and the introduction of BYOL, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions asking for clarification and additional explanation. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the impact of the number of images on model performance and suggests that the first appearance of BYOL in the abstract should be explained. These questions prompt the authors to investigate and clarify aspects of their work that could impact its validity and clarity. However, the comment lacks specific guidance or suggestions on how to conduct this analysis or what specific aspects of the BYOL explanation should be addressed. While it identifies areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient and points out that LLMs are typically trained on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to improve the dataset. The action is implicit and somewhat vague, as the authors can infer that they need to consider the size and diversity of their training data but are not given specific instructions on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient and compares them to the typical training data for LLMs, which is typically on trillions of tokens. The comment suggests that the dataset needs to be massive to cover varied domains. However, it does not specify which part of the paper this concern is related to, such as the methodology or results sections. The authors can infer that it relates to the dataset used for training, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing the concern about the training data. This aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient, comparing them to the typical training data for LLMs, which is typically on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim that 44k dialogues are insufficient. This makes the claim 3, as the authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient, given that LLMs are typically trained on trillions of tokens. The comment suggests that the dataset needs to be massive to cover varied domains, which is a critical consideration for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might improve the dataset or what additional data sources might be considered. While it identifies a potential weakness, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should use other metrics to evaluate the results, specifically mentioning BERTScore as an example. This feedback provides a clear and explicit action for the authors to take, which is to consider using additional metrics for evaluating their results. The suggestion is concrete, as it specifies a specific metric to use, making it easy for the authors to understand and implement the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. However, it does not specify which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors can infer that it relates to the evaluation of results, but the lack of explicit reference makes it weakly grounded. The comment is specific in suggesting the use of BERTScore as an alternative metric, providing some guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. However, the comment does not provide any reasoning or evidence to support why BERTScore is a better choice or why the current metrics are insufficient. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 2, as it lacks sufficient justification to be 5.", "helpfulness_rationale": "The review comment suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. This feedback is 3 as it identifies a potential area for improvement by suggesting the use of a different metric for evaluating the results. However, the comment lacks depth and does not provide detailed guidance on why BERTScore might be a better choice or how it could be integrated into the evaluation process. Additionally, it does not address other potential metrics or discuss the implications of using a different metric. While the suggestion is a step in the right direction, it could be more helpful with additional context and explanation. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare the SynTextBench metric to other metrics proposed in the literature, specifically mentioning metrics like MMLU and Big Bench for language generation. While the comment does not explicitly instruct the authors to conduct this comparison, it provides a clear direction for how to enhance the evaluation of their metric. The action is implicit but concrete, as it specifies the metrics to compare and the conditions under which SynTextBench should be used. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"large amount of work on LLM evaluation\" and references specific metrics like MMLU and Big Bench. It also specifies the issue by pointing out that it is difficult to understand the conditions under which SynTextBench should be used over other metrics. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that there has been a large amount of work on LLM evaluation and that some of the metrics do not satisfy the proposed desiderata. It also mentions that it would be beneficial to compare SynTextBench to other metrics proposed in the literature, specifically mentioning MMLU and Big Bench for language generation. The comment provides a logical reasoning for the need to compare SynTextBench to other metrics, but it lacks specific examples or references to support the claim that some metrics do not satisfy the desiderata. This makes the claim 3, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to compare their SynTextBench metric with other metrics proposed in the literature, specifically mentioning MMLU and Big Bench for language generation. This feedback is valuable as it guides the authors in demonstrating the strengths and limitations of their metric in the context of existing evaluations. By addressing this suggestion, the authors can enhance the clarity and comparability of their work, which is essential for effective communication and impact. However, the comment could be more helpful if it provided additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment points out that the writing and annotations are difficult to follow, but it does not provide any specific guidance on how to improve them. It lacks actionable advice or suggestions on what aspects of the writing or annotations are confusing or unclear, making it challenging for the authors to address the issue. Without concrete details or suggestions, the authors are left without a clear path to enhance the clarity of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"poor writing and annotations,\" but it does not specify which parts of the paper are affected by this issue. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the writing or annotations are difficult to follow. This makes the comment 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the writing and annotations are difficult to follow. However, it does not provide any specific examples or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a general issue with the writing and annotations being difficult to follow. However, it lacks specificity and does not provide any guidance on how to improve the clarity or what aspects of the writing or annotations are particularly challenging. Without actionable feedback or suggestions, the authors are left without a clear path to enhance the readability and accessibility of their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should provide an explanation or analysis to clarify this discrepancy. The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. The comment does not present any claims or opinions but rather seeks clarification or explanation. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a concern about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. This is a relevant observation that could help the authors understand the performance of their method and identify potential areas for improvement. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as suggesting further analysis or clarification of the results. While it points out a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific changes they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this methodology is discussed. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its question about the methodology but lacks grounding as it does not explicitly mention a section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. This is an important point that could impact the validity and generalizability of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what potential implications it might have on the study. While it identifies a potential weakness, it does not offer actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific suggestions for improving the presentation of results, such as labeling the yaxis in Figures 2 and 3 and using a scatter plot with runtime/performance axes. It also recommends highlighting the best results in tables. These actions are explicit and concrete, providing clear guidance on how to enhance the clarity and interpretability of the results. The authors know exactly what changes to make to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be improved, such as labeling the yaxis and using a scatter plot with runtime/performance axes. The comment also suggests highlighting the best results in tables, providing clear guidance on how to enhance the presentation of results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results presentation in Figures 2 and 3 could be improved by labeling the yaxis more clearly and using a scatter plot with runtime/performance axes. It also recommends highlighting the best results in tables. While the comment provides a logical suggestion for improving the clarity of the results, it lacks specific examples or references to support the claim that these changes would indeed improve the presentation. The suggestion is 3, as it provides a reasonable direction for improvement but could benefit from more detailed justification or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on how to improve the presentation of results in the paper. It identifies ambiguities in the yaxis labeling in Figures 2 and 3 and suggests using a scatter plot with runtime/performance axes to enhance clarity. Additionally, it recommends highlighting the best results in tables, which is a helpful suggestion for readers. The comment is clear and provides detailed guidance, making it 4 for the authors in improving the clarity and interpretability of their results. However, it could be more helpful if it included examples of how the suggested changes would enhance the results presentation. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It seeks clarification on whether the base node affects the ordering, key nodes for attention, and model performance. While the comment implies that the authors should provide more information or clarification on this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement \"NodeSort differentially sorts nodes depending on the base node,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the implications of this statement, including whether the base node affects the ordering, key nodes for attention, and model performance. This provides clear guidance on what aspects need clarification or further exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question seeking clarification about the implications of a statement regarding \"NodeSort differentially sorting nodes depending on the base node.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implications of the statement \"NodeSort differentially sorts nodes depending on the base node,\" seeking clarification on whether the base node affects the ordering, key nodes for attention, and model performance. This is a relevant question that could help the authors better understand the potential impact of their method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it points out a potential area for clarification, it lacks actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the arrow in Figure 2, specifically asking why it goes from a Gaussian space into the latent space rather than the other way around. This question implies that the authors should clarify or correct the arrow direction to better align with the intended purpose of the figure. While the comment does not explicitly instruct the authors to make a change, it provides a clear direction for improvement by pointing out a potential inconsistency in the figure. The action is implicit but concrete, as the authors can infer the need to adjust the arrow direction to better align with the intended purpose. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the direction of the arrow in the figure, which is a clear indication of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the direction of the arrow in Figure 2, specifically asking why it goes from a Gaussian space into the latent space rather than the other way around. The reviewer seems to assume that the main purpose of the figure is to influence n^(i), but this assumption is not explicitly stated or justified. The comment lacks specific reasoning or evidence to support the claim that the arrow should be reversed, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the direction of the arrow in Figure 2, specifically questioning why it goes from a Gaussian space into the latent space rather than the other way around. This feedback highlights a potential inconsistency in the figure, which could be confusing for readers. By pointing out this issue, the comment prompts the authors to clarify or correct the figure to better align with the intended purpose. However, the comment does not provide specific suggestions or guidance on how to address this issue, which limits its helpfulness. Therefore, the comment is 3, as it identifies a potential problem but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out that many abbreviations lack definitions and cause confusion, specifically mentioning \"AR\" in Table 5 as an example. It provides a clear and specific action for the authors to take, which is to define these abbreviations in the text or provide a glossary. This guidance is direct and concrete, leaving no ambiguity about what needs to be done to improve the clarity of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abbreviation \"AR\" in Table 5, noting that it stands for domain adaptation tasks and algorithms. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definitions and cause confusion, specifically mentioning \"AR\" in Table 5 as an example. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that many abbreviations lack definitions and cause confusion. It provides a concrete example by pointing out that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This feedback is clear and actionable, as it directs the authors to clarify these abbreviations to improve the clarity and accessibility of their work. By addressing this issue, the authors can enhance the readability and comprehensibility of their paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the technical considerations for conducting the analysis using advantage instead of q value. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific technical considerations should be explored or how to address them. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the technical considerations for conducting the analysis using advantage instead of q value, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine whether it relates to a specific section, table, or figure. Additionally, the comment lacks specificity regarding what technical considerations are being questioned or how they might impact the analysis. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the technical considerations for conducting the analysis using advantage instead of q value. It does not express an opinion, judgment, or suggestion that requires verification. It is a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the technical considerations for conducting the analysis using advantage instead of q value, which is a relevant point for the authors to address. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might explore or address these considerations. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it identifies an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the setting of Unsupervised Online Adaptation is strange, as it requires a training set, including documents, queries, and labels. The reviewer suggests that this is not \"Unsupervised\" because the training set also requires annotations. While the comment identifies a potential issue with the labeling of the adaptation process, it does not provide explicit guidance on how to address this issue or suggest specific changes to improve the clarity or accuracy of the description. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the nature of the training set and its annotation requirements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting of Unsupervised Online Adaptation is strange because it requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. The comment provides clear guidance on what needs to be addressed, namely the clarification of the adaptation process and its unsupervised nature. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the setting of Unsupervised Online Adaptation is strange because it requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. The reviewer supports this claim by referencing Section 3.1, where the model\"s training requirements are described. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a logical basis for the critique, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the setting of Unsupervised Online Adaptation, noting that the model requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. This feedback is 3 as it points out a potential inconsistency in the paper\"s description, prompting the authors to clarify or adjust their terminology. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or improve the clarity of the description. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out an issue with the performance comparison in Table 1, specifically noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This implies that the comparison is unfair and suggests that the authors should address this issue to ensure fairness in their evaluation. However, the comment does not provide explicit guidance on how to rectify this issue or what specific changes should be made to the evaluation process. While the action is implied, it is not detailed enough for the authors to know exactly how to implement the suggested change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the performance comparison, noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair because VINS sets different sample weights while most baselines use a uniform weight of 1. This claim is 3 as it provides a logical reasoning for the unfairness, but it lacks specific examples or references to support the assertion that this difference significantly impacts the comparison. The authors would need to make a concerted effort to understand and address the issue, which requires more detailed evidence or explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance comparison in Table 1, noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This is a critical observation that could impact the fairness and validity of the comparison. However, the comment does not provide suggestions or guidance on how the authors might address this issue, such as recommending a standardized weighting scheme or explaining the potential impact of this difference. While it points out a significant problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the time complexity of the system if the reply buffer is too large. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the time complexity or suggestions for how to manage the reply buffer. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they need to make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"reply buffer,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the time complexity being too high if the reply buffer is too large, and it references a specific work, \"PRMRL: Longrange Robotic Navigation Tasks by Combining Reinforcement Learning and Samplingbased Planning,\" which provides a basis for the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the time complexity will be too high if the reply buffer is too large, referencing a specific work, \"PRMRL: Longrange Robotic Navigation Tasks by Combining Reinforcement Learning and Samplingbased Planning.\" This reference provides a basis for the claim, as it suggests that the time complexity could be an issue in the context of robotic navigation tasks. However, the comment does not provide detailed reasoning or examples to fully substantiate the claim, leaving some gaps in the justification. Therefore, the comment is 3, as it provides a logical basis but lacks comprehensive evidence or explanation.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the system if the reply buffer is too large. It references a specific work, \"PRMRL: Longrange Robotic Navigation Tasks by Combining Reinforcement Learning and Samplingbased Planning,\" which provides a basis for the claim. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or mitigate the time complexity. While it points out a potential problem, it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it provides some insight but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. While the comment provides a specific direction for improvement, it does not offer concrete guidance on how to implement these changes or which specific baselines to consider. The authors are left to infer the necessary steps to take, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative approaches to consider, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why these alternative approaches would be beneficial or how they would improve the paper. Without specific examples or detailed explanations, the claim remains 1, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is 3 as it provides a specific direction for improvement by suggesting alternative approaches to consider. However, the comment could be more helpful if it offered examples of how these alternative approaches have been applied in similar contexts or provided guidance on how to implement them effectively. While the suggestion is actionable, it lacks depth and specificity, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that a brief conclusion and a summary of the article\"s contributions are needed. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, as it specifies the exact content that needs to be added, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need for a brief conclusion and a summary of the article\"s contributions, providing full grounding as it clearly identifies the part of the paper being addressed. It is specific because it clearly specifies what needs to be added, namely a conclusion and a summary of the paper\"s contributions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a brief conclusion and a summary of the article\"s contributions are needed. However, it does not provide any supporting evidence, reasoning, or examples to justify why these elements are necessary or how they would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of a brief conclusion and a summary of the paper\"s contributions. This feedback is clear and actionable, as it directly guides the authors on how to enhance the final section of their paper. By providing a concrete suggestion for enhancing the paper\"s conclusion, the comment offers valuable insight that can help the authors improve the clarity and impact of their work. However, the comment could be more helpful if it provided additional guidance on what elements should be included in the conclusion or how to effectively summarize the paper\"s contributions. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. This feedback implies that the authors should include this comparison in their paper to enhance the results\" meaningfulness. While the action is implicit, it is clear that the authors need to make this addition to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. However, it does not specify which part of the paper this comparison should be included in, nor does it provide details on what specific aspects of the framework should be compared. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the comment highlights an area for improvement, it lacks specificity and grounding, making it challenging for the authors to address the feedback effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that such a comparison would be beneficial. The absence of detailed reasoning or evidence makes it difficult for the authors to fully understand the basis of the suggestion. Therefore, the comment is 3, as it provides a logical suggestion but lacks the necessary evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a constructive suggestion for improving the paper by recommending a comparison with a method designed to defend against multiple attacks. This feedback is actionable as it points out a specific area where the authors could enhance their study, which could lead to more meaningful results. However, the comment could be more helpful if it provided examples of such methods or detailed guidance on how to conduct the comparison. Overall, the comment is 4 as it identifies a clear area for improvement and offers a direction for enhancing the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to define the bounds for \tau_i^l, which is important for understanding the timewarp function. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of the bounds for \tau_i^l, which is important for understanding the timewarp function. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point requests the definition of the bounds for \tau_i^l, which is important for understanding the timewarp function. However, the comment does not provide any supporting evidence or reasoning to justify why this definition is necessary or how it would impact the understanding of the function. Without additional context or explanation, the claim is not 5, as it lacks the necessary justification to be considered 5. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific area where the authors need to provide more detail. By pointing out the importance of defining the bounds for \tau_i^l, the reviewer highlights a critical aspect of the paper that could enhance the understanding of the timewarp function. This feedback is clear and actionable, guiding the authors to include this information in their draft. However, the comment could be more helpful if it provided additional context or examples on how to define these bounds effectively. Overall, the comment is 5 as it directs the authors to a crucial aspect of their work that needs clarification."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment identifies these errors, it does not provide explicit guidance on how to correct them. The authors are left to infer that they need to revise these sections to correct the errors and add a title. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be corrected, namely the writing errors and the lack of a title. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This is a factual observation that does not require verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This feedback is clear and actionable, as it points out specific areas that need correction to improve the clarity and professionalism of the paper. However, the comment could be more helpful if it provided suggestions on how to correct these errors or offered guidance on how to improve the overall writing quality. Despite this, the feedback is 4 as it directs the authors to specific areas for improvement, which can enhance the clarity and professionalism of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the first sentence of the abstract needs to be rewritten. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and provides a concrete action, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the first sentence of the abstract, allowing the authors to accurately identify the part of the paper being addressed. However, it does not provide specific details on what needs to be rewritten or why the current sentence is problematic. This lack of specificity makes the comment weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the first sentence of the abstract needs to be rewritten. However, it does not provide any reasoning, evidence, or examples to support why this change is necessary or how it would improve the paper. Without additional context or explanation, the claim is not verifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the first sentence of the abstract, suggesting that it needs to be rewritten. While this feedback is clear and actionable, it lacks depth and does not provide any further explanation or guidance on what aspects of the sentence need improvement or how to rewrite it effectively. The comment is 3 as it points out a specific area for improvement, but it could be more beneficial with additional context or suggestions for enhancing the revised sentence. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the method or what specific aspects of the method are overly complex. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not specify which part of the paper this observation pertains to, such as a particular section, figure, or table. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in suggesting that the method might be overly complex and that there might be a simpler principle driving the quality gains. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not provide specific guidance or suggestions on how the authors might simplify the method or explore the underlying principle. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it points out a potential issue but lacks depth and specificity in its critique."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment suggests that the hGRU architecture appears adhoc and not wellmotivated. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to improve the motivation or clarify the architecture. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the hGRU architecture appears adhoc and not wellmotivated, but it does not specify which part of the paper discusses this architecture. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part needs attention. Additionally, the comment lacks specificity regarding what aspects of the architecture are considered adhoc or poorly motivated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the hGRU architecture appears adhoc and not wellmotivated. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the hGRU architecture appears adhoc and not wellmotivated, which could be a valid concern for the authors to address. However, the comment lacks specificity and does not provide any detailed reasoning or examples to support this claim. Without actionable feedback or suggestions on how to improve the motivation or clarity of the architecture, the authors are left without a clear path forward. Therefore, the comment is not helpful, as it does not guide the authors in making improvements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the use of s_t instead of s_n on Line 8 of Algorithm 1 and suggests that the authors should provide average return results with more env steps. While the comment implies that the authors should make a change to Line 8 and potentially include additional results, it does not explicitly instruct them to do so. The action is concrete, as it specifies the change to be made and the additional information to be provided, but it is somewhat vague because it does not provide detailed guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 8 of Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of s_t instead of s_n and suggests providing average return results with more env steps. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question about the use of s_t instead of s_n on Line 8 of Algorithm 1 and a request for average return results with more env steps. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the use of s_t instead of s_n on Line 8 of Algorithm 1, which is a clear and actionable point for the authors to address. It also suggests providing average return results with more env steps, which could be beneficial for understanding the performance of the proposed method. However, the comment could be more helpful if it provided additional context or examples to support the suggestion for more env steps. Overall, the comment is 4 as it identifies a specific area for improvement and offers a constructive suggestion, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the challenges when analyzing Adam under the (L0,L1)smoothness condition. It suggests that the authors should explain the challenges and the differences between their work and that of Zhang et al. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context and explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of Adam under the (L0,L1)smoothness condition, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the challenges and the differences between the authors\" work and that of Zhang et al. This provides clear guidance on what the authors need to clarify or improve in their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the challenges when analyzing Adam under the (L0,L1)smoothness condition are unclear and suggests that the authors should explain these challenges, especially in comparison to Zhang et al. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the challenges when analyzing Adam under the (L0,L1)smoothness condition. It suggests that the authors should clarify these challenges and explain the differences between their work and that of Zhang et al. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the clarity and depth of their analysis. By addressing these points, the authors can improve the comprehensibility and rigor of their work. However, the comment could be more helpful if it offered specific examples or suggestions on how to present these challenges and comparisons. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point provides a factual statement about the prevalence of person reID methods based on pedestrian detectors and mentions a specific work that combines detection and reID. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this information or what specific aspects of the paper need to be revised based on this knowledge. As a result, the comment lacks actionability and is not helpful for the authors in improving their draft. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment provides a factual statement about the prevalence of person reID methods based on pedestrian detectors and mentions a specific work that combines detection and reID. However, it does not specify which part of the paper this information pertains to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the paper should be addressed or improved based on this information. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point provides a factual statement about the prevalence of person reID methods based on pedestrian detectors and mentions a specific work that combines detection and reID. This is a descriptive statement that does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a factual statement about the prevalence of person reID methods based on pedestrian detectors and mentions a specific work that combines detection and reID. However, it does not offer any insights, suggestions, or guidance on how this information could be used to improve the paper. Without actionable feedback or a connection to the paper\"s content, the comment lacks utility for the authors. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests adding a first sentence to introduce what Section 3.2 is about. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is specific in detailing what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a first sentence to introduce what the section is about, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests adding a first sentence to introduce what Section 3.2 is about. However, it does not provide any reasoning, evidence, or examples to support why this addition is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests adding a first sentence to introduce what Section 3.2 is about. This is a clear and actionable suggestion that can help the authors improve the clarity and accessibility of their paper. By providing a specific and direct recommendation, the comment offers a straightforward way for the authors to enhance the organization and flow of their content. However, the comment could be more helpful if it explained why this introduction is important or how it would benefit the reader. Overall, the comment is 4 as it provides a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, it does not provide explicit guidance on what the authors should do to address this issue or how to clarify the statement. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the meaning of the term, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this statement is problematic or unclear. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the meaning of the phrase \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. This feedback highlights a potential inconsistency or confusion in the paper, which could be clarified to improve the clarity and coherence of the text. However, the comment does not provide specific suggestions or guidance on how to address this issue or what alternative phrasing might be more appropriate. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors experimented with using domain ontologies to avoid placeholder generation in the evaluated responses. It also asks for clarification on the number of questions created for the zeroshot intent classifier and its accuracy. While the comment implies that the authors should provide more information about their experimental setup, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about their experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the usage of domain ontologies to avoid placeholder generation and asks for clarification on the number of questions created for the zeroshot intent classifier and its accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the usage of domain ontologies to avoid placeholder generation and seeks clarification on the number of questions created for the zeroshot intent classifier and its accuracy. However, it does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or how they could impact the paper\"s findings. Without additional context or explanation, the authors may find it challenging to understand the basis of the questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the usage of domain ontologies to avoid placeholder generation in the evaluated responses, which is a relevant and potentially valuable aspect to explore. It also seeks clarification on the number of questions created for the zeroshot intent classifier and its accuracy, which could provide additional insights into the paper\"s findings. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address these questions or incorporate domain ontologies into their work. While it identifies areas for improvement, it does not provide actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. While the suggestion is clear, it lacks specific guidance on which methods to compare with or how to conduct the comparison. The authors are left to infer that they should explore other methods, but without detailed instructions on how to do so, the action remains vague. Therefore, the comment is 3, as it provides a direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this comparison could be made. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a comparison with other methods, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. However, it does not provide any supporting evidence, examples, or references to justify why this comparison is necessary or beneficial. Without such details, the claim remains 1, as it lacks the necessary information to support the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. This is a valuable suggestion as it could help the authors broaden the scope of their work and demonstrate the applicability of their method in a wider context. However, the comment lacks specificity and does not provide guidance on which methods to compare with or how to conduct the comparison. Without detailed instructions or examples, the authors may find it challenging to implement this suggestion effectively. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the abstention process, specifically asking for clarification on how it differs from a decision threshold used by the models. While the comment implies that the authors should provide a clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction between the two processes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstention process,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how the abstention process differs from a decision threshold used by the models, and it suggests that the authors clarify this distinction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the abstention process, specifically asking for clarification on how it differs from a decision threshold used by the models. The comment does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the abstention process, asking for clarification on how it differs from a decision threshold used by the models. This is a clear and actionable request for the authors to provide additional explanation or clarification in their draft. By addressing this question, the authors can improve the clarity and understanding of their methodology. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. It suggests that the authors should compare their work with a chainofthought prompting approach, which is a specific and concrete suggestion for improvement. This feedback provides clear guidance on what the authors need to do to enhance their comparisons and make their work more robust. The explicit nature of the suggestion and the concrete example of a potential baseline make the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of meaningful baselines and the suggestion to compare with a chainofthought prompting approach. This provides clear guidance on what the authors need to improve in their comparisons. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. The reviewer suggests that the authors should compare their work with a chainofthought prompting approach. While the comment identifies a potential issue with the baselines, it does not provide specific examples or references to support the claim that the current baselines are insufficient. The suggestion to compare with a chainofthought prompting approach is logical, but the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the lack of meaningful baselines limits the comparisons made by the authors. It suggests that the authors should consider using a chainofthought prompting approach as a more robust baseline. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the robustness and credibility of the paper. By addressing this point, the authors can significantly strengthen their work. However, the comment could be more helpful if it explained why the chainofthought prompting approach is considered meaningful or how it would benefit the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also inquires about the generalizability of this approach when labels are not available. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification or explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the pretraining of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the generalizability of the approach when labels are not available. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the pretraining of the cardiac signal representation learning model. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the pretraining of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalizability of this approach when labels are not available. This feedback is 3 as it prompts the authors to clarify an important aspect of their methodology, which could impact the robustness and applicability of their results. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to improve the generalizability of the model. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study in Table. While the comment implies that the authors should investigate these issues, it does not provide explicit instructions or concrete steps on how to address them. The authors can infer that they need to assess the accuracy of the ground truth and the noticeability of the difference, but the comment lacks specific guidance on how to do so. Therefore, the action is implicit and somewhat vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study in Table. However, it does not specify which part of the paper these questions pertain to, such as a specific section or table. The authors can infer that it relates to the results or analysis sections, but this inference is not direct. The comment is specific in its inquiry about the accuracy and noticeability of the differences, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study in Table. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of these questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the accuracy and reliability of the results presented in the paper. It questions whether the small differences observed are actually noticeable or due to noise or randomness in the training process. Additionally, it points out a lack of difference between the results reported in the ablation study in Table. While the comment identifies potential issues, it does not provide specific suggestions or guidance on how the authors might address these concerns. The feedback is 3 as it prompts the authors to consider the reliability of their results, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of new evaluation metrics and the limited exploration of existing metrics in the experimental analysis section. It explicitly states that there needs to be an indepth exploration of the reasons for the experimental results. This provides a clear and concrete action for the authors to take, which is to conduct a more thorough analysis of the experimental results and consider proposing new metrics. The comment is specific in detailing what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental analysis section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of new evaluation metrics and the limited exploration of existing metrics. The comment suggests an indepth exploration of the reasons for the experimental results, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that no new evaluation metrics are proposed and that existing metrics are linearly combined. It suggests that the experimental analysis section needs an indepth exploration of the reasons for the experimental results. However, the comment does not provide specific examples or references to support the claim that existing metrics are insufficient or that the exploration is lacking. Without detailed reasoning or evidence, the claim remains 3, as the authors may find it challenging to understand the basis of the critique without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the lack of new evaluation metrics and the limited exploration of existing metrics. It suggests that the experimental analysis section needs an indepth exploration of the reasons for the experimental results. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by proposing new metrics or conducting a more thorough analysis of the existing ones. However, the comment could be more helpful if it offered examples of how to conduct such an exploration or provided guidance on what specific aspects to focus on. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the notation \"K\" is being used inappropriately, as it is used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176). However, it does not provide explicit guidance on how to resolve this issue or suggest alternative notations. The action is implicit and vague, as the authors are left to infer that they need to clarify or change the notation to avoid confusion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L166\" and \"L176,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the notation \"K,\" which is being used for both a known kernel function and the number of layers, causing confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation \"K\" is being used inappropriately, as it is used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176). However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"K,\" noting that it is being used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176), which can cause confusion. This feedback is clear and actionable, as it points out a potential source of confusion in the paper and suggests a way to clarify the notation. However, the comment could be more helpful if it provided suggestions on how to resolve this issue, such as recommending a different notation or explaining the context in which \"K\" is used. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the concern about the practical impact or suggestions for improving the paper to better demonstrate its relevance. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the theoretical interest and the potential practical impact, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. This feedback highlights a potential limitation in the paper\"s relevance and applicability, which could impact its impact on the field. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or demonstrate the practical relevance of their work. While it points out a potential weakness, it does not provide actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the relevance of connecting human cognition to the problem at hand, given that the authors acknowledge that the problem is reductionist and lacks mechanisms like bargaining and negotiation. The reviewer suggests that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR might have a greater impact on selforganization. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify their argument. The suggestion for more citation is implied but not directly stated, leaving the authors with a vague understanding of what steps to take. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unclear connection between human cognition and the problem at hand. The comment suggests that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR might have a greater impact on selforganization than previously appreciated, and it questions the relevance of human cognition. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the relevance of connecting human cognition to the problem at hand, given that the authors acknowledge that the problem is reductionist and lacks mechanisms like bargaining and negotiation. The reviewer suggests that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR might have a greater impact on selforganization than previously appreciated. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to make a significant effort to understand and address the reviewer\"s point, as the reasoning is not fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid point about the relevance of connecting human cognition to the problem at hand, given that the authors acknowledge that the problem is reductionist and lacks mechanisms like bargaining and negotiation. The reviewer suggests that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR might have a greater impact on selforganization than previously appreciated. This feedback is 3 as it prompts the authors to reconsider the relevance of human cognition in their analysis and potentially explore alternative perspectives. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue or what additional evidence or analysis might be needed. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant in multiple places. However, it does not provide specific guidance on how to tone down the language or suggest alternative phrasing. The comment lacks explicit instructions or concrete examples of what constitutes overly exaggerated or flamboyant language, making it difficult for the authors to know exactly how to address the issue. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the conclusion, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording, describing it as overly exaggerated and flamboyant. This provides clear guidance on what needs to be addressed in the conclusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant in multiple places. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without specific instances or references to overly exaggerated or flamboyant language, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient evidence or justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and suggests that the word choice is flamboyant in multiple places. This feedback is 3 as it points out a potential weakness in the language used, which could be revised to be more appropriate and professional. However, the comment lacks specific examples or suggestions on how to tone down the language or what alternative phrasing might be more appropriate. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific direction for the experiments, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need for ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This provides full grounding as it clearly identifies the part of the paper that needs revision. The comment is also specific because it specifies the exact comparison that needs to be made, which is the number of learnable parameters and GFLOPs. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these comparisons are necessary or how they would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by conducting additional experiments. By doing so, the authors can demonstrate the effectiveness of their method in comparison to other approaches, which could enhance the paper\"s contribution and credibility. However, the comment could be more helpful if it included suggestions on how to design these experiments or what specific insights to focus on. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific baselines to compare against or detailing the expected utility measure. The comment lacks concrete steps for the authors to take, leaving them uncertain about how to improve their draft. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for comparison to baselines. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a comparison to simple feature acquisition baselines like expected utility or some other measure, which is a significant weakness. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific examples or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure to prove the effectiveness of the proposed approach. This is a critical oversight that could impact the credibility and impact of the paper. However, the comment does not provide specific guidance on how the authors might address this issue, such as suggesting which baselines to compare against or how to implement the comparison. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement, but it does not provide explicit instructions or concrete steps for the authors to follow. The comment mentions that Figure 5a seems strange and asks for more explanations, but it does not specify what aspects of the figure are problematic or how to address them. Similarly, it mentions the handling of DVS input when the input is in AER format but does not offer guidance on how to improve this aspect. The comment also suggests analyzing energy consumption as in reference [15], but it does not provide specific details on how to implement this analysis. Overall, the comment lacks actionable steps or detailed guidance, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5a\" and \"11,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with \"Fig. 5a\" and suggests providing more explanations, as well as addressing the handling of DVS input when the input is in AER format. Additionally, it recommends analyzing energy consumption as in reference [15]. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of several questions and suggestions for improvement, rather than making a subjective claim or opinion. It does not contain any claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides several pieces of feedback that can help the authors improve their draft. It points out that Figure 5a seems strange and suggests that more explanations are needed. It also questions how the authors handled DVS input when the input is in AER format, which is a relevant concern for the paper. Additionally, the comment recommends analyzing energy consumption as in reference [15], which could strengthen the paper\"s solidity. While the comment identifies areas for improvement, it lacks specific guidance or examples on how to address these issues. Therefore, it is 3, as it provides some direction but could be more comprehensive with additional details."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. While the comment implies that additional experiments are needed, it does not provide specific guidance on which tasks or domains to focus on or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that additional experiments across different downstream tasks and domains are needed to address these concerns. However, the comment does not specify which part of the paper discusses the similarityaware positive sample selection or the transfer performance of the model. This makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its concern about the potential issues but lacks grounding as it does not reference specific sections or experiments. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that additional experiments across different downstream tasks and domains are needed to address these concerns. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the concern or how to address it. The lack of detailed evidence or references makes the claim 3, as the authors would need to infer the basis of the concern and the potential solutions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that additional experiments across different downstream tasks and domains are needed to address these concerns. While the comment identifies a critical area for improvement, it lacks specific suggestions or guidance on how to conduct these experiments or what specific tasks or domains to focus on. The feedback is 3 as it points out a potential issue but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the discussion should be expanded. The action is implicit and somewhat vague, as the authors can infer that they need to provide more discussion on the power of different architectures but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the architectures should be discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that fast SMP is less expressive than SMP. Without such evidence or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the architectures should be discussed. The comment is 3 as it points out a potential gap in the paper, but it does not provide actionable steps for the authors to improve their draft. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the types of situations and social norms mentioned in the paper, such as physical and psychological safety, are not clearly defined. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify these concepts or what specific changes should be made to improve the clarity. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the types of situations and social norms mentioned in the paper, such as physical and psychological safety, are not clearly defined. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of unclear definitions, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the types of situations and social norms, such as physical and psychological safety, are not clearly defined in the main paper. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of the paper, noting that the types of situations and social norms, such as physical and psychological safety, are not clearly defined. This feedback is 3 as it points out a potential area for improvement, but it lacks depth and does not provide specific suggestions on how to clarify these concepts or what aspects of the paper need further explanation. While it highlights an important issue, the comment could be more helpful with additional guidance or examples. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to define the dashed lines in figures 2AB and 4B. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete request, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 2AB\" and \"fig. 4B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of the dashed lines in these figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point requests clarification about the definition of the dashed lines in figures 2AB and 4B. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 5 as it directly addresses a specific issue by requesting the definition of the dashed lines in figures 2AB and 4B. This is a clear and actionable piece of feedback that can help the authors improve the clarity and understanding of their figures. By providing this guidance, the reviewer helps the authors enhance the presentation and comprehensibility of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods is questionable. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the comparability of the results or what specific aspects need to be improved. As a result, the authors are left without any clear direction on how to enhance the significance of their work. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods is questionable. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the results are not comparable or how they could be improved. Without clear guidance on where to focus the revision, the authors may struggle to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results are not comparable to existing methods, which suggests that the significance of the proposed methods is questionable. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods may be questionable. However, it does not provide any specific examples or guidance on how the authors might address this issue or improve the comparability of their results. Without actionable feedback or detailed suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the paper regarding the assumption that the spectrum of a kernel is subgaussian, noting that this assumption excludes popular classes of kernels like Matern kernels. The reviewer suggests that the results could be restrictive due to this assumption. However, the comment does not provide explicit guidance on how the authors should address this limitation or suggest ways to broaden the scope of the results. The action is implicit and somewhat vague, as the authors need to infer that they should consider including other classes of kernels in their analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the assumption regarding the spectrum of a kernel being subgaussian, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the assumption excludes popular classes of kernels like Matern kernels, which could limit the scope of the results. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the assumption of the spectrum of a kernel being subgaussian is a limitation, as it excludes popular classes of kernels like Matern kernels. The reviewer supports this claim by noting that Matern kernels have polynomially decaying spectra, which could restrict the applicability of the results. However, the comment lacks specific examples or references to Matern kernels or other classes of kernels to fully substantiate the claim. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper regarding the assumption that the spectrum of a kernel is subgaussian, which excludes popular classes of kernels like Matern kernels. This is a relevant point that could impact the applicability and generalizability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or broaden the scope of their analysis to include other classes of kernels. While it highlights an important issue, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should focus more on the unsupervised pretraining method in the main paper, as it appears to be a key factor in performance gain. While the comment explicitly states the need for more discussion on the unsupervised pretraining, it does not provide specific guidance on how to integrate this discussion into the main paper. The authors are left to infer that they should add more details about the pretraining method, but the comment lacks concrete steps or examples on how to do so. Therefore, the action is explicit but somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"unsupervised pretraining,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of detailed discussion on the unsupervised pretraining in the main paper, and it suggests focusing more on this aspect. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in performance gain, based on data from Table 4. However, it does not provide specific evidence or detailed reasoning to support this claim, such as data analysis or comparisons with other methods. The comment suggests that the unsupervised pretraining is more important than other modules presented in the paper, but it lacks specific examples or detailed justification to fully substantiate the claim. Therefore, the comment is 3, as it provides a direction for further exploration but requires more detailed evidence or reasoning to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the unsupervised pretraining is a key factor in performance gain but is not discussed in detail in the main paper. It suggests that the authors should focus more on the pretraining method, as it appears to be more important than other modules presented in the paper. This feedback is clear and actionable, providing the authors with a direct and specific direction for improvement. However, it could be more helpful if it included suggestions on how to integrate the discussion of the unsupervised pretraining into the main paper or provided examples of how other papers have effectively discussed similar topics. Overall, the comment is 4 as it guides the authors on a critical aspect of their work that needs further attention and elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how to choose an ELM (male/female) and whether this requires knowing the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not provide explicit guidance or suggestions on how to address this issue. It lacks concrete steps or recommendations for the authors to follow, leaving them uncertain about how to proceed. Therefore, the comment is 3, as it identifies a potential issue but does not offer specific actions for the authors to take.", "grounding_specificity_rationale": "The comment raises a question about how to choose an ELM (male/female) and whether this requires knowing the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment. While the authors might have an idea of where this discussion might occur, the comment lacks full grounding. It is specific in its critique of the methodology but does not provide detailed guidance on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand. The reviewer suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment lacks specific examples or references to support the claim that this is a drawback or how it affects the accuracy of the model. Without detailed reasoning or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a critical question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline, especially in cases where vocal traits match the speaker\"s identity. This feedback is 3 as it identifies a potential issue with the methodology that the authors may not have considered. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what alternative approaches might be considered. Overall, the comment offers a valuable insight but lacks detailed guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the paper is incremental and lacks technical substance, suggesting that it only adds a new loss to an existing work. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical substance or what specific aspects of the paper need attention. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental and lacks technical substance, specifically mentioning that it only adds a new loss to an existing work. However, it does not specify which part of the paper this assessment is based on, such as the methodology or results sections. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity in detailing what aspects of the paper are considered incremental or lacking in technical substance. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental and lacks technical substance, suggesting that it only adds a new loss to an existing work. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper is incremental and lacks technical substance, specifically mentioning that it only adds a new loss to an existing work. However, it does not provide any specific examples or details about what aspects of the paper are considered incremental or lacking in substance. Without this context or guidance, the authors may struggle to understand how to address the critique or improve their draft. Therefore, the comment is 2, as it identifies a potential issue but lacks depth and actionable suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of notation in equations (7) and (10), expecting them to be analogous but noting a discrepancy. However, it does not provide any explicit or implicit suggestions for the authors to address this issue. The comment lacks guidance on how the authors might clarify or justify the notation choices, leaving the authors uncertain about how to proceed. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of notation, expecting them to be analogous but noting a discrepancy. However, the comment does not provide further details or suggestions on how to address this issue, such as explaining why the notation is not analogous or proposing alternative notation choices. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point questions the choice of notation in equations (7) and (10), expecting them to be analogous but noting a discrepancy. However, the comment does not provide any reasoning, explanation, or references to support why the notation should be analogous or why the discrepancy exists. Without additional context or justification, the claim is not verifiable, as it lacks the necessary information to substantiate the claim. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The comment raises a question about the choice of notation in equations (7) and (10), expecting them to be analogous but noting a discrepancy. This observation could prompt the authors to reconsider their notation choices and provide clarity or consistency in their equations. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address this issue. While it points out a potential area for improvement, it does not provide actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide empirical evidence to demonstrate the applicability of their model to realworld diffusion processes. While the comment implies that the authors should conduct experiments or provide examples to support their claims, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors know they need to provide empirical evidence but may not be entirely sure of the specifics of what is expected. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the applicability of the model to realworld diffusion processes, suggesting that the authors should provide empirical evidence to demonstrate its effectiveness. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for empirical evidence, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the applicability of the model to realworld diffusion processes is a concern, and it provides a logical reasoning by stating that the authors should provide empirical evidence to demonstrate its effectiveness. However, the comment lacks specific examples or references to support the claim that the model captures diffusion phenomena in realworld scenarios. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the applicability of the proposed model to realworld diffusion processes. It acknowledges the elegance of the solutions presented but suggests that empirical evidence is needed to demonstrate the model\"s effectiveness in realworld scenarios. This feedback is clear and actionable, as it provides a specific direction for the authors to address the applicability issue by providing empirical evidence. However, the comment could be more helpful if it offered suggestions on how to conduct such experiments or what specific aspects of the diffusion process should be examined. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should test their method on more datasets to gain a better understanding of its performance. While the action is implicit, it is clear that the authors need to expand their testing to include more datasets. The comment provides a specific suggestion for improvement, which is to test on additional datasets. However, it does not offer detailed guidance on which datasets to use or how to conduct the additional testing. Therefore, the action is 3, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the testing and evaluation of the method, but this inference is not direct. The comment is specific in suggesting the need for additional testing, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not provide any supporting evidence, reasoning, or references to justify why testing on more datasets would be beneficial or necessary. The claim is based on a logical assumption, but without additional context or examples, it lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. This is a reasonable suggestion that could improve the robustness and generalizability of the results. However, the comment lacks specificity and does not provide guidance on which datasets to use or how to conduct the additional testing. Without detailed suggestions or examples, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel, as alternatives already exist. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment lacks actionable details, such as recommending alternative approaches or suggesting ways to differentiate their contribution from existing work. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the main contribution, which is the combination of attention with other linear mechanisms. However, it does not specify which part of the paper discusses this contribution, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the combination are not novel or how the authors could differentiate their work from existing alternatives. Without clear guidance on where to focus improvements, the authors may struggle to address the critique effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the main contribution of combining attention with other linear mechanisms is not novel, as alternatives already exist. However, the comment does not provide specific examples or references to these alternatives, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or reasoning, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel, as alternatives already exist. However, it does not provide specific examples or suggestions on how the authors might address this issue or differentiate their work from existing alternatives. Without actionable feedback or guidance, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is not helpful, as it lacks depth and specificity in its critique."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should provide a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a clear and concrete action that the authors can take to improve their draft. The comment provides a specific direction for visualizing the results, which is a direct and actionable point. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests providing a plot of how different weights of the model move, specifically after unlearning, to see which layers are affected the most. However, it does not specify which part of the paper this plot should be included in, such as a specific section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular visualization, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a request for additional visualization to support the understanding of the method. However, the comment does not provide any specific reasoning or evidence to justify why this plot is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the claim is considered 2.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends that the authors include a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a clear and constructive piece of feedback that can help the authors better understand and communicate the impact of their method. By addressing this suggestion, the authors can enhance the clarity and comprehensiveness of their results, making the paper more informative and valuable to the reader. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific information should be included in the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where the inputs are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or clarified regarding the domain of the inputs. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper\"s validity. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. This is a relevant point that could impact the validity and generalizability of the results. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or what additional information might be needed. Without actionable feedback or detailed advice, the authors are left with a vague understanding of the problem but no clear path to improvement. Therefore, the comment is rated as 2, as it identifies a potential weakness but does not offer sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z\u00e2\u0080\u0099 and the independence of x and y given W. The reviewer suggests that taking Z\u00e2\u0080\u0099 to be the empty set would lead to a contradiction with Eq. (7), which states that x and y are dependent given W. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to resolve the conflict. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the definition of Z\u00e2\u0080\u0099 and possibly revise the equation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 2\" and \"the definition of minimal conditional dependence,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, particularly regarding the definition of Z' and the independence of x and y given W. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z' and the independence of x and y given W. The reviewer provides a logical explanation by taking Z' to be the empty set, which leads to a contradiction with Eq. (7). This reasoning is 3 as it highlights a potential issue but lacks detailed justification or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z' and the independence of x and y given W. By taking Z' to be the empty set, the reviewer demonstrates a logical contradiction that could be addressed. However, the comment does not provide specific suggestions or guidance on how the authors might resolve this issue or improve their draft. While it points out a potential problem, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the comprehensive nature of the data presented in Figure 3 but points out that the visual presentation, specifically the subscripts, could be improved for better readability and aesthetic appeal. While the comment identifies an area for enhancement, it does not provide explicit guidance on how to achieve this improvement. The authors are left to infer that they should make changes to the subscripts, but without specific suggestions or examples, the action remains vague. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the visual presentation of the subscripts, for better readability and aesthetic appeal. This provides clear guidance on how to improve the figure. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the visual presentation of the subscripts in Figure 3 could be enhanced for better readability and aesthetic appeal. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks the necessary evidence or examples to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the comprehensive nature of the data presented in Figure 3 but points out a specific area for improvement. It identifies the visual presentation, specifically the subscripts, as needing enhancement for better readability and aesthetic appeal. While the comment provides a clear direction for improvement, it lacks depth and does not offer specific suggestions or examples on how to enhance the visual presentation. This limits the comment\"s helpfulness, as it provides a general direction but does not fully guide the authors on how to achieve the desired improvements. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about how the archetype positions are updated after initialisation in Algorithm 2. It explicitly asks the authors to clarify this aspect, providing a clear action for the authors to take. The comment is explicit in its request for clarification, making it 5. The authors know exactly what needs to be addressed and how to implement the action, as they are instructed to provide a comment on the update process. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"the query Q consists of the archetypes z_1, \u00e2\u0080\u00a6, z_k,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the update process of the archetype positions after initialisation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of the update process for the archetype positions in Algorithm 2. It does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, which is a factual statement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the update process of the archetype positions in Algorithm 2. It asks the authors to clarify this aspect, which is important for understanding the methodology. This feedback is clear and actionable, as it directs the authors to provide a comment on the update process. However, the comment could be more helpful if it offered suggestions on how to clarify this aspect or provided examples of how the update process might be explained. Overall, the comment is 4 as it points out a critical area for clarification, but it could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two main issues: the timeconsuming nature of training the shape model and the complexity of the parsing model. It suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific aspects of the training and testing process should be described. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed description and comparison with existing work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the timeconsuming nature of training the shape model and the complexity of the parsing model, suggesting that the processing efficiency of training and testing should be described and compared with existing work. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the training and testing process, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact parts needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the shape model is timeconsuming due to its training in pixel level (though sparsity by landmark) and the model being trained independently on all font images and characters. Additionally, it suggests that the parsing model is a highorder factor graph with four types of factors, which affects processing efficiency. The comment further recommends describing and comparing the processing efficiency of training and testing with existing work. While the comment provides some logical reasoning by pointing out the complexity of the models and the need for comparison, it lacks specific examples or references to existing work that could substantiate the claim. This makes the claim 3, as it provides a general rationale but requires more detailed evidence or references to fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the timeconsuming nature of training the shape model and the complexity of the parsing model. It suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment highlights important areas for improvement, it lacks specific guidance on how to address these issues or what aspects of the training and testing process should be described and compared. The feedback is 3 as it points out areas that need attention, but it could be more beneficial with additional details or suggestions on how to improve the draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the clarity of the motivation or how to differentiate the paper from incremental engineering papers. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the motivation of the paper is difficult to follow and that it appears to be an incremental engineering paper. However, it does not specify which part of the paper is problematic or where the motivation is unclear. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the motivation or the paper are unclear or how they could be clarified. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific details or references, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the motivation of the paper is difficult to follow and that it appears to be an incremental engineering paper. However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity or originality of their work. Without actionable feedback or detailed insights into what aspects of the paper are unclear or lacking, the authors are left without a clear path for improvement. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the proposed dataset is a different train/test split of an existing dataset, SQUALL. Additionally, the comment mentions a synthetic benchmark paper based on a single question template. While the comment highlights these issues, it does not provide explicit guidance on how the authors should address them. The authors can infer that they need to demonstrate novelty and incremental improvements, but the comment lacks concrete suggestions on how to achieve this. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific issue of the lack of novelty and incremental nature of the work, as well as the problem of column operations in designing semantic parsers for TexttoSQL. It also mentions the design of a new dataset, which is a different train/test split of an existing dataset, SQUALL. Additionally, it points out a synthetic benchmark paper based on a single question template. This level of detail allows the authors to accurately identify the parts of the paper being addressed. The comment is specific in detailing what needs to be improved, such as demonstrating novelty and incremental improvements, and providing suggestions for addressing the issue of column operations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature, specifically addressing a problem of column operations in designing semantic parsers for TexttoSQL. The reviewer provides some justification by mentioning that the proposed dataset is a different train/test split of an existing dataset, SQUALL, and that the synthetic benchmark paper is based on a single question template. However, the comment could be strengthened by providing more detailed reasoning or examples to support the claim of lack of novelty. While the critique is 3, the authors would benefit from additional context or evidence to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the proposed dataset is a different train/test split of an existing dataset, SQUALL. Additionally, the comment mentions a synthetic benchmark paper based on a single question template, which further highlights the lack of novelty. This feedback is valuable as it directs the authors to address the issue of novelty and incremental nature in their work. However, the comment could be more helpful if it provided specific suggestions on how to enhance the novelty or incremental nature of the work. Overall, the comment is 3 as it identifies a critical weakness but lacks detailed guidance on how to improve it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests adding a few more sentences to explain the experimental setting for continual learning, and it explicitly asks for an explanation of the correspondence between the learning curves and MPHATE in Figure 3. The reviewer also questions the rationale behind the learning curves and the accuracy numbers, providing specific questions that the authors should address. These actions are clear and detailed, giving the authors a clear path to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including the need for an explanation of the experimental setting for continual learning, the correspondence between the learning curves and MPHATE, and the accuracy numbers. The comment provides detailed questions that guide the authors on what aspects of the paper need clarification or expansion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors add a few more sentences to explain the experimental setting for continual learning. It also requests an explanation of the correspondence between the learning curves and MPHATE in Figure 3, questioning the rationale behind the learning curves and the accuracy numbers. This feedback is clear and constructive, as it guides the authors on how to enhance the clarity and understanding of their experimental setup. By addressing these points, the authors can improve the comprehensibility and rigor of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. While it suggests that labeled data might provide effective information for consistency training, it does not offer any explicit guidance or actionable steps for the authors to take. The comment lacks specific instructions or suggestions on how to incorporate this idea into their work, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in suggesting that labeled data might provide effective information for consistency training and references external works to support this claim. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. The comment suggests that labeled data might provide effective information for consistency training, referencing external works to support this claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to further explore the potential benefits and challenges of using labeled data for consistency training, which is not directly addressed in the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data might provide effective information for consistency training, which could be a valuable addition to the current approach. The comment references two external works to support this claim, which adds credibility to the suggestion. However, the comment could be more helpful if it provided specific examples or detailed reasoning on how labeled data might enhance consistency training. While it offers a valuable insight, the authors would need to further explore and develop this idea to fully address the suggestion. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experimental part needs to be reorganized and improved, and it provides specific suggestions for how to do so. It suggests that the experimental content listed in the main text should highlight the superiority of the method, and it provides a list of experimental suggestions that should be included in the main text. These suggestions are concrete and provide clear guidance on what changes the authors should make to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental part\" and the \"experimental section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely the reorganization and highlighting of the experimental content to showcase the superiority of the method. The suggestions for improvement are detailed and provide a clear direction for the authors to follow. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental part needs to be reorganized and improved, suggesting that the experimental content listed in the main text does not effectively highlight the superiority of the method. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks concrete evidence or references to specific sections of the paper where the issue is apparent, making it difficult for the authors to understand and address the critique. As a result, the claim is 3, as it provides a general direction for improvement but lacks the necessary detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental part of the paper, noting that the experimental content listed in the main text does not effectively highlight the superiority of the method. It provides a clear and actionable suggestion to reorganize the experimental section and offers specific guidance on what should be included, such as experimental suggestions in the main text. This feedback is valuable as it directs the authors to make a significant improvement in their draft, ensuring that the experimental part effectively communicates the strengths of their method. However, the comment could be more helpful if it provided additional context or examples of how the experimental suggestions should be structured or presented. Overall, the comment is 4 as it offers clear and actionable guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors include a plot with sparsity on the xaxis and performance on the yaxis to compare the flexibility of SGC with LoRA. This explicit action provides a clear and concrete step for the authors to take, as it specifies the exact visualization needed to demonstrate the practical benefits of SGC. The comment is 5 because it directly instructs the authors on how to enhance their draft with a specific visualization, ensuring that the authors know exactly what to do to improve their work.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the limited applicability of SGC and the need for a plot to compare its flexibility with LoRA. It specifies the issue by suggesting a visualization with sparsity on the xaxis and performance on the yaxis. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that SGC offers a more flexible, finegrained tradeoff but is limited in practicality due to the need for extra tuning. The reviewer suggests including a plot to demonstrate the flexibility of SGC compared to LoRA. This claim is 3 as it provides a logical reasoning for the need to visualize the tradeoff, but it lacks specific examples or references to support the claim about the limitations of SGC. The suggestion for a plot is a helpful addition, but the comment could be strengthened with more detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s claim about the flexibility and performance of SGC, specifically in the context of computeconstrained scenarios. It suggests including a plot to demonstrate the flexibility of SGC compared to LoRA, which could help clarify the practical benefits of SGC\"s finegrained control. This feedback is clear and actionable, providing a specific suggestion for improving the draft by adding a visualization that could enhance the authors\" understanding of their results. However, the comment could be more helpful if it explained why this visualization is necessary or how it would contribute to the paper\"s overall argument. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, and suggests that the code should be published to demonstrate the computation time advantage. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information or publish the code to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" and \"German and Law school dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the reason for the shorter training time in Gerrymandering compared to Independent, and suggests that the code should be published to demonstrate the computation time advantage. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, suggesting that the shorter training time might be unreasonable. The comment also suggests that the code should be published to demonstrate the computation time advantage. However, the comment lacks specific evidence or references to support the claim about the training time or the need for code publication. The reasoning is based on logical reasoning and common sense, but it does not provide detailed justification or examples to fully substantiate the claim. Therefore, the comment is 3, as it requires further elaboration to fully support the claim.", "helpfulness_rationale": "The review comment raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, suggesting that the shorter training time might be unreasonable. It also suggests that the code should be published to demonstrate the computation time advantage. While the comment identifies a potential issue with the experimental setup, it lacks depth and does not provide specific suggestions or guidance on how to address this concern. The feedback is 3 as it points out a potential weakness but does not offer actionable steps for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a significant issue with the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. It also points out that the abstract statement about beating a human who learned from the same resources is misleading due to the limited human data. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their draft. It lacks specific suggestions or actions for the authors to take, leaving them uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the human baseline, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. Additionally, it points out that the abstract statement about beating a human who learned from the same resources is misleading due to the limited human data. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the human baseline is considerably weaker than the model baseline due to the limited amount of speech recordings followed by the human. The comment supports this claim by pointing out that the human baseline only closely follows a little more than 1 hour of speech recordings, while the model baseline is evaluated on the full 15 hours. Additionally, the comment notes that the abstract statement about beating a human who learned from the same resources is misleading due to the limited human data. This provides a logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim about the human baseline being weaker. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. It also points out that the abstract statement about beating a human who learned from the same resources is misleading due to the limited human data. This feedback is clear and actionable, as it highlights a critical weakness in the human baseline and suggests that the authors should address this issue to improve the validity of their results. By providing specific guidance on how to improve the human baseline, the comment offers valuable insights for the authors to enhance the robustness and credibility of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. However, it does not provide explicit guidance on which methods should be used as a baseline or how to incorporate them into the paper. The action is implicit and somewhat vague, as the authors can infer that they need to consider using these methods as a baseline but are not given specific instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This provides clear guidance on what needs to be addressed in the paper, namely the inclusion of these methods as a baseline. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the related work section, noting that it discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This feedback is 3 as it points out a potential gap in the paper\"s analysis, which could be addressed by including these methods as baselines. However, the comment lacks specific guidance on how to incorporate these methods or which ones to consider, leaving the authors with a general direction but not detailed steps for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential ambiguity in the authors\" use of the term \"efficient proxy\" or \"efficient proxies\" in their work. It suggests that the term \"is\" might imply a particular proxy, but the lack of a specific \"Efficient Proxy\" suggests that it might refer to a family of efficient proxies. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should clarify this ambiguity or what specific actions they should take to address it. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the meaning of \"efficient proxy\" or \"efficient proxies\" in their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"efficient proxy\" or \"efficient proxies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ambiguity in the term and suggests that it might refer to a family of efficient proxies rather than a particular proxy. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the term \"efficient proxy\" or \"efficient proxies\" in the paper, suggesting that the use of \"is\" might imply a particular proxy but that there is no such proxy called \"Efficient Proxy.\" This provides a logical reasoning for the claim, but it lacks specific examples or references to support the argument fully. The authors might need to clarify the intended meaning of the term, but the comment does not provide detailed guidance on how to do so. Therefore, the claim is 3, as it requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the paper regarding the term \"efficient proxy\" or \"efficient proxies.\" It suggests that the use of \"is\" might imply a particular proxy, but the lack of a specific \"Efficient Proxy\" suggests that it might refer to a family of efficient proxies. This feedback is 3 as it points out a potential source of confusion in the paper, which the authors can address to clarify their terminology. However, the comment could be more helpful if it provided suggestions on how to clarify this ambiguity or offered examples of how the authors might rephrase their terminology for greater clarity. Overall, the comment is 3 as it highlights an area for improvement but lacks detailed guidance for the authors to fully address the issue."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the authors stacking methods from Mirzasoleiman et al., 2020 and using a grouplearning setting, followed by a classical method like DBSCAN for clustering. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to improve the approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the authors\" methodology, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the grouplearning setting, followed by the use of a classical method like DBSCAN for clustering. However, it does not specify which part of the paper this methodology is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the methodology, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors stack methods from Mirzasoleiman et al., 2020 and use a grouplearning setting, followed by a classical method like DBSCAN for clustering. However, the comment lacks any supporting evidence, reasoning, or references to justify why this approach is problematic or inappropriate. Without additional context or explanation, the claim remains 1, as it does not provide sufficient justification for the authors to understand or address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment points out a potential issue with the authors\" methodology, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the grouplearning setting, followed by the use of a classical method like DBSCAN for clustering. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or detailed advice, the authors are left without a clear path forward. Therefore, the comment is 2, as it identifies a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. It also mentions that the authors might have missed this in the appendix. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the resilience of the metric to the choice of random projection. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the chosen random projection matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. The comment also mentions that the authors might have missed this in the appendix, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the variability in results with the chosen random projection matrix, suggesting that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but suggests investigating the resilience of the metric to the choice of random projection. The comment is 3 as it provides a logical reasoning for the need to test the resilience of the metric, but it lacks specific examples or references to support the claim about pathological projection matrices. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the results obtained using the chosen random projection matrix, suggesting that pathological projection matrices could skew the MFTMA capacity and width scores. It raises a valid point about the resilience of the metric to the choice of random projection and suggests that the authors might have missed this in the appendix. While the comment highlights an important area for investigation, it lacks specific guidance or suggestions on how to address this issue or what specific tests could be conducted. The feedback is 3 as it points out a potential weakness but does not provide detailed guidance on how to resolve it. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises questions about the synthetic data used in the paper, specifically asking for examples of what \"support data\" and \"predicted training count data\" might look like. It also requests that the authors explicitly state the model used in the paper, suggesting that this information could be added to the appendix. While the comment provides some guidance on what the authors should include, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide examples and model details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the clarification of \"support data\" and \"predicted training count data\" in Figure 1 and the explicit mention of the model used in the paper. This level of detail provides clear guidance on what needs to be clarified or added, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about specific terms and data used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the clarity and specificity of the synthetic data used in the paper. It specifically asks for examples of what \"support data\" and \"predicted training count data\" might look like, as well as requests that the model used be explicitly stated in the appendix. This feedback is clear and actionable, as it provides specific guidance on how to improve the clarity and transparency of the paper. By addressing these questions, the authors can enhance the understandability and reproducibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to make the model more complex or explaining why it is considered overly simple. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as a particular section, figure, or table where the model is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the model are considered overly simple or how this simplicity affects the paper\"s results or conclusions. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the model seems overly simple, which is both a feature and a bug. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the model is considered overly simple or how this simplicity affects the paper\"s results. Without specific details or references, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the model\"s complexity. Without actionable feedback or detailed analysis, the comment lacks depth and does not assist the authors in enhancing their draft. Therefore, it is rated as 2, as it identifies a potential weakness but does not offer a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the scope of the work or how to demonstrate its broader impact. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the narrow focus, but it lacks grounding as it does not identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion and how it affects the paper\"s impact. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation of the work, specifically its narrow focus on a specific task (climate change QA) in a specific language (Arabic), which could limit its broader impact. While it identifies a potential issue, it does not provide any actionable suggestions or guidance on how the authors might address this limitation or expand the scope of their work. The comment lacks depth and specificity, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as 2, as it highlights a potential weakness but does not offer constructive feedback for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not contribute novelly to the understanding of the winnertakeall property, as it uses extremely simplified settings and reports findings that have been previously reported in other works. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the originality or how to present the findings in a more novel or innovative way. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"winnertakeall property\" and \"Sec 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not contribute novelly to the understanding of this behavior due to the use of extremely simplified settings and the repetition of findings from previous works. This provides clear guidance on what needs to be addressed to improve the originality of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not contribute novelly to the understanding of the winnertakeall property due to the use of extremely simplified settings and the repetition of findings from previous works. However, the comment lacks specific references to these previous works or detailed examples of how the findings have been reported. Without specific references or detailed reasoning, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it does not contribute novelly to the understanding of the winnertakeall property due to the use of extremely simplified settings and the repetition of findings from previous works. This is a critical observation that could impact the paper\"s originality and impact. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or differentiate their work from previous studies. While it points out a potential weakness, it does not provide actionable feedback or detailed advice on how to improve the paper. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. While the action is explicit, it is somewhat vague as it does not specify which part of the main paper should include the mention or how to present the runtimes. However, the authors can infer that they need to add a brief mention and provide examples, making the comment 4.", "grounding_specificity_rationale": "The comment suggests mentioning the negligible computational cost of CHR in the main paper and providing a rough example of runtimes in the experiments. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the computational cost is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the inclusion of a brief mention and examples, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests mentioning the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. While the comment provides a logical suggestion for improving the paper, it lacks specific examples or references to support the claim about the computational cost. The mention of \"negligible\" implies that the cost is minimal, but without further context or evidence, the claim is 3. The suggestion to include runtime examples is a helpful addition, but the lack of detailed justification for the computational cost claim makes it 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It recommends mentioning the negligible computational cost of CHR in the main paper, which could help motivate the method. Additionally, it suggests providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. This feedback is specific and offers concrete steps for the authors to enhance the clarity and applicability of their work. By addressing these points, the authors can improve the comprehensiveness and accessibility of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly recommends that the authors elucidate the EEG token quantization process in greater detail, specifically addressing the ambiguity in interpretation. It suggests that the authors should clarify whether the spatial arrangement of the EEG sensors played a role in this process. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the ambiguity in the interpretation of the EEG topography plots and the need to clarify the role of the spatial arrangement of the EEG sensors in the EEG token quantization process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 presents ambiguity in interpretation due to the EEG topography plots for both the input and output during the EEG token quantization process. The reviewer suggests that the authors should elucidate this procedure in greater detail, specifically questioning whether the spatial arrangement of the EEG sensors played a role. While the comment identifies a potential issue with interpretation, it lacks specific examples or references to support the claim that the spatial arrangement of the sensors is relevant. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that the EEG topography plots for both the input and output during the EEG token quantization process lead to ambiguity in interpretation. It suggests that the authors should clarify this procedure in greater detail, specifically questioning whether the spatial arrangement of the EEG sensors played a role in the process. This feedback is clear and actionable, providing the authors with a concrete direction for improving the clarity and understanding of their results. By addressing this issue, the authors can enhance the transparency and reproducibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors leverage the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific changes could be made to improve the directness of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors\" approach to leveraging the complexity of checking on the Witness oracle, specifically mentioning that it is \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this critique is based on, such as a specific section or table where this complexity is discussed. Without explicit references, the authors may struggle to identify the exact part of the paper being addressed. The comment is specific in detailing the issue with the approach, but it lacks grounding as it does not point to a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors leverage the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case. This claim is 3 as it suggests that the authors are not addressing the problem directly, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The reviewer could provide more context or evidence to support the assertion that the approach is not direct, such as by explaining how the complexity affects the overall efficiency or effectiveness of the method. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a potential issue with the authors\" approach, specifically the use of the Witness oracle complexity, which is described as \"polynomial time\" in the tabular case. This observation suggests that the authors may not be addressing the problem directly, as they leverage the complexity rather than addressing it. However, the comment does not provide specific suggestions or guidance on how the authors might improve their approach or address this issue. Without actionable feedback or detailed advice, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, as it identifies a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should compare their work with existing code completion commercial applications, such as Copilot, as a baseline. It provides a specific suggestion for testing on a smaller subset of RepoEval and highlights the importance of comparing with stateoftheart code completion systems. This feedback is clear and concrete, giving the authors a direct action to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the work with existing code completion commercial applications, such as Copilot, as a baseline. It specifies that this comparison should be tested on a smaller subset of RepoEval and is essential for comparing with stateoftheart code completion systems. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors can infer that it relates to the evaluation or comparison sections, the lack of explicit grounding makes it weakly grounded. The suggestion is specific, as it clearly identifies what needs to be addressed, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the work with existing code completion commercial applications, such as Copilot, as a baseline. This claim is 3 as it provides a logical reasoning for the suggestion, which is to test the performance of the proposed system against stateoftheart code completion systems. However, the comment lacks specific examples or references to these existing applications, making it somewhat challenging for the authors to fully understand and implement the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of baselines, specifically comparing the proposed work with existing code completion commercial applications like Copilot. This is a valuable piece of feedback as it highlights a potential gap in the evaluation and suggests a specific method for addressing it. By including this comparison, the authors can enhance the credibility and robustness of their results. However, the comment could be more helpful if it provided additional guidance on how to implement this comparison or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. While the comment implies that the authors should consider expanding their evaluation to include more tasks or datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that understanding the criteria behind the selection and exploring other tasks or datasets might yield different insights. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. However, the comment lacks specific examples or references to support the claim that the current evaluation is limited in scope. While it highlights a potential issue, the lack of detailed justification or evidence makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides a logical basis for the claim but requires more detailed support to be fully substantiated.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. This feedback is 3 as it prompts the authors to consider the broader implications of their evaluation approach and how it might impact the generalizability of their findings. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what additional tasks or datasets might be relevant to include. Overall, the comment offers a valuable direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the performance of the shiftedMNIST dataset and suggests that it would be useful to show the model and baselines on test samples from the observational (in) distribution. While the comment implies that the authors should provide additional data or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments or analyses. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"shiftedMNIST,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the performance difference between shift=0 and shift~N (0, \u03c3 2) and suggests showing performance on test samples from the observational (in) distribution. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the performance difference between shift=0 and shift~N (0, \u03c3 2) in the context of the shiftedMNIST dataset. It suggests that both cases incorporate a domain shift, implying that the performance difference is not as significant as stated. However, the comment does not provide specific reasoning or evidence to support this claim, nor does it offer alternative explanations or comparisons. This lack of detailed justification makes the claim 3, as the authors would need to further explore the issue themselves to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance difference between shift=0 and shift~N (0, \u03c3 2) in the context of the shiftedMNIST dataset. It suggests that both cases incorporate a domain shift, implying that the performance difference might not be as significant as stated. The comment also recommends showing the performance of the model and baselines on test samples from the observational (in) distribution, which could provide valuable insights into the model\"s robustness. While the comment identifies a potential issue and offers a suggestion for improvement, it lacks specific guidance on how to implement these changes or what specific data or analyses should be included. This limits the comment\"s helpfulness, as it provides some direction but not enough detail for the authors to fully address the issue. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should analyze the quality of the local minima, specifically the approximation ratio under certain assumptions. This feedback provides a clear and explicit action for the authors to take, which is to include an analysis of the quality of the local minima. The comment is specific in detailing what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of Algorithm 1 and the local minima, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests analyzing the quality of the local minima, such as the approximation ratio under certain assumptions. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of the local minima, specifically the approximation ratio under certain assumptions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that the authors analyze the quality of the local minima, particularly the approximation ratio under certain assumptions. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their analysis and improve the paper. By addressing this suggestion, the authors can strengthen their work by providing more detailed insights into the performance of their algorithm. However, the comment could be more helpful if it included specific examples or references to similar analyses in the literature, which would guide the authors in implementing this suggestion effectively. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms, and references a specific sentence regarding the performance of the secret model with or without fusion. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the algorithms should be clarified or how the authors might address the issue of information redundancy. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Fill, Propagate, Decode algorithms\" and the specific sentence \"Finally, by comparing the performance of the secret model with or without fusion, we conclude that the robustness of Cans largely comes from the information redundancy implemented in our design of the weight pool.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it asks for clarification on how information redundancy is built into the algorithms and how it affects the performance of the secret model. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on how information redundancy is built into the Fill, Propagate, Decode algorithms. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implementation of information redundancy in the Fill, Propagate, Decode algorithms, specifically asking for clarification on how this redundancy is built into the algorithms. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the algorithms need clarification. The feedback is 3 as it points out a potential weakness, but it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of the added complexity in using multiple INs at different speeds in the dynamics predictor. It implies that the authors should consider ablating this feature to determine its impact on the model\"s performance. However, the comment does not provide explicit instructions or concrete suggestions on how to conduct this ablation or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an ablation study to address the question. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the model, namely the use of multiple INs at different speeds in the dynamics predictor. However, it does not specify which part of the paper this feature is discussed in, making it weakly grounded. The comment is specific in questioning the importance of the added complexity and suggesting an ablation study to determine whether one IN would suffice. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the importance of the added complexity in using multiple INs at different speeds in the dynamics predictor. It suggests that the authors should consider ablating this feature to determine its impact on the model\"s performance. However, the comment lacks any supporting evidence, reasoning, or references to justify why this feature is important or how it affects the model. Without such information, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the importance of the added complexity in using multiple INs at different speeds in the dynamics predictor. It suggests that the authors should consider ablating this feature to determine its impact on the model\"s performance. This feedback is 3 as it prompts the authors to consider a potential area for improvement and provides a direction for further exploration. However, the comment could be more helpful if it offered specific suggestions on how to conduct the ablation study or what aspects to focus on. Overall, the comment provides a valuable insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include experimental results demonstrating the pure contribution of their proposed method by excluding the mixup technique used in LUMP. This is a clear and direct action, as it specifies exactly what needs to be done to improve the draft. The authors know exactly what additional experiments are needed and how to implement them, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of experimental results demonstrating the pure contribution of the proposed method without the mixup technique used in LUMP. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the mixup technique used in LUMP should be excluded from the proposed method to demonstrate its pure contribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the results. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the mixup technique used in LUMP is also adopted for the proposed method in the experiments on SplitCIFAR100 and SplitTinyImageNet. It suggests that the authors should include experimental results demonstrating the pure contribution of their proposed method by excluding the mixup technique. This feedback is clear and actionable, as it provides a concrete direction for the authors to improve their draft by including additional experiments. However, the comment could be more helpful if it explained why the mixup technique is important or how its exclusion might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their experimental setup."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the object detectionbased attention being performed on the image or on some convolutional feature map. It suggests clarifying this point and potentially rescaling based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the object detectionbased attention, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on whether the attention is performed on the image or on some convolutional feature map, and whether rescaling is done based on the receptive field. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the object detectionbased attention and its implementation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the object detectionbased attention, specifically asking whether it is performed on the image or on some convolutional feature map. It also suggests that rescaling might be necessary based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how to clarify or address this issue. The feedback is 3 as it points out a potential area for clarification, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the lack of details regarding how the network fits the residual instead of directly learning the inputoutput mapping. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide more information about the network\"s training process, but it lacks concrete steps or suggestions for improvement. As a result, the authors are left without a clear understanding of what actions to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of detail regarding how the network fits the residual instead of directly learning the inputoutput mapping. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of lacking details regarding the network\"s training process, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the lack of details regarding how the network fits the residual instead of directly learning the inputoutput mapping. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that this is a significant issue or a problem that needs to be addressed. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of details on how the network fits the residual instead of directly learning the inputoutput mapping. This is a relevant point that could impact the understanding and effectiveness of the network. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what additional details might be needed. While it highlights a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the experiment setup in Section 3.3, specifically asking about data augmentation methods and learning rate. While the comment implies that the authors should provide more details about these aspects, it does not explicitly instruct them to do so. The reference to the paper \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" provides some context but does not offer specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the experiment setup. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for details about the experiment setup, such as data augmentation methods and learning rate, and provides a reference to a related paper for context. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the experiment setup in Section 3.3, specifically asking for details on data augmentation methods and learning rate. While it identifies a potential area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. The reference to the paper \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" is helpful in providing context but does not offer actionable advice. Overall, the comment is 3 as it points out a potential area for improvement but lacks depth and specificity in its guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider an error in the initial calibration steps (steps 1 and 2) as a possible explanation for the speed disparities observed between the RSPs and FDs. However, it does not provide explicit instructions or concrete guidance on how to investigate or address this potential error. The authors are left to infer that they should look into the initial calibration steps, but without specific suggestions on how to do so or what specific aspects to focus on, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section III of \u201cRecognition and Velocity Computation of Large Moving Objects in Images\u201d\u2014RVC paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that an error in the initial calibration steps might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that an error in the initial calibration steps might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific details or examples to substantiate the claim, making it difficult for the authors to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the initial calibration steps, suggesting that an error might explain the speed disparities observed between the RSPs and FDs. While it highlights an area for further investigation, it lacks specific guidance or suggestions on how the authors might address this issue or what specific aspects of the initial calibration steps should be examined. The comment is 3 as it points out a potential area for improvement, but it could be more beneficial with additional details or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that the artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, it does not provide any actionable guidance or suggestions for the authors to address this issue or improve their draft. The comment lacks specificity and does not offer any concrete steps for the authors to take, making it 1.", "grounding_specificity_rationale": "The comment addresses the issue of artificial networks trained using ASAP (and similar methods) not necessarily resembling biological networks, except for the weight transport problem. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the resemblance of artificial networks to biological networks, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment acknowledges that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, it does not provide any actionable feedback or suggestions for improvement. The comment does not guide the authors on how to address this issue or improve the draft, leaving them without a clear path forward. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors conducted statistical significance tests for the numbers presented in the paper. While it implies that the authors should consider conducting such tests, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct statistical significance tests. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the statistical significance of the numbers presented in the paper, specifically regarding the comparison between the proposed method and baselines. However, it does not specify which part of the paper this comparison is presented in, making it weakly grounded. The comment is specific in its request for statistical significance tests, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the statistical significance of the numbers presented in the paper, specifically regarding the comparison between the proposed method and baselines. However, it does not provide any evidence, reasoning, or examples to support the claim that statistical significance tests should be conducted. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the statistical significance of the numbers presented in the paper, specifically regarding the comparison between the proposed method and baselines. It prompts the authors to consider whether they conducted statistical significance tests, which is an important aspect of evaluating the robustness and reliability of their results. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to conduct these tests or what specific tests to consider. This limits the comment\"s helpfulness, as it points out an important issue but does not provide actionable steps for the authors to address it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the paper\"s focus on learning HMMs with nonparametric emission distributions but questions how these distributions affect inference. It specifically asks about the inference tasks that can be computed with an NPSPECHMM, such as filtering, smoothing, and marginal observation likelihood. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the inference tasks should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the impact of emission distributions on inference tasks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"nonparametric emission distributions\" and the \"common inference tasks in a discrete HMM,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions how these emission distributions affect inference and asks about the inference tasks that can be computed with an NPSPECHMM. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It asks which inference tasks, such as filtering, smoothing, and marginal observation likelihood, can be computed exactly or approximately with an NPSPECHMM. This is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It specifically questions which inference tasks, such as filtering, smoothing, and marginal observation likelihood, can be computed exactly or approximately with an NPSPECHMM. This feedback is valuable as it prompts the authors to clarify and expand on the implications of their work regarding inference tasks. However, the comment could be more helpful if it provided suggestions on how to address this gap or examples of how the authors might present this information. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the analysis of experimental results, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should conduct a more detailed analysis of the experimental results, including identifying the factors contributing to the poor performance. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While the action is implied, it is not as concrete as it could be, leaving some ambiguity about the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of experimental results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the analysis, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a gap in the analysis but lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the need for a more detailed analysis themselves, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it highlights a gap in the paper that needs to be addressed to provide a more comprehensive understanding of the results. By pointing out the lack of analysis, the comment empowers the authors to enhance their draft by including a more detailed explanation of the factors contributing to the poor performance. However, the comment could be more helpful if it suggested specific areas to explore or provided examples of how to conduct a deeper analysis. Overall, the comment is 4 as it directs the authors to a critical area needing improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. While the comment implies that the authors should expand their analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analyses. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific section where the authors discuss the datasets considered, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions why only 10 out of 120 datasets are considered and suggests comparing batch and greedy algorithms in the remaining 110 datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid point about the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. This feedback is 3 as it identifies a potential area for improvement in the paper\"s analysis. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on. While it points out a potential gap in the analysis, it does not provide detailed instructions or examples on how to address it. Therefore, the comment is 3, as it offers a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation in the introduction, specifically the lowrank factorization, is unnecessary given that the main result is about polytopes. It also implies that if the result has implications for lowrank matrix factorization, it should be explicitly discussed. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the implications of the lowrank factorization in the context of the main result. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"lowrank factorization\" in the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unnecessary nature of the lowrank factorization and the potential implications for lowrank matrix factorization. This provides clear guidance on what the authors should consider and discuss in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation in the introduction, specifically the lowrank factorization, is unnecessary given that the main result is about polytopes. The reviewer suggests that if the result has implications for lowrank matrix factorization, it should be explicitly discussed. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the need for discussing lowrank matrix factorization based on the comment alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation in the introduction, specifically the lowrank factorization, which may not be necessary given the main result about polytopes. It suggests that if the result has implications for lowrank matrix factorization, it should be explicitly discussed. This feedback is 3 as it points out a potential area for improvement in the paper\"s motivation and alignment with the main results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what aspects of the lowrank factorization should be discussed in the context of the main result. Overall, the comment offers some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the labels for each dataset in 4.1, specifically asking where they are coming from and whether they are generated or not. While the comment implies that the authors should clarify these labels, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about the labels. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on the labels for each dataset, including \"caspealr1\" and \"mugshot.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the labels for each dataset in 4.1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the labels for each dataset in 4.1, specifically asking where they are coming from and whether they are generated or not. This is a relevant inquiry that could help the authors clarify their methodology and provide more transparency about the datasets used. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address this issue. While it points out a potential area for improvement, it does not provide actionable advice or detailed feedback. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper is incremental with respect to a specific reference [31] and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might improve their work or what specific aspects of the paper are lacking. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental with respect to a specific reference [31] and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, it does not specify which part of the paper this assessment is based on, such as the methodology or results sections. This makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how the authors could improve their work. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental with respect to a specific reference [31] and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, the comment does not provide any specific details or references to support this claim, such as how the paper is incremental or how the adaptation affects the results. Without additional context or evidence, the claim is difficult for the authors to verify or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is incremental with respect to a specific reference [31] and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might improve their work or address the issue of incrementality. Without actionable feedback or detailed analysis, the comment does not assist the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the sensitivity of performance and sample efficiency to the \u03bb parameters, and questions how \u03bb is calculated. It also mentions that the authors explain why ELLA does not increase sample efficiency in a COMBO environment but does not fully understand the implications. The reviewer provides references to related works, which could be helpful for the authors to understand the context better. However, the comment does not explicitly instruct the authors on how to address these issues or provide specific guidance on how to improve the explanation or calculations. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the process of calculating \u03bb and improve the explanation of the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines on pages 8 and 9, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning how \u03bb is calculated and the explanation of ELLA\"s sample efficiency in a COMBO environment. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the sensitivity of performance and sample efficiency to \u03bb parameters, questioning how \u03bb is calculated and the explanation of ELLA\"s sample efficiency in a COMBO environment. The reviewer provides references to related works, which could be helpful for the authors to understand the context better. However, the comment lacks specific examples or detailed reasoning to support the claim that performance and sample efficiency are sensitive to \u03bb parameters. The references are provided as a means of context, but they do not fully substantiate the claim. Therefore, the comment is 3, as it provides some evidence but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the sensitivity of performance and sample efficiency to \u03bb parameters, which is a critical aspect of the paper. It questions how \u03bb is calculated and the explanation of ELLA\"s sample efficiency in a COMBO environment, which are important areas for clarification. The reviewer also provides references to related works, which could be helpful for the authors to understand the context better. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve the explanation. While it points out areas for improvement, it does not offer actionable steps or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the specific method used to solve the minmin problem, which is mentioned in passing. However, it does not provide any guidance or suggestions on how the authors should address this issue. The comment lacks explicit instructions or concrete details on what the authors should do to clarify or expand on this aspect of their work. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of an alternating direction method to solve the minmin problem, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what needs to be addressed or improved regarding this method, making it underspecific. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point consists of a question asking for clarification about the specific method used to solve the minmin problem. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the specific method used to solve the minmin problem, which is mentioned in passing. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or improve the explanation. The comment lacks depth and actionable feedback, leaving the authors with only a vague idea of what needs to be clarified. Therefore, the comment is 2, as it points out a potential weakness but does not offer concrete steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the scope of the experiments. However, the comment does not provide specific guidance on how to expand the experiments or what additional aspects to consider. The authors are left to infer that they need to make their experiments more comprehensive, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the scope of the experiments. However, the comment does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The suggestion to make the experiments more comprehensive is specific, but without clear grounding, the authors may struggle to identify the exact sections that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It highlights the limitation of the model size and the restrictive baselines, which constrain the scope of the experiments. However, the comment does not provide specific examples or references to support why these limitations are problematic or how they impact the results. Without detailed reasoning or evidence, the claim is 3, as it provides a general observation but lacks the necessary justification to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the scope of the experiments. While the comment identifies a potential weakness in the experiments, it lacks specific guidance on how to expand the experiments or what additional aspects to consider. The authors are left with a general idea of what needs to be addressed but without actionable steps or detailed suggestions, making the feedback 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors elaborate on the Hoeffding\"s bound and its implications for stochastic algorithms. It provides a clear and specific action for the authors to take, which is to elaborate on the topic. The comment is explicit and provides concrete guidance on what needs to be added to the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 124125,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the Hoeffding\"s bound and its implications for stochastic algorithms. This provides clear guidance on what the authors need to address in this section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Hoeffding\"s bound holds true for any w as long as samples are drawn independently, and that stochastic algorithms impose conditioning on the previous iterate to guarantee the inequality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where the authors could provide more detail or elaboration. It points out that the Hoeffding\"s bound and its implications for stochastic algorithms are not fully explained, suggesting that elaboration on this topic would be beneficial. This feedback is clear and actionable, as it directs the authors to expand on a particular aspect of their work that could enhance its clarity and depth. However, the comment could be more helpful if it provided specific suggestions on how to elaborate on the topic or what aspects to focus on. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. While the comment implies that the authors should consider adding this information, it does not provide explicit instructions on how to implement this suggestion or what specific details should be included. The action is clear but lacks concrete guidance on execution, making the comment 3.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this addition would be relevant. The authors can infer that it relates to the table or data presentation, but this inference is not direct. The comment is specific in suggesting the addition of a particular approach, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how it would enhance their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. This is a specific and actionable suggestion that could enhance the paper by providing additional context and comparison to existing methods. However, the comment lacks depth and does not explain why this addition would be beneficial or how it would impact the paper\"s overall contribution. While it identifies a potential area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to be careful with the terms \"causal mechanisms\" and \"temporal relationship,\" as they are not interchangeable. This feedback is clear and provides a specific action for the authors to take, ensuring that they use the terms correctly. The comment is concrete, as it specifies the exact issue and offers a direct way to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of terms like \"causal mechanisms\" and \"temporal relationship,\" providing guidance on how to avoid confusion and ensure clarity in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the use of terms \"causal mechanisms\" and \"temporal relationship,\" suggesting that they are not interchangeable. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it points out a specific issue with the use of terms like \"causal mechanisms\" and \"temporal relationship\" in the paper. It provides a clear and actionable suggestion to avoid confusion by using these terms carefully. However, the comment could be more helpful if it offered additional guidance on how to effectively use these terms or provided examples of how they might be misused. Overall, the feedback is valuable but could be more comprehensive to fully support the authors in improving their draft. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment questions the claim that \"better than random\" is a strong demonstration of capability, suggesting that it may not be sufficient. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what alternative demonstrations could be used. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific statement from the paper, \"Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance,\" allowing the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity as it does not detail what aspect of the demonstration is questionable or how it could be improved. It suggests that \"better than random\" may not be a strong demonstration of capability, but without further explanation or examples, the authors are left without clear guidance on how to address this concern. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point questions the claim that \"better than random\" is a strong demonstration of capability. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations to justify why \"better than random\" might not be a strong demonstration. As a result, the claim is 1, as it does not provide sufficient evidence or justification to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the claim that \"better than random\" is a strong demonstration of capability, suggesting that it may not be sufficient. However, it does not provide any specific reasoning or examples to support this claim or offer alternative demonstrations that could be used. The comment lacks depth and actionable guidance, leaving the authors without clear direction on how to address the concern or improve their demonstration. As a result, the feedback is not helpful, as it does not provide the authors with meaningful insights or suggestions for improvement. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the results section, specifically that the results only apply to shallow fullyconnected ReLU networks. However, it does not provide any guidance on how the authors should address this limitation or suggest ways to expand the results to include other network architectures. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the results only apply to shallow fullyconnected ReLU networks, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in section 4 apply only to shallow fullyconnected ReLU networks. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the results section, noting that the results only apply to shallow fullyconnected ReLU networks. This is a relevant observation that could impact the generalizability and applicability of the results. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this limitation or expand their results to include other network architectures. While it points out an area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to provide results or observations regarding the use of sequential MCB versus a single MCT layer for the decision head. This is a clear and direct request, as it specifies exactly what the authors need to include in their discussion. The action is concrete, as it specifies the exact information that should be added to the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB versus a single MCT layer for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation or results regarding the observed differences between the two approaches. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the discussion of using sequential MCB versus a single MCT layer for the decision head, noting that no results were shown. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is important or how it could be improved. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of interest in the paper, namely the discussion of using sequential MCB versus a single MCT layer for the decision head. It points out that while the discussion is interesting, no results or observations are presented, prompting the authors to provide more details. This feedback is 3 as it highlights a gap in the paper that could be addressed with additional information or analysis. However, it lacks specific suggestions on what kind of results or observations would be beneficial, leaving the authors with a general direction but not detailed guidance on how to proceed. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights specific language issues in the paper, such as \"we typically considers\" and \"two permutation,\" and requests that the authors proofread the paper to fix all language problems. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should proofread the paper to fix language issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"the above of (7)\" and \"the above of Theorem 1,\" allowing the authors to accurately identify the parts being addressed. It also specifies the language issues, such as \"we typically considers\" and \"two permutation,\" providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of comments on language usage, such as \"we typically considers\" and \"two permutation,\" without any subjective claims or opinions. It does not present any arguments, evidence, or references to support the need for language corrections. Therefore, it is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies specific language issues in the paper, such as \"we typically considers\" and \"two permutation,\" and requests that the authors proofread the paper to fix all language problems. While this feedback is clear and actionable, it does not provide detailed guidance on how to address these language issues or suggest specific improvements. The comment could be more helpful if it offered examples of better phrasing or provided examples of similar language used in the field. Overall, the comment is 3 as it directs the authors to a specific area for improvement but lacks depth and detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the choice of 20 distribution sets and suggests that the authors might need to control the number of distribution sets for each class. It also asks about the implications of selecting only a few distribution sets. While the comment implies that the authors should consider these aspects, it does not provide explicit instructions or concrete steps on how to address these questions. The authors are left to infer that they need to consider these aspects, but the comment lacks specific guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the choice of 20 distribution sets, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the number of distribution sets for each class can be controlled and what the implications would be if only a few distribution sets are selected. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the choice of 20 distribution sets and suggests that the authors might need to control the number of distribution sets for each class. It also asks about the implications of selecting only a few distribution sets. However, the comment lacks specific reasoning or evidence to support why this choice is problematic or how it could be improved. Without additional context or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of 20 distribution sets and questions whether the authors can control the number of distribution sets for each class. It also inquires about the implications of selecting only a few distribution sets. This feedback is 3 as it prompts the authors to consider the potential limitations and consequences of their choice. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending alternative approaches or providing examples of how other studies have handled similar concerns. While it points out a relevant area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more current and relevant in NLP trends. This is a clear and concrete action for the authors to take, as it provides a specific direction for improvement. The comment also highlights the issue with using obsolete language models, which adds context and guidance for the authors. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"perplexity experiments\" and the specific language models used, such as ngram HMM and RNN, which are considered obsolete. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more current and relevant in NLP trends. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the perplexity experiments are conducted on obsolete language models, specifically ngram HMM and RNN, which are not commonly used nowadays. The reviewer suggests that the authors should showcase their approach using transformerbased (masked) language models to align the paper with current NLP trends. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to current NLP trends or the relevance of transformerbased models. The authors would need to make an effort to understand and address the suggestion, which justifies a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the perplexity experiments, noting that they are conducted on obsolete language models (ngram HMM and RNN) that are no longer commonly used in NLP. The reviewer suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more current and relevant in NLP trends. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that could enhance the relevance and impact of the paper. By addressing this issue, the authors can better align their work with current research trends and demonstrate the applicability of their approach. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the experiments are insufficient and suggests that more empirical experiments or toy experiments are needed to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions the need to cite the result in Kaplan et al. 2020. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments or referencing specific works to support their claims. The explicit nature of the suggestions and the detailed guidance on what needs to be done make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simplified selfattention model\" and \"theoretical analysis,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The comment also mentions the need to cite the result in Kaplan et al. 2020, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are insufficient and suggests the need for more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The reviewer references the result in Kaplan et al. 2020 as a potential source of validation. However, the comment lacks specific examples or detailed reasoning to support why the current experiments are insufficient or how additional experiments would address the issue. The reference to Kaplan et al. 2020 provides some context but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental setup, noting that the experiments are insufficient to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It suggests that more empirical experiments or toy experiments are needed to address this gap. Additionally, it references the result in Kaplan et al. 2020 as a potential source of validation. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance their experimental setup and substantiate their claims. By addressing these points, the authors can significantly improve the robustness and credibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the discussion on the misestimation of mu, noting that it is the proportion of missing observations, making it unclear how it can be estimated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might clarify this issue or what specific steps they could take to address it. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the discussion on the misestimation of mu, which is a specific part of the paper. However, it does not explicitly mention which section or part of the paper this discussion is located in, making it weakly grounded. The comment is specific in pointing out the issue with the estimation of mu, as it is the proportion of missing observations, and how this affects the clarity of the discussion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the discussion on the misestimation of mu, noting that it is the proportion of missing observations. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the discussion is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the discussion on the misestimation of mu, noting that it is the proportion of missing observations, which makes it unclear how it can be estimated at all. This feedback highlights a gap in the clarity of the discussion, which could be confusing for readers. However, the comment does not provide specific suggestions or guidance on how the authors might clarify this issue or improve the discussion. While it points out a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*. It provides a specific suggestion to randomly sample a matrix M^0 within a certain distance range (0.01:0.01:0.1) from M^* as initialization and report the performance accordingly. This feedback is explicit and provides concrete guidance on how to implement the suggested approach. The authors know exactly what steps to take to address the issue of sensitivity to initialization. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sensitivity to initialization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*, with a detailed explanation of how to implement this approach. This includes randomly sampling a matrix M^0 within a specific distance range and reporting performance accordingly. The comment is specific in detailing what needs to be addressed and how to implement the suggested approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*. It provides a specific suggestion to randomly sample a matrix M^0 within a certain distance range (0.01:0.01:0.1) from M^* as initialization and report the performance accordingly. This claim is 3 as it logically suggests that the mean error and variance might increase as the quality of initialization decreases. However, the comment lacks detailed justification or references to support this claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for addressing the issue of sensitivity to initialization. It suggests presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*, which is a clear and concrete approach. The comment also provides a detailed explanation of how to implement this approach, including randomly sampling a matrix M^0 within a specific distance range and reporting performance accordingly. This feedback is 5 as it offers a clear and constructive way for the authors to improve their draft by addressing a critical aspect of their work. By following this suggestion, the authors can enhance the robustness and generalizability of their results. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This provides a clear and direct action for the authors to take, which is to remove the absolute value operation. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unnecessary use of the absolute value operation in the definition of the Frobenius norm. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This is a factual observation about the mathematical definition of the Frobenius norm, which does not require an opinion or subjective judgment. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of the Frobenius norm in line 77, noting that the absolute value operation is unnecessary because tensor entries are real numbers. This is a clear and actionable point that can help the authors improve the clarity and accuracy of their draft. By pointing out this oversight, the comment provides the authors with a concrete step to take in revising their manuscript. However, the comment could be more helpful if it offered suggestions on how to better explain or justify the use of the absolute value operation in the context of the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider providing highprobability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the feedback. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should provide highprobability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting the use of ensemble methods and robustness measures, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should provide highprobability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to ensemble methods or robustness measures that have been successfully used in similar contexts. This makes the claim 3, as the authors would need to infer the specifics of how to implement these suggestions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It recommends adding highprobability bounds by using ensemble methods, as performed in the experiments, and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is specific and offers a concrete direction for enhancing the paper\"s rigor and comprehensiveness. By addressing these points, the authors can significantly improve the quality and credibility of their work. However, the comment could be more helpful if it provided examples or references to ensemble methods or robustness measures that have been successfully used in similar contexts. Overall, the comment is 4 as it offers clear and actionable guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the paper\"s motivation for diversity, noting that the model does not enforce diversity explicitly. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might incorporate diversity into their model or what specific changes could be made to improve the paper. As a result, the comment lacks actionability, leaving the authors without a clear path forward to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the paper\"s motivation for diversity, specifically mentioning that the model does not enforce diversity explicitly. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the model\"s lack of diversity enforcement, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper motivates \"diversity\" extensively but does not enforce it explicitly in the model. The reviewer expresses disappointment at the lack of diversity in the model. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the paper\"s motivation for diversity, noting that the model does not enforce diversity explicitly. This is a critical point as it undermines the paper\"s central argument. However, the comment lacks specificity and actionable suggestions on how the authors might address this issue or improve their model to enforce diversity. Without detailed guidance or examples, the authors may find it challenging to understand and implement the necessary changes. Therefore, the comment is 3, as it points out a critical weakness but does not provide sufficient direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any guidance on how the authors should address this issue or what specific experiments should be included. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of certain experiments, specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in identifying the missing experiments, but without clear grounding, the authors may struggle to determine where to address these issues. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how their absence affects the paper\"s conclusions. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue by pointing out the absence of certain experiments, such as contrastive learning and adversarial learning. This feedback is 3 as it highlights a potential gap in the experimental setup, which the authors should address to provide a more comprehensive evaluation of their work. However, the comment lacks depth and does not offer suggestions on how to incorporate these experiments or what specific aspects of the paper would benefit from their inclusion. While it points out a potential area for improvement, it does not fully guide the authors on how to address it. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons. This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The suggestion to use DinoV2 Frechet Distances is specific and provides a concrete detail for the authors to implement, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simplistic Inception network\" and \"FIDs,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of DinoV2 Frechet Distances for comparisons in addition to the widely used FID metric. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are \"clear flaws associated with FIDs and the simplistic Inception network,\" but it does not provide specific examples or references to support this claim. The suggestion to use DinoV2 Frechet Distances is made without further explanation or justification, leaving the authors without a clear understanding of why this alternative metric is preferred or how it addresses the flaws mentioned. This lack of supporting evidence or detailed reasoning makes the claim 1, as it does not provide sufficient justification for the authors to understand and address the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of FIDs and the simplistic Inception network, noting that there are clear flaws associated with these methods. It provides a clear and actionable suggestion by recommending the use of DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This feedback is valuable as it directs the authors to consider an alternative method that could potentially improve the robustness and accuracy of their evaluations. However, the comment could be more helpful if it explained why DinoV2 Frechet Distances are preferred over FIDs or provided examples of their use in similar contexts. Overall, the comment is 4 as it offers a concrete suggestion for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests conducting an experiment where the image is occluded, which simulates irregularity in neural/behavioral data. It also mentions that this would allow for inspection of the longrange inference capacity of the model. The reviewer explicitly states that these experiments should be included in the final version unless the authors can provide a convincing reason not to. The action is explicit and concrete, as it clearly specifies what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting an experiment where the image is occluded, which simulates irregularity in neural/behavioral data. It also mentions the need to inspect the longrange inference capacity of the model. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting the need for the experiment. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests conducting an experiment where the image is occluded to simulate irregularity in neural/behavioral data and to inspect the longrange inference capacity of the model. The reviewer provides a logical reasoning for why this experiment would be beneficial, noting that it would help address issues like keypoint detection failure in some mice or frames. However, the comment lacks specific examples or references to similar experiments in the literature, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable argument but could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by conducting an experiment where the image is occluded to simulate irregularity in neural/behavioral data. This suggestion is relevant as it addresses a potential weakness in the paper, namely the lack of experiments that simulate realworld scenarios where data may be irregular or incomplete. By including this experiment, the authors can demonstrate the robustness and generalizability of their model under such conditions. The comment is also 3 as it highlights the importance of this experiment in understanding the longrange inference capacity of the model. However, it could be more helpful if it provided specific guidance on how to conduct the experiment or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the statement in the abstract is unclear and suggests that it should be revised to be more highlevel. It also implies that technical details are not necessary for the abstract. While the comment provides a clear action\u2014to clarify the statement and simplify the abstract\u2014it does not offer specific guidance on how to achieve this clarity or what aspects of the statement are unclear. The authors are left to infer the necessary changes, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement in the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the statement regarding the lowrank feature subspace, a small number of attacked samples, and other mild assumptions. The comment provides a clear direction for improvement by suggesting that the abstract should be more highlevel and that technical details are not necessary. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in the abstract is unclear and suggests that it should be revised to be more highlevel. The reviewer provides a specific example of the statement in question, which is \"ensure that with a lowrank feature subspace, a small number of attacked samples, and other mild assumptions.\" However, the comment lacks further explanation or justification for why this statement is unclear or how it could be clarified. Without additional context or examples, the claim is 3, as it provides a specific issue but does not fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, pointing out that the statement regarding the lowrank feature subspace, a small number of attacked samples, and other mild assumptions is unclear. It suggests that the abstract should be more highlevel and that technical details are not necessary. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and accessibility of the abstract. However, it could be more helpful if it offered additional guidance on how to achieve this clarity or what specific aspects of the statement are confusing. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be beneficial to include results in other modalities, specifically mentioning languagerelated tasks. It also mentions that people might care more about OOD performance for languagerelated tasks, implying that expected test loss might not be as relevant. However, the comment does not provide explicit guidance on which modalities to include or how to present these results. While it suggests a direction for improvement, the lack of concrete details makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including results in other modalities, specifically mentioning languagerelated tasks. It also mentions that people might care more about OOD performance for languagerelated tasks, implying that expected test loss might not be as meaningful. However, the comment does not specify which part of the paper should include these results or how they should be presented. While the authors can infer that it relates to the results or discussion sections, the lack of explicit grounding makes it weakly grounded. The suggestion is specific, as it provides a clear direction for improvement, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to include results in other modalities, specifically mentioning languagerelated tasks. The comment also mentions that people might care more about OOD performance for languagerelated tasks, implying that expected test loss might not be as meaningful. However, the comment lacks specific examples or references to support the claim that OOD performance is more important for languagerelated tasks. This makes the claim 3, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to include results in other modalities, specifically mentioning languagerelated tasks. It also points out that people might care more about OOD performance for languagerelated tasks, implying that expected test loss might not be as meaningful. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of results in other modalities. However, the comment lacks specific guidance on how to implement this suggestion or what specific modalities should be considered. While it provides a direction for improvement, it could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation of the work should be further justified by explaining how the proposed method leverages the concept of \"fewshot\" in graph link prediction. It highlights the importance of considering how to effectively use \"fewshot\" and how to ensure the trained model can generalize well to new tasks with 0/few training steps. While the comment implies that the authors should provide more detailed justification for their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more justification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"fewshot situation for graph link prediction,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method does not consider how to effectively use \"fewshot\" and how to ensure the trained model can generalize well to new tasks with 0/few training steps. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified by explaining how the proposed method leverages the concept of \"fewshot\" in graph link prediction. The reviewer suggests that the paper defines and creates a fewshot situation but does not consider how to effectively use \"fewshot\" or how to ensure the trained model can generalize well to new tasks with 0/few training steps. While the comment identifies a potential gap in the paper, it lacks specific examples or references to support the claim that the method does not effectively use \"fewshot.\" This makes the claim 3, as the authors would need to further develop the reasoning to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a critical issue with the motivation of the work, specifically in the context of fewshot learning. It points out that the paper defines and creates a fewshot situation for graph link prediction but does not consider how to effectively use \"fewshot\" or how to ensure the trained model can generalize well to new tasks with 0/few training steps. This feedback is valuable as it highlights a gap in the paper that the authors need to address to strengthen their argument. However, the comment could be more helpful if it provided specific suggestions on how to effectively use \"fewshot\" or how to ensure generalizability. Overall, the comment is 4 as it directs the authors to a critical area needing improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some of the ablations mentioned in previous sections are difficult to locate in the following contents, suggesting that the writing could be improved in this part. However, it does not provide specific guidance on how to improve the writing or which ablations are particularly challenging to locate. The action is implicit and vague, as the authors are left to infer that they need to improve the clarity of the writing, but without concrete steps on how to achieve this. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"previous sections\" and \"the following contents,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the ablations being difficult to locate in the writing, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some ablations mentioned in previous sections are difficult to locate in the following contents, suggesting that the writing could be improved in this part. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues or how to address them. Without specific examples or references, the claim lacks verifiability, making it challenging for the authors to understand and act upon the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the writing, noting that some ablations mentioned in previous sections are difficult to locate in the following contents. This feedback is valuable as it highlights an area where the authors can improve the readability and accessibility of their work. However, the comment could be more helpful if it provided specific examples of where the ablations are difficult to locate or suggested ways to improve the clarity of the writing. Despite this, the comment still offers actionable guidance, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the differential privacy application is currently \"halfbaked\" and encourages the authors to think through it more clearly. It also highlights the novelty of the online algorithm and robustness, which should be integrated into the main paper. However, the comment does not provide specific guidance on how to improve the differential privacy application or what aspects need more clarity. The feedback lacks concrete steps or detailed suggestions, leaving the authors uncertain about how to address the issues. As a result, the comment is 3, as it identifies areas for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. It also mentions the online algorithm and robustness as being interesting and novel, and suggests that the experimental results in the appendix would be better in the main paper. However, the comment does not specify which part of the paper discusses the differential privacy application, making it weakly grounded. The comment is specific in its critique of the differential privacy application and the suggestion to integrate the online algorithm and robustness into the main paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. However, the comment does not provide specific reasoning or examples to support this claim. It mentions the online algorithm and robustness as being interesting and novel, but this does not address the issue of the differential privacy application being \"halfbaked.\" The lack of detailed justification or examples makes the claim 3, as the authors may find it challenging to understand and address the issue without further explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a general critique of the differential privacy application, suggesting that it is currently \"halfbaked\" and encourages the authors to think through it more clearly. It also highlights the novelty and interest of the online algorithm and robustness, which should be integrated into the main paper. However, the comment lacks specific suggestions or guidance on how to improve the differential privacy application or integrate the online algorithm and robustness into the main paper. While it identifies areas for improvement, the feedback is 3 as it points out potential weaknesses but does not provide actionable steps for the authors to address them. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the contribution of multilingual chainofthought is incremental compared to the villa chainofthough. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their work. There is no explicit or implicit action for the authors to take, such as suggesting ways to enhance the contribution or providing examples of how to differentiate the two approaches. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment compares the contribution of multilingual chainofthought to the villa chainofthough, but it does not specify which part of the paper this comparison is made in. The authors cannot confidently determine which section or aspect of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the contribution are considered incremental or how the authors might address this issue. Without explicit references or detailed guidance, the authors cannot effectively understand or address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthough. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment compares the contribution of multilingual chainofthought to the villa chainofthough, suggesting that the former is incremental. However, it does not provide any further explanation or guidance on how the authors might address this issue or improve their work. Without specific suggestions or examples, the comment lacks actionable feedback that could help the authors enhance their draft. Therefore, it is rated as 2, as it identifies a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, it does not provide explicit guidance on how to implement this change or what specific aspects of the methodology need to be adjusted. The action is implied and somewhat vague, as the authors need to infer that they should consider using robotic manipulation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to use robotic manipulation, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the current methodology is insufficient or why robotic manipulation would be more appropriate. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting that the proposed methodology may not be specific to bimanual manipulation. It recommends using robotic manipulation instead, which could be more appropriate. This feedback is 3 as it points out a potential limitation in the methodology and provides a suggestion for improvement. However, the comment lacks depth and does not explain why robotic manipulation is more appropriate or how it would address the issue. Additionally, it does not provide specific guidance on how to implement this change or what aspects of the methodology need to be adjusted. While the feedback is 3, it could be more actionable with additional details and examples. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a discrepancy in the advantage of UNIFORM over other procedures, particularly in the 1shot setting, and questions whether the authors have a theory to explain this. It also acknowledges the clarity and welldesigned experiments, but does not provide specific guidance on how to address the issue with the UNIFORM advantage. The comment implies that the authors should provide a theoretical explanation or further analysis to support their claims, but it does not offer concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"UNIFORM\" method and the \"tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the inconsistency in the advantage of UNIFORM over other procedures, particularly in the 1shot setting. The comment further asks for clarity on the authors\" theory regarding the method\"s effectiveness in this setting. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the advantage of UNIFORM over other procedures is not consistent, particularly in the 1shot setting. The reviewer supports this claim by referencing the tables, which show that UNIFORM does not always offer a clear advantage over the results. However, the comment lacks specific examples or detailed analysis to fully substantiate the claim. While it provides some evidence, it could be strengthened by offering more detailed reasoning or references to support the assertion. Therefore, the comment is 3, as it provides some evidence but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the advantage of the UNIFORM method over other procedures, particularly in the 1shot setting. It highlights a discrepancy in the results and questions whether the authors have a theory to explain this. While the comment acknowledges the clarity and welldesigned experiments, it does not provide specific suggestions or guidance on how the authors might address this issue or explore the underlying reasons for the discrepancy. The feedback is 3 as it points out a potential weakness but lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider the reason why information value is a stronger predictor for dialogue, and if there is any existing linguistic theory that could explain it. It also recommends adding this information to make the paper stronger. While the comment implies that the authors should explore this topic, it does not provide specific guidance on how to integrate this information into the paper or what specific linguistic theories to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 7\" and \"page 8,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the reason why information value is a stronger predictor for dialogue and whether there is any existing linguistic theory that could explain it. This provides clear guidance on what the authors need to consider and explore in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors consider the reason why information value is a stronger predictor for dialogue and whether there is any existing linguistic theory that could explain it. The comment implies that adding this information would strengthen the paper. However, it does not provide specific examples or references to existing linguistic theories or studies that could support this claim. Without such evidence or detailed reasoning, the claim is 3, as it requires the authors to make a significant effort to explore and substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a potential area for improvement by suggesting that the authors consider the reason why information value is a stronger predictor for dialogue and whether there is any existing linguistic theory that could explain it. This feedback is clear and actionable, as it prompts the authors to explore a specific aspect of their work that could enhance its theoretical foundation and depth. However, the comment could be more helpful if it provided specific suggestions on how to integrate this information or what linguistic theories to consider. Overall, the feedback is valuable but could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a perceived lack of discussion on the potential benefits of using AutoML approaches beyond improving raw performance, specifically mentioning the extraction of hints for future network architecture design. It implies that the authors should elaborate on these aspects and provide more detailed commentary. However, the comment does not explicitly instruct the authors to do so, nor does it offer specific guidance on what aspects to focus on or how to present this information. While the action is implied, it is not as clear as it could be, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of AutoML approaches and the potential benefits beyond raw performance, such as extracting hints for future network architecture design. It also specifies the lack of discussion on these aspects, providing clear guidance on what the authors should address. However, the comment does not provide specific examples or detailed suggestions on how to improve the discussion, which would make it more specific. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the main reason for using AutoML approaches is not just improving raw performance but also extracting hints for future network architecture design. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without concrete evidence or detailed reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of discussion on the potential benefits of using AutoML approaches beyond raw performance, such as extracting hints for future network architecture design. It highlights the importance of this aspect and suggests that the authors should elaborate on these aspects in their discussion. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific examples or suggestions on how to address this gap in the discussion. Overall, the comment is 3 as it points out an important area for improvement but lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the paper where T_a(t) is used in Section 3.1 but only defined in Section 4. This is an explicit observation that the authors can directly address by providing the definition in the appropriate section. The comment is clear and concrete, as it specifies the exact issue and suggests a straightforward action to resolve it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is that T_a(t) is used in Section 3.1 but only defined in Section 4. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that T_a(t) is used in Section 3.1 but only defined in Section 4. This is a factual observation that does not require any subjective judgment or opinion. It is a statement of fact that can be verified by the authors themselves, as it is directly observable from the paper. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a discrepancy in the paper where T_a(t) is used in Section 3.1 but only defined in Section 4. This is a clear and actionable observation that the authors can address to improve the consistency and clarity of their work. By pointing out this inconsistency, the comment provides the authors with a specific area to focus on for revision. However, the comment could be more helpful if it offered suggestions on how to resolve this issue, such as suggesting a way to integrate the definition into the earlier section or providing additional context for the use of T_a(t). Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a confusion regarding the empirical analysis in Figure 3 and requests additional clarification on the adjustments made to the input series and forecasting target based on the Frequency Stability score. It also asks for an explanation of why these adjustments enhance the model\"s performance. While the comment provides a clear direction for the authors to provide additional clarification and explanation, it does not specify how to implement these changes or what specific details should be included. The action is explicit but somewhat vague in terms of execution, as the authors know what needs to be addressed but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the confusion regarding the empirical analysis and the adjustments made to the input series and forecasting target based on the Frequency Stability score. The comment also requests clarification on why these adjustments enhance the model\"s performance and provides a reference to a related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the empirical analysis in Figure 3, specifically questioning the adjustments made to the input series and forecasting target based on the Frequency Stability score. The reviewer requests additional clarification on how these adjustments affect model prediction accuracy and why they are effective. The comment also references a specific work by Liu et al. (2022) to provide context. While the comment identifies a potential issue and seeks clarification, it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is 3, as it provides a starting point for the authors to address the issue but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the empirical analysis presented in Figure 3, noting that the adjustments to the input series and forecasting target based on the Frequency Stability score are not clearly explained. It requests additional clarification on how these adjustments affect model prediction accuracy and why they are effective. The comment also points out that Equations (9) and (10) have large spacing from the preceding text, which could be improved. While the comment provides clear guidance on what needs to be clarified and improved, it could be more helpful if it offered specific suggestions on how to present this information or what aspects of the analysis are most important for the authors to focus on. Overall, the comment is 3 as it directs the authors to specific areas needing clarification and improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the recent related work, CoCoOp, should be compared in the experiments. It provides a clear and direct action for the authors to take, specifying that they should include a comparison with CoCoOp in their experiments. This guidance is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the recent work \"CoCoOp\" and its relation to the experiments. It specifies the need to compare CoCoOp with the experiments, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the recent work \"CoCoOp\" should be compared in the experiments, as it is an extended version of CoOp and was published after the NeurIPS deadline. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, noting that the recent work \"CoCoOp\" is not compared in the experiments. It highlights the importance of including this comparison, as CoCoOp is an extended version of CoOp and was published after the NeurIPS deadline. This feedback is clear and actionable, providing the authors with a direct and concrete suggestion for improving their draft. By addressing this gap, the authors can enhance the comprehensiveness and relevance of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Fig. 1 could be improved by showing the processing pipeline more clearly, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring along with where model training is used to optimize the selection modules. While the comment provides a clear direction for improvement, it does not specify how to enhance the figure or what specific elements should be added or changed. The authors are given a general idea of what needs to be improved but are left to determine the exact details of execution. Therefore, the comment is 3, as it provides a clear direction but lacks concrete guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved, including suggestions for enhancing the figure to show the processing pipeline more clearly. The comment details the elements that should be included, such as prompt generation, manual check, demonstration selection, ground truth scores, and automatic scoring. This level of detail provides a clear path for the authors to follow in making improvements. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Fig. 1 could be improved by showing the processing pipeline more clearly, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring along with where model training is used to optimize the selection modules. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these elements are necessary or how they would enhance the figure. Without additional context or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is categorized as 3, as it provides a direction for improvement but lacks the necessary detail to be 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on how to improve the clarity and presentation of Fig. 1. It suggests that the processing pipeline should be shown more clearly, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring along with where model training is used to optimize the selection modules. This feedback is clear and offers a concrete direction for improvement, helping the authors enhance the visual representation of their work. However, the comment could be more helpful if it provided additional context or examples of how these elements could be integrated into the figure. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to remove abbreviations like \"MoCo\" from section headers, as they might not be familiar to readers. This is a clear and direct action that the authors can take to improve the clarity of their draft. The comment provides concrete guidance on what to remove, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 136,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of abbreviations like \"MoCo\" in section headers. This provides clear guidance on what the authors need to change to improve the clarity of their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests that abbreviations like \"MoCo\" should not appear in section headers because readers might not know what they mean. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it affects the reader\"s understanding. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to improve the clarity of the paper. By pointing out that abbreviations like \"MoCo\" should not appear in section headers, the reviewer highlights a potential source of confusion for readers who might not be familiar with the term. This feedback is clear and direct, offering a straightforward way for the authors to enhance the accessibility of their work. However, the comment could be more helpful if it provided additional context or examples of how this change would improve the clarity of the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. It implies that adding topic entities is incremental and does not provide a clear direction for improvement. However, the comment does not offer specific guidance on how to address these concerns or what additional aspects could be explored to enhance the novelty of the paper. The lack of explicit suggestions or concrete actions makes it difficult for the authors to know how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. However, it does not specify which datasets or parts of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how the novelty could be enhanced. Without clear guidance on what needs to be addressed, the authors cannot effectively improve their draft. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. It implies that adding topic entities seems incremental and does not provide a clear direction for improvement. However, the comment lacks specific suggestions or examples of how the authors could enhance the novelty or impact of their work. Without actionable feedback or guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as 2, as it identifies a potential issue but does not offer sufficient direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the method only provides marginal improvements over baselines, with most improvements within the error bar range. It also notes that the authors claim the method performs better than the baselines, but the high error range suggests that the performance differences are not significant. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the performance of their method. The action is implicit and vague, as the authors are left to infer that they need to improve the performance of their method, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance of the method compared to baselines, suggesting that the improvements are marginal and within the error bar range. It also mentions that the authors claim the method performs better than the baselines, but the high error range suggests otherwise. However, the comment does not specify which part of the paper discusses these claims or where the performance comparisons are made, making it weakly grounded. The comment is specific in its critique of the performance improvements and the high error range, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method provides only marginal improvements over baselines, with most improvements within the error bar range. It also suggests that the authors\" claim of better performance is not supported by the high error range, implying that the performance differences are not significant. The comment provides some logical reasoning by pointing out the high error range, but it lacks specific examples or references to support the claim that the performance differences are not significant. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the method provides only marginal improvements over baselines, with most improvements within the error bar range. It also points out that the authors claim the method performs better than the baselines, but the high error range suggests otherwise. This feedback is valuable as it highlights a potential weakness in the paper\"s claims and provides a clear direction for the authors to address. However, the comment could be more helpful if it offered specific suggestions on how to improve the performance or how to present the results more effectively. Overall, the comment is 4 as it directs the authors\" attention to a critical area needing improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding how to make the proposed evaluation set more diverse and representative than the previous method and how to select representative images. However, it does not provide any explicit guidance or suggestions on how the authors might address these issues. The comment implies that the authors should provide more details or examples, but it does not specify what those details or examples should be. As a result, the action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of diversity and representation in the proposed evaluation set, specifically mentioning the need for clarity on how to make the set more diverse and representative than the previous method and how to select representative images. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where the evaluation set is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what needs to be clarified regarding diversity and representation, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed evaluation set is unclear in terms of diversity and representation, and how to select representative images. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed evaluation set, specifically the lack of clarity on how to make it more diverse and representative than the previous method and how to select representative images. This is an important point that could significantly impact the validity and applicability of the evaluation results. However, the comment does not provide specific suggestions or examples on how the authors might address these issues, such as recommending specific approaches or criteria for diversity and representation. While it highlights a significant area for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. It also suggests providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. These actions are clear and concrete, as they specify exactly what needs to be added to the paper to improve clarity and understanding. The authors know exactly what steps to take to address the feedback, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a background section and a brief overview of the original DPO algorithm. This allows the authors to accurately identify the parts of the paper being addressed, ensuring full grounding. The comment is also specific because it clearly specifies what needs to be included in the background section and how it should be presented. This provides clear guidance on what the authors need to address to improve the clarity of their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the RL context being considered. It also recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. The claim is 3 as it logically suggests that a background section would enhance the clarity of the paper. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting the inclusion of a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. This suggestion is valuable as it helps the authors establish the context and foundation for their work, making it easier for readers to understand the subsequent sections. Additionally, the comment recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This additional information would help the authors clarify the modifications and their significance. Overall, the comment is 5 as it offers specific and constructive guidance for improving the clarity and comprehensibility of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017). While it does not explicitly instruct the authors to make any changes or provide guidance on how to address this question, it implies that the authors should consider the relevance of the term in the context of their work. The action is implicit but clear, as the authors can infer that they need to evaluate the relevance of the term and potentially revise their work accordingly. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017), providing a clear direction for the authors to consider the context and implications of this term in their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017), which is cited in the paper. This question prompts the authors to consider the context and implications of the term in their work, potentially leading to a deeper understanding and clarification of their ideas. However, the comment does not provide specific guidance or suggestions on how to address this issue or improve the paper. While it points out a relevant reference, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it identifies a potential area for clarification but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the experiments are limited to MNIST and a single realworld dataset, suggesting that the authors should consider expanding their experiments to include more datasets. However, it does not provide specific guidance on which additional datasets should be considered or how to implement this expansion. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment points out that the experiments are limited to MNIST and a single realworld dataset, but it does not specify which part of the paper this limitation is discussed in. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. However, it is specific in identifying the issue of limited datasets being used for experiments. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are limited to MNIST and a single realworld dataset. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it affects the validity or applicability of the experiments. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment points out a limitation in the experiments, specifically that they are limited to MNIST and a single realworld dataset. This feedback highlights an area where the authors could potentially expand their experiments to include a more diverse set of datasets, which could enhance the generalizability and applicability of their results. However, the comment does not provide specific suggestions on which datasets to include or how to address this limitation. While it identifies a potential area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the number of parameters in the S2D structure and suggests that more details are needed to explain why the number of parameters does not change. It acknowledges that the efficiency could be improved, but it does not provide specific guidance on how to address this issue or what additional details are expected. The comment lacks explicit instructions or concrete suggestions for the authors to follow, leaving them uncertain about how to proceed. Therefore, the comment is 3, as it identifies an area for improvement but does not offer detailed guidance on how to achieve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the number of parameters in the S2D structure and suggests that more details are needed to explain why the number does not change. The comment also acknowledges the potential for efficiency improvements and provides a logical reasoning for expecting more details. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the number of parameters in the S2D structure and suggests that more details are needed to explain why the number does not change. The reviewer acknowledges that the efficiency could be improved but does not provide specific reasoning or evidence to support the claim that the number of parameters should change. The comment lacks detailed justification or examples to substantiate the claim, making it 3. The authors would need to further explore the issue to understand the basis of the claim and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the S2D structure regarding the number of parameters and suggests that more details are needed to explain why the number does not change. It acknowledges the potential for efficiency improvements but highlights the need for additional information on the parameters. While the comment provides a clear direction for improvement, it lacks specific suggestions or examples on how the authors might address this issue or what additional details are expected. This limits the comment\"s helpfulness, as it points out a potential area for improvement but does not fully guide the authors on how to achieve it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or differentiate their method from [10]. The comment lacks actionable details, such as recommending specific modifications or discussions to be included in the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"approach in [10],\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning why the approach in [10] cannot use the additional information, such as scoring causal predictions and interventional data. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. It questions why [10] cannot use these side information. While the comment identifies a potential issue with the novelty of the proposed method, it lacks specific guidance or suggestions on how the authors might address this concern or differentiate their work from [10]. The feedback is 3 as it points out a potential problem but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This implies that the model may not be incentivized to use fewer factors, leading to increased computation with more tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the model. The authors are left to infer that they need to consider adding a sparsity constraint, but without concrete instructions or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"factorized model with an IBP prior,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which leads to increased computation with more tasks. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which leads to increased computation with more tasks. The comment provides a logical reasoning by explaining the potential consequences of this lack of constraint, but it does not provide specific examples or references to substantiate the claim. The authors might find it challenging to understand the exact impact of this constraint without additional context or evidence. Therefore, the claim is 3, as it provides a logical argument but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This observation highlights a potential limitation of the model, which could lead to increased computation with more tasks. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the impact of the lack of sparsity constraint. While it points out a relevant concern, the feedback could be more helpful by offering actionable advice or examples of how to incorporate a sparsity constraint. Therefore, the comment is 3, as it provides insight but lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out that the authors do not comment on why the GPC (benchmark) is performing better than BPC (their method). It suggests that the authors should reiterate that the GPC\"s superior performance is due to the bandit feedback and not the form of the cost function. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be addressed in the paper. The comment is 5 as it offers a specific guidance on how to improve the draft by addressing the issue of the simulation study presentation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"presentation of the simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation, namely the lack of commentary on why the GPC (benchmark) is performing better than BPC (their method). The comment provides a clear suggestion for improvement by recommending that the authors reiterate the reason for the GPC\"s superior performance, which is due to the bandit feedback and not the form of the cost function. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation of the simulation study does not provide a favorable comparison between the GPC (benchmark) and BPC (the authors\" method). It suggests that the GPC performs better due to bandit feedback and not the form of the cost function. The comment provides a logical reasoning by explaining the potential cause of the GPC\"s superior performance. However, it lacks specific examples or references to support the claim, such as data or comparisons with other methods. This makes the claim 3, as it provides a reasonable explanation but requires more detailed evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not comment on why the GPC (benchmark) is performing better than BPC (their method). It suggests that the authors should reiterate that the GPC\"s superior performance is due to the bandit feedback and not the form of the cost function. This feedback is clear and actionable, as it provides a concrete suggestion for improvement by directing the authors to clarify their explanation of the results. By addressing this point, the authors can enhance the clarity and comprehensiveness of their presentation, which is valuable for improving the draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be helpful. It references the use of ReLUs in the AlexNet paper, which was considered deep at the time, to provide context. However, the comment does not explicitly instruct the authors on how to quantify or clarify the claim. While it implies that the authors should provide more detailed information or examples, it lacks concrete guidance on what specific aspects to address or how to present the information. The action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks.\" It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling rather than ReLUs for the convolutional layers. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in suggesting that quantifying and clarifying the claim could be beneficial. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be helpful. It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling rather than ReLUs for the convolutional layers. This reference provides some context for the claim but does not offer detailed evidence or specific examples to support the assertion that ReLUs do not work well in deep or convolutional networks. The comment is 3, as it provides a logical basis for the claim but lacks detailed evidence or specific examples to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be beneficial. It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling rather than ReLUs for the convolutional layers. This reference provides some context for the claim but does not offer specific guidance or suggestions on how to quantify or clarify the claim. While it points out a potential area for improvement, the comment lacks actionable advice or detailed feedback that would help the authors address the issue. Therefore, the comment is 3, as it identifies a potential weakness but does not provide enough guidance for the authors to fully understand and address it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the evaluation should include experiments on distributed deployment and a larger model. This provides a clear and direct action for the authors to take, specifying exactly what additional experiments are needed to improve the draft. The comment is specific and concrete, giving the authors a clear path to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for additional experiments, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not provide any supporting evidence, reasoning, or examples to justify why these experiments are necessary or how they would improve the evaluation. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the evaluation should include experiments on distributed deployment and a larger model. This feedback is 3 as it identifies a potential area for improvement in the evaluation section. However, it lacks specific guidance on how to conduct these experiments or what aspects of the evaluation would be enhanced by including them. The comment does not provide detailed suggestions or examples, which would help the authors understand how to implement this feedback effectively. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors need to elaborate on the importance of rooted patterns and how they choose the roots. It suggests that a brief discussion is expected or, if nonrooted patterns are sufficient, it might be better to discuss this case in the supplementary material. This feedback provides clear and concrete actions for the authors to take, such as elaborating on the importance of rooted patterns or discussing nonrooted patterns in the supplementary material. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the concept of \"rooted patterns\" and how they are defined, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of elaboration on why rooted patterns are important and how they are chosen. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors do not elaborate on the importance of rooted patterns or how they choose the roots. It suggests that a brief discussion is expected or, if nonrooted patterns are sufficient, that the discussion should be moved to the supplementary material. The comment provides a logical reasoning for the need to clarify these aspects, but it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors need to provide more detail or clarification. It points out that the concept of rooted patterns is defined in a similar way to orbit counting in GSN, but it does not elaborate on why rooted patterns are important or how they are chosen. The comment suggests that a brief discussion is expected or, if nonrooted patterns are sufficient, it might be better to discuss this case in the supplementary material. This feedback is clear and actionable, as it guides the authors on how to enhance the clarity and completeness of their explanation. However, it could be more helpful if it provided specific suggestions on how to elaborate on the importance of rooted patterns or how to choose the roots. Overall, the comment is 4 as it directs the authors to a critical area needing further explanation and provides a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more explanations on the consistency between training and inference, specifically mentioning lines 9597 and 308310. While the comment implies that the authors should elaborate on the smoothness of neural models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more explanations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue, which is the lack of explanation regarding the consistency between training and inference due to the smoothness of neural models. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks explanations regarding the consistency between training and inference due to the smoothness of neural models. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it overly emphasizes the consistency between training and inference due to the smoothness of neural models. It suggests that the authors should provide more explanations on this topic, which is a clear and actionable suggestion. However, the comment could be more helpful if it provided specific examples or guidance on what kind of explanations would be beneficial. Overall, the feedback is 3 as it points out a potential weakness and offers a direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure the availability of the environment or a good OPE method. The action is implicit and somewhat vague, as the authors can infer that they need to consider these factors but are not given concrete steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or where the finetuning is mentioned, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these hyperparameters are introduced, the comment lacks full grounding. It is specific about the issue of finetuning and the dependence on the environment or OPE method, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of two additional hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or evidence, the claim remains 1, as it does not provide sufficient justification for the authors to make improvements. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. This feedback is 3 as it points out a potential problem that the authors need to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how to ensure the availability of the environment or a good OPE method. Without actionable advice or detailed explanation, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that an ablation study on the necessity of the base layer GNN encoding would be helpful. This provides a clear and direct action for the authors to take, which is to conduct an ablation study to understand the role of the base layer GNN encoding in the proposed method. The comment is specific in its request, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"base layer GNN encoding\" in the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the necessity of the base layer GNN encoding and the need for an ablation study. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to understand its role. However, the comment does not provide specific reasoning or evidence to support why the base layer GNN encoding is unnecessary or how an ablation study would benefit the paper. Without detailed justification or examples, the claim remains 3, as the authors may find it challenging to fully understand and address the suggestion without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the necessity of the base layer GNN encoding in the proposed method. It suggests conducting an ablation study to understand the role of this layer and its impact on the overall performance. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to improve their draft by conducting an ablation study. By addressing this point, the authors can enhance the clarity and robustness of their methodology. However, the comment could be more helpful if it included specific guidance on how to conduct the ablation study or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explicitly add the upper bounds of counting homomorphisms and potentially elaborate on empirical runtimes. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment also suggests that the authors should elaborate on empirical runtimes, which adds another actionable point. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the computational complexity of counting homomorphisms, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms. The reviewer provides a specific example of a brief statement made by the authors, which is \"Better still, homomorphism counts of small graph patterns can be efficiently computed even on large datasets\" (L 145). The reviewer suggests that adding the upper bounds of counting and potentially elaborating on empirical runtimes would be beneficial for the paper. However, the comment lacks specific examples or references to support the claim that these additions would improve the paper. While the suggestion is logical, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their paper, namely the discussion of computational complexity in counting homomorphisms. It points out that the authors make brief statements without providing explicit bounds or elaboration on empirical runtimes. The comment suggests that adding these details would enhance the paper\"s clarity and depth. This feedback is clear and actionable, as it provides a concrete direction for the authors to improve their draft. However, it could be more helpful if it included specific examples or references to similar works that have addressed this issue. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a typographical error in the first \"f\" in \"we fixed the form of\" and an extra period in a sentence. It also poses a question about the baseline MCL with deep learning, asking how the authors ensure that each network has converged to reasonable results. The comment provides clear and concrete actions for the authors to correct the typographical errors and offers a specific question for further clarification. The action is explicit and the authors know exactly what to do to address the errors and the question, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, \"line 108\" and \"line 115,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the typographical errors, such as the incorrect \"f\" in \"we fixed the form of\" and the extra period in a sentence, and it poses a question about the baseline MCL with deep learning. The comment provides clear guidance on what needs to be corrected and offers a specific question for further clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual corrections and a question about the baseline MCL with deep learning. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific typographical errors in the manuscript, which are important to correct for clarity and professionalism. It also poses a question about the baseline MCL with deep learning, asking how the authors ensure that each network has converged to reasonable results. This question is relevant and could prompt the authors to provide more detailed explanations or evidence regarding their methodology. However, the comment could be more helpful if it provided suggestions on how to address the question or improve the explanation. Overall, the feedback is actionable and provides valuable insights, but it could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the inference time of their pose estimation method, which is a direct method that does not require detection or keypoint grouping. It also recommends comparing the inference speed of their method to previous topdown and bottomup pose estimation methods. While the comment implies that the authors should conduct this study, it does not provide explicit instructions or concrete steps on how to conduct the study or what specific aspects to focus on. The action is clear but lacks detailed guidance, making it 3.", "grounding_specificity_rationale": "The comment suggests studying the inference time of the pose estimation method, which is a direct method that does not require detection or keypoint grouping. It also recommends comparing the inference speed to previous topdown and bottomup pose estimation methods. However, the comment does not specify which part of the paper should include this analysis or where the inference time is currently discussed. While the authors might have an idea of where this information is discussed, the comment lacks full grounding. It is specific about the need for an inference time comparison but does not provide detailed guidance on how to implement this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks a study of inference time for the pose estimation method, which is a direct method that does not require detection or keypoint grouping. The reviewer provides a logical reasoning by stating that since the method is direct, it should be compared to previous topdown and bottomup pose estimation methods in terms of inference speed. This claim is 3 as it provides a logical basis for the suggestion, but it could be strengthened with specific references or examples to support the comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by suggesting that the authors should study the inference time of their pose estimation method, which is a direct method that does not require detection or keypoint grouping. It also recommends comparing the inference speed of their method to previous topdown and bottomup pose estimation methods. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by including a study of inference time and benchmarking their method against others. However, the comment could be more helpful if it offered suggestions on how to conduct this study or what specific aspects to focus on. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the proof in Theorem A.3, specifically regarding the input x having two indices when it is a vector. It also points out a potential error in the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d, suggesting it should be d. While the comment identifies specific issues, it does not provide explicit guidance on how to address them. The authors can infer that they need to clarify the input x and correct the equation, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential error in the proof regarding the input x having two indices when it is a vector, and it questions the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d. This provides clear guidance on what needs to be addressed in the proof. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual observations and questions about the proof in Theorem A.3. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue in the proof of Theorem A.3, pointing out that the input x is a vector, not a matrix, and questioning the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d. This feedback is clear and actionable, as it directs the authors to correct the input type and the equation, which could improve the accuracy and clarity of the proof. However, the comment could be more helpful if it provided additional context or explanation on why this correction is necessary or how it affects the overall understanding of the theorem. Overall, the comment is 4 as it effectively guides the authors to make a specific correction, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the use of words like \"somewhat\" and \"good generative ability\" in section 4.3 and 4.4, questioning the effectiveness of beam search in ensuring the correctness of the results. It suggests that the authors should address this issue by providing more detailed information on how they ensure the correctness of the pluggedin entities and relationships. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to address the concern. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information on the effectiveness of beam search. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4.3 and 4.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the use of words like \"somewhat\" and \"good generative ability\" in the description, and it raises concerns about the effectiveness of beam search in ensuring the correctness of the results. The comment further asks how the authors ensure the correctness of the pluggedin entities/relationships and suggests that the percentage of correct entities/relationships might be lower without ground truth. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the effectiveness of beam search in ensuring the correctness of the results, questioning the use of words like \"somewhat\" and \"good generative ability\" in the description. It suggests that only 77% of the result lists contain the ground truth logical forms, and it asks how the authors ensure the correctness of the pluggedin entities/relationships without ground truth. The comment provides a logical reasoning by questioning the reliability of the results and suggesting that the authors should address this issue. However, it lacks specific examples or references to support the claim that beam search is insufficient. Therefore, the comment is 3, as it provides a logical basis for the concern but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the description of results in sections 4.3 and 4.4, noting the use of words like \"somewhat\" and \"good generative ability\" and questioning the effectiveness of beam search in ensuring the correctness of the results. It raises a valid concern about the reliability of the results and suggests that the authors should address this issue by providing more detailed information on how they ensure the correctness of the pluggedin entities and relationships. The comment is 3 as it prompts the authors to consider the robustness of their method and provides a direction for improvement. However, it could be more helpful if it offered specific suggestions or examples on how to improve the description or address the concern. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the limitations of FedPCL due to its reliance on pretrained models and suggests that the authors have adequately addressed these limitations by developing a lightweight federated learning framework and integrating pretrained models. However, the comment does not provide explicit guidance on how the authors should further improve their work or what specific aspects of the framework should be refined. It lacks actionable details, such as suggestions for additional experiments or modifications to the framework. As a result, the authors are left without clear direction on how to enhance their draft based on this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the sensitivity of the model accuracy to pretrained models and how the authors addressed this limitation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance of FedPCL heavily relies on the selection of different pretrained models, which limits its applications to more wide areas. The reviewer supports this claim by referencing Table 4, which shows the model accuracy is sensitive to pretrained models. However, the comment does not provide further explanation or examples of how this limitation affects the applicability of FedPCL. While the reference to Table 4 provides some support, the comment could be strengthened by offering more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment acknowledges the limitations of FedPCL due to its reliance on pretrained models and suggests that the authors have adequately addressed these limitations by developing a lightweight federated learning framework and integrating pretrained models for prototyping. However, the comment lacks specific suggestions or guidance on how the authors could further improve their work or address the limitations more effectively. It does not provide actionable feedback or detailed insights into potential enhancements or alternative approaches. As a result, the comment is 3, as it identifies a limitation but does not offer detailed guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include tentative attention maps in the qualitative figures to provide a more comprehensive understanding of the attention mechanism. While the comment implies that the authors should add these maps, it does not explicitly instruct them to do so. The action is concrete, as it specifies what additional information should be included, but it is somewhat vague because it does not provide detailed guidance on how to present these maps. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests including tentative attention maps in the qualitative figures, which implies that it relates to the visualization or discussion of the attention mechanism. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as specific figures or sections where the attention mechanism is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of tentative attention maps, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that including tentative attention maps in the qualitative figures would be beneficial for understanding the attention mechanism. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition would be valuable or how it would enhance the understanding of the attention mechanism. Without such justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that including tentative attention maps in the qualitative figures would enhance the understanding of the attention mechanism. This feedback is 3 as it identifies a potential area for improvement in the visualization of the attention mechanism. However, it lacks specific guidance on how to present these maps or what aspects of the attention mechanism should be highlighted. While it points out a potential enhancement, the comment could be more actionable with additional details or examples. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides several explicit suggestions for improving the paper. First, it recommends describing the two types of attention for deep VAEs in a separate section, followed by the generative and inference models. This action is clear and concrete, as it specifies where the information should be placed and how it should be organized. Second, it suggests referencing tricks like normalization or feature scaling in a separate section, which is also a clear and concrete action. Finally, it mentions that the description of the layerwise attention mechanism is scattered across sections 2.3 and 2.4, providing a specific area for improvement. Overall, the comment is 5 as it provides clear and concrete steps for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections, \"2.3\" and \"2.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as describing the two types of attention for deep VAEs in a separate section and referencing tricks like normalization or feature scaling in a separate section. The comment also suggests reorganizing the description of the layerwise attention mechanism to improve clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point provides several suggestions for improvement, including describing the two types of attention for deep VAEs in a separate section, referencing tricks like normalization or feature scaling, and reorganizing the description of the layerwise attention mechanism. These suggestions are based on logical reasoning and common practices in the field, but they do not include specific examples or references to support the claims. While the suggestions are clear, they lack detailed justification or evidence to fully substantiate the claims. Therefore, the comment is 3, as it provides a solid foundation for improvement but requires more detailed explanation to be fully convincing.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the paper. It recommends describing the two types of attention for deep VAEs in a separate section, followed by the generative and inference models, which can help clarify the contributions of the paper. Additionally, it suggests referencing tricks like normalization or feature scaling in a separate section, which can improve the organization and accessibility of the paper. Finally, it points out that the description of the layerwise attention mechanism is scattered across sections 2.3 and 2.4, suggesting a reorganization to improve clarity. These suggestions are clear and actionable, providing the authors with specific steps to enhance the clarity and organization of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the understanding of Figure 5 or the labels being incorrect. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific steps to take to improve the figure or labels. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper, such as Figure 5, is being addressed. It lacks specificity because it does not provide details on what is unclear or incorrect about the figure or labels. Without explicit references or detailed feedback, the authors cannot effectively identify the issues or make improvements. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The comment consists of a statement expressing confusion about Figure 5 or the labels being incorrect. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual observation about the content of the figure or labels. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment expresses confusion about Figure 5 or the labels being incorrect, indicating a potential issue with the clarity or accuracy of the visual representation. However, it does not provide any specific guidance or suggestions on how to address this issue or what aspects of the figure or labels are problematic. Without actionable feedback or detailed insights, the authors are left without a clear path to improve the figure or labels. Therefore, the comment is not helpful, as it lacks depth and specificity, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of supervised baselines in the paper and suggests that it is reasonable to assume that full annotation is available for datasets of scale ~100k images. It also notes that even if this is not the case, having an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. While the comment implies that the authors should include supervised baselines, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific steps to implement the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the absence of supervised baselines in the paper, specifically mentioning that most experiments are conducted on datasets of scale ~100k images, which implies that full annotation should be available. It suggests that including an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. However, the comment does not specify which part of the paper this issue pertains to, such as the experimental section or the methodology. While the authors can infer that it relates to the experimental setup, the lack of explicit grounding makes it weakly grounded. The comment is specific in its suggestion to include supervised baselines, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the absence of supervised baselines is a significant issue, as most experiments are conducted on datasets of scale ~100k images, which implies that full annotation should be available. The reviewer suggests that including an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. This claim is 3 as it provides a logical reasoning for the inclusion of supervised baselines, but it lacks specific examples or references to support the assertion that full annotation is typically available for datasets of this scale. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines, which are crucial for evaluating the performance of selfsupervised methods. It logically argues that since most experiments are conducted on datasets of scale ~100k images, it is reasonable to assume that full annotation is available. The comment suggests that including an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. This feedback is clear and actionable, providing the authors with a specific direction to enhance their experimental setup and analysis. However, it could be more helpful if it included examples of suitable supervised baselines or detailed guidance on how to implement them. Overall, the comment is 4 as it effectively highlights a critical area for improvement and offers a concrete suggestion for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics. It also questions the absence of BEAR from baselines and suggests that the method may not have much benefit. While the comment implies that the authors should evaluate their method on different domains and include BEAR in the baselines, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to address the concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics. It also questions the absence of BEAR from baselines and suggests that the method may not have much benefit. However, the comment does not specify which part of the paper these questions pertain to, such as specific sections or experiments. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its questions about the method\"s effectiveness and the inclusion of BEAR in the baselines, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics. It also questions the absence of BEAR from baselines and suggests that the method may not have much benefit. However, the comment lacks specific examples or references to support these claims or questions. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several questions and suggestions that could help the authors improve their draft. It questions the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics to assess its empirical efficacy. This feedback is valuable as it encourages the authors to broaden the scope of their evaluation, which could enhance the method\"s applicability. Additionally, the comment questions the absence of BEAR from baselines and suggests that the method may not have much benefit without this comparison. While the comment identifies areas for improvement, it could be more helpful if it provided specific guidance on how to conduct these evaluations or what specific domains to consider. Overall, the comment is 4 as it prompts the authors to consider broader applicability and provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method\"s ability to detect hallucinations in openended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" The reviewer suggests that the method might struggle to detect hallucinations due to the potential for different responses pertaining to different individuals, making it challenging to identify shared information for consistency checking. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve the method. The action is implicit and somewhat vague, as the authors can infer that they need to consider this issue but are not given detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and the specific issue of detecting hallucinations in openended responses, such as the prompt \"introduce a sports celebrity to me.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the problem of detecting hallucinations in openended responses and the potential challenge of identifying shared information for consistency checking. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method might struggle to detect hallucinations in openended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" The reviewer provides a logical reasoning by explaining that the sampled responses could pertain to different individuals, making it challenging to identify shared information for consistency checking. However, the comment lacks specific examples or references to support the claim, such as how the method might fail in detecting hallucinations or how it could be improved. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method\"s ability to detect hallucinations in openended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" This highlights a specific challenge in detecting hallucinations due to the potential for different responses pertaining to different individuals, making it difficult to identify shared information for consistency checking. While the comment points out a potential weakness, it does not provide detailed guidance or suggestions on how the authors might address this issue or improve their method. The feedback is 3 as it alerts the authors to a potential problem but lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors verify the conclusion about label noise and model size on MNIST and CNN, which implies that the authors should conduct additional experiments to test the theoretical findings in a realworld context. While the comment does not explicitly instruct the authors to perform these experiments, it provides a clear direction for action. The authors can infer that they need to conduct these experiments to verify the conclusion, making the action implicit but still clear. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests verifying the conclusion about label noise and model size on MNIST and CNN, which implies that the authors should conduct additional experiments to test the theoretical findings in a realworld context. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need for verification on MNIST and CNN, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the theoretical findings are unclear in their relation to realworld deep learning models. It provides a specific suggestion to verify the conclusion about label noise and model size on MNIST and CNN. This claim is 3 as it logically suggests that verification is necessary to clarify the theoretical findings. However, the comment lacks detailed reasoning or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the theoretical findings and their relation to realworld deep learning models. It suggests that the authors verify the conclusion about label noise and model size on MNIST and CNN, which could provide valuable insights into the practical implications of their theoretical findings. This feedback is clear and actionable, as it directs the authors to conduct additional experiments that could strengthen the paper\"s contribution. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific feedback on the paper\"s organization, writing, and content clarity. It suggests that the writing could be improved by drawing a table to compare different CoT prompting methods across different dimensions. Additionally, it questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and questions the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps are not included. While the comment provides some guidance on potential areas for improvement, it does not offer concrete steps or examples on how to implement these improvements. The authors are left with a general idea of what needs to be addressed but without detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"writing\" and \"content clarity,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the weaknesses, such as the need for a table to compare different CoT prompting methods and the questionable assumption about the frequenterror cluster. Additionally, it raises questions about the selection criteria in section 4.2, providing specific feedback on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is wellorganized and the writing is good, but it also identifies areas for improvement. The reviewer suggests that the writing could be improved by drawing a table to compare different CoT prompting methods across different dimensions. Additionally, the reviewer questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and questions the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps are not included. These points are supported by logical reasoning and specific questions, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the critique. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides both positive and negative feedback. The positive aspect is that the paper is wellorganized and the writing is good, which is a clear indication that the authors have done a good job in presenting their work. However, the comment also identifies areas for improvement, specifically suggesting that the writing could be improved by drawing a table to compare different CoT prompting methods across different dimensions. Additionally, it questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and questions the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps are not included. These suggestions are clear and actionable, providing the authors with specific guidance on how to enhance their draft. While the comment could be more detailed in some areas, it offers valuable insights that can help the authors improve their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the use of suboptimally weight decay across all layers is expected to result in large training losses and suboptimal cosine similarities, especially for large weight decay parameters. It suggests that the lack of reporting cosine similarities for such large weight decay strengths and the plots ending at a weight decay strength where cosine similarities are still close to optimal is convenient. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of suboptimally weight decay across all layers, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of reporting cosine similarities for large weight decay strengths and the plots ending at a weight decay strength where cosine similarities are still close to optimal. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of suboptimally weight decay across all layers is expected to result in large training losses and suboptimal cosine similarities, especially for large weight decay parameters. The reviewer supports this claim by pointing out that cosine similarities for such large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. This provides a logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to similar studies that have observed similar effects. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the application of suboptimally weight decay across all layers, which is expected to lead to large training losses and suboptimal cosine similarities, especially for large weight decay parameters. It points out that cosine similarities for such large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. This feedback is clear and actionable, as it highlights a potential weakness in the paper that the authors can address by either reporting the missing cosine similarities or explaining why they are not reported. By addressing this issue, the authors can enhance the transparency and robustness of their work. Therefore, the comment is 4, as it provides a clear direction for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. The reviewer also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. While the comment provides a clear direction for further analysis, it does not explicitly instruct the authors to conduct this study. The action is implicit but concrete, as it specifies what aspects of the analysis should be explored. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. However, the comment does not explicitly mention which part of the paper this analysis should be integrated into, making it weakly grounded. The comment is specific in detailing what aspects of the analysis should be explored, such as the roles between \"winners\" and \"cooperators\" and the potential impact of cost on collective return. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. The reviewer also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. While the comment provides logical reasoning and examples, it lacks specific references or detailed evidence to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the suggestion but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending a systematic analysis of the impact of the cost of incentivization on performance. It offers a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. The comment also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. This feedback is highly valuable as it guides the authors to a specific area for further exploration and analysis, which could significantly enhance the paper. However, the comment could be more helpful if it provided additional details or examples on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 5 as it offers a clear and actionable direction for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies two main issues with the experimental section: the lack of interpretive insights into why the proposed gyrostructures outperform existing methods and the absence of comparison with other stateoftheart methods that do not rely on gyrostructures. While the comment highlights these gaps, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to include more interpretive insights and comparisons with other methods. The action is implicit and somewhat vague, as it lacks concrete steps or examples of what specific insights or comparisons should be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments part,\" allowing the authors to accurately identify the section being addressed. It also specifies the issues with the related discussion, noting the lack of interpretive insights and the need for comparison with other stateoftheart methods that do not rely on gyrostructures. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related discussion lacks interpretive insights and that the proposed gyrostructures outperform existing methods. It also notes the absence of comparison with other stateoftheart methods that do not rely on gyrostructures. While the comment identifies specific gaps in the discussion, it does not provide detailed reasoning or examples to support the claim that the proposed approach outperforms simpler or more commonly used techniques. The lack of specific examples or references makes the claim 3, as the authors would need to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two significant issues with the experimental section of the paper. First, it points out the lack of interpretive insights into why the proposed gyrostructures outperform existing methods. This feedback highlights an important area for improvement, as it would help the authors better understand the strengths of their approach. Second, it notes the absence of comparison with other stateoftheart methods that do not rely on gyrostructures, making it unclear whether the proposed approach actually outperforms simpler or more commonly used techniques. This omission is crucial for the authors to address, as it affects the validity and generalizability of their findings. By addressing these issues, the authors can significantly enhance the clarity and robustness of their experimental results. Therefore, the comment is 5, as it provides clear and actionable feedback on areas needing improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 5 is difficult to comprehend and recommends providing more details about the two baselines presented. It also points out that the authors only study CATER for Englishcentric datasets, which is a limitation, and suggests extending CATER to other languages in the future. While the comment provides a clear action for the authors to take, it does not specify which details should be added or how to extend CATER to other languages. The action is explicit but lacks concrete guidance on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as its difficulty in comprehension and the need for more details about the baselines presented. The comment also suggests extending CATER to other languages, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is difficult to comprehend and suggests that more details about the baselines presented are needed. It also points out that the authors only study CATER for Englishcentric datasets, which is a limitation. The reviewer suggests extending CATER to other languages, which is a logical suggestion based on the widespread use of translation APIs. However, the comment lacks specific examples or references to support the claim about the difficulty of comprehension or the need for more details about the baselines. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend and suggesting that more details about the baselines presented should be included. It also points out a limitation in the study, noting that the authors only focus on CATER for Englishcentric datasets, despite the widespread use of translation APIs for multiple languages. The comment provides a clear and actionable suggestion for improvement by recommending that the authors extend CATER to other languages in the future. This feedback is valuable as it directs the authors to enhance the comprehensibility and scope of their work, making it 4. However, it could be more helpful if it included specific guidance on how to extend CATER to other languages or what additional details should be included in the figure. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of clarity in the literature review, specifically regarding the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work. While the comment implies that the authors should make these improvements, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added (an explicit and comparative analysis of related work), but it is somewhat vague in terms of how to execute this action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"literature review\" and \"GFlowNet for sequence generation,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely the clarity of the main contribution and the distinction from existing work. The comment provides guidance on how to enhance the literature review by suggesting a more explicit and comparative analysis of related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear, particularly regarding the main contribution of the proposed method and its distinction from existing work. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. While the claim is based on logical reasoning, it lacks specific examples or references to existing work that could clarify the distinction. This makes the claim 3, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the literature review, specifically the lack of clarity regarding the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work, which is crucial for effectively communicating the novelty and significance of the proposed method. This feedback is clear and actionable, as it directs the authors to enhance the literature review section to better support their claims. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct a more comprehensive analysis of related work. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not provide any explicit guidance on how to implement this suggestion or what specific changes should be made to the section. The action is implicit and vague, as the authors are left to infer that they should remove the section without detailed instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not specify which part of section 3.2 is problematic or how it relates to the distribution. Without explicit references to specific sections or elements, the authors cannot confidently determine which part of the paper needs attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that section 3.2 can be eliminated because readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption is valid or how it affects the paper\"s content or clarity. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not provide any reasoning or explanation for why this section is unnecessary or how it might detract from the paper\"s overall clarity or contribution. Without additional context or suggestions for improvement, the comment lacks depth and does not offer actionable guidance for the authors to enhance their draft. Therefore, it is rated as 2, as it provides some insight but not enough to be fully beneficial."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests two specific actions for the authors to take: (i) to include performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, to enhance the credibility of the framework, and (ii) to include morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. These are explicit actions that the authors can directly implement to improve their draft. The second point is a minor suggestion, but it is still clear and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the addition of performance on word similarity and sentence translation tasks and the inclusion of morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. This provides clear guidance on how to enhance the robustness and effectiveness of the framework. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that adding performance on word similarity and sentence translation tasks would enhance the credibility of the framework, similar to the MUSE paper and others. It also recommends including morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. These suggestions are based on common practices in the field and are logical, but the comment lacks specific examples or references to support the claim fully. The authors might need to infer the importance of these additions themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two specific and actionable suggestions for improving the experiments section of the paper. First, it recommends adding performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, which would enhance the credibility and effectiveness of the framework. This is a clear and concrete suggestion that the authors can easily implement to improve their draft. Second, it suggests including morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments, which would further diversify the evaluation and provide more robust results. While the second point is a minor suggestion, it is still actionable and could help the authors expand their experiments. Overall, the comment is 4 as it offers clear and actionable guidance for improving the draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of insight into the rationale behind the need for selfsupervised learning on 360 video data with spatial audio. It implies that the authors should provide more detailed explanations or justifications for this approach. However, the comment does not explicitly instruct the authors to do so or offer specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental results and suggests that while the proposed approach is valuable for selfsupervised learning on 360 video data with spatial audio, it lacks insights into why this approach is needed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of insight into the rationale behind the need for selfsupervised learning on this kind of data. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental results suggest the proposed approach is valuable for selfsupervised learning on 360 video data with spatial audio but lacks insights into why this approach is needed. The comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the rationale behind the need for selfsupervised learning on 360 video data with spatial audio. It highlights that while the experimental results suggest the approach\"s value, the paper lacks insights into why this approach is necessary. This feedback is 3 as it points out an area where the authors could provide more context or explanation to strengthen their work. However, the comment could be more helpful if it suggested specific ways to address this issue or provided examples of how other works have addressed similar questions. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to average their results over multiple runs to determine statistical significance. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific guidance on how to conduct the analysis, making it 5. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment suggests that the results should be averaged over multiple runs to determine statistical significance. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this is relevant. The authors can infer that it relates to the results or analysis sections, but this inference is not direct. The comment is specific in suggesting a method for statistical analysis, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that results should be averaged over multiple runs to determine statistical significance. However, it does not provide any supporting evidence, reasoning, or examples to justify why this approach is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how it would improve their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and actionable piece of feedback that can help the authors improve the robustness and reliability of their analysis. By suggesting a specific method for statistical analysis, the comment provides a concrete step for the authors to take in order to enhance the credibility of their findings. However, the comment could be more helpful if it explained why averaging over multiple runs is necessary or provided examples of how this approach has been used in similar studies. Overall, the comment is 4 as it directs the authors to a specific improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. While these questions imply that the authors should investigate these aspects, they do not provide explicit instructions or concrete guidance on how to address them. The authors can infer that they need to explore the impact of capacity on FID and consider potential artifacts in the pipeline, but the comment lacks specific details or suggestions on how to conduct these investigations. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not specify which part of the paper these questions pertain to, such as a particular section or experiment. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for information about the impact of capacity and artifacts, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The questions themselves are not claims but rather requests for clarification or additional information. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions that could be valuable for the authors to explore: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. These questions highlight potential areas for further investigation and analysis, which could enhance the understanding and robustness of the paper. However, the comment lacks specific guidance or suggestions on how to address these questions, such as recommending specific experiments or analyses. While it points out important areas for exploration, the feedback could be more actionable with additional details. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights two issues: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It suggests that the purpose of Proposition B.1 might be to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also points out the missing \"proof\" for this proposition. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify the purpose of Proposition B.1 and provide a proof, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues: the blank Appendix A and the unclear purpose of Proposition B.1, suggesting that it might be illustrating a wellknown concept in machine learning. The comment also points out the missing \"proof\" for this proposition. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It suggests that the purpose might be to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also points out the missing \"proof\" for this proposition. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claim that the purpose is unclear or that the \"proof\" is missing. This makes the claim 3, as the authors would need to further investigate and clarify the purpose and proof themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues in the paper: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It suggests that the purpose of Proposition B.1 might be to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also points out the missing \"proof\" for this proposition. This feedback is clear and actionable, as it directs the authors to clarify the purpose and provide evidence for their claims. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar concepts have been presented in other works. Overall, the comment is 4 as it highlights important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, which is to conduct these additional experiments. The comment is specific about the types of experiments that are missing, giving the authors a concrete understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in detailing the types of experiments that are missing, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, the comment does not provide specific examples or detailed reasoning to support why these experiments are necessary or how they would enhance the paper. Without such evidence or examples, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it directly points out areas where the paper could be strengthened by including these experiments. However, the comment could be more helpful if it provided specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct a more careful analysis of the model\"s performance, particularly on \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures. While the comment implies that the authors should conduct a more thorough analysis, it does not specify exactly how to do so or what additional details should be included. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed model demonstrates impressive performance on many benchmarks, including some \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures. However, the comment does not specify which part of the paper discusses the model\"s performance or the evaluation procedures, making it weakly grounded. The suggestion to provide more details is specific, but without clear grounding, the authors cannot confidently determine which sections need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed model demonstrates impressive performance on many benchmarks, including some \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. The comment suggests that more careful analysis is needed, particularly for these \"old\" benchmarks. However, the comment lacks specific examples or references to support the claim that the model\"s performance on these benchmarks is problematic. Without detailed evidence or reasoning, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the model\"s performance on \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It suggests that more careful analysis is needed, particularly for these benchmarks. Additionally, it recommends providing more details about the evaluation procedures, which could help the authors improve the transparency and robustness of their results. While the comment highlights important areas for consideration, it lacks specific suggestions or guidance on how to conduct the additional analysis or what details to include in the evaluation procedures. This limits the comment\"s helpfulness, as it provides a general direction but does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a discrepancy in the experimental part of the paper, specifically noting that the different metrics used for different OPE methods are not consistent across the figures. It explicitly requests that the authors provide comments on the differences between the two sets of evaluation methods. This feedback is clear and direct, giving the authors a specific action to take to improve their draft. The comment is concrete, as it specifies the issue and provides a clear direction for addressing it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4 and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the inconsistency in the evaluation methods across different OPE methods and requests an explanation of the differences between the two sets of evaluation methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental part of the paper verifies different metrics for different OPE methods but notes a discrepancy in the evaluation methods across different OPE methods in Figures 4 and 5. The reviewer suggests that the authors should provide comments on the differences between the two sets of evaluation methods. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to make a significant effort to understand and address the issue, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental part of the paper, noting that the different metrics used for different OPE methods are inconsistent across the figures. It explicitly requests that the authors provide comments on the differences between the two sets of evaluation methods. This feedback is clear and actionable, as it directs the authors to clarify and address the inconsistency in their experimental results. By providing a specific area for improvement, the comment offers valuable guidance for enhancing the clarity and accuracy of the paper. Therefore, it is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the experimental results, noting that the proposed method does not show an advantage without prior information, but only when using prior knowledge. The reviewer suggests that this comparison is unfair because the proposed method requires two separate representation models, which adds complexity and cost. While the comment identifies an issue with the experimental setup, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should consider the extra complexity and cost of the proposed method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method does not show an advantage without prior information but only when using prior knowledge. This provides clear guidance on what needs to be addressed, namely the fairness of the comparison and the complexity and cost of the proposed method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method does not show an advantage without prior information but only when using prior knowledge. The reviewer supports this claim by explaining that the comparison is unfair because the proposed method requires two separate representation models, which adds complexity and cost. This reasoning is logical and provides a clear explanation for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to similar studies that have addressed this issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, noting that the proposed method does not show an advantage without prior information but only when using prior knowledge. The reviewer points out that this comparison is unfair because the proposed method requires two separate representation models, which adds complexity and cost. This feedback is valuable as it highlights a potential weakness in the experimental setup and suggests that the authors should consider the impact of prior knowledge on the results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or how to design a more fair comparison. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include collaborative games in their experiments to explore how the evaluated methods behave in both collaborative and competitive settings. While the action is explicit, it is somewhat vague as it does not provide specific guidance on how to implement this suggestion or what specific collaborative games should be included. The authors are left to infer the details of how to incorporate collaborative games into their experiments, which could be improved with more concrete instructions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks collaborative games in the experiments and recommends including them to explore the behavior of the evaluated methods in both collaborative and competitive settings. However, it does not specify which part of the paper this issue pertains to, such as the sections where the experiments are described or the methodology section. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting the inclusion of collaborative games, but it is 1 as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks collaborative games in the experiments and recommends including them to explore the behavior of the evaluated methods in both collaborative and competitive settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this addition would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting the absence of collaborative games in the experiments. It suggests that including such games would be interesting and could provide valuable insights into the behavior of the evaluated methods in both collaborative and competitive settings. This feedback is clear and actionable, as it directs the authors to consider adding a specific aspect to their experiments that could enhance the understanding and applicability of their work. However, the comment could be more helpful if it provided more detailed guidance on how to implement this suggestion or what specific collaborative games should be considered. Overall, the comment is 4 as it points out a meaningful area for improvement and offers a clear direction for the authors to enhance their work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experimental settings for figures 1 to 9 are missing, making them difficult to be convincing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific settings to include or suggesting ways to improve the figures. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1 to Figure 9,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the absence of experimental settings for these figures, making them difficult to be convincing. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings for figures 1 to 9 are missing, making them difficult to be convincing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the absence of experimental settings for figures 1 to 9. This is a critical observation that could impact the credibility and persuasiveness of the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the figures. While it points out a problem, it does not offer actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the adhoc nature of the regularization term and suggests that the authors should provide more theoretical support. It also mentions the use of alternative statistics, such as the median, to replace the mean and standard deviation in the regularization. While the comment implies that the authors should explore these alternatives, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider these alternatives. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the regularization term, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the adhoc nature of the regularization term and suggests the use of alternative statistics, such as the median, to replace the mean and standard deviation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the adhoc nature of the regularization term and suggests that the authors should provide more theoretical support. It also mentions the use of alternative statistics, such as the median, to replace the mean and standard deviation in the regularization. While the comment provides logical reasoning by suggesting the use of alternative statistics, it lacks specific examples or references to support the claim that the median is a better choice. This makes the claim 3, as the authors would need to explore the rationale themselves to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the adhoc nature of the regularization term and suggests that the authors should provide more theoretical support. It also provides a specific suggestion to consider alternative statistics, such as the median, to replace the mean and standard deviation in the regularization. This feedback is actionable and constructive, as it offers a clear direction for the authors to enhance the theoretical foundation of their work. However, the comment could be more helpful if it provided examples or references to support the use of alternative statistics. Overall, the comment is 4 as it guides the authors toward improving the theoretical underpinning of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit and concrete actions for the authors to take. It explicitly instructs them to report average results over multiple runs, which is a clear and actionable step. It also suggests discussing the decision boundaries in the toy dataset, which is another actionable point. Additionally, it asks for clarification on what information is in Fig. 9, which is a specific request for more detail. Each of these points is clearly stated and provides concrete guidance on how to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Experimental section\" and specific sections within it, such as \"Sec. 3.1\" and \"Sec. 3.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as reporting average results over multiple runs, discussing the decision boundaries in the toy dataset, and clarifying the information in Fig. 9. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes several claims regarding the experimental section, including the need to report average results over multiple runs, discussing the decision boundaries in the toy dataset, and clarifying the information in Fig. 9. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of these suggestions. Therefore, the claims are considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the experimental section, particularly regarding the need to report average results over multiple runs to clarify the results. It also suggests discussing the decision boundaries in the toy dataset and clarifying the information in Fig. 9. These points are clear and offer concrete suggestions for improvement, which can help the authors enhance the clarity and robustness of their experimental results. However, the comment could be more helpful if it provided additional context or examples on how to implement these suggestions effectively. Overall, the feedback is 4 as it directs the authors toward specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy in the authors\" use of the center correlation metric, noting that they claim it is not insightful for discriminating model defenses but then use it in figures 4A and 4B. The reviewer questions why the metric is considered useful in one context but not another, and seeks clarification on the authors\" statement on lines 8082. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this discrepancy or clarify their statement. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their reasoning or justify the use of the metric in figures 4A and 4B. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (8082) and figures (4A and 4B), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the authors\" reasoning for using the center correlation metric, asking for clarification on why it is considered useful in one context but not another. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the authors\" use of the center correlation metric, noting a discrepancy between their claim that it is not insightful for discriminating model defenses and its use in figures 4A and 4B. The reviewer seeks clarification on why the metric is considered useful in one context but not another. This is a logical question that highlights a potential inconsistency in the paper, but it does not provide specific examples or references to support the claim. Therefore, the comment is 3, as it raises a valid point but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a discrepancy in the authors\" use of the center correlation metric, noting that they claim it is not insightful for discriminating model defenses but then use it in figures 4A and 4B. This is a clear and actionable observation that prompts the authors to clarify their reasoning or justify the use of this metric in different contexts. By pointing out this inconsistency, the comment provides valuable feedback that can help the authors improve the coherence and credibility of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context on why the center correlation metric might be considered useful in certain scenarios. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use \"above/below diagonal\" instead of \"above/below 45 degree\" to make the plot easier to interpret. While the comment provides a specific suggestion for clarity, it does not offer detailed guidance on how to implement this change or why it is necessary. The action is explicit but somewhat vague, as the authors know they need to make the change but may not be entirely sure of the exact implementation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"plot\" and suggests a specific change to \"above/below diagonal\" instead of \"above/below 45 degree.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the clarity of the plot labels. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which is described as a local property. The reviewer provides a logical reasoning that \"above/below diagonal\" is clearer because it refers to a specific position on the plot, while \"above/below 45 degree\" is ambiguous. However, the comment lacks specific examples or references to support the claim that \"above/below diagonal\" is more intuitive. This makes the claim 3, as the authors may find it challenging to fully understand and address the issue without additional context or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion to improve the clarity of the plot by using \"above/below diagonal\" instead of \"above/below 45 degree.\" This feedback is actionable and offers a clear and concise way for the authors to enhance the interpretability of their plot, which is a valuable contribution. However, the comment could be more helpful if it explained why \"above/below diagonal\" is more intuitive or provided examples of how this change might improve the plot. Overall, the comment is 4 as it identifies a specific area for improvement and offers a clear suggestion for enhancing the clarity of the plot."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the phrasing in lines L240 and L428, specifically asking for clarification on what is meant by \"is sufficient.\" The reviewer implies that the authors might be trying to convey that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. However, the comment does not provide explicit guidance on how to clarify this point or what specific changes should be made to improve the clarity. While the action is implied, it is not directly stated, and the authors are left to infer the necessary changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, \"L240\" and \"L428,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the phrasing and suggesting that the authors might be trying to convey that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the phrasing in lines L240 and L428, specifically asking for clarification on what is meant by \"is sufficient.\" The reviewer provides a logical interpretation of what the authors might be trying to convey, suggesting that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. However, the comment lacks specific examples or references to support this interpretation, making it 3. The authors would need to infer the intended meaning and potentially revise the phrasing to align with the reviewer\"s suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the phrasing in lines L240 and L428, questioning what is meant by \"is sufficient.\" The reviewer provides a logical interpretation of what the authors might be trying to convey, suggesting that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This feedback is 3 as it points out a potential area for clarification and improvement in the draft. However, it lacks specific suggestions or guidance on how to clarify the phrasing or what changes to make to enhance the clarity. While it highlights an issue, the comment could be more actionable with additional details or examples. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of clarity regarding the scientific insight provided by the model and formalism over prior taskoptimized approaches. It specifically questions whether the model is a prototype approximation to nonlinear RNN models that exhibit emergent behavior. The reviewer does not provide explicit guidance on how the authors should address this issue, but the implication is that they should provide a clearer explanation of the scientific insight and the relationship between their work and prior taskoptimized approaches. While the comment is somewhat vague, it does point out a specific area that needs clarification, making it 3. The authors can infer that they need to provide a clearer explanation of their work and its relationship to prior approaches, but the exact steps for doing so are not explicitly stated.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scientific insight provided by the model and formalism over prior taskoptimized approaches. The comment highlights a lack of clarity regarding the relationship between the model and nonlinear RNN models that exhibit emergent behavior. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the scientific insight provided by the model and formalism over prior taskoptimized approaches. It specifically mentions that the model is not shown to be a prototype approximation to nonlinear RNN models that exhibit emergent behavior, which is a critical point for understanding the contribution of the work. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to provide additional evidence or reasoning to fully substantiate the claim, such as comparisons with existing models or detailed explanations of the model\"s relationship to emergent behavior. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically questioning the scientific insight provided by the model and formalism over prior taskoptimized approaches. It points out that the model is not shown to be a prototype approximation to nonlinear RNN models that exhibit emergent behavior, which raises concerns about the contribution of the work. The comment highlights a critical area for clarification, suggesting that the authors need to provide a clearer explanation of how their model relates to emergent behavior and how it differs from prior approaches. While the comment identifies a crucial weakness, it could be more helpful if it offered specific suggestions on how the authors might address this issue or what additional information would be needed to clarify the scientific insight. Overall, the comment is 3 as it points out a significant gap in the paper but lacks detailed guidance on how to resolve it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to make the texts in legends and axis labels larger, similar to the text size. It also clarifies the confusion between Proposition (1) and Equation 1 and suggests increasing the font size of captions and legends in Figures 2 and 3. These actions are direct and concrete, providing clear guidance on how to improve the draft. The authors know exactly what changes to make, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the legends and axis labels, and the beginning of page 6, where Proposition (1) is mentioned. It also specifies the issue with the confusion between Proposition (1) and Equation 1. Additionally, it provides specific guidance on font size and clarifies the issue with captions and legends in Figures 2 and 3. This level of detail provides clear direction for the authors to address the issues raised. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the font size of legends and axis labels, suggesting that they should be larger to improve readability. The comment provides a specific example of the confusion between Proposition (1) and Equation 1, which supports the claim. Additionally, it suggests increasing the font size of captions and legends in Figures 2 and 3, providing a clear and actionable suggestion for improvement. This level of detail and specificity makes the claim 4, as it provides a logical basis and examples for the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on improving the readability of the paper. It identifies issues with the font size of legends and axis labels, noting that they should be larger to enhance clarity. Additionally, it points out the confusion between Proposition (1) and Equation 1, suggesting that the former should be labeled as Proposition 1. The comment also suggests increasing the font size of captions and legends in Figures 2 and 3, which is a clear and constructive suggestion for improving the presentation of the figures. Overall, the comment is 5 as it offers detailed guidance on how to improve the readability and clarity of the paper, providing the authors with specific and actionable steps to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should include a comparison against Journey TRAK in their counterfactual experiments. It specifies that this comparison should be made at a particular step of the sampling trajectory, referring to Figure 2 in Journey TRAK. This provides a clear and concrete action for the authors to take, as they are given specific steps to follow in order to enhance their experimental analysis. The comment is 5 because it provides a direct and specific request for improvement, ensuring that the authors know exactly what needs to be done to address the feedback.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the counterfactual experiments and suggests a comparison against Journey TRAK, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be added, specifically a comparison against Journey TRAK at a particular step of the sampling trajectory, as shown in Figure 2. This provides clear guidance on what the authors should include in their experiments to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a comparison against Journey TRAK should be included in the counterfactual experiments. The reviewer provides a specific reference to Figure 2 in Journey TRAK, which shows a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This provides a logical basis for the claim, as it suggests that including this comparison could enhance the understanding of the results. However, the comment could be strengthened by providing more detailed reasoning or examples from Journey TRAK to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the counterfactual experiments in the paper. It suggests including a comparison against Journey TRAK, which is a relevant work in the field, at a particular step of the sampling trajectory. This feedback is valuable as it offers a clear direction for the authors to enhance their experimental analysis and potentially strengthen their results. By incorporating this comparison, the authors can demonstrate a more comprehensive understanding of their method\"s performance and its implications. However, the comment could be more helpful if it provided additional context or rationale for why this comparison is important or how it might impact the results. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the description of the VAD is puzzling and suggests that the authors should clarify what they mean by \"discarding TF bins with a magnitude of less than epsilon.\" It also notes that this approach is not consistent with a VAD, which is supposed to look for speech presence and is unlikely to be defined over frequency. The comment implies that the authors should reconsider their definition and approach to VAD. While the action is implicit, it is clear and provides a direction for the authors to take, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is problematic with the VAD description, namely that it discards TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. The comment further explains that a VAD should look for speech presence and is unlikely to be defined over frequency, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the VAD description is puzzling and suggests that the authors are discarding TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. The reviewer argues that a VAD should look for speech presence and is unlikely to be defined over frequency, which is a common understanding in the field. The comment provides a logical reasoning and references common knowledge about VADs, making it 4. However, it could be strengthened by providing specific references or examples to support the claim about VADs and their definition. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the description of the VAD, noting that it discards TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. It points out that a VAD should look for speech presence and is unlikely to be defined over frequency, providing a clear and actionable suggestion for improvement. The comment highlights a critical misunderstanding in the paper that could lead to incorrect conclusions, making it 5 for the authors to address this issue. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests including a brief discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, namely the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This feedback is explicit and provides concrete guidance on what the authors should add to their discussion. The action is clear and leaves no ambiguity, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"discussion\" and \"Section 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the empirical motivation for a timevarying Q ^ t and S t , and provides an example of what could be explored, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals. This level of detail provides clear guidance on what the authors need to address, making the comment 5.", "verifiability_rationale": "The review point suggests including a discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one. The reviewer provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This suggestion is based on logical reasoning and provides a clear direction for improvement. However, the comment could be strengthened by referencing specific studies or examples to support the claim. Overall, the claim is 4, as it provides a logical basis for the suggestion but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the draft. It highlights the need for a discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one, which is a critical aspect of the paper. The comment offers a specific example of what could be explored, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This feedback is valuable as it guides the authors to enhance their discussion section with relevant insights, which could strengthen the paper\"s argument. However, the comment could be more helpful if it included references to similar studies or examples that support the need for a timevarying Q ^ t and S t. Overall, the comment is 4 as it provides a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. It also mentions that the experiments have little to hang on to. However, it does not provide any specific guidance or suggestions on how the authors could improve the clarity or coherence of the paper. The comment implies that the authors should make their work more accessible and easier to understand, but it does not offer concrete steps or examples of what changes could be made. As a result, the comment is vague and lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment suggests that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not specify which parts of the paper are particularly challenging or where the lack of clarity is most prominent. Without specific references to sections, figures, or experiments, the authors cannot confidently determine which parts need improvement. Additionally, the comment does not provide specific guidance on how to enhance the clarity or coherence of the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not provide any specific examples or detailed reasoning to support this claim. The comment suggests that the experiments lack something to hang on to, but it does not specify what that \"something\" is or how it could be improved. Without concrete evidence or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, stating that it is not easy to follow and lacks a clear intuition for how the pieces fit together. It also notes that the experiments lack something to hang on to, which further undermines the paper\"s coherence. However, the comment does not provide specific suggestions or guidance on how the authors could improve the clarity or coherence of their work. While it highlights a critical area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it points out a significant weakness but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of the comparison between the student and refinement networks, suggesting that the teacher network\"s performance may be improved by training them simultaneously. The reviewer explicitly requests KID/FID metrics for the teacher network, providing a clear and concrete action for the authors to take. This guidance is explicit and specific, leaving no ambiguity about what needs to be done to address the concern. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the training of the student and refinement networks, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the fairness of the comparison and requests KID/FID metrics for the teacher network. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the fairness of the comparison between the student and refinement networks, suggesting that training them simultaneously may improve the performance of the teacher network. However, it does not provide any evidence, reasoning, or examples to support this claim. The request for KID/FID metrics is a logical step to take, but without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison between the student and refinement networks, suggesting that training them simultaneously may improve the performance of the teacher network. It prompts the authors to provide KID/FID metrics for the teacher network, which is a clear and actionable request. This feedback is 3 as it points out a potential area for improvement and provides a specific direction for the authors to follow. However, it could be more helpful if it included additional context or explanation about why this comparison is important or how it might impact the overall evaluation of the work. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the refined region vector, specifically questioning whether the attention weight is scaled before being used in the calculation. The reviewer suggests that having a scaling variable before the attention weight might help. While the comment implies that the authors should consider this suggestion, it does not provide explicit instructions or concrete guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding a scaling variable before the attention weight. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the refined region vector and suggests that having a scaling variable before the attention weight might help. The comment provides a clear direction for improvement by asking whether the refined vector scales only the most important regions before global pooling. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the refined region vector, specifically the scaling factor applied to the attention weight before global pooling. The reviewer suggests that having a scaling variable before the attention weight might help. However, the comment lacks specific reasoning or evidence to support why this change would be beneficial or how it would affect the results. Without detailed justification or examples, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the refined region vector, specifically the scaling factor applied to the attention weight before global pooling. It suggests that having a scaling variable before the attention weight might help. This feedback is 3 as it prompts the authors to consider a potential improvement in their methodology. However, the comment lacks depth and does not provide specific guidance or examples on how to implement this suggestion or what potential benefits it might have. While it points out a potential area for improvement, it could be more helpful with additional details or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the LLM not accurately recovering the formal goal predicate, especially when faced with ambiguities in human language. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the LLM\"s accuracy or how to handle ambiguities in human language. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to goal misspecification in the LLM, particularly when faced with ambiguities in human language. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem of goal misspecification and its consequences, such as failures on the ALFRED benchmark. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark often occurred due to goal misspecification, where the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the LLM, noting that failures on the ALFRED benchmark often occurred due to goal misspecification. It highlights that the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. This feedback is valuable as it points out a critical area for improvement in the LLM\"s performance. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific techniques or approaches to improve goal misspecification. Despite this, the comment still offers a clear direction for the authors to improve their draft, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. It also raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV. While the comment provides a clear direction for the authors to take, it lacks specific guidance on how to conduct the analysis or what specific aspects of the analysis should be focused on. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"improvement of this method over SOTA methods such as IGEV,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the distribution of disparities produced by IGEV compared to other baselines, suggesting that this analysis could help determine why the effect is not significantly improved on IGEV. Additionally, it raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the improvement of the method over SOTA methods like IGEV is small, and questions whether there is no multipeak distribution problem in iterative optimization schemes similar to IGEV. The reviewer suggests analyzing the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. The comment also raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks like IGEV. While the comment provides a logical basis for the claim, it lacks specific examples or references to support the assertion about the distribution of disparities or the difficulty of SamplingGaussian. This makes the claim 3, as it requires further elaboration to fully substantiate the claims.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. This feedback is valuable as it directs the authors to a specific area for further investigation, which could lead to a deeper understanding of the method\"s performance and potential limitations. Additionally, the comment raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV, prompting the authors to consider this aspect in their analysis. Overall, the comment is 4 as it offers clear and actionable guidance for improving the draft. However, it could be more comprehensive by providing additional context or examples to support the claims made. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should provide modelspecific insights by investigating how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It also recommends presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment provides a clear action to take, it does not specify how to conduct this investigation or what specific aspects of the models should be analyzed. The authors are given a general direction but may need to infer the details of how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ModelSpecific Insights\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the investigation into how specific models behave differently when ReGuide is applied and the presentation of differences in false positive rates (FPR) between models with and without ReGuide. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper focuses on generic findings across models and recommends a deeper investigation into how specific models behave differently when ReGuide is applied. The reviewer provides a specific example of GPT4o and InternVL2, suggesting that differences in false positive rates (FPR) should be presented for a better comparison. This claim is 3 as it provides a logical suggestion for enhancing the paper\"s analysis, but it lacks detailed evidence or references to support the claim that these specific models behave differently. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It suggests presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This feedback is valuable as it directs the authors to a specific area where their analysis could be more nuanced and detailed, offering a clear path for improvement. However, the comment could be more helpful if it provided additional guidance on how to conduct this investigation or what specific aspects of the models should be analyzed. Overall, the comment is 4 as it identifies a meaningful area for enhancement and offers actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper should include results using the GCPG model without pretrained initializations to clarify the contribution of the task formulation and pretrained language models. This is a clear and direct action for the authors to take, as it provides a specific step to address the issue of attribution. The comment is specific in detailing what additional results are needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for results using the GCPG model without pretrained initializations, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of the contribution due to the task formulation and pretrained language models. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks ablations, specifically the results without pretrained language models. The reviewer claims that it is unclear how much performance gain is due to the task formulation and how much is due to pretrained language models. The suggestion to include results using the GCPG model without pretrained initializations is a logical request to clarify the contribution of the task formulation. However, the comment does not provide specific examples or references to support the claim that the current results are unclear. This makes the claim 3, as the authors would need to make a logical inference to understand the basis of the suggestion.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of ablations to clarify the contribution of the task formulation and pretrained language models. It provides a clear and actionable suggestion by recommending the use of the GCPG model without pretrained initializations. This feedback is valuable as it guides the authors to conduct additional experiments that can help clarify the impact of their task formulation and the role of pretrained models. However, the comment could be more helpful if it explained why the current results are unclear or how the additional ablations would enhance the understanding of the paper\"s contribution. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the authors should consider presenting results on ImageNet to enhance the convincingness of their proposed method. While the comment implies that the authors should include these results, it does not provide specific guidance on how to conduct the experiments or what aspects of the results should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should include results on ImageNet to improve the paper\"s credibility. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that results on ImageNet could be more convincing for the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as the results section or the methodology. Without explicit references to sections or specific results, the authors cannot confidently determine which parts need to be addressed. The comment is 1 and lacks specificity, making it difficult for the authors to understand and act upon the suggestion. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that results on ImageNet could be more convincing for the proposed method. However, it does not provide any supporting evidence, reasoning, or examples to justify why this would be beneficial or how it would enhance the credibility of the method. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that results on ImageNet could be more convincing for the proposed method. However, it does not provide specific guidance or examples on how to achieve this or what aspects of the results on ImageNet would be most impactful. Without detailed feedback or actionable steps, the authors are left with a general suggestion that lacks depth and specificity. Therefore, the comment is 2, as it identifies a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the insufficiency of the contribution and suggests that the authors should further explore how to leverage the connection between complementary and model robustness to improve model robustness. While the comment implies that more insightful findings or solutions should be included, it does not provide specific guidance on what these findings or solutions should be. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their analysis to be more comprehensive. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the contribution of the paper, specifically the connection between complementary and model robustness. It suggests that while the authors have studied this connection, they have not explored how to leverage these characteristics to improve model robustness. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, namely, more insightful findings or solutions to improve model robustness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution is insufficient and suggests that the authors should further explore how to leverage the connection between complementary and model robustness to improve model robustness. The reviewer provides a logical reasoning by stating that the conclusion is easily and intuitively obtained, given the relationship between multimodal complementary and robustness. However, the comment lacks specific examples or references to support the claim that the contribution is insufficient or to suggest how to improve it. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a significant concern about the contribution of the paper, noting that while the authors have studied the connection between complementary and model robustness, they have not explored how to leverage this connection to improve model robustness. The reviewer suggests that the conclusion is easily and intuitively obtained, and that more insightful findings or solutions should be included. However, the comment does not provide specific guidance or suggestions on how the authors might expand their analysis or what additional insights could be explored. While it highlights a potential area for improvement, the feedback lacks actionable details, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors should focus on what the differences in representation are between clusters rather than on which clusters are \"best.\" However, it does not provide explicit guidance on how to implement this change or what specific aspects of the representation differences should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should prioritize the differences in representation over the selection of \"best\" clusters. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the focus on which clusters are \"best\" is an odd choice given the motivation of the paper. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where this focus is discussed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the representation differences should be prioritized over the selection of \"best\" clusters. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that focusing on which clusters are \"best\" rather than the differences in representation between them is an odd choice given the motivation of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or unaligned with the paper\"s goals. Without specific examples or detailed explanations, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential inconsistency in the paper\"s focus, suggesting that the authors should prioritize the differences in representation between clusters rather than which clusters are considered \"best.\" This feedback is 3 as it identifies an area where the paper may not align with its stated motivation. However, the comment lacks specific guidance on how to address this issue or what aspects of the representation differences should be emphasized. While it highlights a potential weakness, it does not provide actionable steps for the authors to improve their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to correct the caption. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the caption for Figure 7, and provides the correct label (\"Edge Dynamics\"). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why the current caption is incorrect or how the suggested correction would improve clarity. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific error in the caption for Figure 7, noting that it should be corrected from \"Node Dynamics\" to \"Edge Dynamics.\" This is a clear and actionable piece of feedback that can help the authors improve the accuracy and clarity of their paper. By addressing this issue, the authors can ensure that their figures accurately reflect the content of their work, which is an important aspect of scientific communication. However, the comment could be more helpful if it provided additional context or suggestions on how to improve the figure captions in general. Overall, the comment is 4 as it directs the authors to a specific correction but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer requests clarification on the rationale for considering these factors as separate evaluations. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for their evaluation criteria. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the traditional DCI framework and questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The comment is specific in its critique of the evaluation criteria and provides a logical explanation of how they might be entangled. However, it does not explicitly mention which part of the paper discusses these evaluation criteria, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer provides a logical explanation of how these factors might be entangled, suggesting that changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment lacks specific examples or references to support the claim that these factors are already considered within the framework. This makes the claim 3, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer provides a logical explanation of how these factors might be entangled, suggesting that changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify their motivation for considering these factors as separate evaluations. While it identifies a potential area for clarification, the feedback is 3 as it points out a potential weakness in the paper but does not provide actionable steps for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This feedback is clear and provides a specific action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is concrete, as it specifies the need for clarification and provides a direction for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section\" of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies what needs to be clarified: the standard deviation after multiple experiments and the improvement brought by SoRA compared to the baseline. The comment provides guidance on how to address this issue by suggesting the authors clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the improvement brought by the SoRA method is limited due to random fluctuations, suggesting that the standard deviation after multiple experiments is not provided. The comment provides a logical reasoning by pointing out that the improvement may be due to random fluctuations, but it lacks specific examples or references to support this claim. The authors are left to infer the significance of the standard deviation and its impact on the results, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental section of the paper, noting the lack of standard deviation after multiple experiments. It also points out that the improvement brought by the SoRA method is limited, which may be due to random fluctuations. The comment provides clear and actionable feedback by suggesting that the authors clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This guidance is valuable as it helps the authors understand the significance of their results and how to present them more effectively. However, the comment could be more helpful if it offered suggestions on how to address the issue of limited improvement or how to better present the results. Overall, the comment is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. While the comment provides explicit actions for the authors to take, such as increasing font size and ensuring proper placement, it does not offer detailed guidance on how to address these issues. The authors are left to infer the specific steps needed to improve the organization and layout of their paper. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Figure 1,\" \"Figure 2,\" \"Table 2,\" and \"page 6,\" allowing the authors to accurately identify the areas being addressed. It also specifies the issues with the layout, such as the font size and placement of figures and tables, and the formatting of the top two lines on page 6. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper is not wellorganized and that the layout is rushed, providing specific examples such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. These examples are detailed and provide clear justification for the claim, making the comment 4. However, the comment could be strengthened by providing additional examples or references to similar issues in other papers, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific issues with the paper\"s organization and layout, providing detailed examples of formatting errors and layout inconsistencies. It highlights issues such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. By pointing out these errors, the comment offers actionable feedback that can help the authors improve the clarity and professionalism of their paper. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as recommending specific font sizes or layout improvements. Overall, the comment is 4 as it identifies areas for improvement but lacks detailed guidance on how to implement the suggested changes."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, it does not provide specific guidance on how to assess or address these concerns. The authors are left to infer that they need to consider practicality and safety, but without concrete steps or examples on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, it does not specify which part of the paper this issue pertains to, such as the intervention section or the results section. The authors can infer that it relates to the intervention or querying aspects, but this inference is not direct. The comment is specific in its suggestion to consider practicality and safety, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate why these considerations are necessary or how they would impact the paper\"s findings. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the practicality and safety of the interventions included. It suggests that while the types of interventions are reasonable computationally, they need to be considered in terms of their practicality and safety for querying in the real world. This feedback is 3 as it points out an important aspect that the authors should address, but it lacks specific guidance or suggestions on how to assess or improve the practicality and safety of the interventions. The authors are left with a general direction to consider, but the comment could be more helpful with additional details or examples. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific changes they could make to support the integration of images and their augmentations. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not specify which part of the paper this idea is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the idea are questionable or how it could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\"s skepticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses skepticism about the idea that images and their augmentations need to be treated separately, suggesting that they can be interchangeable. However, it does not provide any specific reasoning or evidence to support this claim or offer suggestions for how the authors might address this concern. Without actionable feedback or detailed guidance, the comment does not assist the authors in improving their draft. Therefore, it is rated as 2, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should evaluate their proposed method separately from baseline detection or parsing techniques to better support their claim of performance gain. This feedback provides a clear and explicit action for the authors to take, which is to conduct separate evaluations of their method and baseline techniques. The suggestion is concrete, as it specifies the need for separate evaluations and provides a rationale for why this is important. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"generative shape model\" and the \"word parsing model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that it is unclear which component contributes to the performance gain and recommends evaluating the method separately from baseline detection or parsing techniques. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that it is unclear which component of the proposed method contributes to the performance gain, and suggests that evaluating the method separately from baseline detection or parsing techniques would better support the claim. The comment provides a logical reasoning by suggesting that the proposed approach follows a detectionparsing paradigm, which implies that evaluating separately would be beneficial. However, the comment lacks specific examples or references to support the claim, such as mentioning which baseline techniques should be used or providing data to substantiate the claim. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed method, noting that it is unclear which component contributes to the performance gain. It suggests that evaluating the method separately from baseline detection or parsing techniques would better support the claim. This feedback is clear and actionable, as it provides a specific direction for the authors to take in order to improve the clarity and robustness of their work. By recommending separate evaluations, the comment offers a concrete way for the authors to address the identified weakness and enhance the credibility of their claims. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the method is not clear about its behavior without the Lipschitz Hessian assumption. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or what specific actions they should take to clarify the behavior. The comment lacks guidance on whether the authors should provide additional analysis, simulations, or explanations to address this concern. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Lipschitz Hessian assumption,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the method\"s behavior without the Lipschitz Hessian assumption. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment claims that the method\"s behavior is not clear without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the clarity of the method\"s behavior without the Lipschitz Hessian assumption. This is a relevant point that could impact the understanding and applicability of the method. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific aspects of the method need clarification. While it points out a potential weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some of the pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the presentation or clarify the use of existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"equation (12)\" and \"the presentation of these methods,\" which provides some grounding as it refers to specific parts of the paper. However, it does not specify which sections or parts of the paper these references pertain to, making it weakly grounded. The comment is specific in pointing out the issue of vagueness in the presentation of existing methods, such as equation (12), and the need for clarity in understanding these methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks specific references or examples to substantiate the claim, making it difficult for the authors to understand the exact issues and address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some pieces rely on existing methods, such as equation (12), and that the presentation of these methods is vague. This feedback is 3 as it points out a potential weakness in the paper\"s originality and clarity. However, the comment lacks specific suggestions or guidance on how to improve the presentation or clarify the use of existing methods. Without actionable advice or detailed feedback, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include the results for all four datasets in Table 4, which provides a clear and direct action for the authors to take. The comment is specific in identifying the missing information and offers a concrete step to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the table, namely the results for all four datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 4 is incomplete and should include results for all four datasets. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, providing the authors with a direct and concrete step to improve their draft. By addressing this issue, the authors can enhance the comprehensiveness and accuracy of their results, which is valuable guidance for improving the paper. Therefore, the comment is rated as 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, it does not provide any specific guidance or suggestions on how the authors could improve the contribution or make it more novel. The comment lacks actionable details, such as recommending new approaches or improvements to the pipeline. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, it does not specify which part of the paper this assessment is based on, such as the methodology, results, or discussion sections. Without explicit references to specific sections, the authors cannot confidently determine which parts need revision. The comment is specific in its critique of the contribution being incremental, but it lacks grounding as it does not point to a particular part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the assertion that the pipeline is a \"pack of tricks\" or that the contribution is incremental. Without such support, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. It implies that the pipeline is a collection of tricks to improve defense evaluation, which could be seen as a negative critique. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors could enhance the novelty or impact of their work, nor does it suggest alternative approaches or improvements. As a result, the comment is not helpful, as it does not provide the authors with any meaningful insights or direction for enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuples instead of sets to better illustrate their tuplelike structure. This is a clear and direct action for the authors to take, as it provides a specific guidance on how to improve the presentation of their data. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the presentation of triples as tuples instead of sets. This provides clear guidance on how to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuples instead of sets to better illustrate their tuplelike structure. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to improve the clarity of the paper by recommending that the triples denoted as $(e_1, r, e_2)$ be presented as tuples instead of sets. This feedback is clear and directly addresses a potential issue with the presentation of the data, which could enhance the readability and understanding of the paper. By following this suggestion, the authors can improve the clarity and precision of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the scalability of optimal quantization, which is mentioned in the paper. It points out that even with clustering before, the cost of quantization is high in terms of both the number of data (N) and the dimension (M). The reviewer notes that the paper aims to speed up VI by achieving fast convergence, which is crucial for big data/big model settings. However, the reviewer suggests that the quantization is a bottleneck for this, making the method lose its purpose. While the comment identifies a potential issue, it does not provide explicit guidance on how to address this scalability problem or suggest specific actions to improve the scalability of the quantization. The authors are left to infer that they need to address this issue, but without concrete steps, the comment remains 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of scalability in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the problem of quantization being a bottleneck for the method, which is crucial for the authors to understand and address. The comment is specific because it clearly outlines the issue with scalability and the impact on the method\"s purpose. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, which is mentioned in the paper. It also notes that even with clustering before, the cost of quantization is high in terms of both N (number of data) and M (dimension). The reviewer further explains that the paper aims to speed up VI by achieving fast convergence, which is crucial for big data/big model settings. However, the reviewer suggests that the quantization is a bottleneck for this, making the method lose its purpose. The claim is supported by logical reasoning and references to the paper, providing a clear understanding of the issue and its implications. Therefore, the comment is 5, aligning with a score of 5.", "helpfulness_rationale": "The review comment identifies a critical issue with the scalability of optimal quantization, which is mentioned in the paper. It points out that even with clustering before, the cost of quantization is high in terms of both the number of data (N) and the dimension (M). This is a significant concern, as it affects the speed of VI (variable importance) and the method\"s purpose in big data/big model settings. The comment highlights the bottleneck created by quantization, which could hinder the method\"s effectiveness. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the scalability of the quantization. While it raises an important point, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a weakness in the assumption that the Pearson correlation coefficient (PCC) is more relaxed than KL divergence due to its invariance to scale and shift. It suggests that the authors should provide a gradient comparison between KL and PCC to substantiate this claim. This feedback is clear and concrete, as it specifies exactly what needs to be done to address the issue. The authors know exactly how to apply this suggestion to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient (PCC),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the assumption that PCC is more relaxed than KL divergence due to its invariance to scale and shift. The comment provides a logical reasoning for why this assumption is not convincing and suggests a comparison between the gradients of KL and PCC to substantiate the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the assumption that the Pearson correlation coefficient (PCC) is more relaxed than KL divergence due to its invariance to scale and shift. The reviewer provides a logical reasoning by comparing the gradient distribution of KL and PCC, suggesting that this comparison is necessary to substantiate the claim. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the gradient comparison themselves to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a key assumption in the paper regarding the relative relaxation of the Pearson correlation coefficient (PCC) compared to KL divergence. It challenges this assumption by pointing out that the constraint strength of a loss function is defined by its gradient distribution, and provides a logical reasoning for why this comparison is necessary. The comment suggests that the authors should provide a gradient comparison between KL and PCC to substantiate their claim. This feedback is clear and actionable, as it guides the authors on how to address a critical aspect of their argument. However, it could be more helpful if it included specific examples or references to similar comparisons in the literature. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. While the comment implies that the authors should provide additional analysis or discussion, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the reproducibility of GPI with noise added and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. The comment also mentions the suitability of the approach for pattern separation tasks and suggests discussing this aspect. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. However, the comment lacks specific examples or references to support the claim about the fit of GPI with behavioral data or the suitability of the approach for pattern separation tasks. The suggestion for discussion is somewhat vague, as it does not provide detailed guidance on what aspects of the discussion should be included. Therefore, the comment is 3, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises several pertinent questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. While the comment identifies potential weaknesses and areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or what specific measures could be used to demonstrate the fit of GPI with behavioral data. The feedback is 3 as it points out areas for further exploration and discussion, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that if the authors have the resources, they should compare the \"small learning rate for attention parameters\" benchmark with the proposed approach. This is an explicit action that the authors can directly infer and implement. However, the comment does not provide specific guidance on how to conduct the comparison or what aspects to focus on, leaving some room for interpretation. Therefore, the action is explicit but somewhat vague in terms of execution. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach, but it does not specify which part of the paper this suggestion pertains to. The authors can infer that it relates to the discussion of the attention parameters or the experimental results, but this inference is not direct. The comment is specific in suggesting a comparison but lacks grounding as it does not explicitly mention a section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison would be valuable or how it would contribute to the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach, which could provide valuable insights into the performance of the proposed method. However, the comment lacks specificity and does not offer guidance on how to conduct this comparison or what aspects to focus on. Without detailed instructions or examples, the authors may find it challenging to implement this suggestion effectively. Therefore, the comment is 3 as it identifies an area for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the comparison of methods, noting that the proposed method uses AdamW with cosine lr for training, while the other methods only use Adam with a fixed lr. The reviewer suggests that directly comparing the results is unfair and recommends reproducing the results using the same setting as the other methods, which have their code released. This feedback provides a clear and explicit action for the authors to take, which is to reproduce the results using the same setting as the other methods. The suggestion is concrete and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of AdamW with cosine lr for training and the comparison of methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, suggesting that directly comparing results is unfair due to the different training settings. This provides clear guidance on what needs to be addressed to ensure fair comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that directly comparing results is unfair due to the different training settings, specifically mentioning the use of AdamW with cosine lr for training in the proposed method. The comment suggests that reproducing the results using the same setting as the other methods, which have their code released, would be more fair. This claim is 3 as it logically points out a potential issue with the comparison, but it lacks specific examples or references to support the claim fully. The authors would need to infer the specifics of the issue and determine how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of methods, noting that the proposed method uses AdamW with cosine lr for training, while the other methods only use Adam with a fixed lr. This observation highlights a potential bias in the comparison, as the different training settings could affect the results. The comment suggests that reproducing the results using the same setting as the other methods, which have their code released, would be more fair. This feedback is clear and actionable, providing the authors with a specific direction to address the issue and ensure a more accurate comparison. However, the comment could be more helpful if it included suggestions on how to reproduce the results or what specific aspects of the comparison should be considered. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear path for addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to conduct this analysis or what specific aspects to focus on. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not specify which part of the paper this curiosity pertains to, such as a specific section or experiment where this combination is discussed. Without explicit references or clear indications, the authors cannot confidently determine which part of the paper should be addressed. Additionally, the comment lacks specificity regarding what aspects of the SOTA method or adaptive metric should be explored or how the performance should be evaluated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not present any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The comment raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it identifies an area of interest, it lacks specificity and actionable guidance for the authors. It does not provide details on what aspects of the SOTA method or adaptive metric should be explored or how the performance should be evaluated. Without concrete suggestions or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the plots are \"terrible\" and provides specific issues with them, such as their small size, difficulty in distinguishing colors, unclear labeling, and visually similar labels. It also mentions that these issues are the main presentation of the experimental results and affect the clarity of the paper. The comment provides clear and concrete actions for the authors to take, such as making the plots larger, improving color distinction, and labeling the axis and labels more clearly. Additionally, it suggests that the authors should make the plots more visually distinct. This level of detail and specificity makes the comment 5, as the authors know exactly what changes to make to improve the clarity and presentation of their results.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"plots\" and \"plots are terrible,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the plots, such as their small size, difficulty in distinguishing colors, unclear labeling, and visually similar labels. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the plots are \"terrible\" due to their small size, difficulty in distinguishing colors, unclear labeling, and visually similar labels. The reviewer provides specific examples, such as pink vs red, sdropout(tr) vs edropout(tr), and unclear axis labels, to support the claim. This detailed description and examples provide a clear rationale for the claim, making it 4. However, the comment could be strengthened by referencing specific sections or figures where these issues are most prominent, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on the quality of the plots, which are the main presentation of the experimental results. It identifies several issues with the plots, such as their small size, difficulty in distinguishing colors, unclear labeling, and visually similar labels. By pointing out these issues, the comment empowers the authors to make significant improvements to the clarity and presentation of their results. Additionally, it highlights the importance of these improvements by noting that the clarity of the paper is rated as \"substandard,\" which further motivates the authors to address these concerns. Overall, the comment is clear, detailed, and provides a clear path for the authors to enhance the quality of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the performance gains are not very high, with most of the metrics showing a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it offer guidance on how to address the issue of low performance gains. As a result, the comment lacks actionability, leaving the authors without any direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the performance gains of the paper, specifically mentioning that most of the metrics show a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, it does not specify which metrics or parts of the paper this analysis is based on, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the performance gains, but it lacks grounding as it does not reference specific sections or metrics. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance gains are not very high, with most of the metrics showing a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a specific issue with the performance gains of the paper, noting that most of the metrics show a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). This is a clear and actionable observation that can guide the authors in understanding the limitations of their work. However, the comment could be more helpful if it provided suggestions on how to improve the performance gains or addressed potential sources of variability in the results. Overall, the comment is 3 as it identifies a specific area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a series of questions about the impact of the information about incorrect and corrected phrases and the type of mistake on the feedback network. It also asks about the performance without and with each of these two types of information and the performance with just natural language feedback. While the questions imply that the authors should analyze and present this information, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this analysis and present the results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"information about incorrect phrase / corrected phrase and the information about the type of the mistake,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the impact of this information on the feedback network and the performance without and with each of these two types of information. Additionally, it asks about the performance with just natural language feedback. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point poses a series of questions about the impact of certain types of information on the feedback network. It does not make any subjective claims or judgments that require verification. The questions are factual and seek clarification, making them purely descriptive and not requiring verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a series of questions about the impact of certain types of information on the feedback network, specifically asking about the performance without and with each of two types of information and the performance with just natural language feedback. This is a thoughtful and insightful question that prompts the authors to consider the effectiveness of their approach in different scenarios. However, the comment does not provide specific suggestions or guidance on how to address these questions or what specific analyses should be conducted. While it points out an area for further exploration, it lacks actionable advice or detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific issue with Table 1, noting that it does not show standard deviations. It suggests that this omission would make the submission stronger if the experiments were more extensive. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to include standard deviations. The action is implied, as the authors can infer that they need to include standard deviations in Table 1, but it remains vague due to the lack of concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of standard deviations in Table 1. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 1 does not show standard deviations, which would make the submission stronger if the experiments were more extensive. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this omission is significant or how it affects the overall strength of the submission. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it does not show standard deviations. This is a clear and actionable point that could significantly improve the paper by including this information. However, the comment could be more helpful if it provided suggestions on how to present the standard deviations or why they are important for the reader to understand. While it highlights a critical area for improvement, the comment lacks depth and specific guidance, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be expanded to include attacks on other architectures and classification tasks beyond neural networks and image classification. While the comment implies that the authors should consider conducting experiments on these additional tasks, it does not provide specific guidance on how to implement these changes or what specific architectures or tasks should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests expanding the experiments to include attacks on other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which parts of the paper these experiments should be added to or which specific architectures or tasks should be considered. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment is not specific about what aspects of the experiments should be expanded or how they should be conducted. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the experiments are limited to neural networks and image classification tasks and recommends expanding them to include attacks on other architectures and classification tasks. However, the comment does not provide any supporting evidence, examples, or references to justify why this expansion is necessary or beneficial. Without additional context or reasoning, the authors may find it challenging to understand the basis of the suggestion and how it could improve their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests expanding the experiments to include attacks on other architectures and classification tasks beyond neural networks and image classification. This feedback is 3 as it identifies a potential area for improvement in the paper, which could enhance its scope and relevance. However, the comment lacks specific guidance on which architectures or tasks should be considered or how the authors might implement these changes. While it points out a potential gap in the experiments, it does not provide detailed suggestions or examples to help the authors effectively address the issue. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. It also points out that if the mitigation strategies significantly impair the model\"s utility, it could deter their adoption. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to mitigate the potential impact. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the potential impact of their mitigation strategies on performance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the mitigation strategies aimed at reducing memorization and questions their impact on the overall performance of the model. It suggests that there might be a tradeoff between reducing a particular behavior and maintaining high performance, and points out that significant impairment of the model\"s utility could deter adoption. However, the comment does not specify which part of the paper discusses these mitigation strategies, making it weakly grounded. The comment is specific in its concern about the potential impact on performance, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. It also points out that if the mitigation strategies significantly impair the model\"s utility, it could deter their adoption. However, the comment lacks specific examples or references to support the claim about the potential impact on performance. Without detailed evidence or examples, the claim is 3, as it provides a logical argument but lacks the necessary substantiation to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation strategies, suggesting that their impact on overall performance is unclear. It raises a concern about the tradeoff between reducing a particular behavior and maintaining high performance, and points out that significant impairment of the model\"s utility could deter adoption. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this issue or what specific mitigation strategies might be more effective. The feedback is 3 as it prompts the authors to consider the potential impact of their mitigation strategies on performance, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. It suggests that additional experiments or more indepth analysis are needed to justify the claims in the paper. While the comment implies that the authors should conduct additional experiments or analysis, it does not provide explicit instructions on how to do so. The action is clear but somewhat vague, as the authors know they need to conduct additional experiments but may not be entirely sure of the specifics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results presented in the table, noting that the proposed approaches only outperform the baselines in one setup and that there is no consistent trend in the results. The comment suggests that additional experiments or more indepth analysis are needed to justify the claims in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods, as the proposed approaches only outperform the baselines in one setup out of three and there is no consistent trend in the results. The comment suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. This claim is 3 as it provides a logical reasoning for the need for additional experiments, but it lacks specific examples or references to support the claim. The authors might need to conduct additional experiments themselves to fully understand the issue and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. It suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. This feedback is clear and actionable, as it points out a critical weakness in the paper\"s results and provides a concrete direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to conduct these additional experiments or what aspects of the analysis should be expanded. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically mentioning the need for a detailed comparison of time complexity and competitiveness with prior art. While the comment implies that the authors should include such a comparison, it does not provide explicit instructions on how to conduct it or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact details of what is expected. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. However, it does not specify which part of the paper this comparison should be included in, nor does it provide details on what aspects of the comparison should be addressed. The authors can infer that it relates to the discussion or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a particular comparison to be made. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. However, the comment does not provide specific examples or references to prior work that should be compared, nor does it explain why this comparison is necessary or how it would enhance the paper. Without detailed guidance or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. This feedback is 3 as it identifies an area where the paper could be strengthened by providing a more comprehensive comparison with existing work. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, leaving the authors with a general direction but without detailed instructions on how to implement the suggestion. Therefore, the comment is 3, as it points out a potential area for improvement but does not provide actionable steps for the authors to take."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper discusses ODA as a method for solving the MOIP problem but does not clearly explain how the presented method improves performance and computation speed over ODA. However, it does not provide specific guidance on how the authors should address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ODA,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not clearly explain how the presented method improves performance and computation speed over ODA. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not clearly explain how the presented method improves performance and computation speed over ODA, which is a subjective claim. The reviewer provides a logical reasoning by pointing out that ODA is a method for solving the MOIP problem and that the paper does not clearly suggest how the presented method enhances performance and speed. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the issue, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it does not clearly explain how the presented method improves performance and computation speed over ODA, which is one of the methods for solving the MOIP problem. This feedback is valuable as it highlights a gap in the paper\"s explanation, prompting the authors to clarify their contributions. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how the authors might present their method\"s enhancements over ODA. Despite this, the comment is 4 as it directs the authors\" attention to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. It questions why the authors compare the proposed method with [9] first and then [16], and why they only compare computational cost with [9]. The reviewer also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. While the comment identifies areas that need clarification and potential issues, it does not provide explicit instructions or concrete suggestions on how to address these concerns. The authors are left to infer that they should provide a more detailed explanation or discussion of these aspects, but the comment lacks specific guidance on how to do so. Therefore, the comment is 3, as it highlights areas that need attention but does not offer detailed guidance on how to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and references specific papers, \"[9]\" and \"16,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the logic behind the comparisons, the computational cost, and its relevance in a practical scenario. The comment provides clear guidance on what needs to be addressed, namely the rationale behind the comparisons and the significance of the computational cost. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. The reviewer questions why the authors compare the proposed method with [9] first and then [16], and why they only compare the computational cost with [9]. The comment also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. While the comment identifies potential issues and questions, it lacks specific examples or references to support the claims. The authors are left to infer the basis of the reviewer\"s concerns, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several pertinent questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. It questions why the authors compare the proposed method with [9] first and then [16], and why they only compare the computational cost with [9]. The reviewer also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. These questions highlight areas that need clarification and potential issues in the paper, prompting the authors to reconsider their approach and provide a more detailed explanation or discussion of these aspects. However, the comment could be more helpful if it offered specific suggestions on how to address these questions or improve the paper. Overall, the comment is 3 as it identifies areas that need attention but lacks detailed guidance on how to improve the draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant gap in the paper regarding the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline references. The comment is clear and concrete, as it specifies exactly what needs to be added and how it should be presented. This provides the authors with a direct and specific action to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the idea of jointly discovering, hallucinating, and adapting, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of discussion on the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of discussion on the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline references. This feedback is clear and actionable, as it points out a critical area that needs attention and suggests a specific improvement to enhance the paper\"s comprehensiveness and rigor. However, the comment could be more helpful if it provided additional guidance on how to conduct this analysis or what specific aspects to consider. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming and lacks theoretical evidence. However, it does not provide specific guidance on how the authors should address this issue or what kind of theoretical evidence would be appropriate. The comment implies that the authors should provide more detailed analysis or theoretical justification, but it does not offer concrete steps or examples of what this might entail. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of the correlation between dataset size and the Frobenius norm and singular values, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of theoretical evidence for the correlation and the need for more detailed analysis across different model architectures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming and lacks theoretical evidence. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of the correlation between dataset size and the Frobenius norm and singular values, noting that it is underwhelming and lacks theoretical evidence. It highlights the need for more detailed analysis and theoretical justification, which is crucial for strengthening the paper\"s contribution. However, the comment does not provide specific suggestions on how to address this issue or what kind of theoretical evidence would be appropriate. While it points out a significant weakness, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential for information leaking in AutoAugment\"s policy, which is obtained through supervised training on ImageNet. It also questions the authors\" conclusion in L114 about the pretraining dataset matching the target dataset in terms of object or scene centricity. The reviewer suggests that this might be a setback for SSL algorithms that strive to learn generic representations. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their conclusions and explore the implications of their findings. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"L114,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the potential for information leaking in AutoAugment\"s policy and the authors\" conclusion about the pretraining dataset matching the target dataset. The comment further raises questions about the implications for SSL algorithms and suggests exploring whether combining datasets can lead to better representations. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the potential for information leaking in AutoAugment\"s policy, which is obtained through supervised training on ImageNet. The reviewer questions the authors\" conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity, suggesting that this might be a setback for SSL algorithms. However, the comment lacks specific examples or references to support the claim about information leaking or the potential impact on SSL algorithms. While it raises valid points, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the potential for information leaking in AutoAugment\"s policy, which is obtained through supervised training on ImageNet. It questions the authors\" conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity, suggesting that this might be a setback for SSL algorithms that strive to learn generic representations. The comment also prompts the authors to consider whether combining two datasets can lead to better representations. While the comment identifies a potential issue and raises thoughtprovoking questions, it lacks specific suggestions or guidance on how the authors might address these concerns or explore the implications of their findings. The feedback is 3 as it points out a relevant area for consideration, but it could be more actionable with additional details or examples. Therefore, it is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should include more analysis on the multilingual alignment of entity representations, specifically recommending visualizations or case studies for different types of languages. It also expresses interest in whether entities from lowresourced languages are well aligned with highresourced ones. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific visualizations or case studies should be included. The action is concrete but somewhat vague in terms of execution, as the authors need to determine the specific aspects of multilingual alignment to focus on and how to present the results. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the languageagnostic characters of entity representations, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more analysis on the multilingual alignment of entity representations and the suggestion for visualizations or case studies for different types of languages. The comment also raises an interest in the alignment of entities from lowresourced languages with highresourced ones. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks analysis on the alignment of entity representations, specifically for multilingual alignment. It suggests that adding more analysis and visualizations or case studies for different languages would be beneficial. While the comment identifies a potential gap in the analysis, it does not provide specific examples or references to support the claim that the current analysis is insufficient. The suggestion for visualizations or case studies is a logical one, but the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of analysis on the alignment of entity representations, particularly for multilingual alignment. It suggests that adding more analysis and visualizations or case studies for different languages would be beneficial. Additionally, it raises an interest in the alignment of entities from lowresourced languages with highresourced ones. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their analysis and presentation. However, it could be more helpful if it included specific examples or suggestions on how to implement these improvements. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. This explicit suggestion provides a clear action for the authors to take, which is to include additional details on using attention in an appendix. The comment is concrete, as it specifies the exact location where the additional information should be included, making it 5.", "grounding_specificity_rationale": "The comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. However, it does not specify which part of the paper discusses attention or where the additional details should be added. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The suggestion to include more details is specific, as it provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why additional details on attention are necessary or how they would enhance the paper. Without such justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by including additional details on using attention. However, the comment could be more helpful if it elaborated on what specific aspects of attention should be addressed or how these details could improve the paper. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the references list contains duplicates and that the publication venues and/or publication years of many of the papers are missing. While it identifies specific issues, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to check for duplicates and ensure the correct publication venues and years are included. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions the references list, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of duplicates and missing publication venues/years, providing clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the references list contains duplicates and that the publication venues and/or publication years of many of the papers are missing. However, it does not provide specific examples or detailed reasoning to support these claims. Without concrete evidence or references, the authors may find it challenging to verify and address the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with the references list, noting that it contains duplicates and that the publication venues and/or publication years of many of the papers are missing. This feedback is clear and actionable, as it directs the authors to verify and correct their references list to ensure accuracy and completeness. By addressing these issues, the authors can improve the credibility and reliability of their work. However, the comment could be more helpful if it provided suggestions on how to avoid duplicates or how to locate missing information. Overall, the comment is 4 as it highlights important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the specific reason for the choice of Gaussian noise in the experiments, noting that the paper claims the model works well for various image noise types. While the comment implies that the authors should address this issue by providing a rationale or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification for the choice of Gaussian noise. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper where the authors discuss their model\"s ability to work well for various image noise types, allowing the authors to accurately identify the relevant section. It is also specific because it questions the choice of Gaussian noise in the experiments and asks for a rationale or explanation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of Gaussian noise in the experiments, suggesting that there might be a particular reason for this choice. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific examples or justification to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the choice of Gaussian noise in the experiments, noting that the paper claims the model works well for various image noise types. This is an important point as it highlights a potential limitation in the scope of the experiments. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional noise types could be considered. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a need for simpler and clearer descriptions of results, specifically mentioning the convoluted nature of some descriptions. It provides a specific suggestion to consider a related idea from [1] and references [2] to check for useful communication. The comment also points out that the differences in figures seem too small, but acknowledges that the topography plots indicate something reasonable. While the comment provides some guidance on what needs to be improved, it lacks explicit instructions on how to simplify the result descriptions or what specific changes should be made. The suggestions are concrete but could be more detailed, making the comment 4.", "grounding_specificity_rationale": "The comment addresses the need for simpler and clearer descriptions of results, specifically mentioning the convoluted nature of some descriptions. It provides a specific suggestion to consider a related idea from [1] and references [2] to check for useful communication. The comment also points out that the differences in figures seem too small, but acknowledges that the topography plots indicate something reasonable. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the results or discussion sections. The comment is specific in suggesting improvements and references, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the result descriptions are needlessly convoluted and suggests that a related idea from [1] should be considered. It references [2] to support the claim that useful communication is not happening. The comment provides specific examples of convoluted descriptions and references external works to substantiate the claim. This makes the claim 4, as it provides a logical basis and references to support the suggestion for improvement. However, the comment could be strengthened by providing more detailed examples or further explanation of why the current descriptions are convoluted. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the complexity and clarity of the result descriptions, noting that some are needlessly convoluted. It provides a concrete suggestion to consider a related idea from [1] and references [2] to check for useful communication. This feedback is actionable and offers a clear direction for improvement, encouraging the authors to simplify their descriptions and provide more straightforward explanations. Additionally, the comment acknowledges that the topography plots seem reasonable, which is a positive point. Overall, the comment is 4 as it provides specific guidance on how to enhance the clarity and accessibility of the results section. However, it could be more helpful if it offered additional suggestions or examples on how to simplify the descriptions. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there are missing details about the division to train and test sets, including numbers and the method of division (random or other considerations). It clearly instructs the authors to add these details, providing a direct action for improvement. The comment is specific and provides concrete guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for details about the division to train and test sets, including numbers and the method of division. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be added, such as details about the division method and numbers. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are missing details about the division to train and test sets, including numbers and the method of division. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing details. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper is lacking, namely the details about the division to train and test sets, including numbers and the method of division. It clearly states that these details should be added to improve the clarity and transparency of the paper. This feedback is actionable and provides a clear direction for the authors to enhance their draft. However, the comment could be more helpful if it offered suggestions on how to present these details or provided examples of how similar studies have addressed this issue. Overall, the comment is 4 as it effectively points out a gap in the paper and provides a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues: the need for human labor in building text descriptions and the potential scalability issue with longtext inputs. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for how to address the labor issue or how to improve scalability. The comment lacks actionable guidance, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of human labor in building text descriptions and the scalability of the framework with longtext inputs. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the need for human labor and the scalability issue, but it lacks detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that building text descriptions for each task still requires human labor and that the optimal textual format for policy learning varies from task to task and model to model. The reviewer also mentions the scalability issue with longtext inputs. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the need for human labor in building text descriptions and the potential scalability issue with longtext inputs. It acknowledges the complexity of determining the optimal textual format for policy learning, which varies across tasks and models. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the scalability of their framework. While it highlights important areas for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out potential weaknesses but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the experimental validation, including the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. While the comment highlights these areas for improvement, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to provide more detailed information about the optimization strategy and consider related works, but the comment lacks specific instructions on how to implement these improvements. Therefore, the comment is 3, as it identifies areas for improvement but does not offer concrete steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental validation\" and \"shallow networks\" being considered, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experimental validation, such as the lack of description of the optimization strategy and the consideration of layer redundancy in the context of network pruning. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experimental validation is not convincing, specifically mentioning the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, such as layer redundancy in the context of network pruning. The reviewer provides a reference to a specific paper that discusses this issue, which adds some level of verification to the claim. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the critique. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the experimental validation section, including the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how to address them. The reference to a specific paper on network pruning could be more helpful if it included suggestions on how to incorporate this work into the experimental validation. Overall, the comment is 3 as it identifies areas for improvement but lacks detailed guidance, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it does not provide any guidance on how the authors might prove these results or what specific theoretical aspects should be addressed. The action is implicit and vague, as the authors are left to infer that they need to provide theoretical evidence or results to substantiate their claims. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the lack of theoretical results, but it is 1 as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might address this issue or what theoretical results could be explored. Without actionable feedback or detailed insights, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors can provide more evidence to either prove or disprove it. While the comment implies that the authors should provide evidence to support or refute the hypothesis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence to substantiate the hypothesis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. However, it does not specify which part of the paper this hypothesis pertains to, making it weakly grounded. The comment is specific in suggesting that the human test results might support the hypothesis but questions whether the authors can provide more evidence to prove or disprove it. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors could provide more evidence to either prove or disprove it. While the comment provides a logical reasoning for the hypothesis, it lacks specific examples or references to support the claim. The suggestion for additional evidence is a clear indication of what the authors could do to improve the draft, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a hypothesis about the two parts of the paper, suggesting that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors could provide more evidence to either prove or disprove it. This feedback is 3 as it identifies a potential area for further exploration and evidence gathering, which could lead to a more robust understanding of the paper\"s findings. However, the comment could be more helpful if it provided specific suggestions on how to gather or present this evidence, such as recommending specific experiments or analyses. Overall, the comment is 3 as it points out a potential area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the testing of the bAbI model, specifically asking whether it was only tested on a single supporting fact dataset (Task 1). While the comment implies that the authors should consider testing the model on other tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should test the model on additional tasks. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"bAbI\" and \"Task 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the model was only tested on a single supporting fact dataset, which is a clear and specific concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking about the testing of the bAbI model on other tasks. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a relevant question about the testing of the bAbI model, specifically asking whether it was only tested on a single supporting fact dataset (Task 1). This is a pertinent inquiry that could help the authors ensure that their model is thoroughly evaluated across different tasks. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this issue. While it points out a potential weakness, it does not offer actionable advice or detailed feedback for improvement. Therefore, the comment is 3, as it identifies an area for further exploration but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically asking about the time required to calculate the hypervolume of different regions in each step of LaMOO. It also mentions that the computation of hypervolume could be timeconsuming, especially for problems with many objectives. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete suggestions on how to improve the time complexity or optimize the algorithm. The action is implicit and somewhat vague, as the authors need to infer that they should address the time complexity issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Time Complexity\" and \"LaMOO,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the time complexity of the proposed algorithm, particularly the repeated calculation of hypervolume for promising region selection. The comment further raises a concern about the practicality of LaMOO for problems with many objectives, suggesting that the time complexity could be a significant issue. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically questioning whether the repeated calculation of hypervolume for promising region selection in LaMOO could be timeconsuming, especially for problems with many objectives. While the comment identifies a potential issue, it lacks specific examples or references to substantiate the claim that the time complexity is a significant problem. The authors are left to infer the potential impact on the practicality of the algorithm, which could be challenging without additional context or evidence. Therefore, the claim is 3, as it provides a logical basis but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment raises a critical question about the time complexity of the proposed algorithm, specifically questioning whether the repeated calculation of hypervolume for promising region selection in LaMOO could be timeconsuming, especially for problems with many objectives. This is an important consideration for the practicality of the algorithm, as it could impact the feasibility of using it for complex problems. The comment prompts the authors to address this issue and consider ways to optimize the algorithm to improve its efficiency. However, the comment could be more helpful if it provided specific suggestions or examples of how to mitigate the time complexity. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several areas for improvement, including the need to discuss leveraging state, reactiveness, and learning during an episode, as well as the generic and vague title. It suggests being honest and direct in the critique and provides a specific example of what \"brittle convergence properties\" means. Additionally, it mentions that DeepRL methods are widely adopted and suggests considering the landscape 10 years ago. While the comment provides some guidance on what aspects to address, it lacks concrete details on how to implement these suggestions. The authors are given a general direction but may need to infer the specific actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues, including the limitations of evolutionary methods, the generic and vague title, and the need for more detailed discussion on leveraging state, reactiveness, and learning during an episode. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in suggesting that the title is too generic and vague and that the authors should be more precise in their critique. It also asks for clarification on the term \"brittle convergence properties\" and mentions the widespread adoption of DeepRL methods. Overall, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point makes several claims, including that the paper discusses limitations of evolutionary methods, the title is too generic and vague, and that DeepRL methods are widely adopted. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The mention of \"brittle convergence properties\" is not explained, and the suggestion to be more precise in critiques is not accompanied by examples or detailed guidance. The comment also suggests considering the landscape 10 years ago, but this does not contribute to the verifiability of the claims. Overall, the comment lacks sufficient evidence or justification to support its claims, making them 1.", "helpfulness_rationale": "The review comment identifies several areas for improvement, including the need to discuss leveraging state, reactiveness, and learning during an episode, which could enhance the paper\"s depth and relevance. It also points out that the title is too generic and vague, suggesting that being more precise in the critique would be beneficial. Additionally, the reviewer questions the term \"brittle convergence properties\" and suggests considering the landscape 10 years ago. While the comment provides some actionable feedback, it lacks specific guidance on how to address these issues or what specific aspects to focus on. The authors are given direction but may need to infer the exact steps to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It asks for clarification on how the defocus map and an image are used to synthesize the defocused image, and how the edges are handled in areas where depth discontinuities occur. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues. The authors know they need to provide more information about the synthesis process, but the comment lacks specific suggestions on how to improve the explanation or what details should be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It specifically asks about how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas with depth discontinuities. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections. The comment is specific in detailing what needs to be addressed, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It asks for clarification on how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas where depth discontinuities occur. While the questions are valid, they do not provide specific examples or references to support the claim that these aspects are unclear or lacking in the paper. The comment lacks detailed reasoning or evidence to substantiate the need for clarification, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It specifically asks for clarification on how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas where depth discontinuities occur. These questions highlight areas where the paper could be improved by providing more detailed explanations or examples. However, the comment does not offer specific suggestions or guidance on how the authors might address these issues, leaving them to infer the necessary steps. While it identifies important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper claims a unique contribution regarding the number of points and apriori knowledge needed for its algorithm, but it suggests that empirical justification would be beneficial. However, it does not provide specific guidance on how to conduct this empirical justification or what kind of evidence would be sufficient. The action is implicit and somewhat vague, as the authors can infer that they need to provide empirical evidence but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first claimed contribution\" of the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the paper lacks empirical justification for the claim about the number of points and apriori knowledge needed for the algorithm. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper\"s first contribution is unique because it does not require as many points or apriori knowledge about dimensions of subspaces. However, the comment suggests that empirical justification would be beneficial. While the claim is logical, it lacks specific examples or references to support the assertion that empirical justification is necessary. The reasoning is 3, as it provides a general idea of what could be improved, but it does not offer detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that could be improved by suggesting the inclusion of empirical justification for the claim about the algorithm\"s unique contribution. It points out that the paper lacks empirical evidence to support the claim that the algorithm does not require as many points or apriori knowledge about dimensions of subspaces. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to enhance the credibility and robustness of their work. However, the comment could be more helpful if it offered specific examples or guidance on how to conduct the empirical justification. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify what aspects of the previous work should be discussed or how the authors should incorporate this discussion into their paper. The comment lacks explicit guidance or concrete suggestions on how to address this issue, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment points out that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify which part of the paper this issue pertains to, such as a particular section or subsection where the discussion should be included. This makes it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the previous work should be discussed or how it should be integrated into the paper. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify which previous works are missing or how they should be integrated into the paper. Without specific references or examples, the claim lacks verifiability, as it does not provide a clear basis for the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant gap in the paper, noting that the authors have not provided a comprehensive discussion of previous work on the topic. This is a critical observation that could significantly impact the paper\"s credibility and relevance. However, the comment lacks specific guidance on which previous works should be discussed or how they could be integrated into the paper. While it highlights an important area for improvement, the lack of actionable suggestions limits its helpfulness. Therefore, the comment is 3, as it points out a critical issue but does not provide detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises questions about the OT sample selection process, specifically whether it runs once or iteratively, and suggests that more details and a flow chart would be helpful. It also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment implies that the authors should provide more details and a flow chart, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add more details and a flow chart. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2.4.3\" and \"equation (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the OT sample selection process, suggesting that more details and a flow chart would be helpful. The comment also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the OT sample selection process, suggesting that more details and a flow chart would be beneficial for clarity. It also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that these details are necessary. The reasoning is 3, as it highlights potential gaps in the paper but does not provide detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the OT sample selection process, suggesting that more details and a flow chart would be beneficial for clarity. It also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. This feedback is clear and actionable, as it prompts the authors to provide additional information that could enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered specific suggestions on how to present this information or what aspects to focus on. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensibility of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a gap in the paper regarding the absence of experiments with continuous tasks, despite the authors discussing how KG handles continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix, asking why these methods are not included in the experiments and how they compare to ConBO. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include experiments with continuous tasks and consider including entropy methods in the experiments. The action is concrete but somewhat vague, as it lacks detailed guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion on how KG handles the continuous task setting, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of experiments with continuous tasks and questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix. The comment further asks how these methods compare to ConBO. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the absence of experiments with continuous tasks, despite the authors discussing how KG handles continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix and asks how these methods compare to ConBO. While the comment identifies a potential gap in the experimental setup, it lacks specific examples or references to support the claim that these methods should be included in the experiments. The reasoning is 3, as it highlights a potential issue but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the absence of experiments with continuous tasks, despite the authors discussing how KG handles continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix and asks how these methods compare to ConBO. This feedback is clear and actionable, as it prompts the authors to address the omission of continuous tasks in their experiments and to consider including entropy methods in the main text. By providing specific questions and suggestions, the comment empowers the authors to enhance the comprehensiveness and rigor of their experimental evaluation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the authors\" explanation of the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. While it acknowledges the novelty of the approach, it explicitly requests a more detailed explanation to better understand the difference. This feedback is clear and provides a specific action for the authors to take, which is to provide a more detailed explanation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of unsupervised feature selection from a diffusion perspective, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for a more detailed explanation of the difference between similarity and exit times in nature. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. The reviewer acknowledges the novelty of the approach but expresses difficulty in understanding the distinction. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim that the explanation is unclear. Without additional context or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the explanation of the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It acknowledges the novelty of the approach but expresses a need for a more detailed explanation to better understand the distinction. This feedback is 3 as it points out a potential gap in the paper\"s explanation, prompting the authors to provide a clearer explanation. However, the comment could be more helpful if it offered suggestions on how to improve the explanation or provided examples of how the distinction might be clarified. Overall, the comment is 3 as it directs the authors to a specific area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. While it implies that the authors should address this limitation, it does not provide explicit instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a response to the question. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the limitations of the framework, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the framework is limited in this way. Without such information, the authors may find it challenging to address the question or understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. This is a relevant point that could help the authors identify potential areas for improvement or expansion in their work. However, the comment lacks specific guidance or suggestions on how to address this limitation or what specific aspects of the framework might need improvement. While it points out an important area for consideration, it does not provide actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This feedback provides a clear and concrete action for the authors to take, specifying exactly what additional tasks should be included in the experiments. The comment is specific and actionable, giving the authors a direct path to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, specifically mentioning \"sentence similarity tasks and open domain QA tasks.\" This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited and suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. The comment provides a logical reasoning by pointing out that these tasks are common in the NLP field and could enhance the scope of the experiments. However, the comment lacks specific examples or references to support the claim that these tasks are necessary or how they would improve the experiments. This makes the claim 3, as the authors would need to infer the importance of these tasks themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, specifically noting that the authors only conduct evaluations on sentence similarity tasks and open domain QA tasks. It suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing a specific direction for the authors to expand their experiments and enhance the scope of their work. By addressing this suggestion, the authors can improve the comprehensiveness and relevance of their evaluation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment points out that the parameter S remains a problem, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps the authors should consider to improve the parameter setting. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the issue of setting the parameter S, but it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspect of the parameter S setting is problematic or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The comment states that \"How to set the parameter S remains a problem,\" but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a specific issue with the parameter S, noting that setting it remains a problem. However, it lacks any actionable guidance or suggestions on how to address this issue or improve the parameter setting. Without detailed feedback or examples, the authors are left without a clear path forward to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. While the comment implies that the authors should consider conducting a human evaluation, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The authors are left to infer that they should consider conducting a human evaluation, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, it does not specify which part of the paper discusses the evaluation metrics or the caption generation process, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to include human evaluation, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this suggestion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. This feedback highlights a potential weakness in the paper\"s evaluation methodology and provides a clear direction for improvement. However, the comment lacks specific guidance on how to conduct a human evaluation or what aspects of the caption generation process should be evaluated by humans. While it identifies an area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but requires further elaboration to be fully actionable."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out the issue with the theoretical proof for convergence, stating that it appears trivial and lacks novelty and rigor. It highlights a specific assumption (Assumption 4.1) that indicates $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer suggests that the convergence proof can be trivially adapted with straightforward modifications following Modification 1 in Appendix C. This provides a clear and concrete action for the authors to take, which is to reconsider the theoretical proof and potentially revise it to enhance its rigor and novelty. The comment is explicit and provides detailed guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Assumption 4.1\" and \"Modification 1 in Appendix C,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical proof for convergence, noting that it lacks novelty and rigor due to the trivial adaptation following Modification 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence appears trivial and lacks novelty and rigor. It supports this claim by pointing out that Assumption 4.1 indicates that $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer also mentions that following Modification 1 in Appendix C, previous theorems can be trivially adapted with straightforward modifications. This provides a logical reasoning for the claim, but it could be strengthened by referencing specific theorems or providing more detailed examples of the modifications. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical proof for convergence, noting that it appears trivial and lacks novelty and rigor. It highlights a specific assumption (Assumption 4.1) that indicates $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer suggests that the convergence proof can be trivially adapted with straightforward modifications following Modification 1 in Appendix C. This feedback is clear and actionable, as it provides the authors with a specific area to address in their draft. By addressing this issue, the authors can enhance the rigor and novelty of their theoretical proof, which is crucial for the credibility and impact of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the experimental setup borrowed from [2] is only semireal because it involves artificially created multinode seed cascades by merging singlenode seed cascades. This provides a clear and direct action for the authors to take, which is to mention this fact clearly in their paper. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental setup borrowed from [2], allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental setup, namely that it is only semireal due to the artificial creation of multinode seed cascades by merging singlenode seed cascades. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental setup borrowed from [2] is only semireal because it involves artificially created multinode seed cascades by merging singlenode seed cascades. This claim is 3 as it provides a logical reasoning for the classification, based on the description of the experimental setup. However, the comment lacks specific examples or references to [2] to fully substantiate the claim. Providing more detailed evidence or references would strengthen the claim, making it more 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that it is only semireal due to the artificial creation of multinode seed cascades by merging singlenode seed cascades. This is a clear and actionable point that the authors should address to ensure the validity and credibility of their results. By mentioning this issue clearly, the authors can improve the transparency and accuracy of their experimental setup. However, the comment could be more helpful if it provided suggestions on how to clarify this point in the paper or offered additional context on the implications of this setup. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two main issues: the limited scope of datasets and models used in the study and the lack of assessment of other important biases and datasets. It also points out the absence of assessments on stateoftheart generative models like GPT. While the comment highlights areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should expand their dataset and model selection and include assessments on additional biases and models like GPT. However, the comment lacks concrete suggestions on how to implement these changes or what specific datasets or models should be considered. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the limitations of the datasets and models used in the study, specifically mentioning the bias benchmarks and the absence of assessments on stateoftheart generative models like GPT. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the limitations of the dataset and model selection and the need for additional assessments. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the datasets and models used in the study are limited and that the bias benchmarks only assess gender, race, and religion. It also mentions the absence of assessments on stateoftheart generative models like GPT. While the comment identifies specific limitations, it lacks detailed justification or examples to fully substantiate the claim. The authors would need to infer the importance of these assessments and the potential impact on the study\"s conclusions. Therefore, the comment is 3, as it provides some basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant limitation in the study, noting that the datasets and models used are limited and that the bias benchmarks only assess gender, race, and religion. It also points out the absence of assessments on stateoftheart generative models like GPT. This feedback is valuable as it highlights areas where the study could be expanded to include a broader range of biases and models, which would enhance its scope and relevance. However, the comment could be more helpful if it provided specific suggestions on which datasets or models to consider or how to incorporate assessments of generative models like GPT. Overall, the comment is 4 as it directs the authors\" attention to important areas for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or a citation to the metrics. This feedback is explicit, as it clearly states what the authors need to do to improve their draft: either provide an explanation or a citation to the metrics used. The action is concrete, as it specifies exactly what the authors need to do to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"description of the metrics,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: an explanation or a citation to the metrics used in the paper. This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the metrics is limited and suggests that an explanation or citation to the metrics would be beneficial. However, the comment does not provide specific examples or detailed reasoning to support why the current description is insufficient or how an explanation or citation would improve the paper. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically the lack of an explanation or citation for the metrics used. This is a critical feedback as it highlights an area where the authors could enhance the clarity and transparency of their work. By suggesting that an explanation or citation would be beneficial, the comment provides a clear and actionable suggestion for improvement. However, it could be more helpful if it offered specific examples of how the metrics are used or why they are important, which would guide the authors in addressing the issue more effectively. Overall, the comment is 4 as it points out a significant area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks motivation for the applications of the fast label aggregation algorithms in a streaming setting. It highlights that all the datasets used in the empirical analysis are static, which is a concern for the paper\"s usefulness. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting specific ways to motivate the problem or providing examples of streaming applications that could benefit from such algorithms. The action is implicit and somewhat vague, as the authors need to infer that they should provide a stronger motivation for the problem and consider dynamic datasets. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the objective of the paper, which is to design fast label aggregation algorithms for a streaming setting. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of motivation for the problem and the use of static datasets in the empirical analysis. The comment provides clear guidance on what needs to be addressed, namely the need to motivate the problem and consider dynamic datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the applications of fast label aggregation algorithms in a streaming setting. It notes that all the datasets used in the empirical analysis are static, which is a concern for the paper\"s usefulness. However, the comment does not provide specific examples or references to support this claim, nor does it offer suggestions on how to address the issue. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of motivating the problem and consider dynamic datasets. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it lacks motivation for the applications of fast label aggregation algorithms in a streaming setting. It points out that all the datasets used in the empirical analysis are static, which is a concern for the paper\"s usefulness. The comment highlights the need to motivate the problem and consider dynamic datasets to enhance the paper\"s relevance. While it provides a clear direction for improvement, it could be more helpful if it offered specific examples or suggestions on how to address this issue. Overall, the comment is 3 as it guides the authors toward a meaningful enhancement of their draft, but it could be more actionable with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific aspects of the connection should be explored. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While it identifies a potential area for further exploration or discussion, it does not provide any actionable feedback or suggestions for the authors to address this question or improve their draft. The comment lacks depth and specificity, leaving the authors without clear guidance on how to proceed. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This guidance is clear and specific, giving the authors a direct action to take. The comment also highlights the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the importance of error analysis and its role in evaluating model performance and identifying potential issues. It also encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This provides clear guidance on what needs to be addressed, making the comment fully grounded. The comment is specific because it details the importance of error analysis and its role in guiding subsequent improvements and expansions of the ERC research. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This claim is 3 as it logically supports the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. However, the comment lacks specific examples or references to substantiate the claim fully. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This feedback is valuable as it highlights the importance of error analysis in evaluating model performance and identifying potential issues, which is crucial for guiding subsequent improvements and expansions of the ERC research. By following this advice, the authors can enhance the rigor and comprehensiveness of their work. However, the comment could be more helpful if it included specific examples or guidance on how to conduct error analysis or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the scalability of the model, specifically noting that performance degrades as the maximum number of identities grows. It suggests that the capacity should be set to a small number, like 10, to address this issue. The reviewer also questions whether the authors have considered how to scale up without compromising performance. While the comment provides a clear direction for the authors to consider setting a capacity limit, it does not offer specific guidance on how to achieve this or what specific steps to take. The action is explicit but somewhat vague in terms of implementation details, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 (a)\" and the issue with the performance degradation as the maximum number of identities grows. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the scalability of the model, suggesting that the capacity should be set to a small number like 10. It also raises a question about how to scale up without compromising performance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of the model degrades as the maximum number of identities grows, suggesting that the capacity should be set to a small number like 10. The reviewer provides a logical reasoning by explaining that in realworld scenarios, the number of objects can be more than 10, and the authors should consider how to scale up without compromising performance. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the issue and provide evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the scalability of the model, noting that performance degrades as the maximum number of identities grows. It suggests that the capacity should be set to a small number, like 10, to address this issue. The reviewer also raises a valid question about how to scale up without compromising performance, prompting the authors to consider this aspect of their model. While the comment provides clear and actionable feedback, it could be more helpful if it offered suggestions on how to achieve the suggested capacity limit or how to scale up without sacrificing performance. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the proposed method, noting that it comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters. The comment suggests that the current version of the ablation study does not provide definitive answers to these questions. While the comment identifies an area for improvement, it does not explicitly instruct the authors on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a more detailed analysis or provide additional experiments to clarify the contribution of each module. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method, which comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the ablation study, noting that it does not provide definitive answers to the questions raised. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method comprises several complicated modules and has more parameters than the baselines, which raises questions about whether the main performance gain is due to a specific module or the increased number of parameters. The reviewer suggests that the current version of the ablation study does not provide definitive answers to these questions. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to infer the need for more detailed analysis or additional experiments to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, noting that it comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters, and points out that the current version of the ablation study does not provide definitive answers to these questions. This feedback is 3 as it highlights an area where the authors could improve their analysis and provide more detailed explanations of the method\"s performance. However, the comment could be more helpful if it suggested specific experiments or analyses that could address these questions. Overall, the comment provides some guidance but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the robustness of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It suggests that the use of ULiRA [1] is recommended. However, the comment does not provide explicit instructions on how to address this concern or implement the suggested use of ULiRA. While the authors can infer that they should consider using ULiRA, the comment lacks concrete guidance on how to integrate it into their work. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the use of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness and raises concerns about the robustness of MIA testing for privacy guarantees. It also suggests using ULiRA [1] as a recommendation. However, the comment does not specify which part of the paper discusses the use of MIA testing or where the recommendation for ULiRA should be integrated. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue with MIA testing and the recommendation for ULiRA, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness is not robust enough for privacy guarantees. It suggests that the use of ULiRA [1] is recommended. The comment provides a logical reasoning by pointing out the potential limitations of MIA testing and the need for a more robust approach. However, it lacks specific examples or references to support the claim about the robustness of MIA testing or the effectiveness of ULiRA. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It points out that the robustness of MIA testing itself is questionable for privacy guarantees. The comment suggests using ULiRA [1] as a more robust alternative. While the comment highlights an important consideration, it lacks specific guidance on how to address the issue or integrate ULiRA into the paper. The authors are given a direction to consider, but the feedback could be more actionable with detailed suggestions on how to implement the suggested change. Therefore, the comment is 3, as it provides insight but lacks depth and actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of detailed explanations, minimal or absent simulation procedures, and confusing figures. It suggests that the authors should provide more details in the paper and/or supplementary information to clarify the procedures and include error bars or pvalues when making statistical inferences. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer that they should add more details and clarify the figures. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 2\" and \"simulation or experimentbased evidence,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the explanations being qualitative, the lack of detailed procedures, and the confusion with figures like \"sample count.\" The comment provides clear guidance on what needs to be addressed, such as adding more details and including error bars or pvalues when making statistical inferences. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations in the paper are qualitative and that the procedures are described minimally or not at all, with some figures being confusing. The reviewer suggests that adding more details and clarifying the procedures would be beneficial. The comment also mentions the absence of error bars or pvalues when statistical inferences are made. While the comment identifies specific issues, it lacks detailed examples or references to support the claim that the explanations are qualitative or that the procedures are unclear. This makes the claim 3, as the authors would need to make a concerted effort to address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of detailed explanations, minimal or absent simulation procedures, and confusing figures. It suggests that the authors should provide more details and clarity in the paper and/or supplementary information to enhance the understanding of the experiments. Additionally, it points out the absence of error bars or pvalues when statistical inferences are made. This feedback is clear and actionable, as it directs the authors to improve the clarity and comprehensiveness of their explanations and figures. However, the comment could be more helpful if it provided specific examples of what additional details or clarifications would be beneficial. Overall, the comment is 4 as it guides the authors toward improving the quality and comprehensiveness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out an unclear aspect of the paper regarding the presentation of specific examples of biases and prediction shifts, noting that while the authors mention the possibility of bias, they do not provide sufficient information on how general these situations are. However, the comment does not explicitly instruct the authors on how to address this issue or what specific information should be included to clarify the generalizability of these examples. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context or examples to address the concern, but the comment lacks concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding the generalizability of the examples of biases and prediction shifts presented in these sections. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents specific examples of biases and prediction shifts but lacks clarity on their generalizability. The comment suggests that while the authors mention the possibility of bias, they do not provide sufficient information on how general these situations are. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper regarding the generalizability of the examples of biases and prediction shifts presented in sections 3.2 and Theorem 1. It points out that while the authors mention the possibility of bias, they do not provide sufficient information on how general these situations are. This feedback is 3 as it highlights a potential weakness in the paper that the authors can address to improve clarity and understanding. However, the comment could be more helpful if it suggested specific ways to address this issue, such as providing additional context or examples to illustrate the generalizability. Overall, the comment provides some guidance but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that adding a few more datasets would be beneficial, particularly in terms of crosstask transferability. While the comment implies that the authors should consider adding more datasets, it does not provide specific guidance on which datasets to include or how to incorporate them into the analysis. The action is implicit and somewhat vague, as the authors need to infer that they should add more datasets but are not given concrete details on which datasets to include or how to integrate them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion on crosstask transferability. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need to be revised. The comment is specific in suggesting the addition of datasets, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or how it would impact the analysis. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which datasets to include or how they would enhance the analysis. The feedback is 3 as it points out a potential gap in the paper, but it does not offer actionable steps for the authors to address this suggestion. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to clarify whether there is any additional novel effort in the section on 3D Gaussians generation, specifically mentioning the previous work by Luciddreamer. This request is clear and provides a direct action for the authors to take, which is to address the issue by either explaining the novelty or providing evidence of additional effort. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely whether there is any additional novel effort in this section. This provides clear guidance on what the authors need to clarify or improve in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions whether the section on 3D Gaussians generation is merely a repetition of previous work, specifically mentioning \"Luciddreamer.\" However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the section on 3D Gaussians generation, specifically questioning whether there is any additional novel effort beyond the previous work by Luciddreamer. This feedback is 3 as it prompts the authors to clarify whether their work builds upon existing efforts or introduces new contributions. However, the comment lacks specific guidance on how the authors might address this issue or what additional efforts could be highlighted. While it points out a potential weakness, it does not provide actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the tractability of MMD DRO compared to other methods like phidivergence or Wasserstein uncertainty sets. It points out that the upper bound provided in Theorem 3.1 is crude and that the nonnegative constraint on the distribution is dropped, requiring further approximation. Additionally, it questions the assumption that the loss function belongs to the RKHS. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the tractability and assumptions of their method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the crude upper bound in the theorem and the assumption that the loss function belongs to the RKHS. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that MMD DRO does not enjoy a tractable exact equivalent reformulation, which is a severe drawback. The reviewer supports this claim by pointing out that the upper bound in Theorem 3.1 is crude because it drops the nonnegative constraint on the distribution, and further approximation is needed even for a simple kernel ridge regression problem. Additionally, the reviewer questions the assumption that the loss function belongs to the RKHS, which is already pointed out by the authors. The comment provides logical reasoning and specific examples to support the claim, making it 4. However, it could be strengthened by providing more detailed examples or references to similar works that have addressed this issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the tractability of MMD DRO compared to other methods like phidivergence or Wasserstein uncertainty sets. It points out that the upper bound provided in Theorem 3.1 is crude, as it drops the nonnegative constraint on the distribution, and further approximation is needed even for a simple kernel ridge regression problem. Additionally, it questions the assumption that the loss function belongs to the RKHS, which is already pointed out by the authors. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is 3 as it alerts the authors to potential weaknesses in their methodology, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it seeks clarification on the implications of the nonvanishing duality gap and difficulty of maximization over nonnorm type constraints. It also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the questions themselves do not provide explicit instructions, they imply that the authors should address these issues in their paper. The action is implicit but concrete, as it points to specific areas that need clarification or elaboration. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it specifically references the \"nonvanishing duality gap\" and the difficulty of maximization over nonnorm type constraints. It also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the comment does not explicitly mention a specific section or page, the authors can infer that it relates to the theoretical aspects of the framework or the application to nonconvex losses. The comment is specific in detailing what needs to be addressed, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it seeks clarification on the implications of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints. The reviewer also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the comment does not present specific claims or opinions that require verification, it does pose thoughtful questions that could guide the authors in improving their draft. Therefore, the comment is classified as \"3,\" as it provides a basis for further exploration and discussion but lacks detailed evidence or references to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises important questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it seeks clarification on the implications of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints. It also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the questions themselves do not provide actionable feedback, they prompt the authors to consider and address these important theoretical aspects of their work. The comment is 3 as it encourages the authors to clarify and strengthen their theoretical foundations, but it could be more beneficial with additional guidance or suggestions on how to address these questions. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. While the comment implies that the authors should consider this approach, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests an experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. However, it does not provide any supporting evidence, reasoning, or references to justify why this approach would be beneficial or how it would impact the results. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests an experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This is a clear and actionable suggestion that could potentially improve the paper by providing additional insights into the performance of the baselines. However, the comment lacks depth and does not explain why this approach might be beneficial or how it could be implemented effectively. While it provides a direction for further exploration, it could be more helpful with additional guidance or rationale. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the reproducibility of the paper, noting that while the pseudocode is provided in the supplementary material, it does not provide enough detail for actual reproduction. The reviewer suggests that more technical details, such as the number of units in the RNN implementation, are missing. This feedback implies that the authors should include more detailed descriptions of the technical aspects of their work to improve reproducibility. However, the comment does not explicitly instruct the authors to add these details, leaving it somewhat vague. While the action is implied, the authors can infer that they need to provide more technical information, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the supplementary material, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with reproducibility, such as the lack of technical details like the number of units in the RNN implementation. This provides clear guidance on what needs to be addressed to improve reproducibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not written to be reproduced, as it lacks technical details necessary for reproduction. The reviewer provides a specific example of the lack of details about the RNN implementation, such as the number of units. This claim is 3 as it highlights a gap in the paper\"s reproducibility, but it could be strengthened by providing more detailed examples or references to similar works that require such technical details. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the reproducibility of the paper, noting that while the pseudocode is provided in the supplementary material, it does not provide enough detail for actual reproduction. The reviewer highlights specific areas that are missing, such as technical details about the RNN implementation, which are necessary for reproducing the work. This feedback is clear and actionable, as it points out specific gaps in the paper that need to be addressed to improve its reproducibility. However, the comment could be more helpful if it suggested ways to address these gaps or provided examples of how similar details have been presented in other works. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 1 would be stronger if it included error bars or more random trials to potentially reduce random fluctuations in the results. While the comment implies that the authors should consider adding these elements, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add error bars or more trials to improve the figure. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of error bars or more random trials to potentially reduce random fluctuations in the results. This provides clear guidance on how to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 would be stronger with the inclusion of error bars or more random trials to potentially reduce random fluctuations in the results. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these additions would be beneficial or how they would impact the results. Without such justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in Figure 1, suggesting that the inclusion of error bars or more random trials could strengthen the figure by potentially reducing random fluctuations in the results. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the figure\"s robustness and clarity. However, the comment could be more helpful if it explained why error bars or additional trials are beneficial or how they might impact the interpretation of the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors provide a brief introduction to energy models in the related work section and clarifies the correspondence between different learning rates and steps in Figure 1. It also references external works that discuss contextaware robust finetuning, finetuning impact on foundation models, and robust finetuning of zeroshot models. While the comment provides explicit actions, it does not specify how to implement these suggestions or what specific details should be included in the introduction or Figure 1. The authors are given clear guidance on what needs to be added but lack detailed instructions on how to execute these actions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"related work section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a brief introduction to energy models in the related work section and the lack of clarity regarding the correspondence between different learning rates and steps in Figure 1. The comment also provides references to external works that could be relevant to the contextaware robust finetuning discussed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors provide a brief introduction to energy models in the related work section and clarifies the correspondence between different learning rates and steps in Figure 1. The reviewer references external works to support their claim, such as \"Contextaware robust finetuning,\" \"Finetuning can cripple your foundation model; preserving features may be the solution,\" and \"Robust finetuning of zeroshot models.\" These references provide a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or examples of how these references relate to the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include a brief introduction to energy models in the related work section. It also points out a lack of clarity in Figure 1, specifically regarding the correspondence between different learning rates and steps. The reviewer references external works that could be relevant to the contextaware robust finetuning discussed in the paper, which adds depth to the feedback. This guidance is clear and constructive, empowering the authors to enhance their draft by addressing these specific issues. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they should consider to improve the clarity of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not specify which part of the paper this issue pertains to, such as a particular section, figure, or table. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in its concern about the model\"s ability to generate novel knowledge or testable hypotheses, but without clear grounding, it lacks actionable guidance for the authors. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve the clarity of their work. Without actionable feedback or detailed insights, the comment does not assist the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a simplified version of Theorem 2 could be presented for the general audience, similar to how Theorem 1 is presented. This implies that the authors should consider simplifying the content of Theorem 2 to make it more accessible to a broader audience. However, the comment does not provide specific guidance on how to achieve this simplification or what aspects of Theorem 2 are particularly challenging for the general reader. While the action is implied, it lacks concrete details on how to implement the suggestion, making it 3.", "grounding_specificity_rationale": "The comment suggests simplifying Theorem 2 to make it more accessible to the general audience, similar to Theorem 1. However, it does not specify which part of the paper contains Theorem 2 or where the simplified version should be placed. The authors can infer that it relates to the section containing the theorem, but this inference is not direct. The comment is specific in suggesting a potential simplification but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests simplifying Theorem 2 to make it more accessible to the general audience, similar to Theorem 1. However, it does not provide any reasoning, examples, or references to support why this simplification is necessary or how it would benefit the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests simplifying Theorem 2 to make it more accessible to the general audience, similar to Theorem 1. This feedback is 3 as it identifies a potential area for improvement in the clarity and accessibility of the paper. However, the comment lacks specific guidance on how to achieve this simplification or what aspects of Theorem 2 are particularly challenging for the general reader. While it points out a potential issue, it does not provide detailed suggestions or examples to help the authors address it effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the keypoint mask averaged feature vector, specifically asking whether it is calculated by multiplying each feature map elementwise by H_psi. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the calculation of the keypoint mask averaged feature vector, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the calculation of the keypoint mask averaged feature vector. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the calculation of the keypoint mask averaged feature vector, specifically asking whether it is calculated by multiplying each feature map elementwise by H_psi. While this question may be relevant to the authors, it does not provide any guidance or suggestions for improvement. It lacks actionable feedback or context that would help the authors understand how to address the issue or improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should use styles or add color to make it easier to distinguish between the different curves in Figure 2. While the suggestion is clear and provides a specific action to take, it lacks detailed guidance on which styles or colors to use. The authors are left to infer the specifics of how to implement this suggestion, which makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which is the difficulty in distinguishing between the different curves. The comment provides a clear suggestion to use styles or add color to improve the figure, offering a concrete action for the authors to take. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the curves in Figure 2 are difficult to distinguish, and it provides a specific suggestion to use styles or add color to improve the figure. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the current figure is difficult to distinguish or how the suggested changes would improve clarity. Without additional context or explanation, the claim remains 3, as the authors may find it challenging to understand the basis of the suggestion without further elaboration. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on Figure 2, noting that the different curves are difficult to distinguish. It suggests using styles or adding color to improve clarity. While the comment identifies a specific issue with the figure, it lacks depth and does not provide detailed guidance on how to implement the suggested changes or which styles or colors might be most effective. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional details. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly recommends that the authors tone down the introduction and not refer to the task as \"language learning.\" It suggests that the task is more accurately described as a feedbackdriven QA in the form of a dialog. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be changed in the introduction. The comment is 5 as it gives a direct and specific direction for improvement, ensuring that the authors know exactly how to address the issue.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction\" and the \"claims made in the introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the overstatement of the task as \"language learning\" and the evaluation on question answering, suggesting that it is more accurately described as a feedbackdriven QA in the form of a dialog. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claims made in the introduction are far from what has been achieved by the tasks and models, and suggests that the authors should tone down the introduction and not refer to it as \"language learning.\" The reviewer provides a logical reasoning by pointing out that the task is more accurately described as a feedbackdriven QA in the form of a dialog. However, the comment lacks specific examples or references to support the claim that the task is significantly different from language learning. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3, as it requires further elaboration to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the claims made in the introduction, noting that they are far from what has been achieved by the tasks and models. It suggests that the authors should tone down the introduction and not refer to it as \"language learning,\" as it is more accurately described as a feedbackdriven QA in the form of a dialog. This feedback is clear and actionable, providing the authors with a specific and constructive suggestion for improving the draft. By recommending a more accurate description, the comment helps the authors clarify their claims and enhance the clarity of their introduction. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it points out that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. While the comment implies that the authors should focus on proving lower bounds for round complexity, it does not provide explicit instructions or concrete steps on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should focus on this aspect of the work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it also points out that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the results and methodology sections where the lower bound results are discussed. The comment is specific in detailing what is problematic about the paper\"s approach, but it lacks grounding as it does not specify which part of the paper is being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it suggests that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. The comment provides a logical reasoning for why the lower bound results are not as significant as they might seem, but it lacks specific examples or references to support this claim. This makes the claim 3, as the authors would need to further explore the reduction and its implications to fully understand the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it also points out that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. This feedback highlights a potential oversight in the paper\"s approach and suggests that the authors should focus on proving lower bounds for round complexity to strengthen their results. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions on how to address this issue or what additional analyses might be needed. Overall, the comment is 3 as it identifies a potential area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the prompting technique used in the study is basic and fails to leverage the full potentials of LLMs. It recommends using carefully curated prompts to generate better systematic reviews. While the comment implies that the authors should consider using more advanced prompting techniques, it does not provide specific guidance on how to implement this suggestion or what specific prompts might be effective. The action is implicit and somewhat vague, as the authors need to infer the need for more advanced prompting techniques and how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the prompting technique used in the study, suggesting that it is basic and fails to leverage the full potentials of LLMs. It recommends using carefully curated prompts to generate better systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique, making it weakly grounded. The suggestion to use carefully curated prompts is specific, but without clear grounding, the authors may struggle to identify the exact section that needs improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is basic and fails to leverage the full potentials of LLMs. It suggests that using carefully curated prompts could lead to better results in generating systematic reviews. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or reasoning makes the claim 3, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the study, namely the use of a basic prompting technique that fails to leverage the full potential of LLMs. It suggests that using carefully curated prompts could lead to better results in generating systematic reviews. While the comment highlights an important area for improvement, it lacks specific guidance on how to implement this suggestion or what criteria should be used to curate prompts. This limits the comment\"s usefulness, as it provides a general direction but does not offer detailed steps for the authors to follow. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that additional experiments on larger datasets would be beneficial but acknowledges the potential issue of compute. It also thanks the authors for their response and provides a positive assessment of how well the authors addressed concerns. However, the comment does not explicitly instruct the authors to conduct additional experiments or specify how to manage the compute issue. While the suggestion is clear, the lack of concrete guidance on execution makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on larger datasets and acknowledges the potential issue of compute. It also thanks the authors for their response and provides a positive assessment of how well the authors addressed concerns. However, the comment does not specify which part of the paper should include these additional experiments or how the compute issue should be addressed. While the authors might infer that it relates to the experimental section, the comment lacks explicit grounding. It is specific about the need for additional experiments but does not provide detailed guidance on execution. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting additional experiments on larger datasets but acknowledges the potential issue of compute. It also thanks the authors for their response and provides a positive assessment of how well the authors addressed concerns. The comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment suggests conducting additional experiments on larger datasets, which could provide valuable insights into the model\"s performance. However, it acknowledges the potential issue of compute and notes that maintaining probabilities might become an issue at large batch sizes. While the comment identifies a potential area for improvement, it does not offer specific guidance or suggestions on how to address the compute issue or how to conduct the additional experiments. The feedback is 3 as it points out a potential area for improvement but lacks detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the performance of the model on REC and RES is behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the performance or suggestions for potential improvements. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance on REC and RES, comparing it to more recent models and providing specific examples like GLaMM and UNINEXT. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the performance of the model on REC and RES being behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. This claim is supported by references to external works, which provides a basis for the comparison. However, the comment could be strengthened by providing more detailed analysis or specific metrics to support the claim further. As it stands, the claim is 4 due to the inclusion of references, but it could be more robust with additional evidence or explanation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment highlights a significant issue with the performance of the model on REC and RES, comparing it to more recent models and providing specific examples like GLaMM and UNINEXT. This feedback is valuable as it identifies a clear area for improvement, allowing the authors to address the issue and potentially improve their results. However, the comment could be more helpful if it provided suggestions on how to improve the performance or offered guidance on potential strategies for catching up with more recent models. Despite this, the feedback is 4 as it directs the authors\" attention to a critical area needing improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed video storyboarding approach lacks novelty, as it relies heavily on framewise SDSA, which is similar to the approach used in ConsiStory. The reviewer notes that the only notable difference is the mask source, which uses CLIPseg and OTSU segmentation instead of crossattention. While the comment identifies a specific area of concern, it does not provide explicit guidance on how the authors should address this issue or improve the novelty of their approach. The action is implicit and somewhat vague, as the authors can infer that they need to explore ways to enhance the innovation of their method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed video storyboarding approach\" and \"framewise SDSA,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty in the approach, noting that it relies heavily on framewise SDSA and that the only notable difference is the mask source. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed video storyboarding approach lacks novelty, as it relies heavily on framewise SDSA, which is similar to the approach used in ConsiStory. The reviewer notes that the only notable difference is the mask source, which uses CLIPseg and OTSU segmentation rather than crossattention. This claim is 3 as it provides a specific comparison to ConsiStory, which is a wellknown approach, and highlights the difference in the mask source. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the novelty of the proposed video storyboarding approach, noting that it relies heavily on framewise SDSA, which is similar to the approach used in ConsiStory. The reviewer highlights the only notable difference as the mask source, which uses CLIPseg and OTSU segmentation rather than crossattention. This feedback is 3 as it points out a specific area where the paper could be improved by exploring more innovative approaches or techniques. However, the comment lacks detailed suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. To be more helpful, the comment could provide specific suggestions or examples of alternative methods that could be considered. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes. It also proposes an interesting comparison with previous approaches on fewshot classification in such datasets. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison, but it is not as concrete as it could be. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes, and proposes a comparison with previous approaches on fewshot classification in such datasets. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a comparison with previous approaches, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes. However, it does not provide any supporting evidence or references to substantiate this claim. The comment implies that a comparison with previous approaches on fewshot classification in such datasets would be interesting, but it lacks detailed reasoning or examples to support the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes, which is a valuable observation. It also proposes an interesting comparison with previous approaches on fewshot classification in such datasets. This feedback provides a clear direction for the authors to consider, which could enhance the relevance and impact of their work. However, the comment could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it identifies a potential area for improvement and provides a direction for further exploration."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the kernels are implemented with OpenAI\"s Triton, not CUDA, and suggests that a fullpage explanation is unnecessary due to wellknown engineering improvements. This provides clear and direct guidance on what the authors should change in their draft. The comment is specific about the issue and suggests a clear action to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"OpenAI\"s Triton\" and \"CUDA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the implementation of kernels with OpenAI\"s Triton instead of CUDA. This provides clear guidance on what the authors need to correct or clarify in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the kernels are implemented with OpenAI\"s Triton, not CUDA, and suggests that a fullpage explanation is unnecessary due to wellknown engineering improvements. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this is the case. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific observation about the implementation of kernels with OpenAI\"s Triton, rather than CUDA, which is a wellknown engineering improvement. It suggests that a fullpage explanation is unnecessary due to this fact. However, the comment lacks depth and does not offer any suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for clarification, it does not provide actionable feedback or detailed advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability. The reviewer also points out that the manipulation scenario might be challenging due to the complexity of the tasks. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the transferability and complexity of the tasks, but the comment does not offer detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability and provides examples of the manipulation scenario. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the transferability of the policy and the complexity of the tasks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the zeroshot nature of the work and the transferability of the policy. The reviewer suggests that the difficulty of the source and target tasks might limit the transferability, providing examples of the manipulation scenario. However, the comment lacks specific evidence or references to support the claim that the transferability is limited or misleading. The reasoning is somewhat logical, but the absence of detailed justification or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability, providing examples of the manipulation scenario to support this claim. The reviewer also points out that the policy transfer from simpler tasks to more complex tasks might be challenging. While the comment identifies potential weaknesses and areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or improve the clarity of their paper. The feedback is 3 as it prompts the authors to consider the complexity of the tasks and the potential limitations of the transferability, but it could be more comprehensive with additional actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the relative gains of the proposed method, noting that it achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. The reviewer suggests that the proposed method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment does not provide specific guidance on how the authors should address this concern or what steps they should take to improve the results on larger backbones like SwinB or SwinL. The action is implicit and somewhat vague, as the authors can infer that they need to test the method on larger backbones but are not given clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the relative gains of the proposed method, noting that it achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. It also suggests that the proposed method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the relative gains and the potential impact of the global pooling structure on smaller backbones. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. The reviewer suggests that the method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment lacks specific examples or references to support the claim about the relative gains or the potential impact of the global pooling structure on larger backbones like SwinB or SwinL. Without detailed evidence or comparisons, the claim is 3, as it provides a logical reasoning but lacks sufficient support to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, noting that the relative gains are not very strong, even on a smaller backbone like ResNet50. It suggests that the method might be easier to improve on smaller backbones due to its global pooling structure. The comment raises a valid concern about the method\"s performance on larger backbones like SwinB or SwinL, which could be important for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the method\"s performance on larger backbones. While it points out a potential weakness, the feedback could be more helpful with additional details or actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fullyconnected neural networks is trivial with the existing NTK theorem. It points out that the work bypasses the core problem of overparametrized neural networks and only considers easy wide fullyconnected neural networks. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or improve their analysis. The action is implicit and vague, as the authors are left to infer that they need to reconsider their analysis of neural networks and possibly expand it to include more complex models. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2, 3.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the analysis of neural networks, noting that the extension from linear models to wide fullyconnected neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of neural networks is less significant due to the existing NTK theorem, which trivially extends from linear models to wide fullyconnected neural networks. The reviewer supports this claim by referencing specific sections (3.2, 3.3) where this analysis is discussed. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why the existing NTK theorem makes the analysis trivial or how the work bypasses the core problem of overparametrized neural networks. While the reference to specific sections provides some context, the comment could be strengthened with additional justification or examples. Therefore, the comment is 3, as it provides some support but lacks comprehensive evidence or detailed reasoning.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of neural networks, noting that the extension from linear models to wide fullyconnected neural networks is trivial due to the existing NTK theorem. It points out that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. This feedback is 3 as it highlights a potential weakness in the analysis section, prompting the authors to reconsider their approach and potentially expand their analysis to address the issue. However, the comment could be more helpful if it provided suggestions on how to address this problem or what specific aspects of the analysis need improvement. Overall, the comment offers some guidance but lacks detailed suggestions for improvement, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the rigor of the evaluation, given the limited number of datasets for each task (5, 6, and 4). It suggests that having such a small number might not be sufficient, particularly if some datasets are too large for all algorithms to be used. The reviewer provides a specific suggestion to consider using more datasets to ensure rigor. However, the comment does not provide explicit guidance on how to select additional datasets or which datasets to prioritize. While the action is implied, it lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment raises a concern about the rigor of the evaluation, given the limited number of datasets for each task. It suggests that having 5, 6, and 4 datasets for the tasks, respectively, might not be enough, particularly if some datasets are too large for all algorithms to be used. The comment is specific in its concern about the number and choice of datasets, but it does not explicitly mention which part of the paper this issue pertains to. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the rigor of the evaluation, given the limited number of datasets for each task. It suggests that having 5, 6, and 4 datasets for the tasks, respectively, might not be enough, particularly if some datasets are too large for all algorithms to be used. The reviewer provides a logical reasoning by pointing out that having a limited number of datasets could impact the evaluation\"s thoroughness. However, the comment lacks specific examples or references to support the claim that some datasets are too large for all algorithms. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the rigor of the evaluation, given the limited number of datasets for each task. It suggests that having 5, 6, and 4 datasets for the tasks, respectively, might not be enough, particularly if some datasets are too large for all algorithms to be used. The comment provides a logical reasoning for this concern and highlights the potential impact on the thoroughness of the evaluation. However, it lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional datasets or methods for evaluating the algorithms. While the comment identifies a potential weakness, it does not offer actionable steps for improvement, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential confusion in the paper regarding the use of terms like \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what specific changes should be made to clarify the terms. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the multifidelity framework and sequential design for learning quantities, specifically mentioning a reference to Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al., 2017). This provides full grounding as it clearly identifies the part of the paper being addressed. The comment also specifies the issue of confusion regarding the terms \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the terms \"relatively inexpensive\" and \"expensive to evaluate\" are confusing, as they appear in different parts of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these terms are confusing or how they could be clarified. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper regarding the terms \"relatively inexpensive\" and \"expensive to evaluate\" used in different parts of the document. This is a clear and actionable observation that can help the authors clarify their language and improve the coherence of their writing. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific changes or clarifications to be made in the text. Overall, the comment is 3 as it points out a specific area for improvement but lacks detailed guidance on how to implement it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the method addresses sparse reward problems and questions whether it can solve sparsereward tasks as well as other methods (Qmix). However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, or suggesting ways to improve the method\"s performance in sparsereward scenarios. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the method and the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the method addresses sparse reward problems and whether it can solve sparsereward tasks as well as other methods (Qmix). The comment provides a clear direction for improvement by asking for clarification on the method\"s performance in sparsereward scenarios. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the method\"s ability to address sparse reward problems and suggests that the experiments do not support this claim. The reviewer provides a logical reasoning by comparing the proposed method to dense reward signals and subtaskspecific rewards, which could be seen as a way to address sparse reward issues. However, the comment lacks specific examples or references to support the claim that the method does not address sparse reward problems effectively. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the method\"s ability to address sparse reward problems effectively, based on the experiments presented. It suggests that the proposed method requires subtaskspecific rewards, which is similar to dense reward signals, and questions whether it can solve sparsereward tasks as well as other methods (Qmix). The comment also includes minor comments that suggest specific areas for improvement. However, the feedback lacks detailed guidance or suggestions on how the authors might address these issues or improve their method. While it identifies potential weaknesses, the comment could be more helpful by providing actionable steps or examples to enhance the draft. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide this clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"curated AH36M dataset\" and the need for clarification on whether it is used for training. It also raises questions about whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the fairness of the comparison. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the use of the curated AH36M dataset for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. This is an important consideration for ensuring the fairness and validity of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify their methodology. While it identifies a potential area for improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including the lack of clarity in the motivation for using an adversarial network, the unfairness of the experimental results, and the comparison with a larger model. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The comment lacks concrete details or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses several issues related to the motivation, experimental results, and comparison of the proposed model. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment does provide some specificity by mentioning the addition of CAT and GAN, which could be used to guide the authors in identifying the relevant sections. Overall, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in detailing the issues. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the motivation for using an adversarial network is unclear and that the experimental results are unfair. It also suggests that the proposed model is equipped with a larger CAT and GAN, which could be considered an unfair comparison. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to address the issues raised. Therefore, the comment is considered 2, as it provides some basis for the claims but lacks sufficient detail to fully substantiate them.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of clarity in the motivation for using an adversarial network, the unfairness of the experimental results, and the comparison with a larger model. While it highlights these areas for improvement, the comment does not provide specific suggestions or guidance on how the authors might address these issues. It lacks actionable advice or detailed feedback that could help the authors improve their draft. As a result, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This raises concerns about the validity of the results. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the reliability of the results or what specific steps to take to validate them. As a result, the authors are left without clear direction on how to improve the draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, particularly the MSE being significantly smaller than the MAE, which raises concerns about their validity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This observation raises concerns about the validity of the results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental results, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This observation raises concerns about the validity of the results and highlights a potential weakness in the paper. However, the comment does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the reliability of their experimental results. Without specific recommendations or examples, the feedback lacks depth and does not fully support the authors in improving their draft. Therefore, the comment is rated as 2, as it points out a problem but does not offer a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the novelty of their work. The comment lacks actionable details, such as recommending ways to differentiate the methodology or suggesting alternative approaches to enhance its originality. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not specify which part of the paper this critique is based on, such as specific sections or methods where the extension is evident. Without explicit references to sections or details, the authors cannot confidently determine which parts of the paper need attention or improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide specific examples or references to existing methods to substantiate this claim. Without detailed comparisons or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how the authors might differentiate their work or enhance its originality. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address the critique or improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the limited comparison of performance with only a few methods and the lack of consistent superiority of the proposed method over others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. The reviewer is open to changing their rating based on feedback from the authors and comments from other reviewers. While the comment implies that the authors should provide additional analysis, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as it lacks specific guidance on what kind of analysis should be provided. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of limited comparison with only a few methods and the lack of consistent superiority of the proposed method over others. It also suggests that some analysis should be provided to address the issue of inferior results, which violate the motivation. This provides clear guidance on what needs to be addressed, making the comment fully grounded. The comment is specific because it details the problem of limited comparison and the need for additional analysis to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. The comment provides a logical reasoning by pointing out the limited comparison and the need for additional analysis to justify the results. However, it lacks specific examples or references to support the claim that the results violate the motivation. This makes the claim 3, as it provides a reasonable basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the limited comparison of performance with only a few methods and the lack of consistent superiority of the proposed method over others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. This feedback is clear and actionable, as it points out a specific area where the authors need to improve their work. However, the comment could be more helpful if it provided suggestions on what kind of analysis would be beneficial or how to address the issue of inferior results. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. While the comment implies that the authors should expand on this topic, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should add more content on this topic. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information is discussed. The authors can infer that it relates to the dataset analysis or discussion, but the comment lacks full grounding. It is specific in suggesting what needs to be addressed, but without explicit references, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these aspects are important or how they could be addressed. Without specific examples or detailed explanations, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This feedback is clear and actionable, as it points out a gap in the paper that could enhance its depth and relevance. However, the comment could be more helpful if it provided examples of specific activities or detailed suggestions on how to address this issue. Overall, the comment is 4 as it directs the authors to a meaningful area for expansion and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should use different notation to avoid confusion between the dimensionality of points and the dilation factor. This is a clear and direct action for the authors to take, as it provides a specific recommendation for improving the clarity of their paper. The comment is concrete, as it specifies the need for different notation, and it is also somewhat vague in that it does not provide detailed guidance on what specific notation should be used. Overall, the comment is 5, as it clearly identifies an area for improvement and provides a concrete suggestion for addressing it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of \"D\" to represent both dimensionality and dilation factor, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of different notation to avoid confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the use of \"D\" to represent both dimensionality and dilation factor can cause confusion. However, it does not provide any supporting evidence or examples to substantiate this claim. The comment lacks specific reasoning or references to justify why using different notation would be beneficial or how it would clarify the paper. As a result, the claim is 1, as it does not provide sufficient evidence or reasoning to support the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper regarding the use of \"D\" to represent both dimensionality and dilation factor. It suggests that using different notation would help avoid confusion. This feedback is clear and actionable, as it provides a specific recommendation for improving the clarity of the paper. However, the comment could be more helpful if it offered suggestions on what alternative notation might be more appropriate or how to effectively communicate this change to the reader. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the concept of \"state\" and questions the equivalence of \"elements\" to \"states\" or \"actions\" in a specific section of the paper. While the comment identifies an area that needs clarification, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to provide more elaboration on the concept of state and its relationship to elements or actions. The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 186line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the concept of \"state\" and its relationship to \"elements\" or \"actions.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the clarity of the concept of \"state\" and its relationship to \"elements\" or \"actions.\" It suggests that more elaboration is needed. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the concept of state is unclear or how it should be clarified. Without additional context or examples, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the concept of \"state\" and its relationship to \"elements\" or \"actions.\" It questions the equivalence of these terms and suggests that more elaboration is needed. This feedback is 3 as it points out a potential area of confusion that the authors should address to improve the clarity of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify the concept or examples of how it might be misinterpreted. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any explicit or implicit suggestions on how the authors should clarify these comparisons or what specific aspects need to be addressed. There is no guidance on whether additional explanations or examples are needed, nor is there a recommendation for how to present the comparisons more clearly. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theoretical comparisons to adaptive learning of GPRGNN, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the theoretical comparisons to adaptive learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the theoretical comparisons to adaptive learning of GPRGNN. It points out that the comparisons are not clear, which is a critical issue for the paper\"s theoretical foundation. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify these comparisons or what aspects need to be addressed. While it highlights an important area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it provides a direction for improvement but lacks the depth and specificity needed for full utility."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the sufficiency of using only yes/no responses to measure object hallucination. It highlights that a simple yes response does not necessarily indicate comprehension of the object in the image, as the model may still produce incorrect objects when performing other tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the measurement. The action is implicit and somewhat vague, as the authors can infer that they need to consider alternative methods for measuring object hallucination, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the sufficiency of using only yes/no responses to measure object hallucination, highlighting that a simple yes response does not necessarily indicate comprehension of the object in the image. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where this measurement is used. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its critique of the methodology but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the sufficiency of using only yes/no responses to measure object hallucination. It highlights that a simple yes response does not necessarily indicate comprehension of the object in the image, as the model may still produce incorrect objects when undertaking other tasks. This claim is 3 as it provides a logical reasoning for why a simple yes/no response might not be sufficient. However, the comment could be strengthened by providing specific examples or references to studies that have demonstrated the limitations of such a measurement approach. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the sufficiency of using only yes/no responses to measure object hallucination, highlighting that a simple yes response does not necessarily indicate comprehension of the object in the image. It points out that the model may still produce incorrect objects when undertaking other tasks. This feedback is 3 as it identifies a potential limitation in the methodology and encourages the authors to consider alternative methods for measuring object hallucination. However, the comment could be more helpful if it provided specific suggestions or examples of alternative methods that could be used. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the verylongterm forecasting task is of limited practical significance and that the discussion requires improvement. It explicitly recommends conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon to put the results in a proper context. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments and adjusting the model training to improve the context of their results. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment addresses the verylongterm forecasting task and the discussion regarding its practical significance. It suggests that the discussion requires improvement, such as conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon to put the results in context. However, the comment does not specify which part of the paper discusses the verylongterm forecasting task or the current discussion, making it weakly grounded. The suggestion to improve the discussion is specific, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the verylongterm forecasting task is of limited practical significance and suggests that the discussion requires improvement. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the limited practical significance of the verylongterm forecasting task. It suggests that the discussion requires improvement by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon to put the results in context. This feedback is clear and actionable, providing the authors with concrete steps to enhance the relevance and robustness of their findings. However, the comment could be more helpful if it explained why the current discussion is insufficient or how the suggested improvements would impact the paper\"s contribution. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of experiments and explanation regarding the different queries used in spatiotemporal representation, specifically spatial, temporal, and summary. It suggests that this is a key difference between the work and VideoChatGPT and other works. The reviewer implies that the authors should include experiments and explanation to address this gap. However, the comment does not provide explicit instructions on how to conduct these experiments or what specific aspects to focus on. While the action is implied, it lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Experiments  Ablation\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the inclusion of experiments and explanation regarding the different queries used in spatiotemporal representation, specifically spatial, temporal, and summary. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absence of experiments and explanation regarding the different queries used in spatiotemporal representation is a key difference between the work and VideoChatGPT and other works. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing components. Without concrete evidence or detailed reasoning, the claim is not 5, leaving the authors with a vague understanding of what needs to be addressed. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of experiments and explanation regarding the different queries used in spatiotemporal representation. It highlights the importance of this aspect, as it is a key difference between the work and VideoChatGPT and other works. The comment suggests that the authors should include experiments and explanation to address this gap, which is a clear and actionable suggestion. However, it could be more helpful if it provided specific examples of queries or detailed guidance on how to conduct these experiments. Overall, the comment is 4 as it points out a critical area for improvement and offers a clear direction for the authors to enhance their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, it does not provide specific guidance on how the authors should address this issue or what aspects of the FRM should be elaborated upon. The comment implies that the authors should provide more details about the innovative aspects of their model, but it does not offer concrete steps or examples of what these details should include. As a result, the action is implicit and vague, making it difficult for the authors to know exactly how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, it does not specify which part of the paper discusses the FRM, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for more details on the innovative aspects of the FRM, but it is 1 as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation. It suggests that the innovative aspects should be detailed, but it does not provide specific guidance on how the authors should address this issue or what aspects of the FRM should be elaborated upon. While the comment highlights a potential weakness, it lacks actionable advice or examples that would help the authors improve their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider the potential social impacts of their work, such as increased automation and the risks from dual use. While the comment does not explicitly instruct the authors to include these aspects in their paper, it provides a clear direction for improvement by highlighting areas that could be explored. The action is implicit but concrete, as it specifies the potential social impacts that should be addressed. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 379,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the potential social impacts of the work, such as increased automation and dual use risks. This provides clear guidance on what the authors should consider in their paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not consider the potential negative social impacts of their work, specifically mentioning increased automation and dual use risks. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The suggestion to consider these aspects is logical, but without detailed evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential oversight in the paper regarding the social impact of the work. It suggests that the authors should consider the potential negative social impacts, such as increased automation and dual use risks. While the comment highlights an important area for consideration, it lacks specific guidance or examples on how the authors might address these issues. The feedback is 3 as it points out a gap in the paper, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It suggests that the authors should provide more details to establish a connection between these concepts. However, the comment does not specify what kind of details are needed or how to present them, leaving the authors to infer the necessary actions. While the comment identifies an area for improvement, it lacks concrete guidance on how to address the issue, making it 3.", "grounding_specificity_rationale": "The comment addresses a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, such as the connection between these concepts and the zeroshot learning effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It points out that this lack of clarity is due to poor clarity in the paper. However, the comment does not provide specific suggestions or guidance on how to improve the clarity or establish a connection between these concepts. While it highlights an area for improvement, the feedback lacks depth and actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment implies that these analyses are missing from the paper, it does not explicitly instruct the authors to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these analyses to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"strong empirical results\" of the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the potential contribution of finding out the reasons behind the empirical results through theoretical analyses or experiments. However, the comment lacks specificity regarding what kind of theoretical analyses or experiments would be needed to address the questions raised. Therefore, this comment is 4, aligning with a score of 4.", "verifiability_rationale": "The review point suggests that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment raises valid questions about the empirical results, it lacks specific examples or references to support the claim that these analyses are missing from the paper. The suggestion is logical and relevant, but the lack of detailed evidence or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. This feedback is clear and actionable, as it points out a specific area where the authors could enhance their work by conducting additional analyses or experiments. However, the comment could be more helpful if it provided specific suggestions on how to conduct these analyses or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for a citation regarding the kmax problem, which is a clear and direct action for the authors to take. The comment provides a specific request for additional information, ensuring that the authors know exactly what is expected of them. The action is concrete, as it specifies the need for a citation, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for a citation regarding the kmax problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a citation regarding the kmax problem. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for a citation regarding the kmax problem. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual request for additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where additional information or clarification is needed. By asking for a citation regarding the kmax problem, the reviewer prompts the authors to provide more context or references to support their claims. This feedback is actionable and can help the authors enhance the comprehensiveness and credibility of their work. However, the comment could be more helpful if it provided more detailed guidance on how to address the issue or suggested specific sources to consider. Overall, the comment is 3 as it points out a potential gap in the paper but lacks depth in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. This feedback implies that the authors should provide more detailed information about the estimation process and the model\"s reliability. However, the comment does not explicitly instruct the authors to include this information, nor does it provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should include this information but may not be entirely sure of the exact details to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of information on how the function for the optimal sequence length was estimated and how reliable the model is expected to be. This provides clear guidance on what the authors need to include in their paper to improve it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is no information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. This feedback is clear and actionable, as it points out a gap in the paper that the authors need to address to provide a more comprehensive understanding of their methodology. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a discrepancy in the language used in Figure L006, specifically noting that \"thousands\" is not accurate. It suggests a possible correction by adding \"on the subword level.\" This feedback is clear and provides a direct action for the authors to take, which is to revise the language in the figure to be more accurate. The suggestion is concrete, as it specifies the exact change needed to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L006,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the language used in the figure and suggests a possible correction by adding \"on the subword level.\" This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figure caption, \"thousands,\" is not accurate. However, it does not provide any supporting evidence or reasoning to substantiate this claim. The comment suggests a possible correction by adding \"on the subword level,\" but without further explanation or examples, it lacks verifiability. The authors may find it challenging to understand the basis of the claim and how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the language used in Figure L006, noting that the term \"thousands\" is not accurate. It suggests a possible correction by adding \"on the subword level,\" which could improve the accuracy of the figure. This feedback is clear and actionable, as it provides a direct suggestion for the authors to consider when revising their draft. However, the comment could be more helpful if it explained why \"thousands\" is not accurate or how the suggested correction would enhance the figure\"s clarity. Overall, the comment is 4 as it points out a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement. It notes that several hyperparameters, such as regularization, are not explicitly mentioned and asks for clarification on why the yvalue in the latent path figures is always 0 at x=0. The reviewer also expresses interest in further analysis of the model, specifically mentioning interpolations as a potential area for exploration. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The suggestions are somewhat vague and lack detailed guidance, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Fig 3\" and \"regularization,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues by questioning the yvalue at x=0 in the latent path figures and expressing interest in further analysis of the model. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the absence of certain hyperparameters, such as regularization, and the yvalue at x=0 in the latent path figures. It also expresses interest in further analysis of the model. While the comment identifies areas for clarification and potential improvements, it lacks specific examples or references to support the claim that these issues are problematic or require attention. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is categorized as 2, as it provides some basis for the claim but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the absence of certain hyperparameters, such as regularization, and the yvalue at x=0 in the latent path figures. It also expresses interest in further analysis of the model, specifically mentioning interpolations as a potential area for exploration. While the comment highlights important issues, it lacks specific guidance or suggestions on how to address these concerns or improve the paper. The authors are given direction but not detailed steps on how to implement the suggested improvements. Therefore, the comment is 3, as it provides insight into potential weaknesses but could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. It specifically points out that the exact contributions need to be written more clearly in the Introduction and that the material supporting the main contributions is in the appendix rather than the main sections. While the comment provides a clear indication of what needs to be addressed, it does not offer specific guidance on how to improve the clarity of the contributions or suggest ways to integrate the material into the main sections. The action is explicit but somewhat vague in terms of execution, as the authors know what needs to be done but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"deeprag algorithm,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of forward referencing, where material is introduced without proper explanation and is later explained in later sections. The comment further details the need for clearer contributions in the Introduction and the placement of supporting material in the appendix. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. The reviewer provides specific examples, such as Figure 1 and the deeprag algorithm, to support this claim. However, the comment lacks detailed reasoning or references to explain why this is a problem or how it affects the paper\"s clarity or impact. While the examples are helpful, the lack of comprehensive justification makes the claim 3, as the authors may need to infer the full extent of the issue and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. It provides specific examples, such as Figure 1 and the deeprag algorithm, to illustrate the problem and suggests that the exact contributions need to be written more clearly in the Introduction. Additionally, the comment points out that the material supporting the main contributions is in the appendix rather than the main sections, which could be confusing for readers. This feedback is clear and actionable, as it directs the authors to improve the clarity and organization of their paper. However, it could be more helpful if it provided suggestions on how to integrate the material into the main sections or offered guidance on how to present the contributions more effectively. Overall, the comment is 4 as it effectively identifies a weakness and provides specific suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the effect of rounding core tensors on the full tensor error and seeks clarification on whether there is an error bound in terms of epsilon. While the comment identifies a potential area for improvement, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they should provide more information on the theoretical aspects of the approximation error, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it points out a potential area for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the authors discuss the rounding of core tensors to smaller ranks with a given accuracy by clustering values or imposing some error decision epsilon. This allows the authors to accurately identify the relevant section. The comment is also specific because it asks for clarification on the effect of rounding on the full tensor error and seeks information on any error bound in terms of epsilon. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the theoretical aspects of rounding core tensors and the effect on the full tensor error. It seeks clarification on whether there is an error bound in terms of epsilon. While the comment identifies a potential area for improvement, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The authors are left to infer the need for clarification, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the authors discuss the rounding of core tensors to smaller ranks with a given accuracy. It raises a question about the effect of this rounding on the full tensor error and seeks clarification on whether there is an error bound in terms of epsilon. This feedback is valuable as it prompts the authors to consider the theoretical aspects of their method and provides a clear direction for further exploration and explanation. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how other studies have approached similar questions. Overall, the comment is 4 as it guides the authors toward a deeper understanding of their method and its implications."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the Table 1 only shows results on the discriminative setting, which is not applicable in real applications. It suggests that the authors should include results on the generative setting as well. While the comment implies that the authors should add results on the generative setting, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"visual dialog,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of results on the generative setting in Table 1. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Table 1 only shows results on the discriminative setting, which is not applicable in real applications. The reviewer suggests that the authors should include results on the generative setting as well. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that Table 1 only shows results on the discriminative setting, which is not applicable in real applications. It suggests that the authors should include results on the generative setting as well. This feedback is clear and actionable, as it directs the authors to address a gap in their experimental evaluation. However, the comment could be more helpful if it provided additional context or examples on how to conduct the analysis on the generative setting. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps to take to explore the effectiveness of the approach for other language families. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the effectiveness of the proposed approach for other language families, which is a clear and specific point. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of unknown effectiveness, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the effectiveness of the proposed approach for other language families. It highlights a gap in the paper that needs to be addressed, which is important for the authors to consider. However, the comment lacks depth and does not provide specific suggestions or guidance on how to explore or demonstrate the effectiveness of the approach for other language families. While it points out a relevant issue, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the form of p should be described near line 135, as it is assumed to be a Gaussian distribution. This provides a clear and direct action for the authors to take, which is to explicitly mention the form of p in their draft. The comment also references the reviewer\"s previous comment, which adds context and clarity. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the form of p is not explicitly stated and assumes it to be a Gaussian distribution. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the form of p should be described near line 135, as it is assumed to be a Gaussian distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption is valid or necessary. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the form of p is not explicitly stated near line 135, despite being assumed to be a Gaussian distribution. This feedback is clear and actionable, as it directs the authors to explicitly mention the form of p in their draft. By addressing this point, the authors can improve the clarity and completeness of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4, as it guides the authors toward a specific improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. While it implies that the authors should expand on these differences, it does not explicitly instruct them to do so or provide specific guidance on how to approach this enhancement. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed descriptions of the differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. However, it does not specify which parts of the related work section are lacking in detail or which works are not described adequately. Without explicit references to specific sections or works, the authors cannot confidently determine which parts need attention. The comment is 1 as it does not specify where in the paper the related work section is located, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. However, it does not provide specific examples or references to the works that are lacking in detail or clarity. Without these details, the claim is not fully substantiated, making it difficult for the authors to understand the exact areas that need improvement. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the related work section, specifically noting that some related works are named but not described in sufficient detail. This feedback is 3 as it points out a specific area where the paper could be strengthened, providing a clear direction for the authors to enhance the clarity and comprehensiveness of their related work section. However, the comment could be more helpful if it offered specific suggestions on how to improve the descriptions or provided examples of what kind of details might be missing. Overall, the comment is 3 as it highlights an area for improvement but lacks detailed guidance for the authors to fully address the issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly asks the authors to explain what type of understanding is gained by looking at the PPP maps, which is a clear and direct action. This request is specific and provides a concrete direction for the authors to improve their draft. The comment is 5 as it guides the authors on how to enhance the clarity and comprehensiveness of their explanation regarding the importance of PPP metrics.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors state the importance of reliable PPP metrics for understanding PPP effects in different tasks. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely an explanation of the understanding gained by looking at the PPP maps. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the explanation regarding the understanding gained from looking at PPP maps. It does not make a subjective claim or express an opinion but rather seeks clarification on the content. Therefore, it is a factual request for more detailed explanation, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their paper by explicitly explaining the understanding gained from looking at PPP maps. It highlights a gap in the explanation provided, which is crucial for understanding the effects of PPP in different tasks. By asking for clarification on this point, the comment provides a clear and actionable suggestion for the authors to enhance the comprehensiveness and clarity of their work. This feedback is 5 as it directs the authors to a specific area that needs attention and guidance on how to address it. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors have not compared their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. This implies that the authors should include such comparisons to enhance the credibility of their work. The action is clear and concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with stateoftheart methods for spanrelated tasks, such as SpanBERT. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of comparisons with other stateoftheart methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not compared their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT, which affects the credibility of their work. However, the comment does not provide specific examples or references to these stateoftheart methods or explain how the absence of such comparisons impacts the credibility of the work. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the significance of the omission themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors have not provided sufficient evidence for the credibility of their work. It points out the lack of comparison with stateoftheart methods for spanrelated tasks, such as SpanBERT, which is a relevant benchmark for evaluating the effectiveness of the proposed methods. This feedback is clear and actionable, as it directs the authors to include such comparisons to enhance the credibility of their work. However, the comment could be more helpful if it provided examples of how these comparisons could be conducted or what specific aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. It suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. The reviewer also questions the authors\" choice of baseline and suggests they should provide a stronger baseline to prove the usefulness of FP. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should provide a stronger baseline and consider the impact of rewardless actions on RBI. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the training process for RBI, specifically noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. It suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. The comment also questions the authors\" choice of baseline and suggests they should provide a stronger baseline to prove the usefulness of FP. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology or results sections where RBI and FP + RBI are discussed. The comment is specific in its critique of the training process and the need for a stronger baseline, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The comment suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the significance of the issue and the potential impact on the results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. This is a significant observation that could impact the performance and effectiveness of the method. The comment suggests that this could be a factor contributing to the superiority of FP + RBI over RBI alone. Additionally, it questions the authors\" choice of baseline and recommends providing a stronger baseline to prove the usefulness of FP. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are given a clear direction to consider the impact of rewardless actions and to strengthen their baseline, but the feedback could be more actionable with additional details. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the multiscale statement is misleading because the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The reviewer suggests that the only benefit is the reduction of gradient path by the slow RNN. While the comment identifies a potential issue with the statement, it does not provide explicit guidance on how the authors should address this misleading aspect. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the time scales involved and possibly revise the statement to be more accurate. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"multiscale statement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, explaining that the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The comment further suggests that the only benefit is the reduction of gradient path by the slow RNN. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the multiscale statement is misleading because the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The reviewer supports this claim by explaining the distinction between physical and logical time scales and the potential benefit of reducing gradient path by the slow RNN. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. As it stands, the comment is 4, as it provides a logical explanation but lacks specific references or detailed evidence to fully support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential misleading aspect in the paper regarding the multiscale statement. It points out that the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. This feedback is valuable as it highlights a potential source of confusion in the paper, which could be clarified to improve the accuracy and understanding of the work. However, the comment could be more helpful if it provided specific suggestions on how the authors might clarify this aspect or rephrase the statement to be more accurate. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should clarify the distinction between the expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. While the comment implies that the authors should make this distinction clearer upfront, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction, but it is concrete in that it provides a clear direction for improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"formulation in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. The comment provides a clear direction for improvement by suggesting that the distinction should be made clearer upfront. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the expected performance under observation noise is typically used for evaluation because the decisionmaker is interested in the true objective function and the noise is assumed to be noise (misleading, not representative). The reviewer suggests that in the current paper, the decisionmaker does care about the noise, and the objective function of interest is a stochastic noisy function. The comment provides a logical reasoning for the distinction between the two scenarios, but it lacks specific examples or references to support the claim that the current paper\"s approach is misleading. Therefore, the claim is 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s approach to evaluation, noting that the expected performance under observation noise is typically used because the decisionmaker is interested in the true objective function and the noise is assumed to be noise. However, in the current paper, the decisionmaker is interested in the stochastic noisy function, which is a different objective. The comment suggests that the distinction between these two should be clarified upfront to avoid misleading the reader. While the comment provides a clear and actionable suggestion for improvement, it could be more helpful if it offered specific guidance on how to clarify this distinction or provided examples of how other papers have addressed similar issues. Overall, the comment is 4 as it directs the authors to a critical area for clarification, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work. It also proposes a minor point about optimizing the inference part of the model by keeping the generative model fixed and parameterizing it as either SIGVAE or VGAE to compare representations. While the comment provides a clear action to take regarding the VGAE implementation, it lacks specific guidance on how to implement the suggested comparison with SIGVAE or VGAE. The minor point about optimizing the inference part is also mentioned but not further elaborated on. Therefore, the comment is 3, as it provides a clear action but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"VGAE with a vamp prior\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the potential benefits of the generative model and the inference part of the model. The comment provides a clear suggestion to run VGAE with a vamp prior to better match the doubly stochastic construction and offers a minor point about optimizing the inference part of the model. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work. This claim is 3 as it provides a logical reasoning for the potential benefits of the generative model and inference part of the model. However, the comment lacks specific examples or references to support the claim, such as detailed comparisons or studies that demonstrate the effectiveness of this approach. Additionally, the minor point about optimizing the inference part of the model is mentioned but not fully developed. Therefore, the comment is rated as 3, as it provides a logical basis for the claim but lacks detailed evidence or references to fully substantiate it.", "helpfulness_rationale": "The review comment provides two distinct pieces of feedback. The first part suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work, which could help inform whether the benefits are coming from a better generative model or better inference due to doublysemi implicit variational inference. This is a clear and actionable suggestion that could significantly impact the authors\" understanding and interpretation of their results. The second part is a minor point about optimizing the inference part of the model by keeping the generative model fixed and parameterizing it as either SIGVAE or VGAE to compare the representations. While this suggestion is relevant, it lacks depth and does not provide detailed guidance on how to implement this optimization or interpret the results. Overall, the comment is 4 as it offers actionable suggestions for improving the draft, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether there is a demonstration or result related to the model collapsing less than other methods. It also asks about the specific observation of gradients becoming 0 and collapsing, mentioning line 159. While the comment implies that the authors should provide evidence or examples to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information or examples to address the reviewer\"s concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 159,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for a demonstration or result related to the model collapsing less than other methods, and it raises questions about the common occurrence of gradients becoming 0 and collapsing. This provides clear guidance on what the authors need to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the demonstration or results related to the model collapsing less than other methods. It specifically mentions line 159, where the authors mention gradients becoming 0 and collapsing. This feedback is 3 as it prompts the authors to provide evidence or examples to support their claim, which could strengthen the paper\"s argument. However, the comment lacks depth and does not offer specific suggestions on how to address the issue or what kind of evidence would be beneficial. While it points out a potential area for improvement, it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests conducting experiments with different LLM families, specifically mentioning OPT, BLOOM, or other alternatives. This provides a clear and concrete action for the authors to take, as it specifies the exact models to include in the experiments and the purpose of doing so. The comment is specific and directs the authors on how to enhance their draft by adding experimental results, making it 5.", "grounding_specificity_rationale": "The comment suggests conducting experiments with different LLM families, specifically mentioning OPT, BLOOM, or other alternatives. This provides a clear direction for the authors to expand their experimental scope. However, the comment does not specify which part of the paper should include these experiments, such as the results or discussion sections. While the authors can infer that it relates to the experimental section, the comment lacks full grounding as it does not explicitly mention the section. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks experiments on different LLM families, specifically mentioning OPT, BLOOM, or other alternatives. This claim is 3 as it provides a logical reasoning for expanding the experimental scope to include a broader range of LLM families. However, the comment lacks specific examples or detailed justification for why these particular models are important or how they would enhance the study. Providing more detailed reasoning or references to similar studies could strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of experiments on different LLM families. It suggests conducting trials with models like OPT, BLOOM, or other alternatives to provide valuable insights into the method\"s applicability and generalizability across various LLM families. This feedback is clear and actionable, as it directs the authors to expand their experimental scope and includes specific models to consider. By addressing this suggestion, the authors can enhance the robustness and comprehensiveness of their study. However, the comment could be more helpful if it provided additional context or rationale for why these specific models are important or how they might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a perceived weakness in the connections between the curve finding and FGE, suggesting that the process described in the first part does not match the title or the author\"s imagined process. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the connections. The comment lacks actionable details, such as suggesting ways to clarify or strengthen the connections, making it difficult for the authors to know exactly how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first part and the second part, allowing the authors to accurately identify the sections being addressed. It also specifies the issue by pointing out the perceived weakness in the connections between the curve finding and FGE, and it provides a rationale for this observation. However, the comment lacks specificity regarding what needs to be addressed or improved in these connections. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the connections between the curve finding and FGE are weak, based on the author\"s interpretation of the first part and the title. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The comment suggests that the process described does not match the imagined process, but without further elaboration or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the connections between the curve finding and FGE, suggesting that the process described in the first part does not match the title or the author\"s imagined process. It highlights a disconnect between the theoretical framework and the practical application, which could lead to confusion or misunderstanding. However, the comment lacks specific suggestions or guidance on how to address this issue or improve the connections. While it points out a potential problem, it does not provide actionable feedback for the authors to improve their draft. Therefore, the comment is 3, as it offers insight but lacks depth and specificity."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include results for linear scalarization + Concorde, which is a heuristicbased solver, in their experimental analysis. This is an explicit action that the authors can directly implement to improve their draft. The comment provides a clear rationale for why this inclusion is necessary, as it highlights the competitive nature of learningbased solvers compared to heuristicbased solvers and the fact that the SOTA heuristicsolver usually has the best performance for single objective TSP. However, the comment could be more concrete by specifying which section of the paper should include these results, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and \"Pareto front,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of results for linear scalarization + Concorde, a heuristicbased solver, for a better comparison. This provides clear guidance on how to improve the paper by including these results. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers are better than the heuristicbased solvers, but it also acknowledges that for single objective TSP, the SOTA heuristicsolver (e.g., Concorde) usually has the best performance. The comment suggests that the authors should include results for linear scalarization + Concorde to provide a better comparison. This claim is 3 as it is based on the experimental results, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to conduct their own analysis to verify the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It highlights the competitive nature of learningbased solvers compared to heuristicbased solvers, particularly for single objective TSP, where the SOTA heuristicsolver (e.g., Concorde) usually has the best performance. The comment suggests that the authors should include results for linear scalarization + Concorde to provide a better comparison. This feedback is valuable as it directs the authors to include a relevant comparison that could enhance the paper\"s contribution. However, the comment could be more helpful if it explained why this comparison is important or how it would impact the paper\"s conclusions. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should discuss the proposed method in relation to existing methods that use generalized Voronoi graphs, semantic maps, or pose graphs for exploration. While the comment implies that the authors should provide a comparison or discussion of their method with these existing methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion of their method in relation to these existing methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"generalized Voronoi graph or semantic maps,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a discussion of the proposed method in relation to existing methods that use similar concepts for exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some of the general ideas in the proposed method are already present in other methods, specifically mentioning the use of generalized Voronoi graphs, semantic maps, and pose graphs for exploration. The reviewer supports this claim by referencing existing methods, such as graphbased SLAM and curiositydriven exploration, which use similar concepts. This provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to specific methods, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that some of the general ideas presented are already present in other methods, specifically mentioning the use of generalized Voronoi graphs, semantic maps, and pose graphs for exploration. It suggests that the paper should discuss the proposed method in relation to these existing methods, which could enhance its originality and contribution. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific examples or references to these existing methods, which would guide the authors in their comparison and discussion. Overall, the comment is 4 as it highlights an area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. While the comment implies that the authors should provide an explanation or rationale for this choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address this question but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where these architectures are discussed. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the choice of architectures but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice might be problematic or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the choice of using GRU for the Pyramid and LSTM for the sequential part, questioning whether the combination of these architectures is a reason for the improvements. This is a valuable point as it prompts the authors to consider the rationale behind their choice of architectures and whether it is a significant factor in their results. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered insights into potential alternatives or comparisons. While it identifies a critical area for consideration, it lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the definition of \"active vertices\" in a specific line of the paper. While it identifies a potential issue with the clarity of the definition, it does not provide any guidance on how the authors should address this concern. The comment lacks explicit instructions or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the definition of \"active vertices\" and asking for clarification. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on the definition of \"active vertices\" in a specific line of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of \"active vertices\" in a specific line of the paper, which is a clear and actionable point. By asking for clarification on the definition, the reviewer prompts the authors to provide more detailed explanations or definitions to ensure that their work is clear and understandable. This feedback is valuable as it helps the authors improve the clarity and comprehensibility of their draft. However, the comment could be more helpful if it suggested alternative ways to present the definition or provided examples to illustrate the concept. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a discrepancy between the paper\"s claims and the limitations it discusses. It points out that the theory is not mentioned as a limitation in the main text, despite being applicable to the used model. The reviewer suggests that the authors should address this issue by explicitly mentioning the theoretical limitation in the main text. Additionally, the comment notes that the vagueness of structural assumptions in the appendix makes it difficult to find the theoretical limitation. The reviewer also suggests that the authors should elaborate on the potential negative societal impact of graph neural networks in general, which could be a valuable addition to the paper. The feedback is explicit and provides concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"fact that their theory does not seem to be applicable to the used model\" and the \"vagueness of unspecified 'structural assumptions,\" that are only given in the appendix,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of the theoretical limitation not being mentioned in the main text and suggests that the authors should elaborate on the potential negative societal impact of graph neural networks in general. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper does not mention the theoretical limitation of its theory being applicable to the used model, despite the vagueness of structural assumptions in the appendix. The reviewer suggests that the authors underestimate the current use of graph neural networks in industry and should elaborate on the potential negative societal impact of these networks. The comment provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion about the current use of graph neural networks in industry. Additionally, the suggestion to elaborate on the potential negative impact is somewhat vague, as it does not provide detailed guidance on what aspects should be addressed. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks specific evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the theoretical limitation of the theory being applicable to the used model is not mentioned in the main text. This is a critical oversight, as it affects the validity and applicability of the paper\"s claims. The reviewer suggests that the authors should address this limitation by explicitly mentioning it in the main text, which would enhance the transparency and credibility of the work. Additionally, the comment points out the vagueness of structural assumptions in the appendix, making it difficult for readers to find the theoretical limitation. This feedback is valuable as it highlights a critical area for improvement in the paper. However, the comment could be more helpful if it provided specific guidance on how to address the vagueness of structural assumptions or how to elaborate on the potential negative societal impact of graph neural networks. Overall, the comment is 4 as it identifies a significant issue and offers actionable suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to ensure that both heads are affected. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors should address this issue. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). This is a clear observation that could be relevant for the authors to address, as it highlights a potential imbalance in the paper\"s focus. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific changes could be made to ensure a more balanced presentation. While it points out a potential weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the focus distance shown in Figure 8, noting that it only includes 1m and 5m, which are both present in the training data. The reviewer asks whether the focus distance extends beyond these examples and if it generalizes well. While the comment implies that the authors should consider including additional focus distances, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand the focus distance range. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the focus distance shown in the figure, suggesting that it should include other distances beyond those present in the training data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the focus distance shown in Figure 8, noting that it only includes 1m and 5m, both of which are present in the training data. The reviewer asks if the focus distance extends beyond these examples and if it generalizes well. This claim is 3 as it raises a valid question about the scope and applicability of the results. However, it lacks specific examples or references to support the claim that other focus distances should be considered. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 8, noting that it only shows focus distances of 1m and 5m, both of which are present in the training data. It raises a valid question about the generalizability of the results to other focus distances. This feedback is 3 as it prompts the authors to consider whether their results are limited to these specific distances and whether they can be extended to other distances. However, the comment could be more helpful if it provided suggestions on how to address this limitation or what additional experiments could be conducted to test generalizability. Overall, the comment offers a clear direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider defining content and style more broadly, particularly in the context of their neural application. It provides an example from Gabbay & Hosehn (2018) to illustrate how style is instancespecific and content includes information that can be transferred among groups. The comment also raises a question about the authors\" understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. While the comment provides a clear direction for the authors to consider broadening their definition of content and style, it does not offer specific guidance on how to implement this suggestion. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider defining content and style more broadly, particularly in the context of their neural application. It provides an example from Gabbay & Hosehn (2018) to illustrate how style is instancespecific and content includes information that can be transferred among groups. The comment also raises a question about the authors\" understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion of content and style in the context of their neural application. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should consider defining content and style more broadly, particularly in the context of their neural application. It provides an example from Gabbay & Hosehn (2018) to illustrate how style is instancespecific and content includes information that can be transferred among groups. The comment also raises a question about the authors\" understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. While the comment provides a logical reasoning for broadening the definition of content and style, it lacks specific examples or references to fully substantiate the claim. This makes the comment 3, as it provides a basis for the suggestion but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to consider broadening their definition of content and style, particularly in the context of their neural application. It offers an example from Gabbay & Hosehn (2018) to illustrate how style is instancespecific and content includes information that can be transferred among groups. Additionally, the comment raises a pertinent question about the authors\" understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. This feedback is valuable as it prompts the authors to reconsider their terminology and potentially enhance the clarity and depth of their work. However, the comment could be more helpful if it provided specific guidance on how to apply this broader definition or how to address the question about the temporal dynamic structure. Overall, the comment is 4 as it offers a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the analysis of vit quantification could be explained in depth, specifically addressing the argument that a direct quantization method leads to information distortion and the quantization of MHSA introduces a large loss of precision. The reviewer provides specific examples from the paper, such as the variance difference in Fig1(b) and Fig5(b) for Block.3, and references to NLP models like QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert, which have experienced similar issues. This feedback is explicit and provides concrete details on what the authors need to address to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of vit quantification, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the direct quantization method and the quantization of MHSA, providing examples from the paper and references to other works. This level of detail helps the authors understand what needs to be addressed and improved in the analysis. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the analysis of vit quantification, specifically arguing that the direct quantization method leads to information distortion and that the quantization of MHSA introduces a large loss of precision. The reviewer provides specific examples from the paper, such as the variance difference in Fig1(b) and Fig5(b) for Block.3, and references to NLP models like QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert, which have experienced similar issues. This provides a robust basis for the claim, making it 4. The authors can understand the basis of the critique and address it by examining these examples and references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the analysis of vit quantification, specifically addressing the argument that a direct quantization method leads to information distortion and the quantization of MHSA introduces a large loss of precision. The reviewer provides specific examples from the paper, such as the variance difference in Fig1(b) and Fig5(b) for Block.3, and references to NLP models like QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert, which have experienced similar issues. This feedback is 5 as it not only identifies specific weaknesses in the analysis but also offers actionable suggestions for improvement. By addressing these points, the authors can enhance the depth and accuracy of their analysis, which is crucial for the credibility and impact of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a main weakness of the paper, which is the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It suggests that the proposed Xtransformation seems similar to STN, and points out that existing works have applied STN in a local pixel neighborhood. Additionally, it notes the absence of empirical or conceptual comparisons to STN in the paper. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific comparisons should be made. The action is implicit and somewhat vague, as the authors can infer that they need to include comparisons to STN and provide more detailed explanations of the Xtransformation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"spatial transformer networks (STN)\" and the \"Xtransformation,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of technical novelty and the absence of comparisons to STN, which are important aspects that need to be addressed. The comment provides specific guidance on what needs to be improved, such as the need for empirical or conceptual comparisons to STN. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical novelty of the work is limited due to its similarity to spatial transformer networks (STN) and the absence of comparisons to STN. The reviewer supports this claim by pointing out that the proposed Xtransformation seems similar to STN and that existing works have applied STN in a local pixel neighborhood. Additionally, the comment notes the absence of empirical or conceptual comparisons to STN in the paper. While the comment provides some logical reasoning and references to existing works, it could be strengthened by providing specific examples or references to these existing works. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, which is the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It points out that the proposed Xtransformation seems similar to STN and that existing works have applied STN in a local pixel neighborhood. Additionally, it notes the absence of empirical or conceptual comparisons to STN in the paper, which is crucial for demonstrating the novelty of the work. The comment provides clear and actionable feedback by suggesting that the authors should include comparisons to STN and provide more detailed explanations of the Xtransformation. This feedback is valuable as it guides the authors on how to enhance the technical novelty and comparative analysis of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit actions for the authors to take. It explicitly instructs them to correct the labeling of \"Fig.7\" to \"Fig.12\" in Supp. Page 31 and to attach each theorem and corollary to its corresponding proof link. Additionally, it highlights the primary concerns of motivation, methodology soundness, and experiment persuasion, which the authors should address to improve the paper. The comment is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31\" and \"Fig.7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected (the labeling of \"Fig.7\" to \"Fig.12\") and suggests attaching each theorem and corollary to its corresponding proof link. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the labeling of \"Fig.7\" in Supp. Page 31 and suggests attaching each theorem and corollary to its corresponding proof link. The reviewer provides a specific correction for the labeling issue and suggests a way to improve the paper\"s organization. However, the comment lacks detailed reasoning or references to support the claim about the importance of these changes or how they would enhance the paper. While the suggestion is logical, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the paper\"s content, particularly regarding the labeling of figures and the organization of theorems and corollaries. It suggests correcting the labeling of \"Fig.7\" to \"Fig.12\" and attaching each theorem and corollary to its corresponding proof link, which would improve the reader\"s ability to follow the paper. Additionally, the comment acknowledges the paper\"s strengths, such as its novelty, clear theoretical guarantees, and convincing empirical results. This feedback is 4 as it offers concrete steps for improvement and acknowledges the paper\"s positive aspects. However, it could be more helpful if it provided additional suggestions or examples on how to enhance the motivation, methodology soundness, and experiment persuasion. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions about the definition and implementation of certain concepts in the paper. It specifically asks about the determiner missing in Section 3, the action verbs used, and the \"action frames\" mentioned later in the paper. While the questions are clear and specific, they do not provide explicit guidance on how the authors should address these issues. The authors can infer that they need to clarify the missing determiner, explain the action verbs, and provide more information on the \"action frames,\" but the comment lacks concrete details on how to implement these changes. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed instructions on how to execute them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3\" and \"306ff,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by asking about the determiner missing in Section 3, the action verbs used, and the \"action frames\" mentioned later in the paper. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions about the definition and implementation of certain concepts in the paper, specifically the missing determiner in Section 3, the action verbs used, and the \"action frames\" mentioned later in the paper. These questions are clear and specific, prompting the authors to clarify and provide more detailed explanations in their draft. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of what the authors might consider in their explanations. Overall, the comment is 4 as it identifies areas for improvement and prompts the authors to provide more detailed explanations, but it could be more actionable with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly identifies a single spelling mistake on line 32 of page 1, suggesting that the word \"Empiically\" should be corrected to \"Empirically.\" This is a clear and direct action for the authors to take, as it provides a specific correction to make in their draft. The comment is explicit and concrete, as it specifies the exact change needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the spelling of \"Empiically\" on line 32, suggesting that it should be corrected to \"Empirically.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual observation about a spelling mistake in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a minor but specific issue with the spelling of the word \"Empiically\" on line 32 of page 1, suggesting that it should be corrected to \"Empirically.\" This is a clear and actionable suggestion that can help improve the accuracy and professionalism of the paper. However, the comment does not provide any context or explanation for why this correction is necessary or how it might impact the overall quality of the paper. While it is helpful in pointing out a specific error, it could be more beneficial if it included additional guidance or reasoning. Therefore, the comment is 3, as it provides a clear and actionable suggestion but lacks depth and context."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the proposed invariant learning module could be improved by considering representation learning, which is currently discussed in the appendix. It also points out that the framework seems not to be limited to rawlevel selection, as evidenced by the discussion in Section 4. The comment provides a clear direction for the authors to consider incorporating representation learning into the feature selection process in Section 4.2. This feedback is explicit and concrete, as it specifies the exact area that needs improvement and how to address it. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"Line 167174, Sec. 4,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue with the proposed invariant learning module, suggesting that it could be improved by considering representation learning. Additionally, it provides a specific suggestion for improvement by mentioning the appendix discussion on representation learning. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed invariant learning module could be improved by considering representation learning, which is currently discussed in the appendix. The reviewer provides a logical reasoning by pointing out that the framework seems not to be limited to rawlevel selection, as evidenced by the discussion in Section 4. However, the comment lacks specific examples or references to the appendix or Section 4 to fully substantiate the claim. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3, as it requires further elaboration to fully support the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the proposed invariant learning module by suggesting that it could be enhanced by considering representation learning, which is currently discussed in the appendix. It points out that the framework seems not to be limited to rawlevel selection, as evidenced by the discussion in Section 4. This feedback is clear and actionable, as it provides a specific direction for the authors to consider incorporating representation learning into the feature selection process. By addressing this suggestion, the authors could significantly improve the robustness and generalizability of their approach. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some details are missing, specifically mentioning the design of rewards as an example. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific steps to clarify the reward design or suggesting ways to improve the explanation. As a result, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the design of rewards, which is a clear and specific point. However, it does not explicitly mention which part of the paper discusses the rewards, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the lack of understanding of how the rewards are designed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"some details are missing,\" specifically mentioning the design of rewards as an example. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some details are missing, particularly regarding the design of rewards. This is a clear and actionable point that the authors can address to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to design the rewards or examples of how this might be done. Overall, the comment is 3 as it highlights a critical area for improvement but lacks detailed guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count. This is a clear and direct action for the authors to take, as it provides a specific area for improvement and highlights the importance of runtime as a limitation for MLbased emulators of climate model parametrizations. The comment is concrete, as it specifies the need for runtime discussion, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Prithvi WxC\" emulator, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the runtime of Prithvi WxC and its potential limitations for applications. This provides clear guidance on what aspect of the emulator needs attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count, as it could be a limitation for MLbased emulators of climate model parametrizations. However, the comment does not provide any supporting evidence, reasoning, or references to justify why runtime is a critical issue or how it affects the applicability of the emulator. Without additional context or examples, the claim remains 3, as the authors may find it challenging to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the runtime of Prithvi WxC should be discussed, given its large parameter count. This is a clear and actionable suggestion that could help the authors address a potential limitation of their emulator in the context of MLbased climate model parametrizations. By discussing the runtime, the authors can provide valuable insights into the practicality and applicability of their emulator, which could enhance the overall quality and usefulness of their work. However, the comment could be more helpful if it provided additional context or examples on how the runtime might impact the emulator\"s performance or applicability. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the paper oversells the method, making the contribution less clear. However, it does not provide any specific guidance on how to address this issue or what changes should be made to improve the clarity of the contribution. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making it difficult for the authors to know how to apply the feedback to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors cannot confidently determine where to address this issue. Additionally, the comment lacks specificity regarding what aspects of the framing are problematic or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper oversells the method, making the contribution less clear. However, it does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper oversells the method, making the contribution less clear. However, it does not provide specific examples or detailed guidance on how the framing could be improved to better convey the actual contribution of the work. Without actionable feedback or suggestions, the authors are left without a clear understanding of what changes to make or how to enhance the clarity of their paper. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the quality of paraphrases generated for training data, specifically noting that the paraphrases should be distinct from the original sentences. It also points out that the quality of these paraphrases impacts subsequent steps, as the model relies on them. However, the comment does not provide explicit guidance on how to address this issue or what specific steps the authors should take to ensure the paraphrases are distinct. While the action is implied, it is not detailed enough for the authors to know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the process of generating paraphrases for training data, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unclear paraphrases and their impact on the quality of the final training data. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paraphrases generated for training data are unclear and impact the quality of the final training data. This claim is 3 as it logically follows that if the paraphrases are not distinct from the original sentences, the quality of the training data could suffer. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the issue, as the comment does not provide detailed guidance on how to improve the paraphrases. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the quality of paraphrases generated for training data, noting that the paraphrases should be distinct from the original sentences. This is crucial because the model\"s reliance on these paraphrases could impact the quality of the final training data. The comment highlights the potential consequences of poor paraphrasing, such as the discarding process resulting in few pairs being added to the new training data. While the comment provides a clear and actionable suggestion for improvement, it could be more helpful if it offered specific guidance on how to ensure the paraphrases are distinct or provided examples of what constitutes an acceptable level of distinctness. Overall, the comment is 4 as it directs the authors to a critical area needing attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the clarity of Figure 2, noting that the \"bold\" text is hard to see and suggests that another color or a larger font might help in highlighting the humanidentified rationales better. While the comment provides a clear and concrete suggestion for improving the figure, it does not explicitly instruct the authors on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should consider changing the font or color to enhance readability. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that the \"bold\" text is hard to see and suggesting that another color or a larger font might help in highlighting the humanidentified rationales better. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that identifying rationales for more complicated NLP tasks like machine translation is not a simple problem, and that the paper is wellorganized and easy to follow. The comment suggests that Figure 2 is cluttered and that the \"bold\" text is hard to see, proposing a solution of using another color or a larger font to enhance readability. While the comment provides a logical reasoning for the issue with Figure 2, it lacks specific examples or references to support the claim about the complexity of identifying rationales for NLP tasks. The suggestion to improve the figure is 3, as it provides a clear rationale but could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Figure 2, noting that the \"bold\" text is hard to see and suggesting that another color or a larger font might help in highlighting the humanidentified rationales better. This feedback is actionable and provides a clear direction for improving the figure\"s readability. However, the comment could be more helpful if it offered additional suggestions or examples of alternative colors or font sizes that might work better. Overall, the comment is 4 as it provides a clear and actionable suggestion for improving the figure, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not provide any specific guidance or suggestions on how to improve the writing. The authors are left without any concrete steps or examples to follow in order to enhance their draft. As a result, the comment lacks actionability, leaving the authors uncertain about how to address the issue. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not specify which parts of the paper are particularly challenging to understand or where the writing could be improved. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point suggests that the writing could be improved, indicating that it was difficult to understand the main idea and theoretical analysis of the paper. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to identify the exact areas that need improvement. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the writing could be improved, indicating that it was difficult to understand the main idea and theoretical analysis of the paper. However, it does not provide specific examples or guidance on how to improve the writing, such as suggesting clearer explanations or more accessible language. Without actionable feedback or detailed suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as 2, as it identifies a potential issue but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. It suggests that the authors should address these concerns to improve the paper. However, it does not provide specific guidance on how to address these concerns or what aspects of the method should be improved. The mention of existing methods and references to ClopperPearson intervals and Gaussian elimination suggest that the authors should provide more detailed explanations or comparisons with these methods. However, the comment lacks concrete instructions or examples on how to implement these improvements. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"existing methods\" that it builds upon, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concerns about the lack of significant theoretical novelty and the need to address these concerns. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer acknowledges a willingness to improve their score if the authors address these concerns. However, the comment does not provide specific examples or detailed reasoning to support the claim about the lack of novelty. The references to ClopperPearson intervals and Gaussian elimination suggest that the reviewer is familiar with these methods, but this alone does not fully substantiate the claim. The comment could be strengthened by providing more detailed reasoning or examples to support the critique. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a significant concern about the novelty of the proposed method, noting that it primarily builds upon existing methods and lacks theoretical novelty. It acknowledges the authors\" willingness to improve their score if the concerns are addressed. However, the comment does not provide specific guidance or suggestions on how the authors might address these concerns or improve the novelty of their work. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it points out a critical issue but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific actions they should take to improve their draft. The comment lacks explicit or implicit actions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the concatenation of text elements, but without explicit references to sections or figures, the authors cannot confidently determine where to address this question. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point poses a question about whether the text input can be concatenated by the four text elements of an object. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The comment poses a question about the concatenation of text elements, which could be a relevant aspect to consider in the context of the paper. However, it lacks any guidance or suggestions on how the authors might address this question or what potential implications it might have for their work. Without actionable feedback or context, the comment does not provide much value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it identifies a potential area for consideration but does not offer detailed guidance or suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the abstract sentence in lines 1217 is cumbersome and could be made clearer. However, it does not provide any guidance on how to achieve this clarity or what specific changes should be made to the sentence. The action is implicit and vague, as the authors are left to infer that they need to revise the sentence but without detailed instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract sentence in lines 1217, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that the sentence is cumbersome and could be made clearer. This provides clear guidance on what the authors need to improve. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract sentence in lines 1217 is cumbersome and could be made clearer. However, the comment does not provide any specific reasoning or examples to support this claim. It lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract sentence in lines 1217, noting that it is cumbersome and could be made clearer. While the comment highlights a potential problem, it does not provide detailed guidance or suggestions on how to improve the clarity of the sentence. The authors are left to infer that they need to revise the sentence, but without specific instructions or examples, the feedback lacks depth and actionability. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the comparisons made between the domainspecific model and zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative comparisons that might be more fair. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their comparisons, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the domainspecific model being trained on Pix3D and the experiments being conducted on Pix3D, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the comparisons to zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparisons between the domainspecific model and zeroshot singleimage 3D reconstruction models are unfair due to the use of Pix3D as both the training and testing dataset. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these comparisons are unfair. Without additional context or explanation, the claim remains 1, as it lacks the necessary information to support the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparisons made between the domainspecific model and zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. This feedback highlights a potential bias in the experimental setup that could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the bias in their comparisons. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a limitation in the evaluation, specifically the reliance on only four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. While the comment implies that the authors should expand their evaluation to include additional datasets, it does not explicitly instruct them to do so. The action is concrete, as it specifies the need for more diverse datasets, but it is somewhat vague in terms of how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 4(5)\" and \"4 OCR QA datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the evaluation being limited to these datasets and suggests the inclusion of more scenarios like the LLaVA benchmark, especially in ablation studies. This provides clear guidance on what needs to be addressed to improve the evaluation section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited and relies on only four OCR QA datasets, which may be unreliable. The reviewer supports this claim by referencing Fig 4(5) and suggesting that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. This provides a logical basis for the claim, as it highlights the potential limitations of the current evaluation approach. However, the comment could be strengthened by providing specific examples or references to studies that have used the LLaVA benchmark, which would further substantiate the claim. Overall, the comment is 4, as it provides a reasonable basis for the claim but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation section, specifically the reliance on only four OCR QA datasets. It suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies, to enhance the reliability of the evaluation. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their evaluation to include additional datasets. However, the comment could be more helpful if it explained why the LLaVA benchmark is particularly relevant or how it might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their evaluation section."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It also questions the interpretation of the models\" learning and whether simpler tasks would suffice. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve the clarity of their visual reasoning tasks. It lacks specific actions or concrete steps for the authors to take, leaving them uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It also questions the interpretation of the models\" learning and whether simpler tasks would suffice. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the abstract visual reasoning tasks and the need for proof that more complex tasks are necessary. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. The reviewer expresses difficulty in solving these tasks and questions the interpretation of the models\" learning. However, the comment lacks specific examples or references to support the claim that these tasks are overly complex or confusing. Without detailed evidence or reasoning, the authors may find it challenging to address the issues raised. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification to be 5.", "helpfulness_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions the interpretation of the models\" learning and whether simpler tasks would suffice. The comment also asks for proof that more complex tasks are necessary. While the comment identifies a potential issue with the clarity and complexity of the visual reasoning tasks, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the paper. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of essential visualization of intermediate processes and comparisons, which is a clear actionable point. However, it does not provide specific guidance on what visualizations or comparisons are missing or how they should be presented. The authors are left to infer that they need to include visualizations and comparisons, but without concrete details on what is expected, the comment remains somewhat vague. Therefore, the comment is 3, as it points out an area for improvement but lacks specific guidance on how to implement it.", "grounding_specificity_rationale": "The comment highlights a lack of essential visualization of intermediate processes and comparisons, which is a specific issue related to the presentation of the paper. However, it does not specify which parts of the paper should include these visualizations or comparisons, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in identifying the need for visualization and comparison, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, namely the lack of essential visualization of intermediate processes and comparisons. This is a clear and actionable point that can help the authors improve the clarity and comprehensiveness of their work. However, the comment does not provide specific guidance on what types of visualizations or comparisons are missing or how they could be incorporated into the paper. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it points out a critical area for enhancement but lacks depth in its guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. However, it does not provide any guidance on how the authors should address this issue or what specific changes need to be made to ensure compliance with the stated condition. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment explicitly mentions \"Definition 1\" and \"expected counterfactual,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the expected counterfactual violates a condition stated in Definition 1. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. This is a clear and actionable point that the authors can address to improve the accuracy and validity of their work. However, the comment lacks depth and does not provide suggestions on how to resolve the issue or what specific changes need to be made. While it highlights a critical area for improvement, it could be more helpful with additional guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include keypoint detection results in the experiments section. This is a clear and direct action, providing the authors with a specific step to take in order to improve their draft. The comment is specific in detailing where the results should be included, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included, namely \"keypoint detection results,\" providing clear guidance on what needs to be addressed in the experiments section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that keypoint detection results should be included in the experiments section. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is clear and actionable, as it directly instructs the authors to include keypoint detection results in the experiments section. This feedback is specific and provides a concrete step for the authors to improve their draft, ensuring that the results are presented in a more comprehensive manner. However, the comment could be more helpful if it explained why keypoint detection results are important or how they might enhance the understanding of the experiments. Despite this, the feedback is 4 as it guides the authors on how to improve the presentation of their results."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the grid search for learning rate, specifically asking whether it is performed on the validation set. It also mentions minor problems, but does not provide further details or suggestions for improvement. The comment implies that the authors should clarify this aspect of their methodology, but it lacks explicit guidance on how to address the issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the grid search process but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"grid search of learning rate,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking whether the grid search is performed on the validation set, providing clear guidance on what needs to be clarified. However, the comment lacks specificity regarding the minor problems mentioned, such as what these problems are or how they impact the paper. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point consists of a question asking about the grid search for learning rate, specifically whether it is performed on the validation set. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the grid search for learning rate, specifically asking whether it is performed on the validation set. This is a relevant point that could impact the robustness and generalizability of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it identifies a potential area for clarification, it does not offer actionable advice or detailed feedback that would help the authors enhance their draft. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an issue with the use of \"discourse\" for nondiscourse elements in the Universal Dependencies (UD) framework. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific actions to take. The authors are left to infer that they might need to clarify the use of \"discourse\" or investigate the high number of discourse relations, but the comment lacks concrete details on how to implement these actions. Therefore, the comment is 3, as it identifies an area for consideration but does not provide explicit instructions on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an issue with the use of \"discourse\" for nondiscourse elements in the Universal Dependencies (UD) framework. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an issue with the use of \"discourse\" for nondiscourse elements in the Universal Dependencies (UD) framework. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an issue with the use of \"discourse\" for nondiscourse elements in the Universal Dependencies (UD) framework. This is a relevant point that could prompt the authors to reconsider their methodology or the interpretation of their results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what specific actions to take. While it identifies a potential problem, it does not provide actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the diversity of the sample in terms of racial and economic backgrounds, and it asks how well the results might generalize to other groups, including marginalized ones. While the comment implies that the authors should consider this aspect in their analysis, it does not provide explicit instructions or concrete suggestions on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should consider diversity and generalizability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the diversity of the sample in terms of racial and economic backgrounds and questions how well the results might generalize to other groups, including marginalized ones. This provides clear guidance on what aspects of the paper need further consideration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the diversity of the sample in terms of racial and economic backgrounds, and it asks how well the results might generalize to other groups, including marginalized ones. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this diversity is important or how it might impact the results. Without additional context or explanation, the authors may find it challenging to understand the significance of this question. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the diversity of the sample in terms of racial and economic backgrounds, and it questions how well the results might generalize to other groups, including marginalized ones. This is a relevant and insightful point that could prompt the authors to consider the broader implications of their findings and ensure that their work is inclusive and applicable to diverse populations. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional analyses or discussions. While it identifies a critical area for improvement, it could be more helpful with more detailed advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the output quality is reasonable but not realistic, comparing it to recent GAN works that have achieved higher quality results. It suggests that there is still room for improvement in the result quality, given the limited novelty, low resolution output, and high hardware requirements. However, the comment does not provide specific guidance on how the authors should improve the output quality or what aspects of the paper need attention. The action is implicit and somewhat vague, as the authors can infer that they need to work on improving the output quality, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the output quality of the paper, comparing it to recent GAN works and suggesting that there is still room for improvement. However, it does not specify which part of the paper discusses the output quality, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the output quality and the need for improvement, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output quality is reasonable but not realistic, comparing it to recent GAN works that have achieved higher quality results. The reviewer suggests that there is still room for improvement in the result quality, given the limited novelty, low resolution output, and high hardware requirements. However, the comment lacks specific examples or references to recent GAN works that demonstrate the improvement in quality. This makes the claim 3, as it provides a general idea but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the output quality of the paper, comparing it to recent GAN works that have achieved higher quality results. It suggests that there is still room for improvement in the result quality, given the limited novelty, low resolution output, and high hardware requirements. However, the comment lacks specific suggestions or guidance on how the authors might improve the output quality or what aspects of the paper need attention. While it highlights an area for improvement, the feedback is 3 as it points out a potential weakness but does not provide actionable steps for the authors to address it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the simple/traditional experiment for unseen characters is a good idea but is presented as an afterthought. It implies that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. The reviewer also suggests adding translations to Figure 6 for nonChinese speakers. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific translations to include. The action is concrete but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of more evaluation on classifying unseen words and the addition of translations to Figure 6 for nonChinese speakers. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the simple/traditional experiment for unseen characters is presented as an afterthought and implies that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. The reviewer also suggests adding translations to Figure 6 for nonChinese speakers. While the comment provides a logical reasoning for the need for more evaluation and translation support, it lacks specific examples or references to substantiate the claim fully. This makes the comment 3, as it provides a reasonable basis for the suggestion but requires more detailed evidence or examples to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of the simple/traditional experiment for unseen characters, noting that it is presented as an afterthought. It suggests that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. Additionally, the reviewer suggests adding translations to Figure 6 for nonChinese speakers. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these changes or what specific translations to include. This limits the comment\"s helpfulness, as it offers actionable suggestions but does not fully support the authors in making those improvements. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of discussion on computational aspects and questions the practical usefulness of the proposed methods for high dimensions. It points out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their discussion. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed discussion on computational aspects and address the practical limitations of their methods. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of discussion on computational aspects and questions the practical usefulness of the proposed methods for high dimensions. It specifically mentions the appendix and the algorithm\"s requirement to solve several LPs in high dimensions, which is not easily calculable. The comment also points out that the experiments are performed on small datasets. However, it does not explicitly mention which part of the paper discusses computational aspects or where the appendix is located, making it weakly grounded. The comment is specific in detailing the issues with the computational aspects and the experiments, but without clear grounding, it is difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not discuss computational aspects in detail and questions the practical usefulness of their proposed methods for high dimensions. The reviewer supports this claim by pointing out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. This provides a logical reasoning for the claim, but it could be strengthened by referencing specific examples or studies that demonstrate the challenges of highdimensional LPs. Therefore, the comment is 3, as it provides a reasonable basis for the claim but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the discussion of computational aspects and the practical usefulness of the proposed methods for high dimensions. It points out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. This feedback is valuable as it highlights a critical area for improvement in the paper, specifically the discussion of computational aspects and the practical limitations of the proposed methods. However, the comment could be more helpful if it provided specific suggestions on how the authors might address these issues or improve the discussion. Overall, the comment is 4 as it directs the authors\" attention to a crucial area for enhancement, but it could be more actionable with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a major issue with the paper\"s motivation, specifically regarding the crossencoder architecture. It notes that the architecture is not ignoring crossentity comparison but instead attends to all candidates at once, which may not be as finegrained as expected. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the motivation or what specific changes should be made to the architecture. As a result, the authors are left without a clear understanding of how to improve their draft in this area. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the motivation of the crossencoder architecture, which is not ignoring crossentity comparison but instead attending to all candidates at once. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the motivation, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation for the crossencoder architecture is poorly explained, as it is not ignoring crossentity comparison but instead attends to all candidates at once. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a major issue with the paper\"s motivation, specifically regarding the crossencoder architecture. It points out that the architecture is not ignoring crossentity comparison but instead attends to all candidates at once, which may not be as finegrained as expected. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the motivation for their architecture. Without actionable feedback or detailed advice, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is rated as 2, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the work uses an outdated GNN model and method, which affects the performance of the framework. It also mentions that the baseline algorithms/methods are also outdated. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue, such as suggesting modern alternatives or updating the methods. Without actionable guidance, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of an outdated GNN model and method, which affects the performance of the framework. However, it does not specify which part of the paper discusses the GNN model or the baseline algorithms/methods, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment lacks specificity regarding what aspects of the GNN model or baseline algorithms/methods are outdated or how they could be improved. Without clear guidance on what needs to be addressed, the authors may struggle to effectively address the critique. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work uses an outdated GNN model and method, which impacts the performance of the framework. However, the comment does not provide specific examples or references to support this claim, nor does it explain how the use of outdated methods affects the performance. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the work, noting that it uses an outdated GNN model and method, which impacts the performance of the framework. This is a critical observation that could significantly affect the paper\"s credibility and relevance. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue, such as suggesting modern alternatives or updating the methods. Without detailed feedback or constructive advice, the authors are left with only a general critique, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the experiment estimates the quality of uncertainty estimates by comparing the true feature importance to a 95% credible interval. However, the true feature importance is not available, so the experiment relies on pseudo feature importance. The reviewer suggests that the correctness of the pseudo feature importance is based on Proposition 3.2 and a large enough perturbation value. The comment provides two ways to strengthen the experiment: by either using a different method to estimate the true feature importance or by providing a more detailed explanation of the perturbation value. While the comment provides some guidance on how to address the issue, it lacks specific instructions on how to implement these suggestions. The action is explicit but somewhat vague, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment that estimates the quality of uncertainty estimates, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the experiment, which relies on pseudo feature importance due to the unavailability of true feature importance. The comment provides specific guidance on how to strengthen the experiment by suggesting two ways: using a different method to estimate true feature importance or providing a more detailed explanation of the perturbation value. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment relies on pseudo feature importance due to the unavailability of true feature importance. It suggests that the correctness of the pseudo feature importance is based on Proposition 3.2 and a large enough perturbation value. The reviewer provides a logical reasoning by explaining the potential issue with the experiment\"s reliance on pseudo feature importance and the need for a more detailed explanation of the perturbation value. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the experiment estimates the quality of uncertainty estimates by comparing the true feature importance to a 95% credible interval. However, the true feature importance is not available, so the experiment relies on pseudo feature importance. The reviewer suggests two ways to strengthen the experiment: by using a different method to estimate the true feature importance or by providing a more detailed explanation of the perturbation value. This feedback is clear and actionable, as it guides the authors on how to improve the reliability and robustness of their experiment. By addressing these suggestions, the authors can enhance the credibility and validity of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide specific guidance on how to conduct this analysis or what aspects should be included. The comment implies that the authors should consider expanding their analysis, but it lacks concrete details on how to achieve this. As a result, the action is implicit and vague, leaving the authors uncertain about how to implement the suggested improvement. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not specify which part of the paper this analysis should be applied to, nor does it provide details on what aspects should be included or how the analysis should be conducted. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need improvement. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would enhance the paper. The comment lacks specificity and does not offer a clear path for the authors to follow, making it difficult for them to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide specific guidance on what aspects of the analysis should be expanded or how to conduct it. The comment acknowledges the limitations of the paper\"s length but does not offer actionable steps for the authors to take. Without detailed suggestions or examples, the feedback lacks depth and specificity, making it 2. Therefore, the comment aligns with a score of 2, as it provides some insight but lacks comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of a proper comparison against online learning approaches and reinforcement learning (RL). It suggests that the authors should clarify why online learning cannot be used and address the challenges of including retraining cost in the evaluation. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these changes or what aspects of the comparison should be addressed. The authors are left with a general idea of what needs to be done but without detailed instructions on how to execute these actions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper where the authors mention that online learning formulation overlooks key practical considerations. This allows the authors to accurately identify the sections being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of a proper comparison against online learning approaches and reinforcement learning, and the challenges of including retraining cost in the evaluation. It provides a clear direction for improvement by asking questions about the reasons behind the limitations of online learning and how to address these challenges. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the lack of a proper comparison against online learning approaches and reinforcement learning, suggesting that the abstract and other parts of the paper overlook key practical considerations. The reviewer provides a logical reasoning by questioning why online learning cannot be used and highlights the importance of including retraining cost in the evaluation. However, the comment lacks specific examples or references to support the claim, such as detailed comparisons or studies that demonstrate the limitations of online learning. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of a proper comparison against online learning approaches and reinforcement learning. It highlights the importance of including retraining cost in the evaluation and questions why online learning cannot be used. The comment provides a clear and actionable suggestion for improvement by asking the authors to address these issues and provide a more comprehensive evaluation. However, it could be more helpful if it offered specific guidance on how to conduct the comparison or what aspects of the retraining cost should be considered. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should cite works related to metalearning and distinguish their approaches from those already cited. It also recommends linking the work on RL for architecture search and optimizers to continual learning. While the comment provides a clear direction for the authors to expand their literature review and improve the connection between their work and related literature, it does not explicitly instruct them on how to do so. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that there is a deeper tie to metalearning and that the authors should cite related works and distinguish their approaches. It also mentions the work on RL for architecture search and optimizers, which should be linked to continual learning. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in suggesting the need to cite related works and link them to the paper, but without explicit references to sections or figures, the authors may struggle to identify the exact parts that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that there is a deeper tie to metalearning and that the authors should cite related works and distinguish their approaches. It also recommends linking the work on RL for architecture search and optimizers to continual learning. While the comment provides a logical reasoning for the need to cite and distinguish related works, it lacks specific examples or references to support the claim about the deeper tie to metalearning. The suggestion to link the RL work to continual learning is more concrete, but the overall claim could be strengthened with more detailed evidence or examples. Therefore, the comment is 3, as it provides a logical basis but lacks specific references or detailed justification.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors should cite and distinguish their approaches from related works in the field of metalearning. It also recommends linking the work on RL for architecture search and optimizers to continual learning, which could enhance the paper\"s connection to the broader literature. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific examples of related works or detailed guidance on how to distinguish the approaches. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. While the comment implies that the authors should consider these options, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these alternatives. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. However, the comment does not specify which part of the paper this issue pertains to, such as the methodology or results sections. While the authors might have an idea of where this feedback is relevant, it is not explicitly grounded. The comment is specific in suggesting alternative approaches to improve the diversity of teacher feedback, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. However, the comment does not provide any supporting evidence, examples, or references to justify why this diversity is important or how it would improve the paper. Without additional context or explanation, the claim remains 3, as the authors may find it challenging to understand the significance of this suggestion without further elaboration. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the diversity of teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. This feedback is 3 as it points out a specific area for improvement and provides a direction for the authors to explore. However, the comment could be more helpful if it offered more detailed guidance on how to implement these suggestions or provided examples of how other studies have addressed this issue. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing the performance with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". While the comment implies that these comparisons could provide valuable insights, it does not explicitly instruct the authors to conduct these comparisons or explain why they are necessary. The action is implicit and somewhat vague, as the authors need to infer the importance of these comparisons and determine how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the performance with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". However, it does not specify which part of the paper these comparisons should be included in, making it weakly grounded. The comment is specific in suggesting the need for these comparisons, as it clearly identifies the potential benefits of including them. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the performance with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". However, the comment does not provide any justification or reasoning for why these comparisons are necessary or how they would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the relevance of these comparisons. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the performance of the paper with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". This feedback is 3 as it provides a clear direction for the authors to consider in terms of benchmarking their work against existing approaches. However, the comment lacks depth and does not explain why these comparisons are important or how they would enhance the paper. Additionally, it does not offer specific guidance on how to conduct these comparisons or what aspects to focus on. While it provides a starting point, the feedback could be more comprehensive and actionable with additional details. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the specificity of the setting and suggests that the approach could be extended to more general settings. However, it does not provide explicit guidance or suggestions on how to achieve this extension. The comment implies that the authors should consider broadening the scope of their work, but it lacks concrete steps or detailed advice on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the specificity of the setting, suggesting that the approach could be extended to more general settings. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the setting and its suggestion for broadening the scope, but without clear references to specific sections or elements, the authors may struggle to identify where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the specificity of the setting and suggests that the approach could be extended to more general settings. However, it does not provide any supporting evidence, reasoning, or references to justify why the current setting is limiting or how it could be expanded. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid point about the specificity of the setting, suggesting that the approach could be extended to more general settings. It questions the limitations of the current setting and encourages the authors to explore broader applicability. However, the comment lacks specific guidance or suggestions on how to achieve this extension or what aspects of the setting might be limiting. While it identifies an area for improvement, it does not provide actionable steps or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the feature extractor used for dimensionality of each region, specifically asking about the feature extractor used in line 201. This is an explicit question that directly asks for clarification, providing a clear action for the authors to take. However, it does not offer specific guidance on how to address the issue or what information should be included in the response. The action is explicit but somewhat vague in terms of detail, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the feature extractor used for dimensionality, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the feature extractor used for dimensionality in line 201. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the feature extractor used for dimensionality in line 201. This is a clear and actionable point, as it prompts the authors to clarify an important aspect of their methodology that could impact the understanding and reproducibility of their work. By addressing this question, the authors can improve the clarity and transparency of their paper, which is valuable feedback. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information in the paper. Overall, the comment is 4 as it identifies a specific area for clarification, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point poses a question about the choice of p < 0.4 in Algorithm 1, indicating that the reviewer is seeking clarification or explanation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific information they should include in their response. The action is implicit and vague, as the authors are left to infer that they need to provide a detailed explanation or justification for their choice. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the choice of p < 0.4 in Algorithm 1, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the choice of p < 0.4 in Algorithm 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the choice of p < 0.4 in Algorithm 1, which is a clear and actionable point. By asking for clarification on this choice, the reviewer prompts the authors to provide a detailed explanation or justification for their decision. This feedback is valuable as it directs the authors to a specific area that may need further elaboration or clarification in their draft. However, the comment could be more helpful if it suggested alternative approaches or provided additional context for understanding the significance of this choice. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not provide specific guidance on how to improve the clarity or what aspects of the motivation should be emphasized. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more explicit explanations or demonstrations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion for improvement, as it clearly identifies the need for a more explicit demonstration or explanation of the motivation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the motivation behind applying CMD in federated learning. It suggests that the motivation could benefit from a more explicit demonstration or explanation, which is a valid point. However, the comment lacks specific guidance on how to improve the clarity or what aspects of the motivation should be emphasized. While it points out an area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of analysis regarding the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. While the comment implies that the authors should provide more analysis and comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more analysis and comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of analysis regarding the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. This provides clear guidance on what needs to be addressed in the paper. However, the comment does not specify which sections or parts of the paper should include this analysis or comparison, making it somewhat specific. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that there is insufficient analysis of the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. The comment provides a logical reasoning by suggesting that such comparisons would clarify the unique advantages of the method. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the claim, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of analysis regarding the effectiveness of data augmentation methods. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, would clarify the unique advantages of the method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and comparison sections. However, the comment could be more helpful if it offered examples of how these comparisons could be conducted or what specific aspects to focus on. Overall, the comment is 4 as it guides the authors toward improving their draft, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of the model\"s performance should be evaluated. The comment lacks explicit instructions or concrete details on how to apply the information, leaving the authors uncertain about what actions to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or table. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspect of the model\"s performance should be evaluated or how it relates to the paper\"s content. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it highlights an area of interest, it does not provide any guidance or suggestions on how the authors might address this question or what aspects of the model\"s performance should be evaluated. Without actionable feedback or context, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to conduct a quantitative analysis to substantiate the computational gains claimed in the paper. It specifies the types of measurements that would be helpful, such as GPU hours, memory usage, or training time. This provides clear and concrete guidance on what the authors need to do to improve their draft. The action is explicit and concrete, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for quantitative analysis to substantiate the computational gains claimed in the paper. This includes suggestions like GPU hours, memory usage, or training time. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks specific measurements or comparisons to substantiate the computational gains from replacing the MAE model with a CNNbased data augmentation strategy. The reviewer suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of the efficiency improvements in DQ V2. This claim is 3 as it logically suggests that quantitative analysis would strengthen the paper\"s claims, but it lacks specific examples or references to similar studies that have used such analyses. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of quantitative analysis to substantiate the computational gains claimed in the paper. It suggests that including measurements such as GPU hours, memory usage, or training time would provide stronger evidence of the efficiency improvements in DQ V2. This feedback is clear and actionable, as it directs the authors to conduct a quantitative analysis that would enhance the credibility and robustness of their claims. However, the comment could be more helpful if it provided examples of how such analyses have been conducted in similar studies or offered guidance on how to conduct them effectively. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several questions about the \"filter manifold network\" (FMN) and its scalability with the number of filter parameters. It asks if the authors experimented with other architectures for FMN and how adaptive convolutions scale with the number of filter parameters. Additionally, it questions whether FMN can scale well with larger input and output channels, which is common in many CNN architectures. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these questions, but the comment lacks specific guidance on how to do so. Therefore, the comment is 3, as it implies actions but does not provide detailed instructions on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filter manifold network\" (FMN), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the scalability of the FMN with larger input and output channels, and it suggests experimenting with other architectures. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the discussion and analysis of the \"filter manifold network\" (FMN), which is the main part of the technique. It asks if the authors experimented with other architectures for FMN and how adaptive convolutions scale with the number of filter parameters. The reviewer also questions whether FMN can scale well with larger input and output channels, which is common in many CNN architectures. While the comment identifies areas for improvement, it lacks specific examples or references to support the claims about scalability or the need for further analysis. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion and analysis of the \"filter manifold network\" (FMN), which is the main part of the technique. It raises important questions about the scalability of the FMN with larger input and output channels, suggesting that the authors should experiment with other architectures and explore how adaptive convolutions scale with the number of filter parameters. Additionally, the comment questions whether FMN can reasonably scale for larger input and output channels, which is common in many CNN architectures. This feedback is clear and actionable, providing the authors with specific areas to focus on for improving their draft. However, it could be more helpful if it offered suggestions on how to address these questions or provided examples of alternative architectures to consider. Overall, the comment is 4 as it directs the authors to important areas for improvement and enhances the clarity and depth of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the proposed CoNO model, questioning the contribution of the UNet part after the fractional transform and suggesting that comparisons to UNets are necessary. While the comment identifies a potential issue with the model, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should make comparisons to UNets, but the comment lacks specific instructions on how to conduct these comparisons or what aspects to focus on. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed CoNO model\" and the \"complex UNet part after the fractional transform,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the contribution of the UNet part and suggests comparisons to UNets, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the contribution of the UNet part in the CoNO model, suggesting that it is unclear whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible for the claimed performance boost. The reviewer references external works, such as Raonic et al and Gupta et al, to support their claim about the strong performance of UNets on regular gridded domains. This provides a logical basis for the claim, but the comment could be strengthened by providing more detailed comparisons or examples from the referenced works. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed CoNO model, questioning the contribution of the UNet part after the fractional transform. It suggests that the authors should make comparisons to UNets, as they have shown strong performance on regular gridded domains. The comment provides a logical basis for the suggestion by referencing external works, such as Raonic et al and Gupta et al, which support the importance of UNets in this context. However, the comment could be more helpful if it offered specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 3 as it highlights a potential area for improvement but lacks detailed guidance for the authors to fully address the issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly requests that the authors rewrite the sentence \"While a smaller j to simulate more accumulate errors along with the inference steps.\" This is a clear and direct action for the authors to take, as it provides a specific line and page number for them to address. The comment also indicates that the current sentence is unclear, which further guides the authors on what changes are needed to improve the clarity. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and pages (\"P. 5, p. 3, l.\") where the issue is located, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the clarity of the sentence regarding the use of \"j\" to simulate errors. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification and a specific suggestion to rewrite a sentence. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of a sentence, requesting that the authors rewrite it to improve understanding. By providing a clear and actionable suggestion, the comment helps the authors address a potential source of confusion in their draft. However, the comment could be more helpful if it offered additional context or explanation about why the current sentence is unclear or how it might be rewritten to improve clarity. Overall, the comment is 3 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the approach taken for handling documents in DocRED, specifically asking whether the documents are considered as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. While the comment identifies a potential gap in the manuscript, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information about their approach but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DocRED\" and \"the documents,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the consideration of documents as an entire sentence and how the model handles concepts involving multiple entity mentions referring to the same entity. This provides clear guidance on what needs to be addressed in the manuscript. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the approach taken for handling documents in DocRED, specifically asking whether the documents are considered as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is missing from the manuscript. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the manuscript is lacking, specifically regarding the handling of documents in DocRED. It asks whether the documents are considered as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. This feedback is clear and actionable, as it points out a gap in the manuscript that the authors need to address to provide a more comprehensive understanding of their approach. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how similar approaches have been handled in the literature. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the contribution of the paper is marginal because the methods used in different stages are welldesigned and demonstrated. It also implies that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived marginality or how to improve the contribution. As a result, the authors are left without any clear direction on how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the contribution of the paper is marginal because the methods used in different stages are welldesigned and demonstrated. However, it does not specify which part of the paper this assessment is based on, such as the methods or the stage where they are used. This lack of specificity makes it difficult for the authors to pinpoint the exact sections that need improvement or clarification. Additionally, the comment does not provide specific guidance on how to address the issue of marginality or what changes could be made to enhance the contribution. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of the paper is marginal because the methods used in different stages are welldesigned and demonstrated. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to specific methods or stages where the methods are demonstrated, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the contribution of the paper is marginal, as the methods used in different stages are welldesigned and demonstrated. It also implies that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. While the comment identifies a potential weakness in the contribution, it lacks specific suggestions or guidance on how the authors could address this issue or enhance their contribution. The feedback is 3 as it points out a potential limitation, but it does not provide actionable advice or detailed feedback for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the detailed distribution of the proposed dataset is unclear. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the distribution should be clarified, how it should be clarified, or what specific aspects of the distribution are unclear. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment points out that the detailed distribution of the proposed dataset is unclear. However, it does not specify which part of the paper discusses the dataset or where the distribution should be clarified. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is specific in identifying the issue of unclear distribution, but it lacks grounding as it does not point to a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the detailed distribution of the proposed dataset is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, namely the lack of clarity regarding the detailed distribution of the proposed dataset. This is a relevant point that could impact the reproducibility and comparability of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending additional details or clarifications. Without actionable feedback, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, as it highlights a potential weakness but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed method is limited in its application to supervised training due to the requirement for annotated labels for learning semantic tokens. It proposes an alternative approach using a selfsupervised pretraining approach without annotations. While the comment implies that the authors should consider this alternative, it does not explicitly instruct them to do so or provide specific guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitation of the proposed method in requiring annotated labels for learning semantic tokens, which limits its application to supervised training. It suggests an alternative approach using a selfsupervised pretraining approach without annotations. However, the comment does not specify which part of the paper discusses the method or the annotation requirement, making it weakly grounded. The suggestion to consider a selfsupervised approach is specific, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is limited in its application to supervised training due to the requirement for annotated labels for learning semantic tokens. It suggests an alternative approach using a selfsupervised pretraining approach without annotations. However, the comment lacks specific examples or references to support the claim that a selfsupervised approach would be more appealing. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a limitation in the proposed method, specifically the requirement for annotated labels for learning semantic tokens, which limits its application to supervised training. It suggests an alternative approach using a selfsupervised pretraining approach without annotations, which could be more appealing. This feedback is 3 as it points out a potential weakness in the methodology and provides a direction for improvement. However, the comment could be more helpful if it offered specific guidance on how to implement the selfsupervised approach or provided examples of similar approaches that have been successful. Overall, the comment provides a clear direction for improvement but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should demonstrate the scalability of their LFF method by showing it can be applied to more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. While the comment implies that the authors should conduct experiments on these tasks, it does not provide explicit instructions or concrete steps on how to implement these experiments. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments to address the reviewer\"s concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the scalability of their LFF method by showing it can be applied to more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to demonstrate scalability by addressing more challenging tasks, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car, and that it is important to demonstrate the scalability of LFF by showing it can be applied to more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. The comment provides a logical reasoning that the scalability of LFF should be demonstrated on more complex tasks, but it lacks specific examples or references to support the claim that these tasks are indeed more challenging. This makes the claim 3, as the authors would need to infer the complexity of the suggested tasks and determine if they are appropriate for demonstrating scalability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the current experimental setup, noting that most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car. It suggests that to fully demonstrate the scalability of the LFF method, it is important to show that it can be applied to more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental setup and demonstrate the broader applicability of their method. However, the comment could be more helpful if it offered suggestions on how to conduct these additional experiments or what specific aspects of the LFF method should be emphasized in the new tasks. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the abstract should include a specific measurement, such as \"attain greater expressivity, as measured by the change in linear regions in output space after [citation], instead of just \"attain greater expressivity.\" Additionally, it recommends including learning curves for all experiments in an appendix. While the comment provides explicit actions, it does not specify which experiments should include learning curves or how to present them. The authors are given clear guidance on what to add to the abstract and an appendix, but the execution of these actions is not detailed. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be changed in the abstract, suggesting a specific measurement to include and recommending the inclusion of learning curves in an appendix. This level of detail provides clear direction for the authors to make improvements. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests changes to the abstract, specifically recommending a specific measurement to include and recommending the inclusion of learning curves in an appendix. The comment provides a logical reasoning for these suggestions, suggesting that the current abstract lacks specificity and could benefit from more detailed information. However, it does not provide specific references or examples to support the claim that the current abstract is lacking in detail. Therefore, the comment is 3, as it provides a logical basis for the suggestions but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the abstract, suggesting that it should include a specific measurement to support the claim of \"attaining greater expressivity.\" This suggestion is clear and offers a concrete way to enhance the clarity and rigor of the abstract. Additionally, the comment recommends including learning curves for all experiments in an appendix, which is a valuable suggestion for providing more detailed information and transparency. However, the comment could be more helpful if it explained why learning curves are important or how they could be presented. Overall, the feedback is 4 as it guides the authors on how to improve the clarity and comprehensiveness of their abstract and experimental results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the paper\"s motivation and application, specifically questioning the need for domain adaptation and the usefulness of the proposed method. It suggests that demonstrating the methodology\"s use on actual tasks involving domain adaptation would be beneficial. While the comment implies that the authors should provide examples of how the method could be applied in practice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples of domain adaptation tasks. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results of mapping one RGB image to another RGB image with a different style, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the motivation and usefulness of the paper, suggesting that demonstrating the methodology\"s use on actual tasks involving domain adaptation would be beneficial. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the motivation and usefulness of the paper, suggesting that the proposed method does not have a clear application or demonstrate its value in domain adaptation tasks. The reviewer provides a logical reasoning by pointing out that the method demonstrated is limited to mapping one RGB image to another with a different style, which does not necessarily require domain adaptation. The comment suggests that demonstrating the methodology\"s use on actual tasks involving domain adaptation would be beneficial. However, the comment lacks specific examples or references to support the claim that domain adaptation is necessary or beneficial. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically questioning the motivation and usefulness of the proposed method. It points out that the method demonstrated is limited to mapping one RGB image to another with a different style, which does not necessarily require domain adaptation. The reviewer suggests that demonstrating the methodology\"s use on actual tasks involving domain adaptation would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the paper by showing the practical applications of their method. However, the comment could be more helpful if it offered examples of such tasks or provided guidance on how to effectively demonstrate domain adaptation. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should consider other baselines or update their references to more recent works. As a result, the authors are left without a clear direction on how to address this issue. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific works, \"MISA,\" \"M2FNet,\" and \"MMDFN,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. This claim is 3 as it provides a specific reference to MULT and its publication year, which supports the assertion that it is outdated. However, the comment lacks detailed reasoning or examples to fully substantiate why MULT is considered out of fashion or how it impacts the current work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but points out that MULT was proposed in 2019 and is therefore out of fashion. This feedback is 3 as it highlights an area where the paper may be outdated and suggests that the authors consider more recent works. However, the comment lacks specific suggestions on how to address this issue or what alternative baselines could be considered. While it provides some insight, it could be more helpful with additional guidance or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a major issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks for all models and the omission of tensor completion results for fair comparison. The reviewer suggests that the authors should compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be done to improve the clarity and fairness of the comparisons. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks and the omission of tensor completion results for fair comparison. It also provides specific guidance on how to address this issue by suggesting that the authors compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear and that the value of the used ranks is omitted, making it difficult to conduct a fair comparison. The reviewer suggests that the authors should compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This claim is 3 as it provides a logical reasoning for the need for a fair comparison and suggests a method to achieve it. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks and the omission of tensor completion results for fair comparison. It provides a clear and actionable suggestion by recommending that the authors compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This feedback is valuable as it guides the authors on how to improve the clarity and fairness of their experimental comparison, making it 5. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between the authors\" claims and the theoretical part of the paper. It highlights that the authors claim that only parts of subdivision splines are useful for decision boundaries, but they did not provide a detailed explanation of how the proposed algorithm removes these splines. The reviewer also questions whether the algorithm requires extra computation cost for space partitioning. While the comment identifies specific areas that need clarification and action, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations and address the computational cost concerns. Therefore, the comment is 3, as it implies a need for more detailed explanations but does not explicitly guide the authors on how to implement these changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the observation and the goal of pruning, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the theoretical part lacks detailed explanation of how the proposed algorithm removes subdivision splines, and it raises a question about the extra computation cost for space partitioning. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim made by the authors regarding the observation that only parts of subdivision splines are useful for decision boundaries. It points out that the theoretical part lacks detailed explanation of how the proposed algorithm removes these splines, and it raises a concern about the extra computation cost for space partitioning. While the comment identifies a potential issue with the claim, it does not provide specific examples or references to support the claim or the need for more detailed explanation. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to further explore and address the issue themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the authors\" claims and the theoretical part of the paper. It points out that the authors claim that only parts of subdivision splines are useful for decision boundaries, but the theoretical part lacks detailed explanation of how the proposed algorithm removes these splines. The reviewer also raises a question about the extra computation cost for space partitioning. This feedback is 3 as it highlights a gap in the paper that the authors need to address. However, it could be more helpful if it provided specific suggestions on how to clarify the theoretical part or address the computational cost concern. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that W1 and W2 are not defined, and it speculates that they might denote the Encoder and Decoder networks. It also mentions that W and V are not defined in the same context, providing specific references to page 3, line A4, and equation 3. This feedback is clear and directs the authors to define these terms, which is a concrete action for them to take. The comment is 5 as it provides specific guidance on what needs to be clarified or defined in the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W1 and W2\" and \"W and V,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that these terms are not defined, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"W1 and W2 are not defined\" and speculates that they might denote the Encoder and Decoder networks. It also mentions that \"W and V are not defined\" and provides specific references to page 3, line A4, and equation 3. This claim is 3 as it points out specific sections where the terms are not defined, providing some basis for the assertion. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that W1 and W2 are not defined and speculating that they might denote the Encoder and Decoder networks. It also points out that W and V are not defined in the same context, providing specific references to page 3, line A4, and equation 3. This feedback is clear and actionable, as it directs the authors to clarify these terms and their definitions. By addressing this issue, the authors can improve the clarity and completeness of their paper. However, the comment could be more helpful if it offered suggestions on how to define these terms or provided examples of how they might be used in the context of the paper. Overall, the comment is 4 as it effectively guides the authors on a specific area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the comparison with some baselines is unfair due to the lack of prior knowledge of users or language embedding computation. It suggests that a better comparison should be considered. While the comment implies that the authors should reconsider their comparison, it does not provide specific guidance on how to conduct a fairer comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison with baselines, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the comparison, stating that it is unfair due to the lack of prior knowledge of users or language embedding computation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparison with some baselines is unfair due to the lack of prior knowledge of users or language embedding computation. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks specific references or detailed explanations to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of baselines, noting that the lack of prior knowledge of users or language embedding computation may unfairly skew the results. This is a valuable observation that could lead to a more robust and fair evaluation of the baselines. However, the comment does not provide specific suggestions on how to address this issue or what alternative comparisons could be considered. While it highlights an important area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions and points of confusion regarding the paper, including the lack of benefits from outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the dimensionality after upsampling in Figure 2(b) and notes the absence of limitations and potential negative societal impact discussions. While the comment identifies areas that need clarification or expansion, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations or examples, but the comment lacks specific guidance on what exactly is missing or how to improve the draft. Therefore, the comment is 3, as it points out areas for improvement but does not offer detailed guidance on how to implement them.", "grounding_specificity_rationale": "The comment addresses several issues, including the lack of benefits from outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the dimensionality after upsampling in Figure 2(b) and notes the absence of limitations and potential negative societal impact discussions. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the clarity of Figure 4 and the presentation of Pixelshuffle details. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and observations about the paper, including the lack of benefits from outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the dimensionality after upsampling in Figure 2(b) and notes the absence of limitations and potential negative societal impact discussions. While the comment identifies areas that need clarification or expansion, it does not provide specific examples or references to support the claims. The authors are left to infer that these issues need attention, but the lack of detailed justification or evidence makes the claims 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the lack of benefits from outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the dimensionality after upsampling in Figure 2(b) and notes the absence of limitations and potential negative societal impact discussions. While the comment highlights important areas for clarification and expansion, it does not provide specific suggestions or guidance on how to address these issues. The authors are left to infer that they need to provide more detailed explanations or examples, but the feedback lacks actionable steps. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also asks whether this alternating process could help improve performance. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification or analysis regarding the behavior of negative chips and the potential impact of the alternating process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also asks whether this alternating process could help improve performance. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the behavior of negative chips and the potential impact of the alternating process. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also inquires whether this alternating process could help improve performance. This feedback is 3 as it prompts the authors to clarify their methodology and potentially explore avenues for improvement. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or improve their work. Overall, the comment offers a starting point for the authors to consider, but it lacks depth and actionable guidance. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should evaluate their proposed approach on both new and old patients. While the comment implies that the authors should conduct this evaluation, it does not provide specific guidance on how to do so or what aspects of the evaluation should be prioritized. The action is implicit and somewhat vague, as the authors need to infer the details of the evaluation themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should evaluate their proposed approach on both new and old patients, which is a specific suggestion for improvement. However, it does not specify which part of the paper this evaluation should be included in, such as a particular section or experiment. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for an evaluation on new and old patients, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should evaluate their proposed approach on both new and old patients. However, it does not provide any supporting evidence, reasoning, or examples to justify why this evaluation is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should evaluate their proposed approach on both new and old patients, which is a relevant and actionable suggestion. However, it lacks depth and does not provide specific guidance on how to conduct this evaluation or what aspects of the approach should be tested. While it identifies a potential area for improvement, the comment could be more helpful if it included detailed instructions or examples on how to implement this suggestion. Therefore, the comment is 3, as it provides a clear direction but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific aspects of the technique should be improved. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying potential issues with the novelty of the technique, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any evidence, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. While it identifies a potential issue with the novelty of the algorithm, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or improve the novelty of their work. The comment is 3 as it points out a potential weakness, but it does not offer actionable advice or detailed feedback for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the authors\" understanding of the integral in Equation (1) and its relation to the bag observation model or spatial aggregation process. It also points out that the authors\" formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the formulation. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider their assumptions about the observations and their aggregation process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1)\" and \"the integral in Equation (1)\" and provides references to specific works, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the authors\" formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the integral in Equation (1) corresponds to the bag observation model in [Law et al., NeurIPS\"18] or the spatial aggregation process in [4]. The reviewer provides references to these works, which supports the claim by referencing established practices in the field. However, the comment lacks detailed explanation or analysis of why these references are relevant to the current work, which could enhance the verifiability. Therefore, the comment is 3, as it provides some support but could be strengthened with additional context or reasoning.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" understanding of the integral in Equation (1) and its relation to the bag observation model or spatial aggregation process. It points out that the authors\" formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. The comment provides a clear and actionable suggestion for the authors to reconsider their assumptions about the observations and their aggregation process, which could lead to a more accurate and robust analysis. However, the comment could be more helpful if it offered specific guidance on how to address this issue or suggested alternative methods for aggregating data. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks indepth analysis and suggests that the authors should provide an explanation for the training dynamics observed. This feedback is clear and provides a direct action for the authors to take, which is to include an analysis of the training dynamics. The comment is specific in its request for an explanation, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks indepth analysis and specifically mentions the observation of inverse scaling over compute. However, it does not specify which part of the paper this observation is made in, making it weakly grounded. The comment is specific in its request for an explanation of the training dynamics, but without clear references to sections or details, the authors may struggle to identify where to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks indepth analysis and implies that the authors should provide an explanation for the observed training dynamics. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 2, as it requires more information to be fully substantiated. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of indepth analysis and suggesting that the authors should provide an explanation for the observed training dynamics. This feedback is clear and actionable, as it points out a specific area where the paper could be strengthened by including more detailed analysis. However, the comment could be more helpful if it provided specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. While the comment implies that the authors should modify their experimental setup, it does not provide explicit instructions on how to implement this change or what specific tasks to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or the discussion of the results. The authors can infer that it relates to the latter part, but this inference is not direct. The comment is specific in suggesting a potential improvement but lacks full grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the setting with a fixed policy is a subset of reinforcement learning and proposes that tasks could be made more complex to test the policy\"s adaptability. However, the comment lacks specific examples or references to support this claim or to justify why the current setting is insufficient. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the suggestion. Therefore, the claim is considered 2.", "helpfulness_rationale": "The review comment suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. This feedback is 3 as it identifies a potential area for improvement in the experimental setup. However, the comment lacks specific guidance on which tasks to consider or how to implement this change. Additionally, it does not provide detailed reasoning or examples to support the suggestion, which limits its usefulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to broaden the scope of the paper or what specific aspects of multitask models should be explored. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the multitask models are problematic or how they could be improved. Without clear guidance on where to focus the revision, the authors may struggle to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any specific guidance or suggestions on how the authors might broaden the scope of the paper or address this limitation. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the literature review ignores several relevant papers, specifically mentioning [1] and [2]. It suggests that VRMARINA and DASHAMVR, mentioned in these papers, could be relevant to the current work. The reviewer provides a specific question about the Assumption 2 and the rate of QSGD in the stochastic regime, implying that the authors should consider these papers for further analysis. While the comment does not explicitly instruct the authors to include these papers, the action is implicit and concrete, as it clearly identifies the need for additional analysis and provides a specific direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"next section\" and the \"Literature review,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of relevant papers, [1] and [2], and suggests that VRMARINA and DASHAMVR could be relevant to the current work. The comment provides a clear direction for the authors to consider these papers and address the Assumption 2 and QSGD rate in the stochastic regime. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review ignores several relevant papers, specifically mentioning [1] and [2]. The reviewer provides a specific example of VRMARINA and DASHAMVR, which are mentioned in these papers, and suggests that they could be relevant to the current work. The comment also includes a question about the Assumption 2 and the rate of QSGD in the stochastic regime. This provides a logical basis for the claim, as it highlights a potential gap in the literature review that could impact the paper\"s conclusions. However, the comment lacks specific references to these papers or detailed analysis of their relevance, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable basis for the claim but could be further substantiated with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the literature review, noting that it ignores several relevant papers. It specifically mentions [1] and [2], which are believed to be relevant to the current work. The reviewer suggests that VRMARINA and DASHAMVR, mentioned in these papers, could be relevant to the Assumption 2 and the rate of QSGD in the stochastic regime. This feedback is clear and actionable, as it provides the authors with specific papers to consider for further analysis and potential inclusion in the literature review. By addressing this issue, the authors can enhance the comprehensiveness and relevance of their literature review, which is valuable for improving the overall quality of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: whether the authors have any additional insights into modest performance gains on Clothing1M and how the algorithm performs on other realworld datasets like WebVision, evaluated by DivideMix. While these questions imply that the authors should provide additional information or analysis, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more insights or data. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises two questions about the performance of the algorithm on Clothing1M and WebVision, evaluated by DivideMix. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions themselves are specific, as they ask for additional insights or performance evaluations on specific datasets. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions asking for additional insights and performance evaluations on specific datasets. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions that could help the authors gain additional insights into the performance of their algorithm on realworld datasets. By asking about modest performance gains on Clothing1M and the algorithm\"s performance on WebVision, evaluated by DivideMix, the reviewer encourages the authors to provide more detailed evaluations and comparisons. However, the comment lacks specific guidance or suggestions on how to address these questions or what additional insights would be beneficial. While it points out areas for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies potential areas for enhancement but lacks depth and specificity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the theoretical results do not have immediate practical implications, but acknowledges that this is understandable given the novelty of the work. It also expresses a desire for more practical takeaways for practitioners, specifically mentioning the idea of querying a cluster proportionally to the square root of its size. However, the comment does not provide explicit guidance on how to incorporate this suggestion or what specific aspects of the paper should be revised to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should focus on making their results more practical and actionable. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical results and their practical implications, suggesting that the paper could provide more practical takeaways for practitioners. It mentions a specific takeaway point regarding querying a cluster proportionally to the square root of its size, but does not specify which part of the paper this relates to. The authors can infer that it pertains to the theoretical results or methodology sections, but this inference is not as direct as it could be. The comment is specific in its suggestion for practical applications but lacks grounding in terms of identifying the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical results do not have immediate practical implications, which is 3. The reviewer acknowledges the novelty of the work but suggests that more practical takeaways should be provided. The comment provides a specific example of a takeaway point, which is the querying of a cluster proportionally to the square root of its size. However, the reviewer does not provide a detailed explanation or evidence to support why this takeaway point is not novel or how it could be improved. The lack of detailed justification or references makes the claim 3, as it provides some support but not enough to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the theoretical results do not have immediate practical implications. It acknowledges the novelty of the work but suggests that more practical takeaways should be provided for practitioners. The comment provides a specific example of a takeaway point, which is the querying of a cluster proportionally to the square root of its size. However, it does not clarify whether this is a novel finding or not. While the comment highlights an area for improvement, it lacks depth and does not offer detailed guidance on how to address the issue or what specific aspects of the paper should be revised to enhance its practical relevance. Therefore, the comment is 3, as it points out a potential weakness but does not provide actionable advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the purpose of separators in section 4, specifically asking for additional information on what they contribute beyond T/I/O. While the comment identifies an area for clarification, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to provide more information or explanation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the purpose of separators and what additional information they provide beyond T/I/O. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the purpose of separators in section 4 and asks for additional information on what they contribute beyond T/I/O. This is a request for clarification and does not make a subjective claim or express an opinion. It is a factual inquiry seeking more information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the purpose of separators in section 4, specifically asking for additional information on what they contribute beyond T/I/O. This feedback is 3 as it identifies a potential area for clarification or expansion in the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional information could be provided. While it points out a potential gap in the explanation, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison of the real search cost in terms of GPU days. The comment is specific and provides concrete guidance on how to enhance the table, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of a comparison of the real search cost in terms of GPU days. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. This feedback is 3 as it identifies a potential area for improvement in the presentation of data, which could provide a more comprehensive view of the system\"s performance. However, the comment lacks depth and does not explain why this comparison is important or how it would enhance the understanding of the system\"s performance. To be more helpful, the comment could provide additional context or examples to support the suggestion. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training details of the VQGAN, specifically inquiring whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. While the comment implies that the authors should provide more information about the training process, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the training details but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"VQGAN\" and \"Computer Vision Figures dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the training details of the VQGAN, specifically inquiring whether it is pretrained or only trained on a subset of images from the dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the training details of the VQGAN, specifically whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the training details of the VQGAN, particularly inquiring whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. This question highlights a potential gap in the paper that could impact the reader\"s understanding of the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed methods, DualIS and DualDIS, in terms of their generic applicability on crossmodel retrieval tasks, specifically mentioning the minor improvements in MSVD (Table 3). However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the methods or what specific aspects of the methods need to be addressed. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DualIS and DualDIS,\" allowing the authors to accurately identify the specific methods being discussed. It also specifies the issue by stating that the methods are not generic on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. However, the comment does not provide specific details or examples of these tasks or the performance improvements, making it difficult for the authors to understand the basis of the claim. Without additional context or references, the claim lacks sufficient evidence or justification to be 5. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the proposed methods, DualIS and DualDIS, by pointing out that they are not generic on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. This feedback is 3 as it highlights an area where the methods may not be as effective as expected, providing the authors with a specific issue to address. However, the comment could be more helpful if it offered suggestions on how to improve the methods or addressed the issue of generic applicability. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method of running vanilla Adam on the final network with 40 random initial points, which could potentially lead to the global minimum. However, the comment does not provide explicit instructions on how to implement this alternative method or why it might be more effective. While the suggestion is clear, it lacks concrete guidance on how to execute it, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. However, it does not specify which part of the paper this concern is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment does provide a specific suggestion for an alternative method of running vanilla Adam on the final network with 40 random initial points, which could potentially lead to the global minimum. This level of detail provides some specificity, but without explicit references to sections or figures, the comment remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the experimental strengths of the approach, specifically the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method of running vanilla Adam on the final network with 40 random initial points, which could potentially lead to the global minimum. This claim is 3 as it provides a logical reasoning for the alternative method, but it lacks specific examples or references to support the claim that running vanilla Adam would be more effective. Therefore, the comment is rated as 3, as it provides a reasonable argument but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method of running vanilla Adam on the final network with 40 random initial points, which could potentially lead to the global minimum. This feedback is 3 as it points out a potential weakness in the experimental setup and offers a suggestion for improvement. However, the comment could be more helpful if it provided more detailed reasoning or examples to support the alternative method. Overall, the comment identifies a potential issue and offers a constructive suggestion, but it lacks depth and clarity, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a typographical error in the phrase \"for \"inbetween\" uncertainty\" by noting that the first quotation mark should be a forward mark rather than a backward mark. This is a clear and concrete action for the authors to take, as they are provided with specific guidance on how to correct the error. The comment is 5 as it directly instructs the authors on what to change to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"for \"inbetween\" uncertainty,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the typographical error, noting that the first quotation mark should be a forward mark rather than a backward mark. This provides clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about a typographical error in the paper, specifically noting that the first quotation mark in the phrase \"for \"inbetween\" uncertainty\" should be a forward mark rather than a backward mark. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific typographical error in the paper, namely the placement of the quotation marks in the phrase \"for \"inbetween\" uncertainty.\" This is a minor but important detail that can enhance the professionalism and clarity of the paper. By pointing out this error, the comment provides clear and actionable feedback that the authors can easily address to improve the quality of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises questions about the clarity of certain aspects in the paper, specifically asking for more explicit explanations. It suggests that the authors should provide information about what Omega is and clarify the link function. Additionally, it asks for more explicit references to the theorem in [32] for the regret guarantee. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to provide more detailed explanations and references, but the action is implicit and lacks concrete guidance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the clarity of certain aspects, such as what Omega is and the link function, as well as the reference to a theorem in [32] for the regret guarantee. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and references, rather than making subjective claims or suggestions. It does not contain any opinions, judgments, or statements requiring verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where the paper could be improved by requesting more explicit explanations and references. It points out that the authors should clarify what Omega is and provide more information about the link function. Additionally, it asks for a more explicit reference to the theorem in [32] for the regret guarantee. This feedback is clear and actionable, as it directs the authors to enhance the clarity and completeness of their work. However, it could be more helpful if it provided suggestions on how to present this information or what specific details to include. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific aspect of the models being learned directly from pixels without a Markovian state. However, it does not provide any guidance or suggestions on how the authors should address this issue or improve their work. There is no explicit or implicit action for the authors to take, nor is there any indication of what the implications of this observation might be. As a result, the comment lacks actionability and does not provide any direction for the authors to follow. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment mentions \"the models are learned directly from pixels without a Markovian state,\" which suggests that the models are not Markovian. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue with the models being Markovian, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the models are learned directly from pixels without a Markovian state. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a specific aspect of the models being learned directly from pixels without a Markovian state, which could be a potential issue or limitation. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or context, the comment does not offer much value to the authors in terms of enhancing their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the usefulness of the sequence example but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically using the Hamming distance over entire parts of the sequence as a scoring loss. The reviewer suggests that the authors should provide references for this approach, which is a clear and explicit action. The comment is specific in identifying the need for references and provides a concrete direction for the authors to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"sequence example\" and \"Example 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the use of the Hamming distance over entire parts of the sequence as a scoring loss, which is a specific practice in the context of CRF. The comment suggests providing references for this approach, which is a clear and specific request for additional information. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the use of the Hamming distance over entire parts of the sequence as a scoring loss in the context of CRF, suggesting that this is a \"common\" practice. The reviewer acknowledges that they are not familiar with this approach and asks for references to support it. While the comment identifies a potential gap in the paper, it lacks specific references or examples to substantiate the claim that this is a \"common\" practice. This makes the claim 3, as the authors would need to make an effort to find and integrate references to fully address the reviewer\"s concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the usefulness of the sequence example but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically using the Hamming distance over entire parts of the sequence as a scoring loss. The reviewer suggests that the authors should provide references for this approach, which is a clear and actionable suggestion. By addressing this point, the authors can enhance the clarity and completeness of their work. However, the comment could be more helpful if it provided specific references or examples of works that use this approach. Overall, the comment is 4 as it identifies a potential gap in the paper and offers a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also suggests mentioning the metrics along with the datasets or in the captions of the tables. While the comment provides a clear action to take, it lacks specific guidance on how to implement these changes or what specific metrics should be included. The authors are given a general direction but may need to infer the details of execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also suggests mentioning the metrics along with the datasets or in the captions of the tables. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the evaluation or metrics sections. The suggestion to change the name and mention metrics is specific, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also recommends mentioning the metrics along with the datasets or in the captions of the tables. This suggestion is based on the claim that \"evaluation\" can have a more general meaning and that most, if not all, of the metrics are wellknown and used as standard practice. However, the comment lacks specific examples or references to support the claim that the metrics are wellknown and standard practice. This makes the claim 3, as the authors would need to infer the reasoning behind the suggestion themselves.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to change the name of the \"Evaluation\" element to \"Metrics,\" which is a clear and concise improvement. It also recommends removing the corresponding sections and mentioning the metrics along with the datasets or in the captions of the tables. This suggestion is based on the rationale that \"evaluation\" can have a more general meaning and that most, if not all, of the metrics are wellknown and used as standard practice. By making these changes, the authors can improve the clarity and consistency of their paper. However, the comment could be more helpful if it provided examples of specific metrics to include or explained why these changes would enhance the paper\"s clarity. Overall, the comment is 4 as it offers clear and actionable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors should explore the new proposed dataset, DRRI, more thoroughly in the paper. However, it does not provide specific guidance on how to do this or what aspects of the dataset should be highlighted. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their discussion of the dataset. Therefore, this comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper this exploration should be added to, nor does it provide details on what aspects of the dataset should be highlighted or discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this exploration is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the authors should explore the new proposed dataset, DRRI, more thoroughly in the paper. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to incorporate this exploration into the paper. The comment does not provide details on what aspects of the dataset should be highlighted or how the authors might integrate this exploration into their analysis. As a result, the feedback is 3, as it points out a potential area for improvement but does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use more objective terms than \"remarkable\" in describing the accuracy improvement. It also points out that the axes are squished, making it difficult to characterize the improvement as remarkable. While the comment provides a specific suggestion to use more objective terms, it does not offer concrete guidance on what terms to use or how to address the issue of squished axes. The action is implicit and somewhat vague, as the authors need to infer the specific terms to use and the exact way to address the squished axes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"axes\" and \"squished,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to use more objective terms than \"remarkable\" in describing the accuracy improvement and points out the issue with the squished axes. This gives the authors clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the term \"remarkable\" is subjective and that the improvement might not be as remarkable as described. It provides a logical reasoning by pointing out that the axes are squished, making it difficult to characterize the improvement as remarkable. However, the comment lacks specific examples or references to support the claim that the term \"remarkable\" is inappropriate. While the reasoning is somewhat valid, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to use more objective terms than \"remarkable\" in describing the accuracy improvement. It also points out that the axes are squished, which could affect the perception of the improvement. This feedback is clear and constructive, as it guides the authors on how to present their findings in a more objective and accurate manner. By addressing these points, the authors can enhance the clarity and credibility of their results. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could benefit from using longer video sequences, such as 16 frames, to address issues with inconsistent motion, changing color, or object disappearing over time. It also mentions that running the LSTM over many time steps could be interesting. While the comment implies that the authors should consider these changes, it does not provide explicit instructions or concrete steps on how to implement them. The authors are left to infer that they should explore longer video sequences, but the comment lacks specific guidance on how to do so or what specific aspects to focus on. Therefore, the comment is 3, as it provides a direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the synthesized results for UCF101, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with inconsistent motion, changing color, or object disappearing over time and suggests using longer video sequences. Additionally, it provides a positive assessment of the paper, noting its interesting idea and extensive experiments, and acknowledges improved results over the previous stateoftheart. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the synthesized results for UCF101 exhibit inconsistent motion, changing color, or object disappearing over time. It suggests that using longer video sequences, such as 16 frames, could address these issues. The comment provides a logical reasoning by pointing out specific problems with the synthesized results and suggesting a potential solution. However, it lacks specific examples or references to support the claim about the synthesized results, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable argument but could be improved with more detailed evidence or examples.", "helpfulness_rationale": "The review comment provides a positive assessment of the paper, noting its interesting idea and extensive experiments. It highlights the improved results over the previous stateoftheart, which is a valuable observation. However, it also identifies specific issues with the synthesized results, such as inconsistent motion, changing color, or object disappearing over time. The comment suggests that using longer video sequences, such as 16 frames, could address these issues. While the feedback provides a clear direction for improvement, it lacks specific guidance on how to implement this suggestion or what aspects of the results are problematic. This limits the comment\"s helpfulness, as it points out an area for improvement but does not offer detailed instructions on how to achieve it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment states a fact about the current state of work on pruning, specifically noting that it is not yet possible to achieve efficiency gains on GPUs. However, it does not provide any actionable guidance or suggestions for the authors to address this issue or improve their work. There is no explicit or implicit action for the authors to take, leaving them without direction on how to respond to this observation. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it addresses. It is a general statement about the state of work on pruning, specifically mentioning GPUs. Without specific references to sections, figures, or other parts of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity as it does not provide details on what aspects of the work on pruning are not yet efficient on GPUs. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a factual statement about the current state of work on pruning, specifically noting that it is not yet possible to achieve efficiency gains on GPUs. It does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment provides a factual observation about the current state of work on pruning, specifically noting that it is not yet possible to achieve efficiency gains on GPUs. While this information is relevant, it does not offer any actionable insights or suggestions for improvement. It lacks depth and does not guide the authors on how to address this issue or what steps they could take to improve their work in this area. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the numerical evaluation is not convincing due to the method being evaluated only on synthetic data and the comparison with [5] being unfair because [5] is designed for a more complex problem. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the evaluation. The comment lacks actionable details, such as suggesting alternative evaluation methods or providing specific examples of how the comparison could be improved. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the numerical evaluation and the comparison with [5], allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the evaluation, noting that the method is only evaluated on synthetic data and that the comparison with [5] is not fair due to the complexity of the problem. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the numerical evaluation is not convincing due to the method being evaluated only on synthetic data and the comparison with [5] being unfair. The reviewer supports this claim by explaining that [5] is designed for a more complex problem, specifically mentioning the absence of knowledge of camera pose parameters. This provides a logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to the complex problem addressed by [5], which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the numerical evaluation, noting that the method is only evaluated on synthetic data and that the comparison with [5] is unfair due to the complexity of the problem addressed by [5]. This feedback is valuable as it highlights a potential weakness in the paper\"s evaluation, which could impact the credibility of the results. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue, such as suggesting alternative evaluation methods or explaining why the comparison with [5] is unfair. Despite this, the comment still offers a clear direction for improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors studied the effect of using numbers of bits in logits on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness against a more powerful adversary. While the comment implies that the authors should consider this experiment, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this experiment to strengthen their paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"PGD attack\" and the \"32bit logit,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the study of the effect of using numbers of bits in logits on robustness against a larger epsilon in the PGD attack. This provides clear guidance on what the authors should consider in their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether the study of numbers of bits in logits helps against a larger epsilon in the PGD attack. The reviewer suggests that intuition suggests that having a 32bit logit should improve robustness against a more powerful adversary. However, the comment lacks specific evidence or references to support this claim, making it 3. The authors would need to make a logical inference to understand the basis of the suggestion, which is not fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the study of numbers of bits in logits and their effect on robustness against a larger epsilon in the PGD attack. It suggests that intuition suggests that having a 32bit logit might improve robustness against a more powerful adversary. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to conduct this experiment or what specific aspects to focus on. The feedback is 3 as it points out a potential area for enhancement, but it lacks actionable details that would fully support the authors in making improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point poses a question about the impact of the method on insurance costs for men and women. While it does not explicitly instruct the authors to provide this information, the question implies that the authors should include this analysis in their paper. The action is implicit but concrete, as the authors can infer that they need to include this information to address the reviewer\"s concern. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment poses a question about the impact of the method on insurance costs for men and women, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where this information should be addressed. Additionally, the comment lacks specificity regarding what aspects of the insurance costs should be analyzed or how the method affects them. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the impact of the method on insurance costs for men and women. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a specific question about the impact of the method on insurance costs for men and women. This is a clear and actionable request for additional information that could help the authors better understand the practical implications of their work. By addressing this question, the authors could provide more comprehensive and relevant information about their method, which could enhance the clarity and usefulness of their paper. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a relevant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. It provides an example of the BERT paper being available on arxiv in October, suggesting that the authors should consider this issue in their paper. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider the availability of papers on arxiv. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of splitting papers according to their publication years on the ACL anthology, noting that many papers are available on arxiv much earlier. It provides an example of the BERT paper being available on arxiv in October. However, the comment does not specify which part of the paper discusses the splitting of papers, making it weakly grounded. The comment is specific in pointing out the issue of papers being available on arxiv before being published in the ACL anthology. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. The reviewer provides an example of the BERT paper being available on arxiv in October, which supports the claim. However, the comment could be strengthened by providing more examples or detailed reasoning on why this issue is significant. As it stands, the claim is 3, as it relies on a specific example but lacks comprehensive evidence or detailed explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s methodology, noting that it splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. This is a relevant observation that could impact the paper\"s credibility and relevance. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a potential problem, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for consideration but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises two concerns: the use of an arbitrary parameter \u03b2 in rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The authors are left to infer that they need to clarify the use of \u03b2 and the difference between QRS and RS, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed instructions on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the proposed relaxation of rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. The comment provides a clear direction for improvement by suggesting that the authors clarify the use of \u03b2 and the difference between QRS and RS. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the use of an arbitrary parameter \u03b2 in rejection sampling and questions the lack of clarity regarding the difference between QRS and RS in Algorithm 1. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the authors should have used Importance sampling instead of rejection sampling. Additionally, the comment lacks specific examples or detailed explanations to support the claim about the difference between QRS and RS. As a result, the claim is not verifiable, as it does not provide sufficient evidence or justification for the authors to understand or address the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the use of an arbitrary parameter \u03b2 in rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. While the comment highlights these areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out areas that need attention, but it could be more beneficial if it offered actionable steps or examples to improve the draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the observed performance enhancements are modest and implies that there is room for further refinement in the future. However, it does not provide specific guidance on how to achieve this refinement or what aspects of the work need improvement. The action is implicit and vague, as the authors are left to infer that they need to make improvements but without clear direction on what those improvements should be. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not specify which part of the paper this observation is based on, such as specific experiments or results. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the work need refinement or how to achieve this refinement. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this observation and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the observed performance enhancements are modest, indicating that there is room for further refinement in the future. However, it does not provide specific guidance or suggestions on how to achieve this refinement or what aspects of the work need improvement. Without actionable feedback or detailed insights, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to provide references for two specific passages in Section 3.2, lines 230234 and 234235, and to clarify what \"MLP\" refers to in Figure 2. These are clear and direct actions that the authors can take to improve their draft. Additionally, the comment highlights a missing reference, which is also actionable. The feedback is specific and provides concrete guidance on what needs to be added or clarified, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in Section 3.2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for references for two passages and clarifies what \"MLP\" refers to in Figure 2. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of requests for references and clarifications, which are factual in nature and do not contain subjective claims or opinions. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying specific lines in Section 3.2 that require references and clarifying what \"MLP\" refers to in Figure 2. This guidance is clear and directs the authors to specific areas that need attention, ensuring that the paper is wellreferenced and accurate. Additionally, the comment highlights a missing reference, which is an important detail for the authors to address. Overall, the comment is 5 as it offers clear and constructive suggestions for improvement, making it fully comprehensive and beneficial for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the validity of the proposed method. However, it does not provide specific guidance on how the authors should address this issue or what steps they should take to improve the results. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the experimental results on the last two datasets, specifically mentioning the performance being similar to IRM. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the issue with the experimental results, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method. However, it does not provide specific reasoning or evidence to support this claim, such as detailed analysis or comparisons with other methods. The comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the validity of the proposed method. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their experimental results. Without detailed guidance or examples, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of detecting both entities in the example of Figure 2, and it asks for clarification on the difference between detecting both entities and just detecting the long one. While the comment implies that the authors should provide a clearer explanation or rationale for this distinction, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the distinction but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of detecting both entities in the example and asking for clarification on the difference between detecting both entities and just detecting the long one. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the necessity of detecting both entities in the example of Figure 2, and it asks for clarification on the difference between detecting both entities and just detecting the long one. While the comment identifies a potential area of confusion or misunderstanding in the paper, it does not provide specific suggestions or guidance on how to address this issue. The authors are left with a vague understanding of the problem but without actionable steps to improve their draft. Therefore, the comment is 3, as it points out a potential area for clarification but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there is no empirical validation and suggests including experiments to validate the bounds. This provides a clear and direct action for the authors to take, which is to conduct experiments to validate the bounds. The comment is specific in its request for empirical validation and offers a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the lack of empirical validation, which provides full grounding as it allows the authors to identify the specific part of the paper being addressed. It also specifies the issue by suggesting the inclusion of experiments to validate the bounds. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is no empirical validation and suggests including experiments to validate the bounds. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of empirical validation for the bounds. It suggests that including experiments to validate the bounds would be beneficial. This feedback is clear and actionable, as it provides a specific direction for improvement by recommending empirical validation. However, the comment could be more helpful if it offered examples of what types of experiments might be appropriate or how to design them. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the upper bound in Theorem 1, which seems incorrect due to a separate node with 0 neighbors. The reviewer asks how to explain this exception. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this question or clarify the exception. The action is implicit and somewhat vague, as the authors can infer that they need to provide a response but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the upper bound in Theorem 1 and asks for clarification on how to explain an exception involving a separate node with 0 neighbors. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the correctness of Theorem 1 and points out an apparent contradiction regarding the upper bound. However, it does not provide any supporting evidence, reasoning, or references to justify why the upper bound is incorrect or how it should be corrected. The claim is based on a logical observation but lacks detailed explanation or examples, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the correctness of Theorem 1, specifically questioning the upper bound in the context of a separate node with 0 neighbors. This is a relevant point that could lead to a misunderstanding or error in the paper. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or clarify the exception. While it identifies a potential problem, it lacks actionable feedback or detailed advice, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the training time reduction is less drastic than the parameter reduction, as most gradients are still computed for early downsampling layers. It suggests that this observation has not been revisited in the Discussion section, and recommends deleting the word \"Discussion\" to avoid confusion. While the comment provides a clear action to take, it does not offer specific guidance on how to revise the Discussion section or what aspects should be revised. The action is explicit but somewhat vague, as the authors need to determine the exact changes needed to address the issue. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pg.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific observation about the training time reduction and parameter reduction, suggesting that the discussion on this topic has not been revisited. This provides clear guidance on what needs to be addressed in the Discussion section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the training time reduction is less drastic than the parameter reduction, as most gradients are still computed for early downsampling layers. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific observation about the training time reduction and parameter reduction, noting that the training time reduction is less drastic than the parameter reduction due to the computation of most gradients for early downsampling layers. It suggests that this observation has not been revisited in the Discussion section, which is fine. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or improve the discussion. While it points out a potential oversight, it lacks actionable feedback that would help the authors enhance their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the problem being discussed is specific to binding affinity prediction or applies to other downstream tasks. It implies that the authors should provide a justification for why the problem is specific to binding affinity prediction. However, the comment does not explicitly instruct the authors to provide this justification or specify how it should be presented. While the action is implied, it is not concrete, as the authors are left to infer what additional information is needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the problem to other downstream tasks or whether it is specific to binding affinity prediction. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for a justification or explanation of why the problem is specific to binding affinity prediction. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the applicability of a problem to other downstream tasks or its specificity to binding affinity prediction. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the applicability of a problem to other downstream tasks or its specificity to binding affinity prediction. This is a relevant point that could prompt the authors to clarify the scope and limitations of their work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional information would be beneficial. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the paper regarding the handling of rumors generated by GPT, specifically questioning the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific analyses or solutions could be proposed. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the handling of rumors generated by GPT, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the need for further analysis or solutions regarding the challenges of detecting rumors generated by GPT, and it questions the rationale behind why GPTgenerated rumors are similar to natural rumors. The comment provides a clear direction for the authors to consider, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect. It suggests that Artificial Rumor, which is also written by humans, should be about the same difficulty as Natural Rumor, but the experimental result shows the opposite. The comment provides a logical reasoning by questioning the experimental result and suggesting that the rationale might be flawed. However, it lacks specific examples or references to support the claim that GPTgenerated rumors are easier to detect than natural rumors. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the handling of rumors generated by GPT, specifically questioning the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect. It points out that Artificial Rumor, which is also written by humans, should be about the same difficulty as Natural Rumor, but the experimental result shows the opposite. This feedback is 3 as it highlights an area where the authors could provide further analysis or solutions to address the challenge of detecting rumors generated by GPT. However, the comment could be more helpful if it suggested specific analyses or experiments that the authors could conduct to explore this issue further. Overall, the comment provides some insight but lacks detailed guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical contribution or what specific changes should be made to Section 4. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the technical contribution, stating that it is limited and not about a formal and principled solution but rather about heuristics. This provides clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical contribution of the paper, specifically noting that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. This feedback highlights an area where the paper could be improved by providing a more comprehensive and rigorous approach to the technical contribution. However, the comment lacks specific suggestions or guidance on how to address this issue or what aspects of the heuristics should be improved. While it points out a potential weakness, it does not offer actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that the font size in Figure 6 is too small, providing a clear and direct action for the authors to take. This feedback is specific and concrete, as it instructs the authors to adjust the font size to make it more readable. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the font size being too small, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment is a factual observation about the font size in Figure 6, which does not contain any subjective claims, opinions, or suggestions. It is a descriptive statement that requires no verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment identifies a specific issue with the font size in Figure 6, noting that it is too small. This feedback is clear and actionable, as it provides the authors with a concrete step to improve the readability of their figure. However, the comment could be more helpful if it suggested a specific font size or provided guidance on how to adjust the font size to improve legibility. Despite this, the comment is 4 as it directs the authors to a specific area for improvement, which can enhance the clarity and accessibility of their work. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the probability mass function (PMF) is not being fully utilized in the experimental setting and recommends considering various PMFs for each learner class. It also mentions that the quasiuniform distribution used in MixBoost is dependent on a single parameter and suggests that individual consideration of each learner class would add depth to the experimental setting. However, the comment does not provide specific guidance on how to implement this suggestion or which PMFs to consider. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"probability mass function\" and the \"MixBoost\" setting, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the use of a quasiuniform distribution and suggests considering various probability mass functions for each learner class. This provides clear guidance on what needs to be addressed in the experimental setting. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the probability mass function is not being fully utilized in the experimental setting, specifically mentioning the use of a quasiuniform distribution in MixBoost. The reviewer suggests that considering various probability mass functions for each learner class would add depth to the experimental setting. However, the comment lacks specific examples or references to support the claim that a quasiuniform distribution is not ideal. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setting, noting that the probability mass function is not being fully utilized in the MixBoost setting. It suggests that considering various probability mass functions for each learner class would add depth to the experimental setting. While the comment highlights a potential area for improvement, it lacks specific guidance on how to implement this suggestion or which probability mass functions to consider. The feedback is 3 as it points out a potential weakness but does not provide detailed instructions on how to address it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the missing references, specifically mentioning [a], which is relevant to the topic of the paper. It suggests discussing connections with [a], which uses supervised learning in QBF solving, where QBF generalizes SMT. However, the comment does not provide explicit instructions on how to incorporate these references or discuss the connections. While the authors can infer that they need to include these references and discuss the connections, the lack of concrete guidance on how to do so makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the missing references and the need to discuss connections with [a], which uses supervised learning in QBF solving. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper is missing relevant references, specifically mentioning [a], which uses supervised learning in QBF solving. The reviewer provides a specific reference to support the claim that this work is relevant to the paper\"s topic. However, the comment lacks detailed reasoning or explanation about why this reference is important or how it relates to the paper\"s content. While the reference is provided, the lack of detailed justification or explanation makes the claim 3, as the authors would need to make a significant effort to understand and incorporate the reference. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue by pointing out the missing references, specifically mentioning [a], which is relevant to the topic of the paper. It suggests discussing connections with [a], which uses supervised learning in QBF solving, where QBF generalizes SMT. This feedback is clear and actionable, as it directs the authors to include relevant references and explore potential connections with the existing literature. However, the comment could be more helpful if it provided specific guidance on how to incorporate these references or discuss the connections, such as suggesting specific sections or methods to integrate. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the comparison in terms of computation cost or running time. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific aspects of the computation cost or running time should be compared, nor is there any suggestion for how the authors might address this issue. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment poses a question about the comparison in terms of computation cost or running time, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the computation cost or running time should be compared or how the authors might address this issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the comparison in terms of computation cost or running time, but it does not contain any subjective claims, opinions, or suggestions that require verification. It is a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the comparison in terms of computation cost or running time, which could be an important aspect of the paper. However, it does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the computation cost or running time should be compared. Without actionable feedback or detailed insights, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. While the comment provides a specific suggestion for improvement, it lacks concrete guidance on how to implement this change or what specific aspects of the paper need to be revised to address this issue. The authors are left with a general idea of what to do but without detailed instructions on how to execute the action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second paragraph, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the introduction, suggesting that the examples chosen do not convincingly demonstrate the need for interprocess communication and recommending a focus on problems where the loss function does not decompose as the sum of sample losses. The comment provides a clear direction for improvement by suggesting a focus on Hogwild and other ERMbased distributed algorithms. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the examples chosen in the paper do not convincingly demonstrate the need for interprocess communication, particularly in the second paragraph where samplingbased Bayesian methods are mentioned. The reviewer suggests that the paper\"s results are irrelevant in this context and recommends focusing on problems where the loss function does not decompose as the sum of sample losses. The comment provides a logical reasoning for the claim by pointing out the specific examples and suggesting a different approach. However, it lacks specific references or detailed evidence to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction, noting that the examples chosen do not convincingly demonstrate the need for interprocess communication, particularly in the context of samplingbased Bayesian methods. The reviewer suggests that the paper\"s results are irrelevant in this context and recommends focusing on problems where the loss function does not decompose as the sum of sample losses. The comment provides a clear and actionable suggestion for improvement by recommending a different approach, such as focusing on problems like Hogwild. This feedback is valuable as it guides the authors on how to strengthen their introduction and better align their work with relevant research areas. However, it could be more helpful if it included specific examples or references to support the claim about the irrelevance of the current examples. Overall, the comment is 4 as it offers a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address these concerns or improve the paper in response. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the privacy preservation issue and the example of traffic signal control, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control, suggesting that this example is a poor choice for demonstrating federated learning. However, the comment lacks any supporting evidence, reasoning, or references to substantiate these claims. Without detailed justification or examples, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control, suggesting that this example is a poor choice for demonstrating federated learning. While the comment identifies a potential weakness in the paper\"s argument, it lacks specific guidance or suggestions on how the authors might address this issue or improve the paper. The feedback is 3 as it points out a potential area for improvement, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This provides a clear and direct action for the authors to take, which is to verify and potentially fix the links. The comment is specific and concrete, as it clearly identifies the problem and offers a straightforward solution. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnotes 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the hyperlinks not working, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hyperlinks for footnotes 3 and 4 do not work. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This is a clear and actionable piece of feedback that the authors can address to improve the quality and accessibility of their paper. By addressing this issue, the authors can ensure that their references are properly linked and accessible to readers, which is an important aspect of academic writing. However, the comment could be more helpful if it provided additional guidance on how to verify the links or suggested alternative solutions. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific guidance on what needs to be revised, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The reviewer also points out that the figure may be misleading, as it suggests that Label Embeddings are the output of the encoder. This feedback is explicit and provides concrete details on what changes need to be made, making it 5. The authors know exactly what needs to be revised to improve the clarity of their discussion.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, which is not clear enough. It provides specific feedback on what needs to be revised, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The comment also points out that the figure may be misleading, suggesting that the Label Embeddings are the output of the encoder. This provides full grounding as it explicitly mentions the sections and elements of the paper being addressed. The comment is specific because it details what needs to be clarified and improved in the discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific feedback on what needs to be revised, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The reviewer also points out that the figure is misleading, as it suggests that Label Embeddings are the output of the encoder. This feedback is 4 as it provides logical reasoning and specific examples to support the claim. However, the comment could be strengthened by referencing specific sections or figures to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on improving the clarity of the discussion in the modeling section. It suggests revising the architecture section to better formalize the architecture and clarify the role of Label Embeddings. The reviewer also points out that the figure may be misleading, as it suggests that Label Embeddings are the output of the encoder. This feedback is 5 as it guides the authors on how to enhance the clarity and accuracy of their discussion, which is crucial for effective communication of their work. By addressing these points, the authors can significantly improve the comprehensibility and impact of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. While it implies that the authors should consider this option, it does not provide explicit instructions or concrete steps on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative approach. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. However, it does not specify which part of the paper this limitation or suggestion pertains to, making it weakly grounded. The comment is specific in suggesting an alternative approach, but without clear grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. However, it does not provide any supporting evidence, reasoning, or references to justify why the current approach is limited or how attentionbased training might be beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. While it identifies a potential area for improvement, it lacks depth and does not provide specific guidance or examples on how to implement this change or what benefits it might offer. The comment is 3 as it points out a potential direction for improvement, but it does not offer actionable steps or detailed reasoning to support the suggestion. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive to be fully beneficial."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the impact of mitigation methods or suggestions for improving image quality. As a result, the authors are left without any clear direction on how to improve their draft in response to this comment. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the impact of mitigation methods on the image generation capabilities of diffusion models, suggesting that this could lead to lower image quality. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the mitigation methods affecting image quality. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the mitigation methods affect the image generation capabilities of diffusion models, which could lead to lower image quality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their mitigation methods. The comment highlights a potential problem but lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not provide explicit guidance on how to address these concerns or what specific steps the authors should take to mitigate these risks. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not specify which part of the paper this concern is related to, such as specific sections or experiments where this issue might arise. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specific guidance on how to address these concerns or what steps to take to mitigate the risks. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references to studies or literature that demonstrate similar issues or offer suggestions on how to address them. As a result, the claim is 3, as it provides a logical concern but lacks the necessary evidence or references to fully substantiate it.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. While the comment identifies a critical issue, it lacks specific guidance or suggestions on how the authors might address this concern or mitigate the risks. The feedback is 3 as it points out a potential problem but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this observation or what changes they should make to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by expressing surprise about the dominance of function words over content words in a Japanese sentence. However, the comment lacks specificity regarding what aspect of the dominance is surprising or how it might impact the paper. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it lacks any actionable feedback or suggestions for improvement. Without further explanation or context, the authors are left without a clear understanding of what aspect of the observation is surprising or how it might impact their work. As a result, the comment does not provide any meaningful guidance for the authors to enhance their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing element in the paper, specifically the FLOT cost matrix in Algorithm 1, which is not defined. This provides a clear and direct action for the authors to take, which is to define the FLOT cost matrix. The comment is specific and concrete, giving the authors a clear understanding of what needs to be added to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"FLOT cost matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the absence of the FLOT cost matrix in Algorithm 1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the FLOT cost matrix in Algorithm 1 is not defined. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the absence of the FLOT cost matrix in Algorithm 1. This is a clear and actionable point that the authors can address to improve the clarity and completeness of their draft. By pointing out this missing element, the comment provides valuable guidance for the authors to enhance the quality and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to define or present the FLOT cost matrix, which would provide even more detailed guidance. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for clarification on the definition of the sparsity of the residual term and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. It also recommends showing the advantages of the proposed method compared to existing methods. While the comment provides clear and specific actions for the authors to take, it does not offer detailed guidance on how to present this evidence or what specific aspects should be highlighted. The authors are given a clear direction but may need to infer the exact steps to follow. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"specific definition of the sparsity of the residual term,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the definition and suggests providing evidence to support the sparsity assumption across various noisy cases. Additionally, it recommends comparing the proposed method with existing methods to highlight its advantages. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the specific definition of the sparsity of the residual term and suggests that evidence is needed to support the sparsity assumption across various noisy cases. The reviewer also recommends comparing the proposed method with existing methods to highlight its advantages. While the comment identifies a potential issue with the clarity of the definition, it lacks specific examples or references to support the claim that the sparsity assumption is not wellfounded. The suggestion to provide evidence is logical, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the definition of the sparsity of the residual term in the paper. It suggests that the authors provide evidence to support the sparsity assumption across various noisy cases and recommends comparing the proposed method with existing methods to highlight its advantages. This feedback is clear and actionable, as it guides the authors to address a critical aspect of their work that could impact its clarity and effectiveness. However, the comment could be more helpful if it provided specific examples or references to support the need for evidence or comparisons. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to the terminology. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"connectivity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is wrong with the term \"connectivity,\" explaining that it does not refer to the structural connections between the brain and body. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the term \"connectivity,\" noting that it is misleading as it does not refer to the structural connections between the brain and body. This feedback is valuable as it highlights a potential source of confusion in the paper, which could be clarified to improve the accuracy and precision of the terminology. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue or what specific changes could be made to improve the clarity of the terminology. While it points out a relevant issue, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific guidance on what aspects are missing or how to address these issues. The authors are left to infer that they need to improve the clarity, quality, novelty, and reproducibility of their work, but without concrete suggestions or examples, they may struggle to know exactly what changes to make. The comment is vague and lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not specify which parts of the paper are missing these details, making it difficult for the authors to pinpoint the exact sections that need improvement. Additionally, the comment references \"Clarity, Quality, Novelty And Reproducibility,\" but does not provide specific examples or details from these sections. This lack of specificity and grounding makes it challenging for the authors to understand and address the issues effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests that these are areas of concern, but without further elaboration or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several areas where the paper is lacking, including clarity, quality, novelty, and reproducibility. However, it does not provide specific examples or detailed feedback on what aspects of these categories are missing or how they could be improved. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests that these are areas of concern, but without further elaboration or suggestions, the authors are left without actionable guidance on how to address these issues. The comment lacks depth and specificity, making it 2 for the authors in improving their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit guidance on what the authors should do to improve their draft. It suggests that the authors should study the essentialness of using an orthogonal matrix weight for the local window MLP, which is not currently presented. This feedback is clear and concrete, as it specifies the need for further exploration and validation of the orthogonal matrix weight. The authors know exactly what needs to be done to address this point, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Step 2\" and \"Step 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the importance of studying the essentialness of using an orthogonal matrix weight for the local window MLP. The comment provides a clear direction for the authors to improve their draft by suggesting that they should explore the validity of using an orthogonal matrix weight. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Step 2 and Step 3 are important for validating the essentialness of using an orthogonal matrix weight for the local window MLP. The reviewer suggests that Step 2 can be done regardless of the weight matrix, and Step 3 is crucial for using an orthogonal matrix weight. However, the comment lacks specific examples or references to support these claims, making it 3. The authors may find it challenging to fully understand and address the claims without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that needs improvement, namely the lack of exploration into the essentialness of using an orthogonal matrix weight for the local window MLP. It suggests that Step 2, which involves the transpose of the matrix, can be done regardless of the weight matrix, and that Step 3 is crucial for validating the use of an orthogonal matrix weight. The comment provides a clear and actionable suggestion for the authors to further explore and validate the use of an orthogonal matrix weight, which is a significant contribution to the paper. However, the comment could be more helpful if it offered specific examples or references to support the claim about the importance of Step 3. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the drop in accuracy in Figure 5, specifically asking why it occurs after a certain order around 45. It does not provide any explicit or implicit actions for the authors to take, such as suggesting further analysis or experiments to address the issue. The comment lacks guidance on how the authors might investigate or resolve the drop in accuracy. As a result, the authors are left without any clear direction on how to respond to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the drop in accuracy after a certain order around 45 and asks if it is due to overfitting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification regarding the drop in accuracy in Figure 5. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the drop in accuracy in Figure 5, specifically asking why it occurs after a certain order around 45. It does not provide any suggestions or guidance on how the authors might address this issue or investigate the cause of the drop in accuracy. While it prompts the authors to consider the possibility of overfitting, it lacks actionable advice or detailed analysis that could help the authors understand and resolve the issue. Therefore, the comment is 3 as it points out a potential area for further exploration but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the models and datasets used are too toylike and recommends using CIFAR100, ResNet 34 or 50, and ViTtiny or small. It also asks if there are foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\"s score. While the comment provides specific recommendations for datasets and models, it lacks concrete guidance on how to implement these changes or what specific aspects of the language tasks should be addressed. The action is explicit but somewhat vague, as the authors know what changes to make but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the models and datasets, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the need for CIFAR100, ResNet 34 or 50, and ViTtiny or small, and raises questions about language tasks. However, the comment does not provide specific guidance on how to address these issues or what aspects of the language tasks should be considered. Therefore, it is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the models and datasets used are \"toylike\" and suggests that the authors should consider using CIFAR100, ResNet 34 or 50, and ViTtiny or small. The reviewer also asks about the foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\"s score. While the comment provides a logical reasoning for the need for more diverse datasets and models, it lacks specific examples or references to support the claim that the current models are too toylike. The suggestion to use CIFAR100 is a specific example, but the comment could be strengthened by providing more detailed reasoning or examples. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks sufficient evidence or references to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific issue with the models and datasets used in the paper, noting that they are too toylike and suggesting the inclusion of more challenging datasets like CIFAR100, ResNet 34 or 50, and ViTtiny or small. It also raises a question about the foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\"s score. While the comment provides clear and actionable feedback on improving the dataset and model selection, it could be more helpful if it offered specific guidance on how to address the language task challenges or provided examples of how these changes could impact the results. Overall, the comment is 4 as it directs the authors to make specific improvements, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential oversight in the experiment, noting that the Vision Transformer was not considered and questioning its applicability to larger image datasets like ImageNet. It also raises a question about the pruning strategy in selfattention layers. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should consider the Vision Transformer and address the pruning strategy question, but the comment lacks specific guidance on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the omission of the Vision Transformer model and questions its applicability to larger datasets like ImageNet. Additionally, it raises a specific concern about the pruning strategy in selfattention layers. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the omission of the Vision Transformer model in the experiment and questions its applicability to larger datasets like ImageNet. It also suggests that the pruning strategy in selfattention layers might differ. However, the comment lacks specific references or detailed reasoning to support these claims. While it identifies potential issues, the lack of detailed justification or examples makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is 3, as it provides a basis for the claims but requires more detailed evidence or explanation to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential oversight in the experiment by noting the absence of the Vision Transformer model, which is an important SOTA model in image classification. It also raises a question about the applicability of the pruning strategy in selfattention layers to larger datasets like ImageNet. This feedback is 3 as it prompts the authors to consider a relevant model and address a potential limitation in their experiment. However, the comment could be more helpful if it provided specific suggestions on how to incorporate the Vision Transformer or how to evaluate the pruning strategy. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper claims advantages over previous work in terms of efficiency but does not provide any metrics to substantiate these claims. This implies that the authors should include metrics to demonstrate the efficiency of their proposed method. However, the comment does not specify which metrics should be used or how they should be presented, leaving the authors with a general direction but without concrete guidance on execution. The action is implicit and somewhat vague, as it highlights a gap in the paper but does not provide detailed instructions on how to address it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim of advantages over previous work in terms of efficiency but notes the absence of metrics to substantiate these claims. It does not specify which part of the paper this issue is discussed in, making it weakly grounded. However, it is specific in detailing what needs to be addressed, namely the inclusion of metrics to demonstrate efficiency. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks metrics to substantiate its claims of efficiency over previous work. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without concrete evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that while the authors claim advantages over previous work in terms of efficiency, they do not provide any metrics to substantiate these claims. This is a critical point that could impact the credibility of the paper, as it lacks empirical evidence to support the claim. The comment highlights a clear area for improvement, suggesting that the authors should include metrics to demonstrate the efficiency of their proposed method. However, it does not provide specific guidance on which metrics to use or how to present them, leaving some room for interpretation. Overall, the comment is 3 as it points out a critical issue but could be more actionable with additional details. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks for more details regarding the statespace, whether it is finite or continuous, and the actions. It also questions the space in which theta lies. While the comment provides a clear and direct request for additional information, it does not specify how the authors should present this information or what format would be most appropriate. The action is explicit but somewhat vague in terms of execution, as the authors know what needs to be added but may not be entirely sure of the exact method to present it. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as providing more details about the statespace, whether it is finite or continuous, and the actions. The comment also questions the space in which theta lies, indicating a need for clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for more details about the statespace, whether it is finite or continuous, and the actions. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a lack of detail in the paper, specifically asking for more information about the statespace, whether it is finite or continuous, and the actions. It also questions the space in which theta lies, indicating that the authors should be more precise in their explanations. While the comment highlights areas for improvement, it does not provide specific guidance or suggestions on how to address these issues. The authors are given a general direction to be more detailed but are not provided with actionable steps to achieve this. Therefore, the comment is 3, as it points out areas for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the method\"s effectiveness on general reasoning tasks or suggestions for potential improvements. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the method are not effective on general reasoning tasks or how they could be improved. Without clear guidance on where to focus the revision or what changes are needed, the authors are left without a clear path for action. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential weakness in the method\"s effectiveness on general reasoning tasks compared to mathematical reasoning. However, it lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the method\"s performance. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The reviewer also mentions that the authors acknowledge this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment identifies a problem, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the proof technique and its applicability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W2.3. Proof Technique\" and \"Appendix A,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The comment further specifies that this issue is acknowledged in Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proof technique in Appendix A relies on a special case where a contradiction arises as matrix norms approach infinity, which is acknowledged in Section 3. The reviewer provides a specific reference to Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. This reference provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. This is acknowledged in Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment highlights a potential weakness in the paper, it does not provide actionable suggestions or guidance on how the authors might address this issue or improve the proof technique. The feedback is 3 as it points out a specific area for improvement, but it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests replacing \"t\" with the size of T in the histogram intersection kernel to improve clarity. While the comment explicitly states the action to take, it lacks concrete guidance on how to implement this change or why it is necessary. The authors are left to infer that they should make this change to enhance clarity, but without specific instructions or examples, the action remains somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"histogram intersection kernel,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of \"t\" in the kernel and the suggestion to replace it with the size of T to improve clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests replacing \"t\" with the size of T in the histogram intersection kernel to improve clarity. However, the comment does not provide any reasoning or evidence to support why \"t\" is unclear or why replacing it with the size of T would improve clarity. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a specific improvement to the clarity of the histogram intersection kernel by recommending the replacement of \"t\" with the size of T. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the readability and understanding of the methodology. However, the comment could be more helpful if it explained why \"t\" is unclear or why the change would improve clarity. Despite this, the suggestion is valuable and offers a straightforward way for the authors to improve their draft, making the comment 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve the adaptation capacity. The comment lacks actionable details, such as recommending specific experiments or modifications to the model architecture. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. However, the comment does not specify which part of the paper this concern is related to, such as a specific section or experiment. Without explicit references, the authors cannot confidently determine which parts of the paper need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the adaptation capacity might be an issue. Without such evidence or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. While the comment identifies a potential concern, it lacks specific guidance or suggestions on how the authors might address this issue or improve the adaptation capacity. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point provides explicit actions for the authors to take, such as giving the EF and D2 transcription norms, correcting specific phrases in the text, and addressing issues with repeated words in a table. Additionally, it points out a discrepancy in the DOI number and the link behind the title. These actions are clear and specific, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and tables in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the phrasing in lines 029 and 188, the repeated words in Table 3, and the discrepancy in the DOI number. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of technical corrections and observations, such as correcting phrasing, addressing repeated words, and pointing out discrepancies in the DOI number. These are factual statements that do not involve subjective opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a mix of technical corrections and observations, which can be beneficial for the authors in improving the clarity and accuracy of their work. It points out specific errors in phrasing and references, such as correcting \"lightweight\" to \"in a lightweight\" and \"PLN\" to \"NLP.\" Additionally, it highlights a discrepancy in the DOI number and the link behind the title. These corrections and observations are actionable and can help the authors improve the clarity and consistency of their work. However, the comment could be more helpful if it provided additional context or suggestions for how to address these issues, such as explaining why the corrections are necessary or offering alternative phrasing. Overall, the comment is 3 as it identifies specific areas for improvement but lacks depth in its guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the notation used in the paper, including the lack of definitions for M and N and the small font size in Figure 1. It provides a specific suggestion to spell out F.L.T.R in Figure 4 and recommends crossreferencing notation and figures to avoid confusion. While the comment does not explicitly instruct the authors to make these changes, the suggestions are clear and actionable, providing concrete steps for the authors to improve the clarity and readability of their paper. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as spelling out F.L.T.R in Figure 4 and making the text larger. The comment also suggests crossreferencing notation and figures to avoid confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation is confusing and suggests spelling out F.L.T.R in Figure 4. It also mentions that the font size in Figure 1 is too small to see and recommends crossreferencing notation and figures. While the comment identifies specific issues with the notation and figure presentation, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to crossreference notation and figures is a logical step, but the comment could be strengthened with more detailed justification or examples. Therefore, the claim is 3, as it provides some support but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including confusing notation and font size in figures. It provides specific suggestions for improvement, such as spelling out F.L.T.R in Figure 4 and making the text larger in Figure 1. Additionally, it recommends crossreferencing notation and figures to avoid confusion. These suggestions are clear and actionable, offering the authors a concrete path to enhance the clarity and readability of their draft. However, the comment could be more helpful if it provided additional guidance on how to address the confusion in the notation or why it is confusing. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential source of confusion in Algorithm1, specifically regarding the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2. While the comment identifies an issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they should clarify or rename the variable to avoid confusion. The action is implicit and somewhat vague, as it lacks concrete details on how to implement the suggested change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1\" and \"Phase 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2, suggesting that this might be confusing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using \"$p$\" to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2 might be confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in Algorithm1, specifically regarding the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2. This feedback is clear and actionable, as it points out a specific issue that could be clarified or addressed to improve the clarity of the paper. However, the comment could be more helpful if it provided suggestions on how to clarify or rename the variable to avoid confusion. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could benefit from a more detailed mathematical formulation, particularly in the appendix, to enhance the understanding of the approach. It also points out that the figure is confusing and recommends adding text labels to clarify its purpose and align it with the main contribution of the paper, which is improvements on the WiC task. The comment provides specific suggestions for reworking the figure to better align with the WiC task, offering actionable steps for the authors to improve their draft. The explicit nature of these suggestions and the concrete guidance on how to implement them make the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"highlevel description\" and the \"figure,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the need for a more detailed mathematical formulation in the appendix and the confusion caused by the figure, including the need for text labels and better alignment with the main contribution of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the highlevel description and figure are confusing and could benefit from a more detailed (e.g., mathematical) formulation and clearer labels. The reviewer provides specific examples of how the figure is abstract and does not align with the main contribution of the paper, which is improvements on the WiC task. The suggestion to rework the figure to depict the WiC task is a concrete and actionable step for the authors to improve their draft. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim about the figure\"s abstraction and misalignment with the main contribution. This makes the claim 3, as it provides a clear direction for improvement but lacks comprehensive evidence or detailed justification.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the paper\"s presentation, suggesting that the highlevel description could benefit from a more detailed mathematical formulation, particularly in the appendix. It also points out that the figure is confusing and does not align well with the main contribution of the paper, improvements on the WiC task. The reviewer offers a concrete suggestion to rework the figure to depict the WiC task, which would help clarify its purpose and better align it with the paper\"s contributions. This feedback is clear and provides the authors with a clear path for improving their draft, making it 4. However, it could be more comprehensive by explaining why the current formulation is confusing or how the suggested changes would enhance the clarity of the paper. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that it would be beneficial to include additional benchmarking tasks outside of AitW. However, it does not provide specific guidance on which tasks should be included or how they should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they should consider additional benchmarking tasks but are not given concrete steps on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not specify which parts of the paper should include these tasks or which specific benchmarking tasks should be considered. Without explicit references to sections or specific tasks, the authors cannot confidently determine which parts of the paper need revision. The comment is 1 and lacks specificity, making it difficult for the authors to understand and address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that additional benchmarking tasks outside of AitW would be beneficial. However, it does not provide specific examples or guidance on which tasks should be included or how they could enhance the paper. While it identifies a potential area for improvement, the lack of detailed suggestions limits its helpfulness. The authors are left to infer the specific tasks that could be included, making the feedback 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for clarification on the comparison results between YOSO and linformer in terms of iterationwise convergence and accuracy in downstream tasks. It also suggests that an explanation is needed to analyze the difference in performance. The comment provides clear and specific actions for the authors to take, such as including the steps vs PPL of linformer with YOSO in Figure 4 and analyzing the performance difference. The explicit nature of the request and the concrete details on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments: YOSO takes linformer as baselines,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including the lack of comparison results between YOSO and linformer in Figure 4, and the need for an explanation of the difference in performance. The comment provides specific suggestions for improvement, such as including steps vs PPL of linformer with YOSO in Figure 4 and analyzing the performance difference. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the lack of comparison results between YOSO and linformer in Figure 4, specifically regarding iterationwise convergence and accuracy in downstream tasks. The reviewer suggests that an explanation is needed to analyze the difference in performance. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the importance of these comparisons and the potential impact on the paper\"s conclusions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement in the paper, namely the lack of comparison results between YOSO and linformer in Figure 4. It suggests that the authors should include steps vs PPL of linformer with YOSO in Figure 4 and analyze the performance difference in downstream tasks, such as SST2. Additionally, it points out that linformer demonstrates better accuracy in downstream tasks, prompting the authors to provide an explanation for this difference in performance. While the comment is clear and actionable, it could be more helpful if it provided specific guidance on how to analyze the performance difference or suggested specific metrics to use. Overall, the feedback is valuable in directing the authors to enhance their experimental analysis and provide a more comprehensive comparison."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify the policy gradient and the phrases in question. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. However, the comment does not specify which part of the paper these issues are located in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, but without explicit references to sections or lines, the authors cannot confidently determine the exact parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect, which could be a significant contribution to the paper. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. While the comment identifies areas for improvement, it lacks specific guidance on how to address these issues or what specific clarifications are needed. The feedback is 3 as it highlights potential weaknesses and areas for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. While it does not explicitly instruct the authors to make a specific change or provide guidance on how to address this question, it does prompt the authors to consider the implications of these assumptions and the potential differences between them. The action is implicit but concrete, as the authors can infer that they need to explore the implications of these assumptions and potentially make a change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where these assumptions are discussed. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in its inquiry about the difference between these distributions, it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. While it highlights a potential area for clarification or consideration, it does not provide any guidance or suggestions on how the authors might address this issue or what the implications of these assumptions might be. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path forward. Therefore, it is rated as 2, as it identifies a potential area for improvement but does not offer sufficient guidance for the authors to make meaningful changes."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to discuss the limitations of freezing the partitioning in the first iteration, which seems like a risky choice. This feedback is clear and provides a specific action for the authors to take, which is to address the limitations of this choice. The comment is concrete because it specifies the need for a discussion on the limitations, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the risky choice of freezing the partitioning in the first iteration and the need to discuss its limitations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. The reviewer suggests that at least the limitations of this choice should be discussed. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors may understand the concern but would need to make a significant effort to address it without detailed guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of freezing the partitioning in the first iteration, noting that it makes strong assumptions about the coverage of the initial data. It suggests that the authors should discuss the limitations of this choice, which is a valuable point for the authors to consider. However, the comment could be more helpful if it provided examples or detailed guidance on how to address these limitations or what specific aspects of the choice should be discussed. While it highlights an important area for improvement, the feedback could be more actionable with additional details. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the intent of Section 5.2, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what the authors should do to address this question or how to clarify the intent of the section. Without any actionable suggestions or advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper, such as a specific section or figure, is being addressed. It lacks specificity because it does not provide any details on what the reviewer finds unclear or what needs to be clarified about the intent of Section 5.2. Without explicit references or detailed feedback, the authors cannot effectively identify the areas that need improvement. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question about the intent of Section 5.2, which does not contain any subjective claims, opinions, or suggestions. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the intent of Section 5.2, which is a valid point as it could be unclear or misleading. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might clarify or improve this section. Without actionable feedback or detailed feedback, the authors are left without a clear path forward. Therefore, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that many aspects of the approach need clarification and expresses concern about the lack of understanding regarding how the approach interacts with knowledge about verbs to overcome reporting bias. It acknowledges that the paper quickly dives into technical details without explaining the overall approach and its benefits. However, the comment does not provide specific guidance on what aspects need clarification or how to clarify them. It lacks concrete suggestions or examples of what the authors should focus on to improve the clarity of their approach. As a result, the authors are left without actionable steps to take in response to the feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights that many aspects of the approach need clarification and expresses concern about the lack of understanding regarding how the approach interacts with knowledge about verbs to overcome reporting bias. It mentions that the paper quickly dives into technical details without clearly explaining the overall approach and its benefits. However, the comment does not specify which parts of the paper need clarification or provide detailed comments on what is unclear. This makes it difficult for the authors to pinpoint the exact areas that need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that many aspects of the approach need clarification and expresses concern about the lack of understanding regarding how the approach interacts with knowledge about verbs to overcome reporting bias. The reviewer mentions that the paper quickly dives into technical details without clearly explaining the overall approach and its benefits. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the concern. The lack of specific examples or references makes the claim 3, as it requires more detailed justification to be fully understood and addressed by the authors.", "helpfulness_rationale": "The review comment identifies several areas where the paper needs clarification, specifically regarding the interaction between the approach and knowledge about verbs to overcome reporting bias. It highlights that the paper quickly dives into technical details without clearly explaining the overall approach and its benefits. This feedback is 3 as it points out a critical area that needs attention, but it lacks specific suggestions or guidance on how to clarify these aspects. The authors are given a direction to focus on but are not provided with actionable steps or detailed advice on how to improve the clarity of their approach. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly, including the attacker\"s level of access, capabilities, and the defender\"s available resources. It also recommends including this information in a dedicated section to enhance clarity. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be added or clarified in the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"threat model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, including the attacker\"s level of access, capabilities, and the defender\"s available resources. Additionally, it suggests including this information in a dedicated section to enhance clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly, including the attacker\"s level of access, capabilities, and the defender\"s available resources. The comment provides a logical reasoning for why this clarification is necessary, as it could enhance the clarity of the paper. However, it lacks specific examples or references to support the claim that this clarification would improve the paper. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further clarification, namely the threat model. It suggests that the authors should define the assumed threat model more explicitly, including the attacker\"s level of access, capabilities, and the defender\"s available resources. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the clarity and comprehensibility of their work. By addressing this suggestion, the authors can improve the understanding and applicability of their threat model, which is crucial for the overall robustness and credibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the paper\"s statement about classimbalanced tasks in the fewshot learning setting. It explicitly asks the authors to provide concrete details on how to set a reasonable classimbalanced task, given the few examples available for each class. This request is clear and specific, providing the authors with a direct action to take in order to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"sampling classimbalanced tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions how to set a reasonable classimbalanced task in the fewshot learning setting, given the limited number of examples per class. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the statement \"sampling classimbalanced tasks\" in the context of fewshot learning, where each class has only a few examples. The reviewer seeks clarification on how to set a reasonable classimbalanced task given the limited number of examples. This is a request for clarification rather than a claim or opinion, as it does not express an opinion or judgment. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s statement about classimbalanced tasks in the fewshot learning setting. It questions how to set a reasonable classimbalanced task given the limited number of examples per class. This feedback is 3 as it prompts the authors to clarify their approach to classimbalanced tasks, which is an important aspect of their work. However, the comment could be more helpful if it provided specific suggestions or examples of how to address this issue. Overall, the comment is 3 as it directs the authors to a critical area needing clarification, but it lacks depth and actionable guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of detail in the explanation of how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. It points out that the authors only state that they estimate a layer\"s sensitivity by pruning, but do not provide details on how the actual pruning was done. The comment implies that the authors should provide more information on the pruning process to clarify the methodology. While the action is implicit, it is clear and concrete, as it specifies the need for more detailed information on the pruning process. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detail on how the ground truth of sensitivity is achieved and the need for more information on the pruning process. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not provide sufficient detail on how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. The reviewer suggests that the authors should provide more information on the pruning process to clarify the methodology. However, the comment lacks specific examples or references to support the claim that the current explanation is insufficient. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of the critique. Therefore, the claim is 3, as it provides a general direction for improvement but lacks the necessary evidence or justification to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors do not provide sufficient detail on how the ground truth of sensitivity is achieved. It points out that the current explanation, which mentions pruning, lacks details on the actual pruning process. This feedback is clear and actionable, as it directs the authors to provide more information on the methodology to clarify the approach. However, the comment could be more helpful if it offered suggestions on how to present this additional information or what specific details should be included. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies specific parts of the text that could be written more clearly, such as line 97 regarding proper rotation matrices and line 105106 regarding the matrix being non positive semidefinite. It provides clear and concrete actions for the authors to take, such as explicitly explaining the concepts in these sections. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the text, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be clarified, such as the definition of a proper rotation matrix and the problem of the matrix being non positive semidefinite. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of requests for clarification regarding specific terms and concepts in the text. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific parts of the text that could be written more clearly, providing actionable feedback for the authors. By pointing out the lack of clarity in lines 97 and 105106, the comment guides the authors to explicitly explain the concepts of proper rotation matrices and the problem of the matrix being non positive semidefinite. This detailed feedback is valuable as it helps the authors improve the clarity and comprehensibility of their draft, which is essential for effective communication of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it might be more appropriate to refer to the g activation function as a binary operator, similar to Cohen and Shashua (2016). It provides a specific example of the activationpooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This feedback is explicit and provides a concrete suggestion for how the authors might improve their draft by changing the terminology. The action is clear and specific, leaving no ambiguity about what the authors need to do to address the comment. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to consider referring to the g activation function as a binary operator, similar to Cohen and Shashua (2016). The comment also references the activationpooling operator introduced by Cohen and Shashua, which helps clarify the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it might be more appropriate to refer to the g activation function as a binary operator, similar to Cohen and Shashua (2016). The reviewer provides a specific example of the activationpooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This reference provides a logical basis for the suggestion, making the claim 3. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion to consider referring to the g activation function as a binary operator, similar to Cohen and Shashua (2016). It offers a clear and actionable piece of feedback by providing a concrete example of the activationpooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This feedback is valuable as it helps the authors improve the clarity and consistency of their terminology, potentially enhancing the readability and comprehensibility of their paper. However, the comment could be more helpful if it explained why this change might be beneficial or how it would impact the paper\"s overall message. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors consider shrinking the captions of Fig. 1 and Fig. 2 to leave more space for their methods or related work. This is a clear and direct action that the authors can take to improve the presentation of their figures. The comment provides a specific suggestion for how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1\" and \"Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the captions, suggesting that they should be shrunk to leave more space for the authors\" methods or related work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the captions of Fig. 1 and Fig. 2 have large overlaps with the content, and it provides a specific suggestion to shrink the captions to leave more space for the authors\" methods or related work. This claim is 3 as it logically suggests a way to improve the presentation of the figures, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors might need to experiment with different caption sizes to determine the optimal size for their purposes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the captions of Fig. 1 and Fig. 2, noting that they have large overlaps with the content. It provides a clear and actionable suggestion to shrink the captions to leave more space for the authors\" methods or related work. This feedback is valuable as it directs the authors to a specific area that could be improved, offering a concrete way to enhance the clarity and presentation of their figures. However, the comment could be more helpful if it included examples of how the captions could be revised or if it explained why this change would be beneficial. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. It suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. While the comment implies that the authors should consider including Vidgen et al, 2021, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add this work as a benchmark. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the inclusion of several works but the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. The comment suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. The comment suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. However, the comment does not provide specific reasoning or evidence to support why Vidgen et al, 2021, should be included as a benchmark. The absence of detailed justification or references makes the claim 3, as the authors would need to infer the importance of including Vidgen et al, 2021, based on the suggestion alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. It suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. This feedback is 3 as it points out a potential oversight in the paper and provides a suggestion for improvement. However, the comment could be more helpful if it offered additional context or justification for why Vidgen et al, 2021, should be included as a benchmark. Overall, the comment provides some guidance but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed approach is merely learning a surrogate model for solving linear/linearized systems arising in FEM, and it points out that the method still requires careful selection of basis functions and meshes. It also mentions that the method heavily relies on FEniCS, which is a specific solver. The reviewer acknowledges that current operator learning methods are not as accurate as specialized numerical solvers but suggests that they are more universal and do not need to be adapted to specific PDEs. While the comment identifies a potential issue with the approach, it does not provide explicit guidance on how to address it or improve the method. The authors are left to infer that they need to consider the limitations of their approach and explore ways to enhance its universality. Therefore, the comment is 3, as it implies a need for further development but lacks concrete details on how to achieve it.", "grounding_specificity_rationale": "The comment critiques the proposed approach for learning a surrogate model for solving linear/linearized systems arising in FEM, and it points out that the method still requires careful selection of basis functions and meshes. It also mentions that the method heavily relies on FEniCS, a specific solver. While the comment provides specific examples of the limitations of the approach, it does not explicitly mention which part of the paper these issues are discussed in. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point claims that the proposed approach is merely learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful selection of basis functions and meshes. It also notes that the method heavily relies on FEniCS, a specific solver. The reviewer acknowledges that current operator learning methods are not as accurate as specialized numerical solvers but suggests that they are more universal and do not need to be adapted to specific PDEs. While the comment provides some logical reasoning and references to specific solvers, it lacks detailed evidence or examples to fully substantiate the claim about the universality of operator learning methods. Therefore, the comment is 3, as it provides a reasonable basis for the claim but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential limitation in the proposed approach, noting that it is merely learning a surrogate model for solving linear/linearized systems arising in FEM. It highlights the need for careful selection of basis functions and meshes and points out that the method heavily relies on FEniCS, a specific solver. The comment acknowledges that current operator learning methods are not as accurate as specialized numerical solvers but suggests that they are more universal and do not need to be adapted to specific PDEs. While the comment provides some insight into the limitations of the approach, it lacks specific suggestions or guidance on how the authors might address these issues or improve their method. The feedback is 3 as it points out a potential weakness but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the authors\" judgement about the lack of immediate societal impact and notes that using fully realistic datasets can make it difficult to control multiple aspects of variation with precision. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this issue or improve their draft. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the issue of controlling multiple aspects of variation with precision in the context of fully realistic datasets. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its agreement with the authors\" judgement about the lack of immediate societal impact, but it does not provide further details or suggestions on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the authors\" judgement about the lack of immediate societal impact and notes that using fully realistic datasets can make it difficult to control multiple aspects of variation with precision. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the authors\" judgement about the lack of immediate societal impact and notes that using fully realistic datasets can make it difficult to control multiple aspects of variation with precision. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their draft. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path forward. Therefore, it is rated as 2, as it identifies a potential challenge but does not offer meaningful assistance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It also points out that the expression \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" was used in a previous work. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and actionable, giving the authors a clear path to enhance the clarity and comparability of their results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (078079 and Line 08), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the mention of the evaluation metric and the expression \"labelled Fmeasure scores (LF1) (including ROOT arcs),\" which was used in a previous work. This provides clear guidance on what needs to be clarified or improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It also points out that the expression \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" was used in a previous work. While the comment provides a logical reasoning for why clarity is needed, it lacks specific references or examples to fully substantiate the claim. The suggestion is 3, as it provides a clear rationale but could be strengthened with more detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It also points out that the expression \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" was used in a previous work, which is relevant to the clarity and understanding of the results reported in this paper. This feedback is specific and offers a concrete suggestion for improving the clarity and comprehensiveness of the paper. By addressing these points, the authors can enhance the transparency and reproducibility of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the behavior of the model under higher noise levels, as the standard deviation of the noise in the simulation study is stated as 3 but appears to be too low based on observations. While the comment implies that the authors should conduct additional simulations with higher noise levels, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the behavior of the model under higher noise levels. The comment provides a clear suggestion to study the model\"s behavior under higher noise, which is a concrete action for the authors to take. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the standard deviation of the noise in the simulation study is too low, based on observations compared to the true trajectories. However, the comment does not provide specific evidence or examples to support this claim, such as data or comparisons to other studies. Without detailed reasoning or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the standard deviation of the noise in the simulation study, suggesting that it may be too low based on observations compared to the true trajectories. It provides a clear and actionable suggestion for the authors to study the behavior of the model under higher noise levels. This feedback is valuable as it points out a specific area for improvement and offers a concrete direction for the authors to explore. However, the comment could be more helpful if it provided additional context or examples of how the authors might conduct these additional simulations. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the bounds having o(1) terms and suggests that this could limit the applications of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps the authors should consider to ensure the applicability of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the bounds of the approach, specifically mentioning the o(1) terms and the improvement over previously known results for arbitrarily long inputs. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the potential limitation of the approach due to the o(1) terms, but it does not provide details on how this limitation affects the applicability of the approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bounds of the approach have o(1) terms and that this could limit the applicability of the approach. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the approach, specifically the use of o(1) terms in the bounds. It raises a concern about the applicability of the approach due to the potential size of inputs required for the approach to be effective. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what specific aspects of the approach might be problematic. While it highlights an important consideration, the feedback does not provide actionable steps for the authors to improve their draft. Therefore, the comment is 3, as it points out a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to conduct this analysis or what specific aspects of DVP performance should be explored. As a result, the authors are left without any clear direction on how to address the comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it does not specify which part of the paper this observation pertains to, such as a specific section, table, or figure. Additionally, it lacks specificity regarding what aspects of DVP performance should be explored or how the authors should conduct this analysis. Without explicit references or detailed guidance, the authors cannot confidently determine which parts of the paper need attention. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses interest in seeing how DVP performs on videos with different lengths. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual observation or request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it lacks any specific guidance or suggestions for the authors to explore this topic or how to conduct the analysis. Without actionable feedback or detailed instructions, the comment does not provide much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. It acknowledges that the clarification is provided in the conclusion but does not specify how the authors should address this issue. The comment lacks explicit guidance on how to clarify the target or what specific changes should be made to improve the clarity. As a result, the authors are left without clear instructions on how to improve the draft in this area. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. However, it does not specify which part of the paper this confusion is related to, such as a specific section or figure. The authors can infer that it relates to the introduction or methodology sections, but this inference is not direct. The comment is specific in detailing the confusion about the target, but it lacks grounding as it does not explicitly mention where this issue is discussed in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. The reviewer acknowledges that the clarification is provided in the conclusion but does not specify how this affects the paper\"s focus or what the implications are. The comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand the basis of the confusion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. It acknowledges that the clarification is provided in the conclusion but does not specify how this affects the paper\"s focus or what the implications are. While the comment identifies a potential area of confusion, it lacks depth and does not provide actionable suggestions or guidance on how the authors might clarify this aspect in their draft. The feedback is 3 as it points out a potential issue, but it does not offer a clear path for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to evaluate the approximation error in the proposed training objective by calculating the actual KLdivergence and checking whether it approaches zero. It provides a clear and concrete action for the authors to take, specifying the exact calculation that needs to be performed. This level of detail makes the comment 5, as the authors know exactly what steps to take to address the issue. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely evaluating the approximation error in the proposed training objective by calculating the actual KLdivergence and checking whether it approaches zero. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed training objective has ignored the KLdivergence term in equation (3) and suggests evaluating the approximation error by calculating the actual KLdivergence. The comment provides a specific suggestion for improvement by asking the authors to check whether the approximation error approaches zero. However, the comment lacks detailed reasoning or references to support why this evaluation is necessary or how it would impact the results. This makes the claim 3, as the authors would need to make a significant effort to understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed training objective, noting that it has ignored the KLdivergence term in equation (3). It provides a clear and actionable suggestion by asking the authors to evaluate the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. This feedback is valuable as it directs the authors to a specific area that needs attention and provides a concrete step for improvement. However, the comment could be more helpful if it explained why this evaluation is important or how it might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, it does not provide explicit guidance on how to address these issues or what specific changes should be made to improve the connection or depth of the analysis. The comment implies that the authors should make improvements, but it lacks concrete details on how to implement these changes. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, it does not specify which part of Section 2 is lacking a connection or how the theoretical analysis could be improved. The authors can infer that the comment relates to the theoretical analysis and its connection to the methodology section, but this inference is not direct. The comment is specific in identifying the issue of a lack of connection and the need for more depth in the theoretical analysis, but it is 1 as it does not explicitly mention the sections being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or references, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the connection between Section 2 and the methodology section, noting that the theoretical analysis appears simplistic and closely related to a specific reference. This feedback is 3 as it points out a potential weakness in the paper, but it lacks depth and does not provide specific suggestions on how to address the issue or improve the connection between sections. The comment could be more helpful if it offered guidance on how to enhance the theoretical analysis or suggested ways to differentiate it from the reference. Overall, the comment provides some insight but lacks actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should further discuss the situations in which the losses help, particularly in specular areas. While the comment implies that the authors should provide more information about the effectiveness of the losses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the effectiveness of the losses in specific situations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing the situations in which the losses help, particularly in specular areas. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or figure. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting a particular area for further discussion, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the losses discussed in the paper might be particularly helpful in specular areas. However, it does not provide any evidence, examples, or references to support this claim. The comment lacks specific reasoning or data to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should further discuss the situations in which the losses help, particularly in specular areas. This feedback is 3 as it identifies a potential area for improvement by encouraging the authors to provide more detailed information about the effectiveness of their losses. However, the comment lacks specific guidance on how to implement this discussion or what aspects of the losses should be highlighted. While it points out a potential gap in the paper, it does not offer actionable steps for the authors to address this issue. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks clarity regarding its major contributions, specifically mentioning that analyzing previous work does not constitute a contribution. However, it does not provide any explicit or implicit suggestions on how the authors might clarify or enhance their contributions. There is no guidance on what aspects of the paper should be emphasized or how the authors might present their contributions more effectively. As a result, the comment is 1, as it does not offer any actionable steps for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"major contributions\" of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the paper\"s contributions and the misconception that analyzing previous work constitutes a contribution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding its major contributions, specifically mentioning that analyzing previous work does not constitute a contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the major contributions are unclear and that analyzing previous work does not constitute a contribution. This is a critical observation that can help the authors clarify their contributions and ensure that their work is properly positioned in the literature. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as by highlighting the novel aspects of their work or providing examples of how they build upon previous research. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks whether the code will be publicly available. While the comment implies that the authors should make the code available, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make the code available to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the difficulty in reproducing the results and asks about the availability of the code. However, it does not specify which part of the paper this issue pertains to, such as the results section or the methodology. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts need attention. The comment is specific in its request for the code to be publicly available, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks about the availability of the code. However, it does not provide any supporting evidence, reasoning, or examples to justify why the results are difficult to reproduce or why the code should be made publicly available. Without additional context or explanation, the claim lacks verifiability, making it challenging for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the difficulty in reproducing the results and questions the availability of the code. While it identifies a potential issue with reproducibility, it does not provide specific guidance or suggestions on how to address this problem or improve the transparency of the code. The comment lacks depth and actionable advice, leaving the authors without clear steps to take in response to the feedback. Therefore, the comment is 2, as it points out a potential problem but does not offer concrete guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. While the comment implies that the authors should consider this extension, it does not provide explicit instructions or detailed guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should consider this extension and determine how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to extend the protected feature to a vector form, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this extension would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. This is a 3 suggestion as it could potentially enhance the paper\"s contribution by allowing for more comprehensive analysis and interpretation of the data. However, the comment lacks specific guidance on how to implement this extension or what benefits it might bring to the paper. Without further explanation or examples, the authors may find it challenging to fully understand and act upon the suggestion. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests that the reviewer should denote the vector representations of the words in the equation and whether they are L2normalized. Additionally, it asks for clarification on whether the nearest neighbor examples are computed using cosine or dotproduct. These questions are direct and specific, providing clear guidance on how the authors can improve their draft. The action is explicit and the authors know exactly what needs to be done to address the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223\" and \"following ones,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including denoting the vector representations of the words, whether the vectors are L2normalized, and the method used for computing nearest neighbor examples. This level of detail provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about specific aspects of the paper, such as the notation used for vector representations and the method for computing nearest neighbor examples. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas for clarification and improvement in the paper. It points out that the notation for vector representations of words is not clearly defined and suggests that the authors denote these somehow. Additionally, it asks whether the vectors are L2normalized and whether the nearest neighbor examples are computed using cosine or dotproduct. These questions provide the authors with actionable steps to improve the clarity and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to denote the vector representations or provided examples of how this could be done. Overall, the feedback is valuable but could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to check Figure 2, Line 433, and Line 468 for issues with ending punctuation in equations. It also explicitly states that the authors should ensure consistency in the punctuation. This feedback is clear and provides concrete guidance on what to check and how to correct it. The action is direct and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2, Line 433, and Line 468,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the ending punctuation in equations, instructing the authors to ensure consistency. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification regarding the ending punctuation in equations in Figure 2. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a minor issue with the punctuation in Figure 2, specifically mentioning lines 433 and 468. It provides clear and actionable feedback by instructing the authors to ensure consistency in the ending punctuation of equations. This is a specific and relevant point that can help the authors improve the clarity and accuracy of their figures. However, the comment could be more helpful if it explained why this consistency is important or provided examples of how to achieve it. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that the method proposed in the paper, $kNNECD$, is similar to $kNNMT$, which limits the technical contribution of the paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their draft. There is no guidance on how to differentiate the method or what specific aspects need to be improved to enhance the technical contribution. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the method proposed in the paper, $kNNECD$, is similar to $kNNMT$, which limits the technical contribution of the paper. However, it does not specify which part of the paper discusses $kNNECD$ or $kNNMT$, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the similarity should be addressed or how the authors might differentiate their method. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the method proposed in the paper, $kNNECD$, is similar to $kNNMT$, which limits the technical contribution of the paper. However, the comment does not provide any specific examples, comparisons, or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the method proposed in the paper, $kNNECD$, is similar to $kNNMT$, which limits the technical contribution of the paper. However, it does not provide any specific guidance or suggestions on how the authors might differentiate their method or what aspects of the similarity should be addressed. Without actionable feedback or detailed reasoning, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if they are artificially generated, the authors should conduct realworld experiments to support the phenomenon occurring in these figures. This feedback implies that the authors should conduct additional experiments to validate their method, providing a clear action for the authors to take. However, the comment does not specify which experiments should be conducted or how to conduct them, leaving some details vague. Therefore, the comment is 4, as it provides a clear direction but lacks concrete guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially, and suggests conducting realworld experiments to support the phenomenon occurring in these figures. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if they are artificially generated, the authors should conduct realworld experiments to support the phenomenon occurring in these figures. This claim is 3 as it logically suggests that realworld experiments could provide additional validation for the method. However, the comment lacks specific examples or references to support the need for such experiments, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon occurring in these figures. This feedback is valuable as it highlights a potential gap in the paper\"s validation and suggests a way to enhance the methodology by including realworld experiments. However, the comment could be more helpful if it provided specific guidance on which experiments to conduct or how to conduct them. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear direction for the authors to enhance their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a concern about the assumption among classes not being practical, but it does not provide any explicit or implicit actions for the authors to take. It mentions that the formulation or definition is trivial but suggests that the optimization and theoretical property analysis could provide insights. However, without specific guidance on how to address this issue or what aspects of the optimization or theoretical property analysis should be emphasized, the authors are left without clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption among classes and the formulation or definition in the manuscript, but it does not specify which part of the paper this pertains to, such as a particular section or figure. The authors can infer that it relates to the theoretical analysis or optimization sections, but this inference is not direct. The comment is specific in its critique of the assumption and the potential for insights from optimization and theoretical property analysis, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption among classes is not practical, but it does not provide any supporting evidence or reasoning to substantiate this claim. The comment suggests that the formulation or definition is trivial, but it lacks specific examples or references to support the claim that optimization and theoretical property analysis could provide insights. Without detailed justification or examples, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption among classes, noting that it is not practical. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment mentions that the formulation or definition is trivial but does not elaborate on what aspects of the optimization or theoretical property analysis could be improved or how the authors might enhance these aspects. Without actionable feedback or detailed suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the evaluation results in Table 1 are based on only three trials for each case, which is not statistically significant. It suggests that the deviations reported are not meaningful and that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense due to this limitation. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the evaluation or the claims made in the paper. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the statistical significance of their results and potentially revise their claims accordingly. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation results, noting that the three trials per case are not statistically significant and that the deviations reported are not meaningful. The comment further explains why this issue affects the validity of claims like \"our performance is at least two standard deviations better than the next best baseline,\" providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation results in Table 1 are based on only three trials per case, which is not statistically significant. It suggests that the deviations reported are not meaningful and that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense due to this limitation. The comment provides a logical reasoning by pointing out the statistical insignificance of the results and the implications for the claims made in the paper. However, it could be strengthened by providing specific references or examples to support the statistical significance threshold or by explaining why three trials are insufficient. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation results reported in Table 1, noting that the three trials per case are not statistically significant. This observation is crucial as it highlights a potential flaw in the methodology, which could undermine the validity of the claims made in the paper. The comment also points out that the deviations reported are often zero, which further questions the significance of the results. By drawing attention to this issue, the comment provides the authors with valuable feedback on how to strengthen their evaluation and ensure the robustness of their claims. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as recommending a more robust evaluation method or suggesting a minimum number of trials needed for statistical significance. Overall, the comment is 4 as it identifies a critical weakness in the evaluation and provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the feature comparison with prior work is shallow and mentions the absence of two relevant papers. However, it does not provide specific guidance on which papers should be included or how to improve the depth of the feature comparison. The authors are left to infer that they need to include these papers, but without concrete instructions or examples, the action remains vague. Therefore, this comment is 3, as it identifies an issue but lacks detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment explicitly mentions the feature comparison with prior work, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the shallow comparison and the absence of two relevant papers. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the feature comparison with prior work is \"shallow\" and mentions the absence of two relevant papers. However, it does not provide specific details about which papers are missing or how they would enhance the comparison. Without these details, the claim lacks sufficient evidence or justification to be 5. The authors would need to infer the relevance of the missing papers and determine how they could improve the comparison. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the shallow feature comparison with prior work and the absence of two relevant papers. This feedback is clear and actionable, as it points out a gap in the literature review that the authors can address to enhance the depth and relevance of their analysis. However, the comment could be more helpful if it provided the names or titles of the missing papers, which would guide the authors in their literature search. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses a lack of understanding regarding the effectiveness of the multiview clustering approach and questions the usefulness of the other views. It highlights the dominance of the paraphrase similarity view and suggests that there is a need for a more detailed analysis of the differences and similarities between the views. However, the comment does not provide explicit guidance on how to conduct this analysis or what specific aspects should be explored. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed analysis of the views. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the effectiveness of the multiview clustering approach and questions the usefulness of the other views. It highlights the dominance of the paraphrase similarity view and suggests a need for a more detailed analysis of the differences and similarities between the views. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its critique of the lack of detailed analysis and the need for more comprehensive exploration of the views. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the effectiveness of the multiview clustering approach and highlights the dominance of the paraphrase similarity view over other views. It suggests that the analysis of the different views is insufficient and lacks detailed exploration of their differences and similarities. The comment provides a logical reasoning for the need for a more comprehensive analysis, but it does not provide specific examples or references to support the claim. This makes the claim 3, as it requires the authors to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of understanding regarding the effectiveness of the multiview clustering approach. It points out that the paraphrase similarity view consistently outperforms other views and their combinations, which raises questions about the usefulness of the other views. The comment highlights the need for a more detailed analysis of the differences and similarities between the views, suggesting that this would help draw solid conclusions about their effectiveness. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide detailed preliminary experimental results on Wikipedia regarding the model size, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. This feedback implies that the authors should include these results to support their claims about model size and performance. However, the comment does not explicitly instruct the authors to include these results or provide specific guidance on how to present them. While the action is implied, it is not as clear as it could be, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide detailed preliminary experimental results on Wikipedia regarding the model size, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental results or analysis sections, but this inference is not direct. The comment is specific in suggesting the inclusion of detailed results, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that increasing the model size can hurt performance, citing a recent paper by Ni et al. that demonstrates the scaling law applies to dense retrieval models. However, the comment does not provide specific details or references from the Ni et al. paper to support this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is 3, as it provides a logical reasoning but lacks sufficient evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the authors\" argument regarding the impact of model size on performance. It suggests that the authors should provide detailed preliminary experimental results on Wikipedia to support their claims, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. This feedback is 3 as it points out a specific area for improvement and provides a direction for the authors to explore. However, the comment could be more helpful if it offered additional guidance on how to present these results or what specific aspects to focus on. Overall, the comment provides a clear direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies specific aspects of the presentation quality that are considered weaknesses, such as the figures, tables, and the management of figures and tables. It provides a detailed list of examples, including the use of a \"Dataset\" column in tables that is not informative, the \"*\" appearing in Table 1 without indication of meaning, and the management of Fig 3 and Table 2. While the comment highlights these issues, it does not provide explicit guidance on how to address them or suggest specific improvements. The authors are left to infer that they need to improve the presentation quality, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures and tables, such as Figs 1&2, Table 1, and Table 2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with these figures and tables, such as the use of a \"Dataset\" column in tables that is not informative, the \"*\" appearing in Table 1 without indication of meaning, and the management of Fig 3 and Table 2. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the presentation quality of the paper is a weakness, specifically mentioning examples such as Figs 1&2, tables with a \"\" for the method, the \"Dataset\" columns in the tables being uninformative, and the management of Fig 3 and Table 2. The reviewer also points out the use of a \"*\" in Table 1 without indication of meaning. While the comment provides specific examples, it lacks detailed reasoning or references to support why these issues are considered weaknesses for a highquality publication like NeurIPS. The authors would need to infer the significance of these issues and address them accordingly. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies specific areas of the presentation quality that are considered weaknesses, such as the use of a \"Dataset\" column in tables that is not informative, the \"*\" appearing in Table 1 without indication of meaning, and the management of Fig 3 and Table 2. It also mentions Figs 1&2 as examples of issues that need attention. While the comment provides a detailed list of examples, it lacks actionable suggestions or guidance on how the authors might address these weaknesses. The feedback highlights areas for improvement but does not offer specific steps or advice on how to improve the presentation quality. Therefore, the comment is 3, as it identifies weaknesses but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include related experiments to demonstrate the utility of the information axis tool. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment 3. The authors can infer that they need to conduct additional experiments, but the lack of explicit instruction makes it somewhat vague.", "grounding_specificity_rationale": "The comment suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the conclusion or discussion, but this inference is not direct. The comment is specific in suggesting the need for related experiments, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not provide any specific examples or references to support this claim. The comment is based on a logical assumption that additional experiments would be beneficial, but it lacks the necessary evidence or reasoning to fully substantiate the claim. As a result, the comment is considered 2, as it provides a suggestion but lacks the necessary detail to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. This feedback is 3 as it identifies a potential area for improvement by suggesting that the authors include additional experiments to validate their claims. However, the comment lacks specific guidance on which experiments to conduct or how to integrate them into the paper. While it points out a potential gap in the paper, it does not provide detailed suggestions or examples to help the authors address this issue effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should consider multiple trucks and drones, which is described as a more interesting and practical setting. However, it does not provide explicit instructions or concrete steps on how to extend the analysis to multiple trucks and drones. The authors are left to infer that they should consider this extension, but without specific guidance on how to implement it, the action remains vague. Therefore, the comment is 3, as it implies an action but lacks concrete details on how to execute it.", "grounding_specificity_rationale": "The comment suggests that the paper should consider multiple trucks and drones, which is a suggestion for extending the analysis. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or results section. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The suggestion is specific in terms of what needs to be addressed, which is the consideration of multiple trucks and drones. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 2, as it lacks sufficient justification to fully support the suggestion.", "helpfulness_rationale": "The review comment suggests that the paper should consider multiple trucks and drones, which is described as a more interesting and practical setting. This feedback is 3 as it identifies an area for potential expansion and improvement in the paper. However, it lacks specific guidance or suggestions on how to implement this change or what specific benefits it might bring. While it points out a potential enhancement, the comment could be more helpful if it provided more detailed advice on how to incorporate multiple trucks and drones into the analysis. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the proposed approach to pretraining lacks novelty because it follows the strategies used in ELECTRA. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or make their approach more novel. There is no guidance on potential modifications, alternative approaches, or additional research directions that could be explored. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the proposed approach to pretraining, specifically mentioning that it follows the strategies used in ELECTRA. However, it does not specify which part of the paper discusses this approach, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the lack of novelty, but it lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed approach to pretraining lacks novelty because it follows the strategies used in ELECTRA. However, the comment does not provide any specific examples or references to the strategies used in ELECTRA, nor does it explain how the proposed approach is similar or different from those used in ELECTRA. Without detailed comparisons or references, the claim is difficult for the authors to verify or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation in the novelty of the proposed approach to pretraining, noting that it follows the strategies used in ELECTRA. While this observation highlights a potential issue, it does not provide specific guidance or suggestions on how the authors might address this limitation or differentiate their approach from existing work. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path forward to enhance the originality or impact of their work. Therefore, the comment is rated as 2, as it identifies a weakness but does not offer meaningful guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of motivation or need for the Newton algorithm in section 4, suggesting that it is a 1dimensional line search on a convex function. It also points out that even a basic bisecting line search will converge linearly, questioning the impact of quadratic convergence on runtime. The reviewer suggests that experiments along these lines would help motivate the need for the analysis/algorithm. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is concrete but inferred, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of motivation or need for the Newton algorithm and the suggestion to conduct experiments to motivate the analysis/algorithm. The comment provides a clear direction for improvement by suggesting experiments to demonstrate the impact of the algorithm on runtime. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the need for the Newton algorithm in section 4, suggesting that it is a 1dimensional line search on a convex function and that even a basic bisecting line search will converge linearly. The reviewer argues that while quadratic convergence is better than linear convergence, the impact on runtime is unclear. The comment provides a logical reasoning for why the Newton algorithm might not be necessary, but it lacks specific examples or references to support the claim about the impact on runtime. This makes the claim 3, as the authors would need to conduct their own experiments to fully understand the impact. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the motivation and need for the Newton algorithm in section 4, suggesting that it is a 1dimensional line search on a convex function. It questions the significance of the analysis/algorithm, noting that even a basic bisecting line search will converge linearly. The reviewer further suggests that while quadratic convergence is better than linear convergence, the impact on runtime is unclear. The comment provides a clear and actionable suggestion for the authors to conduct experiments to demonstrate the impact of the algorithm on runtime, which could help motivate the need for the analysis/algorithm. This feedback is 4 as it guides the authors to a specific area for improvement and offers a concrete step to enhance the clarity and relevance of their work. However, it could be more helpful if it provided additional guidance on how to design and conduct these experiments. Overall, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with Equation 8, specifically that subtracting s from the dynamic information in the LSTM module could result in the loss of some dynamic information. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the equation. The comment lacks actionable details, such as suggesting alternative approaches or methods to mitigate the loss of dynamic information. As a result, the authors are left without a clear understanding of how to proceed with this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the equation, noting that subtracting s from the dynamic information could result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that subtracting s from the dynamic information in Equation 8 could result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with Equation 8, specifically noting that subtracting s from the dynamic information in the LSTM module could result in the loss of some dynamic information. This is a valuable observation that could help the authors improve the clarity and accuracy of their equations. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending alternative approaches or methods to mitigate the loss of dynamic information. While it points out a potential problem, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses two questions about the impact of the number of MC samples and the network structure on performance. While it does not explicitly instruct the authors to conduct experiments or provide specific guidance on how to address these questions, the questions themselves are clear and actionable. The authors can infer that they need to conduct experiments to investigate the effect of these factors on performance and potentially include this analysis in their paper. Therefore, the comment is 3, as it provides a clear direction for the authors to follow but lacks explicit instructions.", "grounding_specificity_rationale": "The comment raises two questions about the impact of the number of MC samples and the network structure on performance, but it does not specify which part of the paper these questions pertain to. The authors cannot confidently determine whether these questions are related to specific sections, such as the methodology or results sections, making the comment weakly grounded. However, the questions themselves are specific, as they ask for empirical evidence and an analysis of the network structure. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions asking for empirical evidence and analysis of the impact of the number of MC samples and network structure on performance. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises two important questions about the impact of the number of MC samples and the network structure on performance, prompting the authors to conduct empirical investigations. By asking for empirical evidence and analysis, the comment highlights areas where the authors could enhance their work by providing more detailed explanations and results. However, the comment does not offer specific guidance or suggestions on how to conduct these experiments or what specific aspects of the network structure should be analyzed. While it points out a potential gap in the paper, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the generalizability of the method to other domains and questions the selection of 21 event types from Freebase. It explicitly asks for clarification on how these event types are selected and what the coverage is on the 33 event types in the ACE data. This provides clear and direct actions for the authors to take, such as explaining the selection process and providing more details on the coverage. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2 line 262,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the selection of 21 event types from Freebase and asking about their coverage on the 33 event types in the ACE data. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the generalizability of the method to other domains and questions the selection of 21 event types from Freebase. It asks for clarification on how these event types are selected and what the coverage is on the 33 event types in the ACE data. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the selection process is problematic. The authors would need to make a significant effort to understand and address the concern, making the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the method to other domains, specifically questioning the selection of 21 event types from Freebase and their coverage on the 33 event types in the ACE data. This is an important point that could impact the applicability and robustness of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve the generalizability of their work. While it identifies a potential weakness, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that certain aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide any specific details or examples of what is unclear or poorly motivated, nor does it offer suggestions on how to clarify or improve these aspects. The comment lacks explicit guidance or concrete steps for the authors to take, leaving them without a clear understanding of what needs to be addressed or how to address it. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"w.r.t. to corpora and datasets,\" indicating that it pertains to the experimental setup. However, it does not specify which part of the paper this pertains to, such as a particular section or table where these aspects are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what is unclear or poorly motivated about the corpora and datasets, making it difficult for the authors to understand the exact issues that need to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"some aspects of the experimental setup were unclear or poorly motivated,\" specifically regarding corpora and datasets. However, it does not provide any specific examples or detailed reasoning to support this claim. Without specific examples or references, the authors may find it challenging to understand which aspects are unclear or poorly motivated. This lack of detailed justification makes the claim 1, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that certain aspects, such as corpora and datasets, are unclear or poorly motivated. However, it does not provide any details or examples of what is unclear or poorly motivated, nor does it offer suggestions on how to clarify or improve these aspects. Without specific guidance or actionable feedback, the authors are left without a clear understanding of what needs to be addressed or how to address it. Therefore, the comment is 2, as it points out a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the authors do not provide details on the size of each hourglass module. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the model size. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"size of the model\" and the \"hourglass modules,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of the model size to competing approaches and the details on the size of each hourglass module. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the authors do not provide details on the size of each hourglass module. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the paper\"s analysis or conclusions. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the size of the model in terms of depth or number of parameters, noting that the authors do not provide details on the size of each hourglass module. This feedback is clear and actionable, as it prompts the authors to include this information in their paper. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details to include. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that needs clarification."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the claim about treating climate emulation as a diagnostictype prediction is misleading because prior work, such as ClimateBench or ClimateSet, already does this. However, it does not provide explicit guidance on how the authors should address this issue or clarify their claim. The comment lacks concrete suggestions on how to improve the clarity or accuracy of the claim, leaving the authors uncertain about what specific actions to take. As a result, the comment is vague and lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about treating climate emulation as a diagnostictype prediction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is misleading about the claim, namely that prior work (e.g., ClimateBench or ClimateSet) already does this. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" claim about treating climate emulation as a diagnostictype prediction is misleading because prior work, such as ClimateBench or ClimateSet, already does this. However, the comment does not provide specific examples or references to these works, nor does it explain how the proposed PACE method differs from these existing approaches. Without detailed evidence or comparisons, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a misleading claim in the paper regarding the novelty of treating climate emulation as a diagnostictype prediction. It points out that prior work, such as ClimateBench or ClimateSet, already does this. This feedback is valuable as it highlights an inaccuracy in the paper\"s claims, which the authors can address to improve the clarity and credibility of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify or revise the claim to avoid misleading readers. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the metric learning theory in the paper is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or improve the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"metric learning theory\" and \"generalization theory of neural networks,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, it does not provide specific suggestions on how to address this issue or improve the results. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, the comment lacks specific references to the theoretical results or specific examples from the paper to support this claim. Without detailed evidence or references, the authors may find it challenging to verify the claim and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the metric learning theory is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. This is a clear and actionable observation that highlights a potential weakness in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it points out a problem, it does not offer detailed advice on how to resolve it, making it 3 but incomplete. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should move some visual results from the supplementary to the main paper. It also points out that there are almost no visual results on crowd density estimation, which is the main experiment of the paper. The reviewer suggests condensing the illustration of the proposed network architecture from three figures to two, and using the extra space for visual results. This feedback provides clear and concrete actions for the authors to take, such as selecting specific visual results to include and condensing the figures. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the main paper and the supplementary material, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that some visual results should be moved from the supplementary to the main paper, and it provides a specific suggestion to condense the illustration of the proposed network architecture from three figures to two. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that visual results should be moved from the supplementary to the main paper, as there are almost no visual results on crowd density estimation, which is the main experiment of the paper. The comment provides a logical reasoning by pointing out the lack of visual results in the main paper and suggesting that condensing the illustration of the proposed network architecture could make room for visual results. However, the comment lacks specific examples or references to support the claim that visual results are necessary or how they would enhance the paper. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors should move some visual results from the supplementary to the main paper. It highlights the lack of visual results on crowd density estimation, which is the main experiment of the paper, and recommends condensing the illustration of the proposed network architecture from three figures to two. This suggestion is clear and constructive, as it offers a concrete way for the authors to improve the presentation and clarity of their work. By addressing these points, the authors can enhance the reader\"s understanding and engagement with their research. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether a test example is crucially different, such as a patient being \"British\" versus \"American,\" and whether this can be detected using the corpus residual value. While the comment implies that the authors should consider this issue, it does not provide explicit guidance on how to address it or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should consider this aspect in their analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the detection of crucial differences in test examples, specifically mentioning the example of a patient being \"British\" versus \"American\" and using the corpus residual value. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this issue might be discussed. The authors can infer that it relates to the analysis or results section, but this inference is not direct. The comment is specific in its question about detecting crucial differences, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the detection of crucial differences in test examples, specifically mentioning the example of a patient being \"British\" versus \"American\" and using the corpus residual value. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that this issue cannot be detected with the corpus residual value. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a thoughtprovoking question about the detection of crucial differences in test examples, specifically considering the example of a patient being \"British\" versus \"American\" and using the corpus residual value. This question prompts the authors to consider a potential limitation in their analysis and encourages them to explore whether the corpus residual value can detect such differences. While the comment does not provide specific suggestions or guidance on how to address this issue, it does offer a valuable point for the authors to consider in their analysis. Therefore, the comment is 3, as it prompts the authors to think critically about their methodology and its limitations."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP for their testbed. It provides a rationale for this suggestion, noting that WebQuestions would be more intuitive and straightforward for the task at hand, and could facilitate direct comparison with mainstream QA research. While the comment explicitly states the action to take, it does not provide specific guidance on how to implement this change or what additional considerations might be necessary. The action is clear but lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"WebQuestionsSP\" dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of dataset, suggesting that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP for their testbed. The reviewer provides a logical reasoning by explaining that WebQuestions would be more intuitive and straightforward for the task at hand, and could facilitate direct comparison with mainstream QA research. However, the comment lacks specific references or examples to support the claim that WebQuestions is more suitable for the task. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3, as it requires further elaboration to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to consider using a more popular dataset, WebQuestions, instead of WebQuestionsSP for their testbed. It offers a logical reasoning that using WebQuestions would be more intuitive and straightforward, and could facilitate direct comparison with mainstream QA research. This feedback is valuable as it encourages the authors to make a change that could enhance the clarity and relevance of their work. However, the comment could be more helpful if it provided specific examples or references to support the claim that WebQuestions is a better choice. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the need for making claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It points out that a larger network may perform better without sparsity, and that any potential training speed increases or cost savings must be demonstrated. While the comment implies that the authors should provide evidence or examples to support their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence or examples to address the reviewer\"s concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It mentions that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. However, the comment does not specify which part of the paper these claims are made in, nor does it provide details on what specific evidence or demonstrations are needed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the claims and the need for evidence, but without explicit references to sections or examples, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. The reviewer provides a logical reasoning by pointing out that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. However, the comment lacks specific examples or references to support the claim that sparsity is not beneficial. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It points out that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. While the comment identifies a potential weakness in the paper\"s claims, it does not provide specific suggestions or guidance on how the authors might address this issue or present evidence to support their claims. The feedback is 3 as it highlights a potential area for improvement, but it lacks actionable advice or detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the novelty of the paper is limited due to the use of attention for motion learning, which is widely used in video understanding. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve the novelty of their work. There is no guidance on how to differentiate their design or what aspects could be improved to enhance novelty. As a result, the authors are left without any clear direction on how to respond to this feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of novelty in the paper, specifically mentioning that the design is not new due to the use of attention for motion learning, which is widely used in video understanding. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what aspect of novelty is lacking, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited due to the use of attention for motion learning, which is widely used in video understanding. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a limitation in the novelty of the paper, specifically noting that the design is not new due to the use of attention for motion learning, which is widely used in video understanding. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a discrepancy between how BigFive and MBTI are described in the abstract and introduction sections, where they are stated as models to be extended, while in the experiments, they are used as datasets. The reviewer suggests that it would be better to state them as datasets throughout the paper unless the authors provide an extended explanation for their use as models. This feedback is explicit and provides a clear action for the authors to take, which is to update the paper to reflect the correct usage of these models. The suggestion is concrete, as it specifies the exact change needed in the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Abstract\" and \"Introduction\" sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the discrepancy between how BigFive and MBTI are described in the abstract and introduction sections as models to be extended, versus their usage as datasets in the experiments. The comment provides a clear suggestion to correct this discrepancy by stating the models as datasets throughout the paper, unless there is a specific reason to extend the explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that BigFive and MBTI are stated as models to be extended in the abstract and introduction sections, while they are used as datasets in the experiments. The reviewer suggests that it would be better to state them as datasets throughout the paper unless there is a specific reason to extend the explanation. The comment is 3 as it provides a logical reasoning for the claim, suggesting that the authors should clarify the usage of these models. However, it lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between how BigFive and MBTI are described in the abstract and introduction sections, where they are stated as models to be extended, while in the experiments, they are used as datasets. The reviewer suggests that it would be more appropriate to state them as datasets throughout the paper, unless the authors provide an extended explanation for their use as models. This feedback is clear and actionable, as it guides the authors on how to clarify the usage of these models in the paper. By addressing this issue, the authors can improve the consistency and clarity of their paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include rejection rates or consider misclassifications as rejections in their experiments. This is a clear and direct action, as it specifies exactly what needs to be added or changed in the paper. The comment provides concrete guidance on how to implement the suggested changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rejection rate\" and \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of rejection rates or the consideration of misclassifications as rejections in the results. This provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the rejection rate is not shown in any experiments and suggests that one could view a misclassification as a rejection. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is an issue or how it affects the paper\"s conclusions. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the rejection rate is not shown in any experiments. It suggests that one could view a misclassification as a rejection, and recommends including rejection rates or considering misclassifications as rejections in the results. This feedback is clear and actionable, as it provides a direct and concrete suggestion for improvement. By addressing this point, the authors can enhance the transparency and completeness of their experimental results. However, the comment could be more helpful if it explained why the inclusion of rejection rates is important or how it would impact the interpretation of the results. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for the final thresholds used for the results and requests the sharing of the full set of hyperparameters. This provides clear and direct actions for the authors to take, ensuring they know exactly what information is needed to improve their draft. The request for the hyperparameters is specific, and the mention of reproducibility highlights the importance of sharing these details. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for the final thresholds used for the results and requests the sharing of the full set of hyperparameters. This allows the authors to accurately identify the parts of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what information is needed to improve the reproducibility of the results. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of requests for information, specifically asking for the final thresholds used for the results and the full set of hyperparameters. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is a factual request for clarification and does not fit the criteria for a claim.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by requesting the final thresholds used for the results and the full set of hyperparameters. This information is crucial for reproducibility and understanding the methodology. However, the comment could be more helpful if it provided guidance on how to present this information or why it is important for reproducibility. Despite this, the feedback is clear and actionable, which makes it 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential inconsistency in the authors\" claim regarding the readability of RC datasets and its impact on question difficulty. However, it does not provide any explicit or implicit actions for the authors to take. The comment implies that the authors should clarify their methodology or consider alternative methods for answer detection, but it does not specify how to do so or what specific changes should be made. Without concrete guidance or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the readability of RC datasets and its impact on question difficulty. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out the potential inconsistency in the authors\" claim and suggesting that it depends on the method/features used for answer detection. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim made by the authors regarding the readability of RC datasets and its impact on question difficulty. It suggests that the authors\" claim is dependent on the method/features used for answer detection, specifically mentioning POS/dependency parse features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the authors\" claim regarding the readability of RC datasets and its impact on question difficulty. It points out that the authors\" claim is dependent on the method/features used for answer detection, specifically mentioning POS/dependency parse features. This feedback is 3 as it highlights a potential weakness in the authors\" argument and suggests a direction for clarification or further exploration. However, the comment could be more helpful if it provided specific suggestions on how to address this inconsistency or how to better substantiate the claim. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly instructs the authors to optimize Figure 1 to use less whitespace. This is a clear and direct action, providing the authors with a specific task to improve the visual presentation of their data. The comment is concrete, as it specifies the exact change needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, optimizing the use of whitespace in Figure 1. This provides clear guidance on how to improve the visual presentation of the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests optimizing Figure 1 to use less whitespace. However, it does not provide any reasoning, evidence, or examples to support why this optimization is necessary or beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment provides a specific and actionable suggestion to optimize Figure 1 by using less whitespace. This feedback is clear and direct, giving the authors a concrete step to improve the visual presentation of their data. By addressing the issue of excessive whitespace, the authors can enhance the clarity and readability of their figure, which is a valuable improvement for the overall quality of their work. However, the comment could be more helpful if it included additional context or examples on how to achieve this optimization. Overall, the comment is 4 as it provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing quality of the paper needs improvement, specifically noting that the authors spend too much space on explaining basic memory networks and then the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should focus on improving the writing quality and expanding the related work section, but the comment lacks concrete details on how to achieve these improvements. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment suggests that the writing quality of the paper needs improvement, specifically mentioning the uneven distribution of space between explaining basic memory networks and the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. However, the comment does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in identifying the need for improvement in the writing quality and related work sections, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the writing quality of the paper needs improvement, specifically mentioning the uneven distribution of space between explaining basic memory networks and the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. However, the comment lacks specific examples or references to support the claim that the writing quality is poor or that the related work section is incomplete. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered 2, as it provides some indication but lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing quality of the paper, noting that the authors spend too much space on explaining basic memory networks and then the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. While the comment highlights areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. The authors are left to infer that they should focus on improving the writing quality and expanding the related work section, but the feedback does not provide actionable steps or examples. Therefore, the comment is 3, as it identifies areas for improvement but lacks depth and specificity to be fully beneficial for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of the recurrent model, suggesting that the sequential relationship might be easier to model. While the comment implies that the authors should explore these areas, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these areas to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should explore improvements in accuracy or specific properties. It provides an example of the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment does not specify which part of the paper discusses FLOPs or inference time, making it weakly grounded. The suggestion to explore accuracy or specific properties is specific, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should explore improvements in accuracy or specific properties. It provides an example of the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment lacks specific examples or references to support the claim that exploring accuracy or specific properties would lead to improvements. The suggestion is logical but lacks detailed evidence or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for the authors to consider if they did not find improvements in FLOPs or inference time. It suggests exploring improvements in accuracy or specific properties, offering an example of the recurrent model. This feedback is actionable and constructive, as it guides the authors to focus on areas that could lead to improvements in their work. However, the comment could be more helpful if it provided more detailed guidance on how to explore these areas or what specific properties to focus on. Overall, the comment is 4 as it offers a clear direction for the authors to enhance their draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the assumption that d_e are good replacements for entity embeddings was tested. While it implies that the authors should address this assumption, it does not explicitly instruct them to do so. The comment is 3 because it provides a clear direction for the authors to consider testing the assumption, but it lacks concrete guidance on how to conduct the test or what specific aspects to focus on. Therefore, the authors can infer that they need to test the assumption but may not be entirely sure of the exact steps to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the assumption that \"d_e are good replacements for entity embeddings,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks whether this assumption was tested and provides a clear direction for the authors to consider testing it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the assumption that \"d_e are good replacements for entity embeddings,\" suggesting that this assumption has not been tested. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption should be tested or how it might impact the paper\"s conclusions. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a critical question about the assumption that \"d_e are good replacements for entity embeddings,\" suggesting that this assumption has not been tested. This is an important point that could impact the validity and reliability of the paper\"s conclusions. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or what tests could be conducted to verify the assumption. While it identifies a potential weakness, it does not offer actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of the simulation should be considered. The comment lacks actionable details, such as recommending ways to categorize or analyze the different physical interactions, or suggesting methods for evaluating the simulation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what kind of physical interactions are being considered or how they might be categorized. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual inquiry, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation, which could be a relevant consideration for the authors. However, it lacks depth and does not provide any context or guidance on how this information might be relevant to the paper or what specific aspects of the simulation should be considered. Without further explanation or suggestions, the comment does not offer actionable feedback for the authors to improve their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a significant issue with the paper\"s model comparison, specifically the choice of datasets and the lack of categorical features. It points out that the paper claims a thorough comparison on a wide range of datasets but only includes one dataset with categorical features, which may affect the conclusions. Additionally, it notes that the authors do not employ one hot encoding for this dataset, which could negatively impact performance for some models. The comment provides explicit actions for the authors to take: to include more datasets with categorical features and to employ one hot encoding for the dataset with categorical features. These actions are concrete and specific, giving the authors clear guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Model Comparison\" and the \"wide range\" of datasets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the selection of datasets, noting that only one dataset has categorical features and that the authors do not employ one hot encoding for this dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model comparison is inadequate due to the selection of datasets, which only includes one with categorical features. The reviewer supports this claim by explaining that categorical features are generally more challenging for deep learning and that the lack of one hot encoding for this dataset could negatively affect performance. This reasoning is logical and based on common knowledge about feature types and their impact on model performance. However, the comment could be strengthened by providing specific examples or references to studies that support the claim about categorical features. Despite this, the claim is 4, as it provides a clear rationale for the critique.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s model comparison, specifically the choice of datasets and the lack of categorical features. It points out that the paper claims a thorough comparison on a wide range of datasets but only includes one dataset with categorical features, which may affect the conclusions. Additionally, it notes that the authors do not employ one hot encoding for this dataset, which could negatively impact performance for some models. This feedback is clear and actionable, as it provides specific guidance on how the authors can improve their model comparison by including more datasets with categorical features and employing one hot encoding for the dataset with categorical features. By addressing these points, the authors can significantly enhance the robustness and credibility of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment critiques the choice of two unpopular IoT datasets for benchmarking, suggesting that there should have been better options. It explicitly suggests alternative datasets, such as wearable health or mobile activity recognition data, or even some sets in UCI. While the comment provides a clear action\u2014to consider alternative datasets\u2014it does not specify which specific datasets should be used or how to integrate them into the paper. The authors are given a clear direction to explore alternative datasets, but the lack of detailed guidance on implementation makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of two unpopular IoT datasets for benchmarking and suggesting better options, such as wearable health or mobile activity recognition data. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the choice of two unpopular IoT datasets for benchmarking is a strange choice, as they are not widely followed or used recently. The reviewer supports this claim by referencing specific datasets (FlatCam Face and Headpose detection) and their publication dates, which provides some evidence for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of why these datasets are considered uncommon or less suitable for benchmarking. Despite this, the claim is 4 due to the reference to specific datasets and their dates, which provides a solid foundation for the authors to address the critique.", "helpfulness_rationale": "The review comment critiques the choice of two unpopular IoT datasets for benchmarking, suggesting that there should have been better options. It provides specific examples of alternative datasets, such as wearable health or mobile activity recognition data, or even some sets in UCI. This feedback is clear and actionable, as it guides the authors to consider more widely used datasets for benchmarking purposes. By suggesting alternative datasets, the comment offers a concrete way for the authors to improve the relevance and applicability of their benchmarking results. However, it could be more helpful if it provided additional context or rationale for why these alternative datasets are more suitable. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be further enhanced with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the annotations in Figure 4 could be enlarged for better visibility. While it implies that the authors should make the annotations larger, it does not provide specific guidance on how to achieve this or what size would be appropriate. The action is implicit and somewhat vague, as the authors need to infer that they should make the annotations larger but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the enlargement of annotations for better visibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the annotations in Figure 4 could be enlarged for better visibility. However, it does not provide any supporting evidence, reasoning, or examples to justify why the annotations are currently too small or how enlarging them would improve visibility. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the annotations in Figure 4 could be enlarged for better visibility. While it provides a specific suggestion for improvement, it lacks depth and does not explain why the current annotations are too small or how enlarging them would improve the figure. The comment could be more helpful if it included additional context or examples to guide the authors on how to implement this suggestion effectively. As it stands, the feedback is 3, as it points out a potential issue but does not fully support the authors in addressing it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the claim made in the paper regarding the existence of multiple entities in both sentences and documents, including relation classification. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific changes should be made to the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 2627,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the claim regarding the existence of multiple entities in both sentences and documents, including relation classification. The comment provides a clear critique of the claim and suggests that the authors should clarify or reconsider their statement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only documentlevel RE or joint entity and relation extraction.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the claim made in the paper regarding the existence of multiple entities in both sentences and documents, including relation classification. This is a relevant observation that could impact the validity of the paper\"s claims. However, the comment lacks specificity and does not provide any guidance on how the authors might address this issue or what changes could be made to strengthen their argument. Without actionable feedback or suggestions, the authors are left without a clear path forward. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with Figure 4, noting that one of the labels on the color bar should say \"worse\" instead of \"better.\" This comment provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be corrected. The action is concrete, as it specifies the exact label that needs to be changed, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the color bar, noting that one of the labels should say \"worse\" instead of \"better.\" This provides clear guidance on what needs to be corrected in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about a specific figure, Figure 4, noting that one of the labels on the color bar is incorrect. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that one of the labels on the color bar is incorrect. This is a clear and actionable piece of feedback that the authors can easily address to improve the accuracy and clarity of their visual presentation. However, the comment could be more helpful if it provided additional context or suggestions on how to correct the error or improve the figure overall. Despite this, the feedback is 4 as it directs the authors to a specific area needing attention."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out a specific error in the text, noting that \"training/validation/test\" should be \"training/validation/test sets.\" This is a clear and direct action for the authors to take, as it provides a specific correction to make in their draft. The comment is explicit and concrete, as it specifies exactly what needs to be changed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 757 in Supp. Page 29,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely, changing \"training/validation/test\" to \"training/validation/test sets.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual correction, noting a typographical error in the text. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific typographical error in the text, noting that \"training/validation/test\" should be \"training/validation/test sets.\" This is a clear and actionable suggestion that can help the authors improve the accuracy and clarity of their manuscript. By addressing this error, the authors can ensure that their paper is more precise and professional in its presentation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions and concerns about the paper, but it does not provide explicit or implicit actions for the authors to take. It asks for clarification on the inference process and the coefficient of the p(L, E | X) term in line 307, but it does not instruct the authors on how to address these questions or provide guidance on how to improve the clarity of the writing. The comment also mentions missing hyperparameter details and suggests that ablation studies may not be welltuned, but it does not provide specific suggestions for improvement. Overall, the comment lacks actionable guidance, leaving the authors uncertain about how to address the issues raised. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises several questions and concerns about the paper, but it does not specify which part of the paper these issues pertain to. It mentions \"line 307\" and \"hyperparameter details,\" but these references are not explicit enough to allow the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity in detailing what is unclear or missing in the paper, such as the exact nature of the inference process or the coefficient of the p(L, E | X) term. Without clear guidance on what needs to be addressed, the authors cannot effectively improve their draft. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises several questions and concerns about the paper, including the inference process, the coefficient of the p(L, E | X) term, and the clarity of the writing. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The questions are presented as observations without detailed explanation or justification, making it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several questions and concerns about the paper, including the inference process, the coefficient of the p(L, E | X) term, and the clarity of the writing. It points out that the writing is not careful and often impedes understanding, which is a valid observation. However, the comment lacks specific suggestions or guidance on how the authors might address these issues, such as providing more detailed explanations or clarifications. While it identifies areas for improvement, the feedback does not offer actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model by Dozat and Manning (2016) is no longer stateoftheart and recommends replacing it with a phrase like \"very high performing model\" or similar. This feedback provides a clear and explicit action for the authors to take, specifying the exact change needed to update the text. The suggestion is concrete, as it offers a specific alternative phrase to use, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the outdated nature of the model by Dozat and Manning (2016) and suggests replacing it with a more current description. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model by Dozat and Manning (2016) is no longer stateoftheart and recommends replacing it with a phrase like \"very high performing model\" or similar. However, the comment does not provide any supporting evidence, references, or reasoning to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the model by Dozat and Manning (2016) is no longer stateoftheart and recommends replacing it with a more appropriate description. This feedback is clear and actionable, as it provides a concrete suggestion for improving the accuracy and relevance of the paper. By addressing this issue, the authors can enhance the credibility and uptodate nature of their work. However, the comment could be more helpful if it included additional context or examples of alternative models that might be more appropriate. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is identified as the main weakness of the method. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the performance or suggestions for potential modifications to the method. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed compression\" and \"PQ,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue, noting that the proposed compression performs worse than PQ when a small code length is allowed, which is the main weakness of the method. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, which is identified as the main weakness of the method. However, the comment does not provide any supporting evidence, comparisons, or references to substantiate this claim. Without additional details or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is considered the main weakness of the method, which is important for the authors to address. However, the comment lacks depth and does not provide suggestions or guidance on how to improve the performance or address this issue. While it points out a critical area for improvement, it does not offer actionable steps or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including inappropriate subjective statements, the need for proofs and references to support claims, and the laborintensive nature of designing effective architectures. It also points out the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. The comment explicitly instructs the authors to provide a detailed explanation to verify these statements. While the action is clear, it is somewhat vague in terms of how to present the detailed explanation, leaving the authors to infer the specifics. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the paper, including inappropriate subjective statements, the need for proofs and references, and the laborintensive nature of designing effective architectures. It also mentions the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. However, the comment does not specify which part of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing a detailed explanation to verify the statements. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims and suggestions, including the need for proofs and references to support subjective statements, the laborintensive nature of designing effective architectures, and the uncertainty regarding when to fuse multiscale features. The reviewer also suggests that models with skip connections could be considered implicit multiscale methods. However, the comment lacks specific examples or references to substantiate these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or reasoning makes the claims 3, as the authors would need to make a significant effort to understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including inappropriate subjective statements, the need for proofs and references to support claims, and the laborintensive nature of designing effective architectures. It also points out the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. The comment provides a clear direction for the authors to address these issues by suggesting they provide a detailed explanation to verify their statements. However, the comment could be more helpful if it offered specific guidance on how to present this explanation or what aspects of the paper need clarification. Overall, the comment is 3 as it highlights areas for improvement but lacks detailed guidance on execution."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about how the proposed method compares with prior art. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what aspects of the comparison should be addressed or how the authors should present this information. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section \"3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking how the proposed method compares with prior art. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point poses a question about how the proposed method compares with prior art. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment poses a question about how the proposed method compares with prior art. While it highlights an important area for consideration, it does not provide any guidance or suggestions on how the authors might address this comparison or what specific aspects of prior art should be considered. Without actionable feedback or direction, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the analysis could be more detailed, specifically mentioning the \"language/nationality\" section. It implies that the authors should explore potential biases in the data and compare them across different languages/nationalities. While the comment does not explicitly instruct the authors to conduct this analysis, it provides a clear direction for improvement by highlighting a specific area that could be expanded upon. The action is implicit but concrete, as it points to a specific aspect of the analysis that could be enhanced. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"language/nationality\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the analysis could be more detailed by exploring potential biases in the data and comparing them across different languages/nationalities. This provides clear guidance on what the authors could address to improve their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section. It implies that there might be interesting observations to be made about biases towards different languages/nationalities. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that such observations would be interesting or valuable. Without additional context or evidence, the claim remains somewhat vague, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the analysis, suggesting that the \"language/nationality\" section could be more detailed by exploring potential biases across different languages/nationalities. It implies that there might be interesting observations to be made about these biases, which could enhance the analysis and contribute to the paper\"s overall quality. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how to conduct this analysis or what specific observations might be interesting. This limits the comment\"s helpfulness, as it points out an area for improvement but does not provide detailed guidance on how to address it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this would be necessary and helpful for the approach design. While the question implies that the authors should consider exploring other properties, it does not provide explicit instructions or concrete suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore other feature properties. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this would be necessary and helpful for the approach design. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this discussion might be relevant. The authors can infer that it relates to the methodology or approach sections, but this inference is not direct. The comment is specific in its suggestion to explore other properties of features, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this would be necessary and helpful for the approach design. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is the case or how it would improve the approach. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment raises a relevant question about the use of other properties of features in addition to norm, suggesting that this could be necessary and helpful for the approach design. This is a valuable point as it prompts the authors to consider alternative approaches that could enhance the robustness and effectiveness of their method. However, the comment lacks specific guidance or suggestions on how to explore these alternative properties or integrate them into the approach. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a relevant area for consideration but lacks depth and specificity in its guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not provide any specific guidance on which tasks should be discussed or how to incorporate this information into the paper. The action is implicit and vague, as the authors are left to infer what additional tasks might be relevant and how to address this suggestion. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or discussion where this topic could be addressed. The authors can infer that it relates to the discussion on tasks or applications of PE, but this inference is not direct. The comment is specific in suggesting a topic for expansion, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it is expected to see a variety of tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this expectation or how it relates to their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. While it identifies a potential area for expansion, it lacks specificity and does not provide any guidance on which tasks or aspects of PE should be discussed. The comment is vague and does not offer actionable advice or examples, leaving the authors without clear direction on how to enhance their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the inclusion of zeroshot generation results in the paper is somewhat unusual and raises a question about its relevance. However, it does not provide explicit guidance on whether the authors should remove these results or explain their inclusion. The comment lacks concrete instructions on how to address this issue, leaving the authors uncertain about how to proceed. Therefore, the comment is 3, as it identifies a potential area for improvement but does not offer specific steps for implementation.", "grounding_specificity_rationale": "The comment addresses the inclusion of zeroshot generation results in the paper, suggesting that it is somewhat unusual and raises a question about its relevance. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its critique of the inclusion of zeroshot generation results, but without clear guidance on where this discussion should be placed, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the inclusion of zeroshot generation results in the paper is somewhat unusual and raises a question about its relevance. However, it does not provide any specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the inclusion of zeroshot generation results in the paper, suggesting that it might be somewhat unusual and questioning its relevance. While it acknowledges the interesting and relevant experiments, it points out that the inclusion of zeroshot generation results might not be necessary. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or justify the inclusion of these results. Without actionable feedback or detailed reasoning, the authors may find it challenging to understand and implement the necessary changes. Therefore, the comment is 3, as it highlights a potential area for improvement but does not provide sufficient guidance for the authors to make meaningful changes."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a minor issue with Figure 3, specifically noting that \"OAA\" is not referenced in the body text and suggesting that there might be more content in the appendix that is missing. The reviewer also mentions that the caption might be out of date. While the comment identifies a specific issue, it does not provide explicit guidance on how to address it, such as suggesting where to add the missing reference or how to update the caption. The action is implicit and somewhat vague, as the authors need to infer that they should review and update the figure and its caption. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that \"OAA\" is not referenced in the body text and suggesting that there might be more content in the appendix that is missing. Additionally, it points out that the caption might be out of date. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that \"OAA\" is not referenced in the body text of Figure 3 and suggests that there might be more content in the appendix that is missing. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a minor issue with Figure 3, specifically noting that \"OAA\" is not referenced in the body text. It suggests that there might be more content in the appendix that is missing or that the caption is out of date. While the comment highlights a specific problem, it lacks depth and does not provide actionable guidance on how to address the issue or improve the figure. The authors are informed of the issue but are not given detailed instructions on how to resolve it. Therefore, the comment is 3, as it points out a potential problem but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effectiveness of the GS module in propagating context information and suggests that the effective receptive field can be computed from a reference [2]. However, it does not provide explicit instructions or suggestions on how the authors should address this question or investigate the impact of the GS module on the effective receptive field. The comment lacks concrete guidance on what specific analyses or experiments the authors should conduct to answer this question. As a result, the authors are left without clear direction on how to proceed with this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GS module\" and suggests that the effective receptive field can be computed from a reference [2]. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks a question about the effectiveness of the GS module and suggests that the authors investigate how the effective receptive field changed after applying it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the effectiveness of the GS module in propagating context information. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the effectiveness of the GS module in propagating context information and suggests that the effective receptive field can be computed from a reference [2]. This is an interesting point that could lead to a valuable exploration of the impact of the GS module on the effective receptive field. However, the comment lacks specific guidance or suggestions on how the authors might investigate or analyze this effect. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a potential area for further exploration but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the objective for the LSTM part is the same for pretraining and finetuning, and that the authors may add another head to the network computing the value functions for the states during the finetuning stage. While the comment provides a clear action\u2014adding another head to the network\u2014it does not specify how to implement this addition or what specific changes are needed in the code or methodology. The authors are left with a general idea of what to do but without detailed guidance on execution. Therefore, the comment is 3, as it provides a clear action but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment addresses the objective for the LSTM part, specifically mentioning the probabilities of actions and the finetuning stage. However, it does not specify which part of the paper this pertains to, such as a specific section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the objective and the potential approach for finetuning, but it lacks grounding as it does not explicitly mention where this information is discussed in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the objective for the LSTM part is the same for pretraining and finetuning, and that the authors may add another head to the network during the finetuning stage. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is the case or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered a valid critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the objective of the LSTM part, suggesting that it is the same for pretraining and finetuning. It also provides a suggestion for the authors to consider adding another head to the network during the finetuning stage to compute the value functions for the states. While the comment highlights a potential weakness in the methodology, it lacks specific guidance or examples on how to implement this suggestion or what specific changes are needed. The feedback is 3 as it points out a potential area for improvement but does not provide detailed instructions on how to address it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should acknowledge some of the older works related to supervised, multilingual systems. While the comment implies that the authors should include this acknowledgment, it does not provide specific guidance on which works to mention or how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related works\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works related to supervised, multilingual systems, providing clear guidance on what needs to be addressed in this section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should acknowledge older works related to supervised, multilingual systems. However, it does not provide specific examples or references to these older works, nor does it explain why acknowledging them is important. Without additional context or reasoning, the claim lacks verifiability, as it does not provide sufficient evidence or justification for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge older works related to supervised, multilingual systems. While it identifies a potential gap in the literature review, it does not provide specific examples of older works to consider or explain why acknowledging them would be beneficial. The comment is 3 as it points out an area for improvement, but it lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the results in Table 2, specifically the linear/exponentialdecay sampling, and suggests that it may underperform uniform sampling. The reviewer points out that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their results. The suggestion is implied and lacks concrete details, making it 3. The authors can infer that they need to reconsider their sampling strategy, but the comment does not offer specific steps or examples on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the results in Table 2, particularly the linear/exponentialdecay sampling, and suggests that it may underperform uniform sampling. The comment further explains the potential reason for this underperformance, based on the authors\" argument about the predictor\"s accuracy in the good subregion. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the results in Table 2, specifically the linear/exponentialdecay sampling, and suggests that it may underperform uniform sampling. The reviewer provides a logical reasoning by pointing out that if the predictor is accurate in the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling, especially when the performance of architectures in the good subregion is close. This reasoning is based on a logical assumption and provides a plausible explanation for the potential underperformance. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment questions the results in Table 2, specifically the linear/exponentialdecay sampling, and suggests that it may underperform uniform sampling. The reviewer provides a logical reasoning by pointing out that if the predictor is accurate in the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling, especially when the performance of architectures in the good subregion is close. This feedback is 3 as it highlights a potential issue with the results and suggests a possible explanation for the observed underperformance. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or improve their results. Overall, the comment offers some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights several issues with the time complexity of the proposed method, including the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. However, it does not provide explicit guidance on how the authors should address these issues or suggest specific actions to improve the time complexity. The comment lacks concrete details on how to implement these improvements, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the time complexity, such as the potential for many users associated with a typical item and the larger number of hidden units compared to matrix factorizationbased methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity of the proposed method is high due to the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks references or examples to substantiate the assertion that the time complexity is high, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 2, as it provides some evidence but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the proposed method, specifically noting the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. While it highlights these factors as contributing to the high time complexity, it does not provide specific suggestions or guidance on how the authors might address or mitigate this issue. The comment lacks actionable advice or detailed analysis, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is rated as 2, as it points out a potential weakness but does not offer sufficient guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the figures would be clearer if they explicitly mention \"pretrained solution encoders & solution decoders\" to account for multiple types of autoencoders. While the comment implies that the authors should add this information to the figures, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added, but it is somewhat vague because it does not provide detailed guidance on how to implement this change. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests that many of the figures would be clearer if they mentioned \"pretrained solution encoders & solution decoders,\" which implies that the authors should clarify the types of autoencoders used in the figures. However, the comment does not specify which figures or sections need this clarification, making it weakly grounded. The suggestion is specific, as it clearly identifies what needs to be addressed to improve the clarity of the figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they mentioned \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the figures. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that many of the figures would be clearer if they mentioned \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback is 3 as it identifies a specific area for improvement in the clarity of the figures. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or why it is important. Additionally, it does not address other aspects of the paper, such as the content or structure of the figures themselves. While the comment points out a potential issue, it could be more helpful with additional explanation or examples. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that a brief explanation of \"multiaspect\" would be helpful and questions the subscripts s and t in Figure 1, suggesting they should be 1 and 2. While the comment implies that the authors should provide an explanation and clarify the subscripts, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation and clarify the subscripts. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 14, 47\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a brief explanation of \"multiaspect\" and the subscripts s and t in Figure 1, suggesting they should be 1 and 2. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a brief explanation of \"multiaspect\" would be helpful and questions the subscripts s and t in Figure 1, suggesting they should be 1 and 2. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these changes would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies specific areas for improvement in the paper, namely the need for a brief explanation of the term \"multiaspect\" and the suggestion to clarify the subscripts s and t in Figure 1. This feedback is clear and actionable, as it provides the authors with specific guidance on how to enhance the clarity and understanding of their work. By addressing these points, the authors can improve the readability and comprehensibility of their draft, making the comment 4. However, it could be more helpful if it included suggestions on how to effectively integrate these explanations into the paper. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It explicitly requests a more detailed analysis of these aspects. While the comment identifies areas for improvement, it does not provide specific guidance on how to conduct the analysis or what aspects should be emphasized. The authors are left to infer that they need to provide more detailed information, but the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"p,\" which likely refers to a specific parameter or value used in the paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It requests a more detailed analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It requests a more detailed analysis of these aspects, which could significantly enhance the paper\"s clarity and rigor. While the comment identifies areas for improvement, it lacks specific guidance on how to conduct the analysis or what aspects should be emphasized. This makes the feedback 3, as it points out potential weaknesses but does not provide detailed instructions for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for information about the computational requirements and runtime of the experiments, including the type of hardware used. This is a clear and direct request for additional details that the authors can easily address by providing the requested information. The action is explicit and concrete, as it specifies exactly what needs to be added to the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for information about the computational requirements and runtime of the experiments, including the type of hardware used. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what information is needed, providing clear guidance on what needs to be added to the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for additional information about the computational requirements and runtime of the experiments. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it prompts the authors to provide additional information about the computational requirements and runtime of the experiments. This is important as it can help the authors understand the feasibility and scalability of their work. However, the comment could be more helpful if it included specific suggestions on how to present this information or what aspects to focus on. Despite this, the feedback is clear and actionable, guiding the authors to enhance the transparency and reproducibility of their work. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors only apply the meta sampler in a decoupled way, specifically when the features are fixed. It also requests more discussion on this aspect and asks for clarification on when the authors start applying the meta sampler. While the comment implies that the authors should provide more information on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more discussion and clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"meta sampler\" and the \"linear classifier,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on whether the meta sampler is applied in a decoupled way and requests more discussion on this topic. Additionally, it asks for clarification on when the meta sampler is applied, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the application of the meta sampler in a decoupled way and requests more discussion on this topic. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the application of the meta sampler in a decoupled way and requests more discussion on this topic. It highlights a potential area for clarification and improvement in the paper, which could enhance the understanding of the methodology and its implementation. However, the comment does not provide detailed guidance or suggestions on how to address this issue or what specific aspects of the discussion should be expanded upon. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to either state the content as a remark or move it to a Discussion section, or to remove it altogether. This provides a clear and direct action for the authors to take, ensuring that the content is either appropriately labeled or removed from the paper. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L107114,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely whether the content is speculative or overly opinionated and suggests that it should be stated as a remark, moved to a Discussion section, or removed. This provides clear guidance on how to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"L107114 seems speculative or overly opinionated.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific section of the paper (L107114) as potentially being speculative or overly opinionated. It suggests that this content should be stated as a remark, moved to a Discussion section, or removed. This feedback is clear and actionable, providing the authors with a concrete suggestion on how to address the issue. However, the comment could be more helpful if it explained why this section is considered speculative or overly opinionated, which would help the authors understand the basis of the critique and improve their draft accordingly. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional context."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is concrete, as it specifies the baselines to consider, but it is somewhat vague because it does not provide detailed guidance on how to implement this suggestion. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. The authors can infer that it relates to the evaluation or experimental sections, but this inference is not direct. The comment is specific in suggesting the inclusion of these baselines, but it lacks grounding as it does not explicitly mention the relevant sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these baselines are relevant or how they would impact the evaluation. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered a valid suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional baselines. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or why these specific baselines are relevant. While it points out a potential enhancement, it could be more helpful if it included more detailed reasoning or examples of how these baselines could be integrated into the evaluation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies two missing elements in the paper: the value of the neighborhood size h and an analysis of its influence on the model\"s performance, and the use of different hyperparameter sets per dataset. It suggests that providing insights into the value of h and its robustness across different neighborhood sizes is essential. Additionally, it questions the use of different hyperparameter sets per dataset and recommends providing insights into how performance varies with a constant set of parameters. The comment is clear and provides specific actions for the authors to take, such as conducting an analysis of h and its influence on performance, and standardizing hyperparameter sets across datasets. The explicit nature of the suggestions and the concrete details on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"value of neighborhood size h\" and the \"analysis of its influence over the model\"s performance,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for an analysis of the robustness of the method with respect to different neighborhood sizes and the use of different hyperparameter sets per dataset. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the value of the neighborhood size h and its influence on the model\"s performance are missing elements in the paper. It suggests that this is a key parameter of the proposed strategy and that providing insights into its value and robustness is essential. The comment also questions the use of different hyperparameter sets per dataset, suggesting that standardizing these parameters would be beneficial. While the comment provides logical reasoning and highlights important aspects that need to be addressed, it lacks specific examples or references to support the claim about the influence of h on performance. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two important missing elements in the paper: the value of the neighborhood size h and an analysis of its influence on the model\"s performance, and the use of different hyperparameter sets per dataset. It suggests that providing insights into the value of h and its robustness across different neighborhood sizes is essential, as this is a key parameter of the proposed strategy. Additionally, it questions the use of different hyperparameter sets per dataset, recommending that authors provide insights into how performance varies with a constant set of parameters. This feedback is clear and actionable, as it directs the authors to address specific gaps in their analysis and provide more comprehensive information to enhance the understanding and robustness of their method. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model\"s ability to construct higherorder interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. While the comment implies that the authors should consider these questions and potentially address them in their paper, it does not provide explicit instructions or concrete suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these aspects of the model. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model\"s ability to construct higherorder interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the model\"s performance or analysis. The comment is specific in its inquiry about the impact of missing modalities and the potential for leveraging additional modalities. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point poses a question about the impact of imperfect multimodal data on the model, specifically asking whether missing modalities affect the model\"s ability to construct higherorder interactions and polynomial tensors. The comment does not make a claim or express an opinion but rather seeks clarification or additional information. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model\"s ability to construct higherorder interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. This feedback is valuable as it prompts the authors to consider a critical aspect of their model\"s robustness and generalizability. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or explore the impact of missing modalities. Overall, the comment is 3 as it directs the authors to consider an important aspect of their model but lacks detailed guidance on how to implement the suggested exploration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. It provides a specific example of how this could be done by showing the frequency of these words in the dataset. While the comment is explicit in its request for additional statistics, it does not provide detailed guidance on how to implement this suggestion or what specific metrics should be used. The action is clear but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. The comment provides a specific example of how this could be done, making it clear and actionable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. The reviewer provides a specific example of how this could be done, which is to show the frequency of these words in the dataset. However, the comment lacks detailed reasoning or references to support why this information is important or how it would enhance the paper. While the suggestion is logical, the lack of detailed justification makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by requesting the inclusion of statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. It offers a clear example of how this could be done by showing the frequency of these words in the dataset. This feedback is actionable and can help the authors enhance the clarity and depth of their analysis. However, the comment could be more helpful if it provided additional context or examples of how these statistics could be used to strengthen the paper. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors consider freezing some layers of the model while only training a few layers or using parameterefficient methods like LoRA. These suggestions are explicit and provide clear actions for the authors to take, such as considering these methods for experimental comparison. The comment also specifies the potential benefits of these approaches, making it clear what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests considering freezing some layers of the model or using parameterefficient methods like LoRA for experimental comparison. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the model training or parameter efficiency sections, but this inference is not direct. The comment is specific in suggesting alternative methods to consider, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests considering alternative methods like freezing some layers of the model or using LoRA for parameterefficient methods. However, it does not provide any supporting evidence, examples, or references to justify why these methods are relevant or beneficial. The claim is based on logical reasoning but lacks specific examples or detailed justification, making it 3. The authors would need to make a significant effort to understand and implement these suggestions, which is why the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests considering alternative methods for parameterefficient model training, such as freezing some layers or using LoRA. This feedback is actionable and provides a clear direction for the authors to explore additional approaches that could enhance their experimental comparison. By suggesting these methods, the reviewer offers a constructive way for the authors to improve their draft. However, the comment could be more helpful if it provided specific examples or references to these methods, which would help the authors understand their potential benefits and limitations. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to expand the related work section and compare their work to strong baselines that use coordinates. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and concrete, giving the authors a clear path to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the \"related work section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need to expand this section and compare it to strong baselines that use coordinates. This level of detail provides full grounding and specificity, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests expanding the related work section and comparing it to strong baselines that use coordinates. However, it does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for expanding the related work section and comparing it to strong baselines that use coordinates. This feedback is specific and offers a concrete direction for the authors to enhance their draft, which could significantly improve the paper\"s comprehensiveness and rigor. By addressing this suggestion, the authors can better situate their work within the existing literature and provide a more robust foundation for their analysis. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the experiments should be expanded to include multiple seed experiments, which would provide a more robust evaluation. This suggestion is clear and concrete, as it specifies the exact action the authors need to take to improve their draft. The comment provides a specific direction for enhancing the evaluation by including multiple seed experiments, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Single Seed Experiments\" and the \"experiments in the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the limitation of the experiments being limited to a single seed and the need for multiple seed experiments to provide a more robust evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to training on a single seed, making it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. This claim is 3 as it logically points out the limitation of singleseed experiments and the need for more robust evaluations. However, it lacks specific examples or references to support the claim, such as discussing how multiple seed experiments would impact the results or what specific aspects of the proposed method would be better evaluated with multiple seeds. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s experiments, specifically the use of a single seed for training. It suggests that multiple seed experiments would provide a more robust evaluation, which is a valuable point for the authors to consider. However, the comment could be more helpful by providing specific guidance on how to implement multiple seed experiments or discussing the potential impact of this change on the results. While it highlights an important area for improvement, it lacks detailed suggestions, making it 3. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the proposed method, noting that an entire multiGPU setup is required for optimizations, making it less accessible for many potential users. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the method more accessible or suggestions for alternative approaches. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the proposed method, noting that an entire multiGPU setup is required for optimizations, which makes it less accessible for many potential users. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on how this requirement affects the accessibility of the method. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method requires an entire multiGPU setup for optimizations, making it less accessible for many potential users. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the accessibility of the method. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the accessibility of the proposed method, noting that an entire multiGPU setup is required for optimizations. This is a relevant point that could impact the practicality and adoption of the method by users who may not have access to such a setup. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending alternative approaches or suggesting ways to make the method more accessible. Without actionable advice or detailed feedback, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the missing citation for the public skipgram data set in L425. This provides a clear and direct action for the authors to take, as they are explicitly instructed to include the missing citation. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the missing citation for the public skipgram data set. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a missing citation for the public skipgram data set in L425. However, it does not provide any supporting evidence, reasoning, or references to justify why this citation is necessary or how it relates to the paper\"s content. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of the missing citation. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the missing citation for the public skipgram data set in L425. This is a clear and actionable point that the authors can address to improve the accuracy and completeness of their work. By providing this feedback, the reviewer helps the authors ensure that their paper is properly cited and referenced, which is crucial for academic integrity and credibility. However, the comment could be more helpful if it included suggestions on how to properly cite the data set or why it is important to include it. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests comparing the current system with another system that also captures semantics, potentially using Ref[2] as a baseline. It provides a clear and explicit action for the authors to take, which is to compare their system with another that captures semantics. The comment also suggests using Ref[2] as a baseline, which provides concrete guidance on how to implement the suggested comparison. However, it does not specify which aspects of the current system should be compared or how to evaluate the performance of the new system. While the action is explicit, the lack of detailed guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment suggests comparing the current system with another system that also captures semantics, potentially using Ref[2] as a baseline. However, it does not specify which part of the paper this comparison should be made in, nor does it provide details on how the current system captures semantics or what aspects should be compared. The comment is weakly grounded because it does not specify where in the paper this comparison should be made, and it is not specific because it lacks detailed guidance on what aspects to compare or how to evaluate the performance of the new system. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests comparing the current system with another system that also captures semantics, potentially using Ref[2] as a baseline. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would improve the paper. Without specific details or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the current system with another system that also captures semantics, potentially using Ref[2] as a baseline. This is a clear and actionable suggestion that could help the authors improve the evaluation and comparison of their system. However, the comment could be more helpful if it provided specific guidance on which aspects of the current system should be compared or how to evaluate the performance of the new system. Additionally, it could suggest specific metrics or methods to use in the comparison. While the feedback is valuable, it could be more comprehensive with additional details. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset. It suggests that one of the assumptions might not be satisfied or that there could be learning difficulties. However, it does not provide specific guidance on how the authors should address these issues or what steps to take to improve the model. The comment lacks concrete actions or detailed suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of model performance and suggesting that assumptions might not be satisfied or that there could be learning difficulties. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset. It suggests that one of the assumptions might not be satisfied or that there could be learning difficulties. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that assumptions are not satisfied or that learning difficulties exist. Without such evidence or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. It prompts the authors to consider whether these issues are related to assumptions or learning difficulties. While the comment identifies a potential problem, it lacks specific guidance or suggestions on how the authors might address these issues or improve their model. The feedback is 3 as it points out a potential area for improvement but does not provide detailed guidance or actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment requests that the authors provide a rationale for why their SE framework can help improve the system and how it does so. It suggests that the authors should not just present their achievements but also explain why and how they managed to achieve them. The reviewer references a specific work, [1] Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. However, the comment does not explicitly instruct the authors to use this reference or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of their approach and its benefits. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4\" and \"2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a rationale and explanation of how the SE framework can help improve the system. The reference to [1] Luo, et al. provides additional context and guidance for the authors. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the rationale and explanation behind the SE framework\"s ability to improve the system. It suggests that the authors should provide a detailed explanation of why and how the framework can help, rather than just presenting results. The reviewer references a specific work, [1] Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. However, the comment does not provide specific examples or detailed reasoning from the referenced work to support the claim. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of a clear rationale and explanation for why the SE framework can help improve the system. It suggests that the authors should not just present their achievements but also provide a detailed explanation of why and how they managed to achieve them. The reviewer references a specific work, [1] Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. This reference could be useful for the authors to consider in their response. However, the comment could be more helpful if it provided specific examples or guidance on how to address the issue. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and does not consider information from all time steps. While the comment identifies an area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the rationale behind the user decoder\"s information usage but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"user decoder\" and \"agent decoder,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the user decoder only uses information up to time step t and does not consider information from all time steps. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the rationale behind the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and does not consider information from all time steps. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind the user decoder\"s use of information from the agent decoder, specifically questioning why it only uses information up to time step t and does not consider information from all time steps. This feedback highlights a potential area of confusion or inconsistency in the paper, prompting the authors to clarify their methodology. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as suggesting alternative approaches or explaining the reasoning behind the current method. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of a section on synonym identification under similarity measurement, which is a clear and direct action for the authors to take. It specifies the missing section and provides a specific suggestion for what should be included, namely a description of how the multiplechoice task is approached. This level of detail makes the action explicit and concrete, allowing the authors to know exactly what needs to be added to their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section on similarity measurement, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely a section on synonym identification, and provides a clear direction for improvement by suggesting a description of how the multiplechoice task is approached. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under similarity measurement, which would describe how the multiplechoice task is approached. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, namely the absence of a section on synonym identification under similarity measurement. This feedback is clear and actionable, as it points out a specific area where the paper could be improved by including a description of how the multiplechoice task is approached. By addressing this gap, the authors can enhance the clarity and completeness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to effectively integrate this section into the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While the action is implicit, it is concrete because it specifies what needs to be added (an overview of the workflow and the model). This provides a clear direction for the authors to enhance their draft by including this information. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not specify which part of the paper this overview should be included in, nor does it provide details on what aspects of the workflow and model should be covered. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in suggesting the need for an overview, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not provide any specific reasoning or examples to support why this overview is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area for improvement by suggesting that an overview of the workflow and the model is needed to provide a clearer understanding of the work. This feedback is clear and actionable, as it directs the authors to include a section that can help readers grasp the overall structure and components of the paper. However, the comment could be more helpful if it provided specific guidance on what aspects of the workflow and model should be covered or how they should be presented. Despite this, the feedback is 4 as it points out a critical area for improvement and offers a clear direction for enhancing the draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the debiasing approach, specifically the need to know the statistical dimension d_lambda of the design matrix A. It also notes that this information cannot be computed accurately without the same runtime as required for ridge regression. The reviewer suggests that this issue is not discussed in the paper and raises a similar concern regarding the surrogate sketch. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors need to infer that they should discuss this issue and provide a rationale for its omission. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to debias the sketch and the statistical dimension d_lambda of the design matrix A, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of not being able to compute d_lambda accurately without the same runtime as ridge regression, and raises a similar concern regarding the surrogate sketch. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the debiasing approach requires knowledge of the statistical dimension d_lambda of the design matrix A, which cannot be computed accurately without the same runtime as ridge regression. The reviewer also notes that this issue is not discussed in the paper and raises a similar concern regarding the surrogate sketch. The claim is 3 as it provides a logical reasoning for the need to compute d_lambda accurately, but it lacks specific examples or references to substantiate the claim fully. The authors might need to conduct additional research or provide more detailed explanations to fully address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the debiasing approach, specifically the need to know the statistical dimension d_lambda of the design matrix A. It highlights that this information cannot be computed accurately without the same runtime as required for ridge regression, which could lead to bias and potentially defeat the purpose of the approach. The comment also notes that this issue is not discussed in the paper, which is a significant oversight. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or discuss it in the paper. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a significant gap but does not fully support the authors in resolving it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to redefine Figure 3 as the expected quantities are scalars but shown as a vector. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is 5 as it clearly specifies what needs to be done to address the issue.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, redefining the figure to accurately represent the expected quantities as scalars. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the figure should be redefined as the expected quantities are scalars but shown as a vector. However, it does not provide any supporting evidence, reasoning, or examples to justify why this change is necessary or how it would improve the clarity or accuracy of the figure. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific issue with Figure 3, noting that the expected quantities are scalars but shown as a vector. This feedback is clear and actionable, as it directs the authors to redefine the figure to accurately represent the expected quantities. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as explaining why the current representation is misleading or offering guidance on how to present the data more effectively. Overall, the comment is valuable for directing the authors to make a specific improvement, but it could be more comprehensive with additional details. Therefore, it is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not provide specific guidance on how to improve the experiment setup or what aspects need to be addressed. The comment lacks explicit instructions or concrete suggestions on how to enhance the experiment setup, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not specify which part of the paper this pertains to, such as the experimental section or a particular figure or table. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in suggesting that the experiment setup should be improved, but without clear grounding, it is difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the ablations deserve better experiment setup due to the many questions that arise. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not provide specific guidance or examples on how to improve the experiment setup or what aspects need to be addressed. Without actionable advice or detailed suggestions, the authors are left with a general idea of what needs to be improved but without clear direction on how to achieve it. Therefore, the comment is 2, as it identifies a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of empirical evidence to support the argument that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should explore this aspect further by providing empirical evidence to test the hypothesis. While the comment implies that the authors should conduct additional experiments, it does not specify which experiments to conduct or how to conduct them. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the argument about the proposed models being particularly useful for learning representations for lowfrequency words, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of empirical evidence to test the hypothesis and suggests exploring this aspect further. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed models are particularly useful for learning representations for lowfrequency words but lacks empirical evidence to support this claim. The reviewer suggests that it would be interesting to explore this aspect further, implying that the absence of empirical evidence is a significant issue. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the issue, as the comment does not provide enough guidance or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of empirical evidence to support the argument that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should explore this aspect further by providing empirical evidence to test the hypothesis. This feedback is clear and actionable, as it points out a critical area for improvement and offers a specific direction for the authors to enhance their draft. However, the comment could be more helpful if it provided examples of what kind of empirical evidence would be useful or how to conduct the experiments. Overall, the comment is 4 as it effectively guides the authors on how to strengthen their paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should study the importance of the global feature by comparing it with different resolutions of voxel features. It specifically mentions that the resolution of the 3D voxel should be considered and that the study should be included in Sec4.2. The comment provides a clear and explicit action for the authors to take, which is to conduct a comparative analysis of the global feature with different voxel resolutions. This guidance is concrete and provides a specific direction for the authors to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the study of the global feature and its resolution, and suggests comparing it with different resolutions of voxel features. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the resolution of the 3D voxel and its potential impact on the network. It suggests that studying the importance of the global feature by comparing it with different resolutions of voxel features would be more convincing. While the comment provides a logical reasoning for the need to consider the resolution, it lacks specific examples or references to support the claim that the resolution introduces unnecessary overhead. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to study the importance of the global feature by comparing it with different resolutions of voxel features. It highlights the potential issue of high computational and memory cost associated with voxellike features and suggests that studying the resolution of the 3D voxel could be beneficial. The comment is specific in its guidance, providing a concrete direction for the authors to improve their draft. By addressing this suggestion, the authors can enhance the clarity and robustness of their study. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the error analysis on the movie dataset is missing and highlights the importance of knowing what cases the model fails in order for other researchers to continue the task. This provides a clear and direct action for the authors to take, which is to include the missing error analysis. The comment is specific and provides concrete guidance on what needs to be added to the paper, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the \"movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed, which is a full grounding. It also specifies the issue by pointing out the missing error analysis and the need to know what cases the model fails. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is a factual observation. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this omission or how it affects the paper\"s contribution. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the absence of an error analysis on the movie dataset. It highlights the importance of including this analysis for other researchers to continue building upon the work. However, the comment does not provide specific guidance on how to conduct the error analysis or what aspects should be covered. While it points out a critical area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer recommends exploring development set trends with respect to these hyperparameters. While the comment implies that the authors should investigate these trends, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these trends. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the trends in the table, noting that PM+CL behaves differently than PM or CL alone and suggesting exploring development set trends with respect to these hyperparameters. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer recommends exploring development set trends with respect to these hyperparameters. However, the comment lacks specific examples or detailed reasoning to support why these trends are important or how they could be explored. Without additional context or evidence, the claim is 3, as it requires the authors to infer the significance of the trends and the need for further exploration. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it is difficult to see trends due to the behavior of PM+CL compared to PM or CL alone. The reviewer suggests exploring development set trends with respect to these hyperparameters, which could provide valuable insights into the impact of these variables. This feedback is clear and actionable, as it directs the authors to investigate a specific area that could enhance the understanding and interpretation of their results. However, the comment could be more helpful if it included suggestions on how to explore these trends or what specific analyses might be useful. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the clarity of Figure 5, noting that there are many lines on top of each other, making it difficult to understand. It also suggests that the authors could report additional metrics, such as flops or model size, to provide a more concrete understanding of the results. While the comment implies that the authors should make these changes, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added or clarified, but it is somewhat vague in terms of how to implement these changes. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the difficulty in understanding the figure due to the overlapping lines and suggests reporting additional metrics like flops or model size to provide a more concrete understanding of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand Figure 5 due to the overlapping lines and suggests that the authors could report additional metrics like flops or model size to provide a more concrete understanding of the results. However, the comment does not provide specific examples or detailed reasoning to support why the current presentation is unclear or how the suggested metrics would improve clarity. While the suggestion is logical, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Figure 5, noting that the overlapping lines make it difficult to understand. It also suggests that the authors could report additional metrics, such as flops or model size, to provide a more concrete understanding of the results. This feedback is clear and actionable, as it directs the authors to improve the clarity and comprehensibility of their figures and metrics. However, the comment could be more helpful if it provided specific guidance on how to present these additional metrics or how to improve the figure\"s layout. Overall, the comment is 4 as it offers concrete suggestions for enhancing the draft, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide specific guidance on what details are missing or how the authors should address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment mentions the \"questions section below,\" which implies that it is referring to a specific part of the paper. However, without explicit mention of a section or page number, the authors cannot confidently determine the exact part being addressed. The comment also lacks specificity regarding what details are missing or how they should be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that \"some details of the proposed method are missing,\" but it does not provide specific examples or reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to identify which details are missing or how they could address this issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide specific details on what these missing details are or how they affect the paper. Without this information, the authors are left without actionable guidance on how to address the issue. The comment lacks depth and specificity, making it 2 for the authors in improving their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation on oversmoothing should include a comparison with the EIGNN model under standard settings on realworld datasets, specifically in relation to variants that focus on dealing with oversmoothing, such as GCNII. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is concrete, as it specifies the type of comparison to be made, but it is somewhat vague in terms of how to implement it. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests a specific comparison to be made regarding the evaluation of oversmoothing, particularly with respect to the EIGNN model and variants that focus on dealing with oversmoothing, such as GCNII. However, it does not specify which part of the paper this evaluation is currently included in, making it weakly grounded. The comment is specific in suggesting a particular comparison to be made, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact location of the evaluation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation on oversmoothing should include a comparison with the EIGNN model under standard settings on realworld datasets, specifically in relation to variants that focus on dealing with oversmoothing, such as GCNII. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this comparison is necessary or how it would benefit the evaluation. Without additional context or examples, the claim remains 3, as it lacks the necessary support to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a specific comparison that could be made in the evaluation of oversmoothing, specifically by comparing the EIGNN model with variants that focus on dealing with oversmoothing, such as GCNII. This feedback is actionable as it provides a clear direction for the authors to enhance their evaluation by including a comparison that could offer insights into the performance of the EIGNN model under standard settings on realworld datasets. However, the comment could be more helpful if it provided additional context or examples of how this comparison might be conducted or what specific aspects to focus on. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the approach method lacks a separate part or subsection to introduce the inference strategy, specifically mentioning the use of multiple prompts in the test stage. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to add a separate section or subsection to introduce the inference strategy, but the comment lacks concrete details on what this section should include or how to implement it. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment explicitly mentions the \"approach method\" and the \"inference strategy,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the lack of a separate part or subsection to introduce the inference strategy, particularly regarding the use of multiple prompts in the test stage. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach method lacks a separate part or subsection to introduce the inference strategy, specifically mentioning the use of multiple prompts in the test stage. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, noting the absence of a separate part or subsection to introduce the inference strategy, particularly regarding the use of multiple prompts in the test stage. This feedback is clear and actionable, as it points out a specific area where the paper could be improved by providing a dedicated section to explain the inference strategy. However, the comment could be more helpful if it offered suggestions on how to structure this section or what specific aspects to cover. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiment results could be discussed more, specifically questioning whether the Streetview experiment supports the conclusion that MaxGapTop2UCB is better than other methods. It also points out the lack of clarity regarding the realworld applications of the problem setting and the computational complexity of the proposed algorithms. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific aspects should be discussed in the paper. The authors are left to infer that they need to provide more detailed discussions and address the computational complexity, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Streetview experiment\" and \"Alg. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the conclusion drawn from the Streetview experiment and asking about the computational complexity of the proposed algorithms in the context of ranking problems. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the conclusions drawn from the Streetview experiment and the realworld applications of the problem setting. It suggests that the authors should discuss the results more and clarify the applicability to sorting/ranking. The reviewer also questions the computational complexity of the proposed algorithms in the context of ranking problems, specifically mentioning the complexity of Alg. 4. While the comment identifies potential issues and questions, it lacks specific examples or references to support the claims about computational complexity. This makes the claim 3, as it provides a basis for the authors to explore these topics further but requires additional evidence or explanation to fully substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two areas for improvement: discussing the experiment results and clarifying the realworld applications of the problem setting. It questions whether the Streetview experiment supports the conclusion that MaxGapTop2UCB is better than other methods and highlights the lack of clarity regarding the realworld applications of the problem setting. The reviewer also points out the computational complexity of the proposed algorithms in the context of ranking problems, suggesting that this could be a significant issue. While the comment provides some insight into areas that need further exploration, it lacks specific suggestions or guidance on how to address these issues. The authors are left with a general idea of what needs to be improved but without detailed steps or examples on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the low results obtained using only ML in the ablation experiments, suggesting that more explanations are needed. However, it does not provide specific guidance on what kind of explanations are needed or how the authors might address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the low results obtained using only ML in the ablation experiments, suggesting that more explanations are needed. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for more explanations, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the low results obtained using only ML in the ablation experiments, suggesting that they are lower than those of some simple early methods like fCLSWGAN [4] and fVAEGAND2 [5]. However, the comment does not provide specific references to these methods or explain why the results are considered low or why they are lower than the mentioned methods. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the basis of the comparison and the significance of the results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid question about the low results obtained using only ML in the ablation experiments, suggesting that more explanations are needed. It points out that the results are lower than those of some simple early methods, which could be beneficial for the authors to consider. However, the comment lacks specific suggestions or guidance on what kind of explanations might be helpful or how the authors might address this issue. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the absence of ablation analysis in the main paper, which makes it challenging to determine the source of the small performance gain. However, it does not provide explicit guidance on how to include ablation analysis or what specific components should be analyzed. The action is implicit and somewhat vague, as the authors are left to infer that they need to include ablation analysis but without clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights the absence of ablation analysis in the main paper, which makes it difficult to pinpoint the source of the small performance gain. However, it does not specify which part of the paper lacks this analysis, such as the specific sections or experiments where it should be included. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in identifying the issue of lacking ablation analysis, but without explicit references to sections or experiments, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of ablation analysis makes it difficult to determine the source of the small performance gain. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of ablation analysis, which makes it difficult to pinpoint the source of the small performance gain. This is a critical observation that could significantly impact the authors\" understanding of their work and its implications. However, the comment does not provide specific guidance on how to address this issue, such as suggesting which components should be analyzed or how to conduct the ablation analysis. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a critical issue but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the verification of the hypothesis, specifically noting that the experiment is not welldesigned. It suggests that the base model should be trained on the original dataset along with the adversarial set to better highlight the impact of the augmented adversarial examples. This feedback provides a clear and explicit action for the authors to take, which is to modify the experiment to include the comparison between the original dataset and the mixture. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the verification of the hypothesis through a comparison of the base model trained on the original dataset versus the adversarial set. This provides clear guidance on how to improve the experiment and enhance the paper\"s motivation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hypothesis is not wellverified by the designed experiment, specifically mentioning that the base model is trained on the adversarial set only, while conventional methods train on the original dataset and the adversarial examples. The reviewer suggests that a comparison between the base model trained on the original dataset and the mixture would be more convincing. This claim is 3 as it provides a logical reasoning for the need to compare the models, but it lacks specific examples or references to support the claim fully. The authors would need to make a significant effort to understand and address the issue, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the verification of the hypothesis, specifically noting that the base model is trained on the adversarial set only, while conventional methods train on the original dataset and the adversarial examples. It suggests that a comparison between the base model trained on the original dataset and the mixture would be more convincing. This feedback is clear and actionable, as it provides a specific direction for the authors to improve the experiment and enhance the paper\"s motivation. By addressing this issue, the authors can significantly strengthen their work. However, the comment could be more helpful if it provided additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is 4 as it effectively points out a critical weakness and offers a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the CNN experiments are not fully convincing, but it does not provide any specific details or examples to support this claim. There is no guidance on what aspects of the experiments are lacking or how they could be improved. Without explicit or implicit suggestions for improvement, the authors are left without a clear understanding of what changes are needed to enhance the credibility of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the CNN experiments, but it does not specify which part of the paper these experiments are discussed in, making it weakly grounded. It also lacks specificity as it does not detail what aspects of the experiments are not convincing or how they could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively address the issue. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the CNN experiments are not convincing, but it does not provide any specific details or examples to support this claim. Without additional context or evidence, the authors are left without a clear understanding of what aspects of the experiments are lacking or how they could be improved. This makes the claim 1, as it lacks the necessary support to substantiate the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment mentions that the CNN experiments are not convincing, but it does not provide any specific details or examples to support this claim. Without further explanation or guidance, the authors are left without a clear understanding of what aspects of the experiments are lacking or how they could be improved. This lack of actionable feedback limits the usefulness of the comment, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the results for model (3) (Chung et al. 2016) for CsEn in Table 1 are not reported in the paper and suggests that if the authors computed these results themselves, they should mention it. This provides a clear and direct action for the authors to take, ensuring that they either report the results from the original paper or acknowledge their selfcomputation. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"model (3) (Chung et al. 2016) for CsEn,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the results were taken from the original paper or computed by the authors themselves. This provides clear guidance on what needs to be corrected or clarified in the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results for model (3) (Chung et al. 2016) for CsEn in Table 1 are not reported in the paper, suggesting that the authors should mention if they computed these results themselves. The comment is 3 as it provides a specific reference to the original paper, which could help the authors verify the claim. However, the comment lacks detailed reasoning or explanation about why the results should be reported or how they might impact the paper. Therefore, the claim is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the results for model (3) (Chung et al. 2016) for CsEn in Table 1 are not reported in the paper. It suggests that if the authors computed these results themselves, they should mention it. This feedback is clear and actionable, as it directs the authors to either report the results from the original paper or acknowledge their selfcomputation. By addressing this issue, the authors can improve the accuracy and transparency of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to present these results or acknowledge the selfcomputation. Overall, the comment is 4 as it effectively guides the authors on how to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should compare their results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. While the suggestion is clear and provides a specific example of what to compare, it does not offer detailed guidance on how to implement this comparison or what aspects to focus on. The authors are given a clear direction but may need to infer additional details to fully execute the action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or experiment. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. The comment is specific in suggesting a comparison with SoTA approaches, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests a specific improvement by recommending the authors compare their results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This feedback is actionable and provides a clear direction for the authors to enhance their work by demonstrating the effectiveness of their approach in relation to existing methods. However, the comment could be more helpful if it included additional guidance on how to conduct this comparison or what aspects to focus on. Overall, the suggestion is valuable but could be more comprehensive with additional details. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the use of freezing in MLS selection and suggests that if adaptive is good, it would be better to use an adaptive method for subset selection. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the rationale behind using freezing but are not given specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of freezing in MLS selection and questions the rationale behind it. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the use of freezing and suggesting an alternative approach, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of freezing in MLS selection and suggests that if adaptive is good, it would be better to use an adaptive method for subset selection. However, the comment lacks specific reasoning or evidence to support why the current approach is ineffective or why an adaptive method would be more beneficial. Without detailed justification or examples, the claim remains 3, as the authors may find it challenging to understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid question about the use of freezing in MLS selection and suggests that if adaptive is good, it would be better to use an adaptive method for subset selection. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically questioning the rationale behind the current approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it points out a potential weakness, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should perform a similar analysis on the proposed knowledgeCLIP model as done in existing work that combines text and KGs. This feedback implies that the authors should conduct a closelyrelated analysis to test the robustness of their model, specifically by adding negation or changing entities in the text. While the comment does not explicitly instruct the authors to perform this analysis, it provides a clear direction for further exploration and experimentation. The action is explicit and concrete, as it specifies the type of analysis to be conducted, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed knowledgeCLIP model, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting a closelyrelated analysis to test the robustness of the model, such as adding negation or changing entities in the text. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed knowledgeCLIP model should be tested for robustness by conducting a closelyrelated analysis, similar to existing work that combines text and KGs. The comment references an external work, which provides a basis for the claim that such an analysis is relevant and valuable. However, the comment does not provide specific examples or details from the referenced work, which would strengthen the claim. Therefore, the comment is 3, as it provides a logical basis for the suggestion but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to conduct a closelyrelated analysis on the proposed knowledgeCLIP model, specifically by testing its robustness with negation or changes in entities in the text. This feedback is valuable as it encourages the authors to explore and validate the robustness of their model, which could enhance the paper\"s contribution. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct this analysis, such as which negations or entity changes to consider. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to clarify how novel values in the test set are handled for clarity. This is a direct and concrete action, as it specifies a specific area that needs attention and provides a clear direction for improvement. The authors know exactly what needs to be done to enhance the clarity of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of how novel values in the test set are handled. This provides clear guidance on what the authors need to improve to enhance the clarity of their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify how novel values in the test set are handled for clarity. However, it does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where clarity is needed, specifically regarding how novel values in the test set are handled. This feedback is actionable as it directs the authors to provide more information on this aspect, which could enhance the clarity and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how similar issues have been addressed in similar works. Overall, the comment provides a clear direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors can avoid using \"1) and 2)\" by using a generic external knowledge base, as demonstrated in Figure 3. However, the reviewer acknowledges that the writing is confusing, making it unclear whether the suggestion is being implemented. The comment provides a specific action\u2014using a generic external knowledge base\u2014but lacks concrete guidance on how to implement it or address the confusion in the writing. The authors are left with a clear action but without detailed instructions on execution, making the comment 3.", "grounding_specificity_rationale": "The comment suggests using a generic external knowledge base to avoid \"1) and 2)\" as demonstrated in Figure 3. However, it acknowledges that the writing is confusing, making it difficult for the authors to determine whether this suggestion is being implemented. While the comment references \"1) and 2)\" and Figure 3, it does not specify which parts of the paper these issues are related to, making it weakly grounded. The comment is specific in suggesting a potential solution but lacks detailed guidance on how to address the confusion in the writing. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that using a generic external knowledge base can avoid \"1) and 2)\" as demonstrated in Figure 3. However, the comment acknowledges that the writing is confusing, making it difficult for the authors to determine whether the suggestion is being implemented. This lack of clarity and justification makes the claim 1, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests using a generic external knowledge base to avoid \"1) and 2)\" as demonstrated in Figure 3. However, it acknowledges that the writing is confusing, making it difficult for the authors to determine whether the suggestion is being implemented. While the comment provides a specific actionable suggestion, it lacks depth and does not offer detailed guidance on how to effectively implement this suggestion or address the confusion in the writing. The feedback is 3 as it identifies a potential solution but could be more comprehensive to fully assist the authors in improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity, the potential impact of the choice, and whether other influential losses have been considered. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues. The comment implies that the authors should provide more detailed explanations or experiments to justify their choices, but it does not specify exactly what additional information is needed or how to present it. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity, the potential impact of this choice, and whether other influential losses have been considered. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. While the questions are specific, the lack of grounding in the comment makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the methodology used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity and the potential impact of this choice. It also asks whether other influential losses have been considered, such as replacing the min with a mean or NDCG. These questions are relevant and could prompt the authors to reconsider their methodology and potentially improve the robustness of their results. However, the comment lacks specific guidance or suggestions on how to address these issues, such as recommending specific experiments or analyses. While it identifies areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of indepth analysis on experimental results, specifically questioning why improvements are limited on one dataset and significant on another. This provides a clear and direct action for the authors to take, which is to conduct a more detailed analysis of the experimental results. The comment is specific in identifying the issue and offers a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the need for an indepth analysis of the experimental results, particularly regarding the improvements of models on the offense detection dataset and the coarse stereotype set. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the limited improvements of models on the offense detection dataset and the significant improvements on the coarse stereotype set. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of indepth analysis on experimental results. It points out that the improvements of models are limited on one dataset and significant on another, which is a critical observation that could lead to a deeper understanding of the results. By highlighting this issue, the comment provides the authors with a clear direction for enhancing the analysis and interpretation of their experimental findings. However, the comment could be more helpful if it offered suggestions on how to conduct the indepth analysis or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests several actions for the authors to take, including training on labeled data, incorporating input mask explanation annotations for a few examples, and using modern backbone baselines like ResNet50 or DenseNet121 for the feature extraction layer. The reviewer also mentions that the current method may not work due to the small number of conv layers. However, the comment does not provide specific guidance on how to implement these suggestions or what specific changes should be made to the method. The action is implicit and somewhat vague, as the authors need to infer the details of how to apply these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the method of training on labeled data and incorporating input mask explanation annotations, as well as the use of modern backbone baselines like ResNet50 or DenseNet121 for the feature extraction layer. It suggests that the current method may not work due to the small number of conv layers. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the use of modern baselines and the potential limitations of the current method. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed method may not work due to the small number of conv layers and the use of modern backbone baselines like ResNet50 or DenseNet121. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to similar interventions that have failed, making it difficult for the authors to understand the basis of the skepticism. As a result, the claim is 3, as it provides a logical argument but lacks sufficient evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides several suggestions for improving the methodology, including training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines like ResNet50 or DenseNet121 for the feature extraction layer. The reviewer also points out that the current method may not work due to the small number of conv layers, which is a valid concern. However, the comment lacks specific guidance on how to implement these suggestions or what specific changes should be made to the method. While it identifies areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, as it provides some direction but could be more comprehensive to be 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method. This implies that the authors should make a comparable effort to optimize the baseline as they do for their proposed method. However, the comment does not provide specific guidance on how to achieve this or what steps to take to ensure a fair comparison. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"multiple hyperparameters\" and the \"extensive hyperparameters search,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need to ensure that the baseline is fully tuned with the same resources as the proposed method, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. While the comment highlights the extensive hyperparameters search, it lacks specific examples or references to support the claim that this is necessary. The reasoning is based on common sense, but without detailed evidence or examples, the claim is 3. The authors might need to infer the importance of this suggestion, making the comment 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the need to ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. This is a relevant point, as it highlights the importance of equalizing the conditions for a meaningful evaluation. However, the comment lacks specific guidance on how to achieve this or what steps the authors should take to ensure a fair comparison. While it points out an area for improvement, it does not provide actionable advice or detailed suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the definition of perplexity given in the paper is incorrect and suggests that it should be replaced with the correct definition. Additionally, it notes that the equation mentioned does not resemble perplexity but instead appears to be crossentropy. While the comment provides explicit guidance on what needs to be corrected, it does not offer specific suggestions on how to revise the definition or equation to ensure accuracy. The action is clear but lacks concrete details on how to implement the correction, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is incorrect about the definition of perplexity and the equation mentioned, providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the definition of perplexity given in the paper is incorrect and suggests that it should be replaced with the correct definition. The reviewer also notes that the equation mentioned does not resemble perplexity but instead appears to be crossentropy. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific error in the paper regarding the definition of perplexity, noting that it is not correctly defined. It also points out that the equation mentioned does not resemble perplexity but instead appears to be crossentropy. This feedback is clear and actionable, as it provides the authors with specific guidance on how to correct the errors in their work. By addressing these issues, the authors can improve the accuracy and clarity of their paper. However, the comment could be more helpful if it offered suggestions on how to revise the definition or equation to ensure correctness. Overall, the comment is 4 as it directs the authors to a critical area needing correction, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should add more baselines of graph contrastive learning and test them on common datasets. This is a clear and direct action for the authors to take, as it specifies the exact improvement needed and provides a concrete direction for testing. The comment is specific and provides a concrete action for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"graph classification task\" and the \"compared baseline,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the missing baselines, such as MVGRL[4] and gptgnn[5], and suggests adding more baselines of graph contrastive learning. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline for the graph classification task is insufficient, specifically mentioning the absence of MVGRL[4] and gptgnn[5]. However, the comment does not provide any supporting evidence or reasoning to justify why these baselines are necessary or how their inclusion would improve the study. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the insufficiency of the baseline for the graph classification task. It points out the absence of certain baselines, such as MVGRL[4] and gptgnn[5], and suggests that the authors should add more baselines of graph contrastive learning and test them on common datasets. This feedback is clear and actionable, as it provides a concrete direction for improvement by suggesting specific additions and tests that could enhance the robustness and comprehensiveness of the study. However, the comment could be more helpful if it explained why these additional baselines are important or how they might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern with the evaluation of the proposed strategies, specifically mentioning the need to test the defense against an adversarial attack. It suggests that the defense should be evaluated against adversarial examples that produce minimal structural alterations to the edge map but mislead the model predictions. However, the comment does not provide specific guidance on how to implement this evaluation or what specific aspects of the defense should be tested. The action is implicit and somewhat vague, as the authors need to infer the details of how to conduct the evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation of the proposed strategies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation, namely the need to test the defense against an adversarial attack that produces minimal structural alterations to the edge map but misleads the model predictions. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of the proposed strategies is insufficient, specifically mentioning the need to test the defense against an adversarial attack that produces minimal structural alterations to the edge map but misleads the model predictions. The comment provides a logical reasoning by highlighting the potential vulnerability of the defense against such attacks. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the need for this evaluation themselves, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern with the evaluation of the proposed strategies, specifically the need to test the defense against an adversarial attack that produces minimal structural alterations to the edge map but misleads the model predictions. This is a crucial point that could significantly impact the effectiveness of the defense strategies. However, the comment lacks specific guidance on how to implement this evaluation or what specific aspects of the defense should be tested. While it highlights an important area for improvement, the lack of detailed instructions makes it 3. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the provided analysis seems weak in light of theoretical work on sampling and particlebased optimization methods. It specifically mentions the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more detailed information about the solution and discretization, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not offer specific guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the theoretical work on sampling and particlebased optimization methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the analysis, specifically mentioning the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the provided analysis is \"somewhat weak\" due to the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). This claim is 3 as it references theoretical work on sampling and particlebased optimization methods, which provides a basis for the expectation of detailed analysis. However, the comment lacks specific references to that theoretical work or examples of what should be included in the analysis. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper\"s analysis is considered weak, namely the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). This feedback is clear and actionable, as it points out specific gaps in the analysis that need to be addressed to strengthen the paper. By highlighting these areas, the comment provides the authors with a clear direction for improving the draft. However, it could be more helpful if it offered suggestions on how to address these gaps or provided examples of how similar issues have been addressed in related works. Overall, the comment is 4 as it guides the authors toward improving the rigor and comprehensiveness of their analysis."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the quality of generated images by the proposed method, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the realism of the generated images or suggestions for potential improvements. As a result, the authors are left without any clear direction on how to enhance the quality of their results. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of generated images by the proposed method, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. However, it does not specify which part of the paper or supplemental material this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of limited realism in the generated images, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of generated images by the proposed method is limited, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the quality of generated images by the proposed method, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. This feedback is 3 as it highlights an area for improvement, but it lacks specific suggestions or guidance on how to address the issue. The authors are informed of a potential weakness but are not provided with actionable steps to enhance the realism of their generated images. Therefore, the comment is 3, as it points out a problem but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to describe the size and elements of G, which is the graph used in the DGCN model. It also suggests adding the dimensions of G, X, and W to provide a better understanding of the model. These actions are clear and concrete, as they specify exactly what needs to be added or clarified in the paper. The authors know exactly what steps to take to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the description of G, the size and elements of G, and the dimensions of G, X, and W. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the construction of G in Section 3.3 and suggests that it would be better to describe the size and elements of G. It also recommends adding the dimensions of G, X, and W to enhance understanding. While the comment identifies a potential gap in the explanation, it does not provide specific examples or references to support the claim that these details are necessary. The suggestion is logical but lacks detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where additional clarity is needed, specifically regarding the construction of G in Section 3.3. It suggests that the authors should describe the size and elements of G and provide the dimensions of G, X, and W to enhance understanding. This feedback is clear and actionable, as it directs the authors to add specific details that could improve the clarity and comprehensibility of their work. By addressing these points, the authors can significantly enhance the reader\"s ability to understand the DGCN model and its components. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the statement regarding Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest how the authors should address this discrepancy or improve their draft. As a result, the authors are left without any guidance on how to respond to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 559560,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the statement regarding Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement regarding Cycle Consistency loss is not entirely true, as it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy in the paper regarding the Cycle Consistency loss, specifically noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. This is a clear and actionable point that the authors can address to improve the accuracy and completeness of their work. However, the comment could be more helpful if it provided additional context or examples to explain the implications of this discrepancy or suggested ways to clarify the statement. Overall, the comment is 4 as it points out a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the term \"hyperspectral\" is confusing, as it is not a standard term in the field of hyperspectral imaging. The reviewer suggests that the authors should clarify or replace the term with a more appropriate one. While the comment provides a clear suggestion for improvement, it does not offer specific guidance on how to address the issue, such as recommending alternative terms or explaining the context in which the term is used. The action is explicit but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"hyperspectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term, explaining that it is confusing and not standard in the field of hyperspectral imaging. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the term \"hyperspectral\" is confusing, as it is not a standard term in the field of hyperspectral imaging. The reviewer provides a definition of hyperspectral imaging, which is a clear and accurate explanation. However, the comment could be strengthened by providing a specific example or context in which the term \"hyperspectral\" is used, which would further substantiate the claim. Despite this, the comment is 4 due to the clear definition of hyperspectral imaging and the logical reasoning behind the claim.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper by pointing out that the term \"hyperspectral\" is not a standard term in the field of hyperspectral imaging. It provides a clear and concise explanation of what hyperspectral imaging is, which helps the authors understand the issue and make a correction. The comment is actionable as it suggests that the authors should clarify or replace the term with a more appropriate one, which is a straightforward suggestion that can improve the clarity and accuracy of the paper. However, the comment could be more helpful if it offered suggestions on how to address the issue in a more detailed manner, such as by providing alternative terms or explaining the context in which the term is used. Overall, the comment is 4 as it provides clear guidance on how to improve the draft, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more detailed information about how each component contributes to the final performance improvements. It specifically mentions that ablation studies in Sections 3 and 4 demonstrate the effectiveness of each component, but the comment implies that a more detailed explanation is needed. While the action is implicit, it is concrete because it specifies what additional information is needed (e.g., how the performance of combining the Linformer and window attention in Big Bird is improved). Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"1), 2) and 3) mentioned above,\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the contribution of each component to the final performance improvements. This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more detailed information about how each component contributes to the final performance improvements. While it mentions ablation studies in Sections 3 and 4, it does not provide specific examples or detailed reasoning to support why this additional information is necessary. The claim is 3 as it highlights a potential gap in the paper, but it lacks the necessary evidence or detailed explanation to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed information about how each component contributes to the final performance improvements. It references ablation studies in Sections 3 and 4, which is a clear indication of where the authors can enhance their explanation. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to present this information. While it highlights a critical area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific gaps in the paper regarding the details of the models, particularly the grammar over kernels and the probabilities associated with it. It explicitly asks for clarification on how the approach is applied in practice, including inference. The comment provides a clear and concrete action for the authors to take, which is to provide more detailed explanations of these aspects. This guidance is explicit and specific, leaving no ambiguity about what needs to be addressed to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"grammar over kernels\" and the \"probabilities associated with the grammar,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detail in explaining the grammar over kernels and the probabilities associated with it, as well as how inference is performed. This provides clear guidance on what needs to be clarified or expanded in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of detail in the explanation of the \"grammar over kernels\" and the probabilities associated with it, which makes it difficult to understand how the approach is applied in practice. The reviewer questions how inference is performed and suggests that these details are likely important for clarity. However, the comment does not provide specific examples or references to support the claim that these details are necessary or how they would improve the clarity of the paper. This makes the claim 3, as it provides a logical basis for the concern but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the authors have not provided sufficient detail, namely the explanation of the \"grammar over kernels\" and the probabilities associated with it. It questions how inference is performed and suggests that these details are crucial for understanding the approach in practice. By pointing out these gaps, the comment provides actionable feedback that can help the authors improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar approaches have been explained in the literature. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of clarity on the role of visual information, the absence of explicit verification in the ablation study, and the questionable significance of the experiment results due to the sample size. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the role of visual information, verify the effectiveness of the ablation study, and ensure that the experiment results are significant. The lack of concrete steps or suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 10\" and \"w/o perception module and w perception,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the ablation study, the lack of verification, and the questionable significance of the experiment results due to the sample size. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the role of visual information is unknown, questioning the effectiveness of the ablation study and the significance of the experiment results due to the sample size. The comment provides some support by mentioning that the w/o perception module and w perception exhibit similar performance, which suggests that the perception module might not be necessary. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the effectiveness of the ablation study or the significance of the experiment results. This makes the claim 3, as it provides some evidence but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of clarity on the role of visual information, the absence of explicit verification in the ablation study, and the questionable significance of the experiment results due to the sample size. It highlights specific concerns, such as the performance of the w/o perception module and w perception, and the implementation detail of w/o perception. While the comment provides some insight into potential weaknesses, it lacks detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out areas that need attention, but it could be more beneficial with additional suggestions or examples on how to improve the draft. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening, but it does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This implies that the authors should include references to these works to provide a more comprehensive comparison. The comment is explicit in its request for inclusion of these references, making it clear and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the end of Section 4.2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of references to previous works on Lasso screening, such as Ren et al. (2017), and suggests including these references for a more comprehensive comparison. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening, but it does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This claim is 3 as it highlights a potential omission in the paper\"s references, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to conduct further research to verify the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening but does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This feedback is clear and actionable, as it points out a gap in the literature review that the authors can address by including these references. By addressing this issue, the authors can enhance the comprehensiveness and credibility of their work. However, the comment could be more helpful if it provided additional guidance on how to effectively integrate these references into the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the model has many components whose hyperparameters are not fully provided, suggesting that someone may need to trace them in the source code. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve the documentation. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed information about the hyperparameters. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the model, noting that many components have hyperparameters that are not fully provided. However, it does not specify which components or hyperparameters are in question, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors should improve the documentation. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the model has many components whose hyperparameters are not fully provided, suggesting that someone may need to trace them in the source code. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the model, noting that many components have hyperparameters that are not fully provided. This is a relevant observation that could impact the reproducibility and clarity of the paper. However, the comment lacks depth and does not provide actionable guidance or suggestions on how the authors might address this issue, such as recommending specific improvements or providing examples of how to better document the hyperparameters. As a result, the comment is 3, as it points out a potential problem but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the notation for results is not clear, specifically mentioning that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This feedback implies that the authors should clarify the meaning of \"%p\" in their results notation. However, the comment does not provide specific guidance on how to address this issue, such as suggesting a possible explanation or alternative notation. While the action is implicit, it is clear that the authors need to clarify the notation, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"notation for results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, pointing out that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation for results is not clear, specifically mentioning that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This claim is 3 as it highlights a potential issue with the clarity of the results notation, but it lacks specific examples or references to support the claim that \"%p\" is unclear. The authors might need to provide additional context or clarification to fully address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the results notation, particularly regarding the use of \"%p\" without further explanation. This feedback is clear and actionable, as it directs the authors to clarify the meaning of \"%p\" in their results, ensuring that readers can understand the improvement claimed for CIFAR10. By addressing this issue, the authors can enhance the transparency and accessibility of their results, making the comment 4. However, it could be more helpful if it provided suggestions on how to clarify the notation or offered examples of alternative notations. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make. The comment lacks concrete suggestions or detailed instructions on how to improve the evaluation, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where the human evaluation is discussed, the comment lacks full grounding. It is specific in its critique of the use of an automatic metric, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of an automatic metric (TSS) in the human evaluation, suggesting that it weakens the convincingness of human evaluation. However, the comment does not provide any supporting evidence, reasoning, or references to justify why an automatic metric is less convincing than a human metric. Without such justification, the claim remains 1, as it lacks the necessary information to support the claim. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. This feedback highlights a potential weakness in the evaluation methodology, which could impact the credibility of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what alternative human metrics could be used. While it identifies a potential problem, it lacks depth and actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would be strengthened by including experiments across more diverse domains, specifically mentioning those in TDMPC 2. While the comment implies that the authors should expand their experiments to include more diverse domains, it does not provide explicit instructions on how to do so or which specific domains to consider. The action is implicit and somewhat vague, as the authors need to infer the need for more diverse experiments and determine which domains to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments prove the point made by the authors and recommends expanding the experiments to include more diverse domains, specifically mentioning those in TDMPC 2. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of more diverse domains, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments prove the authors\" point effectively but recommends expanding the experiments to include more diverse domains, specifically mentioning those in TDMPC 2. This claim is 3 as it provides a logical reasoning for expanding the experiments to enhance the paper\"s impact. However, it lacks specific examples or detailed justification for why these additional domains are necessary or how they would contribute to the paper. The suggestion is somewhat supported by the mention of TDMPC 2, but further elaboration would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the experiments effectively prove the point made by the authors but recommends expanding the experiments to include more diverse domains, specifically mentioning those in TDMPC 2. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional experiments to enhance the paper\"s impact. However, the comment lacks specific guidance on how to implement this suggestion or which specific domains should be considered. While it provides a direction for improvement, it could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on what specific aspects of the interpretability tax should be evaluated or how the evaluation should be conducted. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment points out that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine where to address this issue. Additionally, the comment lacks specificity regarding what aspects of the interpretability tax should be evaluated or how it should be measured. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area where the paper could be improved, noting that it does not evaluate the magnitude of the interpretability tax associated with the method. This is a relevant point as interpretability is an important aspect of many machine learning applications. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. Without actionable advice or examples, the authors may find it challenging to understand and implement the necessary changes. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the main contribution of the paper is not in proposing novel techniques but rather in demonstrating that a simple combination of existing techniques can achieve surprisingly good accuracy. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. The authors are left without guidance on how to address this feedback or what specific changes could be made to enhance the novelty or contribution of their work. As a result, the comment lacks actionability, making it 1.", "grounding_specificity_rationale": "The comment discusses the simplicity of the LUQ design and the standard nature of the approaches presented in Section 5, suggesting that the main contribution is in demonstrating the effectiveness of a simple combination of existing techniques. However, it does not specify which part of the paper this discussion pertains to, such as the sections on the LUQ design or the approaches presented in Section 5. The comment lacks grounding, as it does not specify where in the paper these issues are discussed. Additionally, it is not specific about what needs to be addressed or improved regarding the contribution or the existing techniques. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the LUQ design is straightforward and that the approaches in Section 5 are standard and explored in previous literature. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 1, as it lacks the necessary support to substantiate the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the straightforward nature of the LUQ design and the standard approaches presented in Section 5, suggesting that the main contribution of the paper is in demonstrating the effectiveness of a simple combination of existing techniques. However, it does not provide specific suggestions or guidance on how the authors could enhance the novelty or contribution of their work. The comment lacks actionable feedback or constructive advice, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as 2, as it identifies a limitation but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. While it implies that the authors should provide these losses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include training losses in their analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for training losses, but without clear grounding, it is difficult for the authors to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. However, it does not present any claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The authors are left with a vague request to provide training losses, but without detailed instructions or examples, this feedback is 3 as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the relevance of the proposed method to the authors\" motivations, specifically mentioning that automatic scores are not effective and human evaluation scores are not affordable. It also questions the applicability of the framework FFAEVAL and similar frameworks like Chatbot Arena for evaluating a single dialogue system. The reviewer suggests that these arenabased evaluation systems may not solve the problems of current scorebased evaluation systems. While the comment identifies potential issues, it does not provide explicit guidance on how the authors should address these concerns or what specific changes should be made to improve the evaluation. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider the relevance and applicability of their method in the context of current evaluation systems. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract section\" and the \"proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the relevance of the proposed method to the authors\" motivations, particularly regarding the use of automatic scores and human evaluation scores. The comment further explains why it believes arenabased evaluation systems may not be suitable for evaluating a single dialogue system, providing a clear rationale for the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method may be less relevant to the authors\" motivations, specifically questioning the applicability of the framework FFAEVAL and similar frameworks like Chatbot Arena for evaluating a single dialogue system. The reviewer provides a logical reasoning by explaining that arenabased evaluation systems may not solve the problems of current scorebased evaluation systems. However, the comment lacks specific examples or references to support the claim that automatic scores are not effective or that human evaluation scores are not affordable. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the relevance of the proposed method to the authors\" motivations, specifically questioning the applicability of the framework FFAEVAL and similar frameworks like Chatbot Arena for evaluating a single dialogue system. It suggests that these arenabased evaluation systems may not solve the problems of current scorebased evaluation systems. While the comment highlights a potential weakness, it lacks specific suggestions or guidance on how the authors might address this issue or improve their evaluation approach. The feedback is 3 as it points out a potential limitation but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed compared to other methods. The reviewer suggests that this could result in unfair comparisons. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their training approach or provide additional context to justify the use of 2x samples. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RegMixup\" and \"training,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed and unfair comparisons. The comment provides a clear direction for the authors to address the issue of running speed and potential unfair comparisons. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to a slow running speed and unfair comparisons. The reviewer supports this claim by referencing the authors\" claim of a 1.5x slower running speed compared to other methods. However, the comment lacks specific examples or references to substantiate the claim further, such as detailed comparisons with other methods or specific data to support the claim of a 2x sample rate. This makes the claim 3, as it provides some evidence but could be strengthened with additional details. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed and unfair comparisons. This is a relevant observation that could impact the validity of the results and comparisons made in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a potential problem, it does not offer actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to verify whether the improvements of the proposed model over the RL without feedback model are statistically significant. This is a clear and direct action for the authors to take, as it provides a specific task to ensure the robustness of their findings. The comment is concrete in its request for statistical verification, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"row3 vs. row4 in table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the verification of the proposed model\"s improvements over the RL without feedback model. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed model\"s improvements over the RL without feedback model are not statistically significant, specifically mentioning the comparison between rows 3 and 4 in Table 6. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the proposed model\"s improvements over the RL without feedback model, noting that the improvements are not statistically significant as evidenced by the comparison between rows 3 and 4 in Table 6. The comment suggests that the authors verify if these improvements are statistically significant, providing a clear and actionable piece of feedback. This guidance is valuable as it directs the authors to a specific area that needs further investigation, ensuring that their findings are robust and reliable. However, the comment could be more helpful if it included additional context or examples of how to conduct the statistical verification. Overall, the comment is 4 as it effectively points out a potential weakness and offers a constructive suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about relaxing the need to visit all ballaction pairs with each iteration and suggests exploring partial coverage. However, it does not provide explicit guidance or suggestions on how to address this issue or what specific actions the authors should take. The comment is vague and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"in continuation to the above remark,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how to relax the need to visit all ballaction pairs with each iteration and what would happen if partial coverage is considered. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about relaxing the need to visit all ballaction pairs with each iteration and suggests exploring partial coverage. While it raises an interesting point, it lacks specific guidance or suggestions on how to address this issue or what specific assumptions might be needed. The comment is 3 as it prompts the authors to consider alternative approaches, but it does not provide actionable steps or detailed insights that would help the authors improve their draft. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about whether the observed improvement could be achieved with a better encoder, specifically mentioning RoBERTabase instead of BERT. While it does not explicitly instruct the authors to use RoBERTabase, the implication is clear that they should consider this option. The comment is 3 as it provides a concrete suggestion for improvement but lacks explicit guidance on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the observed improvement could be achieved with a better encoder, specifically mentioning RoBERTabase instead of BERT. However, it does not specify which part of the paper this improvement is discussed in, making it weakly grounded. The comment is specific in suggesting a potential alternative encoder, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point poses a question about whether the observed improvement could be achieved with a better encoder, specifically mentioning RoBERTabase instead of BERT. However, it does not provide any supporting evidence, reasoning, or references to justify why RoBERTabase might be a better choice. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment raises a question about the potential improvement in the observed results with a better encoder, specifically mentioning RoBERTabase as an alternative to BERT. This is a relevant point that could prompt the authors to consider alternative models for their encoder, which could potentially enhance the performance of their system. However, the comment lacks depth and does not provide specific guidance or suggestions on how to implement this change or what specific aspects of the current model might be limiting its performance. While it points out a potential area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a relevant area for consideration but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. This is an explicit action, as it clearly specifies the need for additional datasets to be included in the paper. The comment is concrete because it provides specific examples of datasets that the authors should consider, which gives them a clear direction on what to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests adding more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of additional datasets, but without explicit grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed technique should be evaluated on more datasets, specifically mentioning XNLI and XTREME, to demonstrate its generalizability to tasks with different levels of reasoning requirements. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these datasets are particularly relevant or how they would impact the evaluation of the technique. Without additional context or explanation, the claim remains 3, as it lacks detailed justification or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. This feedback is 3 as it identifies a specific area for improvement by recommending additional datasets to test the technique. However, the comment lacks depth and does not provide detailed guidance on how to select or analyze these datasets, nor does it explain why these specific tasks are important for demonstrating generalizability. While the suggestion is actionable, the comment could be more helpful with additional context or suggestions on how to effectively incorporate the new datasets. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the choice of baseline methods could be improved, specifically recommending RefNeRF and MipNerf as potential baselines for evaluating the appearance decomposition part and larger outdoor scenes, respectively. While the comment provides specific examples of potential baselines, it does not explicitly instruct the authors to use these methods or explain how to incorporate them into their evaluation. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the choice of baseline methods could be improved, specifically recommending RefNeRF and MipNerf as potential baselines for evaluating the appearance decomposition part and larger outdoor scenes, respectively. However, it does not specify which part of the paper these suggestions pertain to, such as a specific section or experiment where these baselines could be applied. The authors can infer that it relates to the evaluation or comparison sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting potential baselines. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the choice of baseline methods could be improved by comparing with other existing methods, such as RefNeRF and MipNerf. While the comment provides specific examples of potential baselines, it lacks detailed justification or evidence to support why these methods are particularly suitable for the evaluation. The suggestion is based on common knowledge about existing methods, but without further explanation or references, the authors may find it challenging to fully understand and implement the suggestion. Therefore, the comment is 3, as it provides a starting point but requires more detailed justification to be fully actionable.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the choice of baseline methods could be improved by comparing with other existing methods, such as RefNeRF and MipNerf. This suggestion is based on common knowledge about existing methods and their suitability for specific tasks, which is a valuable point for the authors to consider. However, the comment could be more helpful if it explained why these specific methods are particularly relevant or how they might enhance the evaluation. Despite this, the feedback is 4 as it directs the authors to consider alternative baselines that could improve their evaluation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the lack of implementation details of the proposed methods is a concern and suggests that these details should be included in Section 4.1. This provides a clear and direct action for the authors to take, specifying where the details should be added and what needs to be included. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of implementation details of the proposed methods. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of implementation details of the proposed methods is a concern and suggests that these details should be included in Section 4.1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these details are necessary or how they would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the lack of implementation details of the proposed methods, which is a critical aspect of the paper. It suggests that these details should be included in Section 4.1, providing a clear and actionable suggestion for improvement. This feedback is valuable as it directs the authors to a specific area where their draft could be strengthened, ensuring that the implementation details are transparent and accessible to readers. However, the comment could be more helpful if it offered additional guidance on how to present these details or what specific aspects should be included. Overall, the comment is 4 as it effectively points out a critical area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the lack of empirical evaluation and comparison with other methods, indicating that the theoretical contributions may be significant but are not adequately demonstrated in the paper. It suggests that the authors should provide empirical evaluation and comparisons with other methods to clarify the practical value of their contributions. The comment is explicit in its request for additional empirical work and comparisons, providing concrete guidance on what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights the lack of empirical evaluation and comparison with other methods, indicating that the theoretical contributions may be significant but are not adequately demonstrated in the paper. It suggests that the authors should provide empirical evaluation and comparisons with other methods to clarify the practical value of their contributions. However, the comment does not specify which sections or parts of the paper should include these evaluations or comparisons, making it weakly grounded. The comment is specific in its critique of the lack of empirical evaluation and comparison, but without explicit references to sections or elements, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation and comparison with other methods, which is a significant issue. The reviewer highlights the lack of clarity regarding the practical value of the theoretical contributions, suggesting that even a theoretical paper should provide some rationale for its significance. The comment is 3 as it identifies a gap in the paper\"s evaluation and comparison, but it does not provide specific examples or references to support the claim. The authors would need to make a significant effort to address this issue, making the comment 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the lack of empirical evaluation and comparison with other methods. It highlights the absence of any practical value demonstration, even in a theoretical context, and suggests that the theoretical contributions may be significant but are not adequately presented. The comment provides a clear and actionable suggestion for improvement by recommending the inclusion of empirical evaluation and comparisons with other methods. This feedback is valuable as it guides the authors to enhance the clarity and impact of their theoretical contributions. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that in the manuscript, P is used to represent a probability but is also used for a cumulative distribution function, leading to confusion. This feedback implies that the authors should clarify the use of P in these instances to avoid confusion. However, the comment does not provide specific guidance on how to address this issue, such as suggesting a change in notation or clarifying the context in which P is used. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the clarity of their manuscript. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the manuscript, including \"P mostly represents a probability but sometimes for a cumulative distribution function (e.g., Eqs. (3) and (4) and L44, all in Appendix), which leads to confusion.\" This allows the authors to accurately identify the parts of the manuscript being addressed. The comment is also specific because it clearly specifies the issue of using P for both probability and cumulative distribution functions, which leads to confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that in the manuscript, P is used to represent a probability but is also used for a cumulative distribution function, leading to confusion. This claim is 3 as it provides a specific example (P used in Eqs. (3) and (4) and L44) to illustrate the confusion. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why this confusion is problematic or how it affects the understanding of the manuscript. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript, noting that P is used to represent a probability but is also used for a cumulative distribution function, leading to confusion. This feedback is clear and actionable, as it points out a specific area where the manuscript could be improved by clarifying the use of P. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a change in notation or explaining the context in which P is used. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include other baselines, such as those mentioned in related work [29, 5, 6]. It also mentions that the authors have addressed the reviewer\"s weakness points and that all unclear parts have been answered. The reviewer provides a specific suggestion to include the explanation of why the chosen baseline makes the most sense. However, the comment does not explicitly instruct the authors to add this explanation or provide guidance on how to integrate it into the paper. While the action is implied, it is not as concrete as it could be, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including other baselines, such as those mentioned in related work [29, 5, 6]. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of these baselines and providing a rationale for why they would be beneficial. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that other baselines should be included, such as those mentioned in related work [29, 5, 6]. However, it does not provide any specific reasoning or evidence to support why these baselines are necessary or how they would enhance the study. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1, as it does not provide sufficient evidence or reasoning to support the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that other baselines should be included, such as those mentioned in related work [29, 5, 6]. This feedback is 3 as it identifies a potential area for improvement by suggesting additional comparisons that could strengthen the study. However, the comment lacks specific guidance on how to incorporate these baselines or why they are particularly relevant. While it points out a potential enhancement, it does not provide detailed instructions or examples on how to implement this suggestion. Therefore, the comment is 3, as it offers a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the uniform setting of \u03b1_m in line 113, noting that it implies the contributions from all modalities are the same. The reviewer suggests that dynamically weighting the modalities is important, as demonstrated in multimodal fusion works. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors are left to infer that they should consider dynamically weighting the modalities but without detailed instructions on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 113,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the uniform setting of \u03b1_m and suggests that dynamically weighting the modalities is important in multimodal fusion. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that setting \u03b1_m uniformly to 1/M implies that the contributions from all modalities are the same, which is not accurate. The reviewer supports this claim by referencing works in multimodal fusion that demonstrate the importance of dynamically weighting modalities. This reference provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to these works, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the uniform setting of \u03b1_m in line 113, noting that it implies the contributions from all modalities are the same. This is a relevant observation that could impact the validity and applicability of the work. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative weighting methods or discussing the implications of this uniform setting. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in Figure 1. While this is an observation that the authors should be aware of, it does not provide explicit guidance on how to correct this inconsistency. The action is implicit, as the authors need to identify and correct the discrepancy themselves, but it is vague because it lacks concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the discrepancy between the labeling of the task loss in the text and the figure, providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in Figure 1. This is a factual observation that does not require any subjective interpretation or judgment. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in Figure 1. This is a minor but important detail that could confuse readers, especially if they are not familiar with the notation. While the comment points out the issue, it does not provide suggestions on how to resolve it or explain the significance of this discrepancy. The feedback is 3 as it highlights a potential source of confusion, but it could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific aspects of the method should be considered for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the network depth is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the method\"s limitations should be addressed or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking about the limitations of the method, specifically regarding the depth of the network in the graph case. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. This is a relevant point that could prompt the authors to consider the depth of their network and its implications for the method\"s effectiveness. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of the method should be considered for improvement. While it identifies a potential area for exploration, it does not offer actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the work should be evaluated in machine translation, which is seen as a more convincing approach due to its lower uncertainty per word. While the comment implies that the authors should consider evaluating their method in machine translation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider this evaluation method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the work should be evaluated in machine translation, which is a specific suggestion for improvement. However, it does not specify which part of the paper this evaluation should be included in, such as the results or discussion sections. The authors can infer that it relates to the evaluation section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the work only uses answer generation and summarization, which are considered \"close to open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the method in machine translation would be more convincing due to its lower uncertainty per word. However, the comment lacks specific examples or references to support the claim that machine translation is a more convincing evaluation method. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization tasks, which are considered \"close to open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the method in machine translation, which exhibits lower uncertainties per word, would be more convincing. This feedback is 3 as it points out a potential weakness in the evaluation approach and suggests an alternative that could strengthen the paper. However, the comment could be more helpful if it provided specific examples or references to support the claim about the benefits of machine translation for evaluating the proposed method. Overall, the comment offers a clear direction for improvement but lacks depth and detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the dropout method used in the paper, specifically regarding the dropping rate and the number of masks generated. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"dropout\" and \"multiple stochastic masks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the dropping rate and the number of masks generated, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the dropout method used in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the dropout method used in the paper, specifically regarding the dropping rate and the number of masks generated. By asking for clarification on these aspects, the comment prompts the authors to provide more detailed information about their methodology, which could enhance the transparency and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how similar methods have been presented in the literature. Overall, the comment is 3 as it identifies a critical area for clarification but lacks depth and actionable guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the effectiveness of the proposed twostage optimization approach needs further justification. It suggests that comparisons with other singlestage attacks and benchmarks with other stateoftheart (SOTA) algorithms are necessary to demonstrate the effectiveness. This feedback provides clear and concrete actions for the authors to take, such as including comparisons and benchmarks to support their claims. The explicit nature of the suggestions and the detailed guidance on what needs to be added make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed twostage optimization approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for further justifications, comparisons with other singlestage attacks, and benchmarks with other SOTA algorithms to demonstrate the effectiveness of the technical contributions. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed twostage optimization approach needs further justification. It suggests that showing only the performance drop on fusion models is insufficient and that comparisons with other singlestage attacks are necessary to demonstrate effectiveness. The reviewer also states that without proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms, it is difficult to justify the technical contributions. This claim is 3 as it provides a logical argument for the need for additional comparisons and benchmarks. However, it lacks specific examples or references to support the claim, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the need for further justification of the proposed twostage optimization approach. It suggests that showing only the performance drop on fusion models is insufficient and that comparisons with other singlestage attacks and benchmarks with other stateoftheart (SOTA) algorithms are necessary to demonstrate the effectiveness. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance their paper by including additional comparisons and benchmarks. By addressing these points, the authors can significantly improve the clarity and robustness of their technical contributions. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not specify the type of GPUs used for testing or the inference time. This is an explicit observation that the authors can directly address by including this information in their draft. The comment provides a clear and concrete action for the authors to take, ensuring that they know exactly what needs to be added to improve their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the absence of information about the type of GPUs used for testing and the inference time, allowing the authors to accurately identify the part of the paper being addressed. It specifies what needs to be added, namely the type of GPUs and inference time, providing clear guidance on what needs to be included in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not provide information about the type of GPUs used for testing or the inference time. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, noting the lack of information about the type of GPUs used for testing and the inference time. This is a clear and actionable point that the authors can address to improve the transparency and reproducibility of their results. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details should be included. Overall, the comment is 3 as it highlights an important area for improvement but lacks depth in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the monotonic increase in performance of RSD4PG with respect to \u03bb values in Table 1 and the missing symbols \"J o b j \u03c0 ( \u03b8 )\" and \"\u03c4\" in the bracket on Page 3, Line 2, and the missing \"s\"\" in the bracket on Line 4 in the paragraph about D4PG. While the comment identifies specific issues, it does not provide explicit instructions on how to address them. The authors can infer that they need to correct the table and the paragraph, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1\" and \"Page 3, Line 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the monotonic increase in performance of RSD4PG with respect to \u03bb values and the missing symbols \"J o b j \u03c0 ( \u03b8 )\" and \"\u03c4\" in the bracket on Page 3, Line 2, and the missing \"s\"\" in the bracket on Line 4 in the paragraph about D4PG. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point makes a claim about the monotonic increase in performance of RSD4PG with respect to \u03bb values in Table 1 and questions what happens when \u03bb is even smaller. The reviewer also points out missing symbols and references in the text. However, the comment lacks specific examples or detailed reasoning to support these claims, making it 3. The authors would need to further investigate and address the issues themselves, which is why the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues in the paper, such as the monotonic increase in performance of RSD4PG with respect to \u03bb values in Table 1 and the missing symbols \"J o b j \u03c0 ( \u03b8 )\" and \"\u03c4\" in the bracket on Page 3, Line 2, and the missing \"s\"\" in the bracket on Line 4 in the paragraph about D4PG. This feedback is clear and actionable, as it directs the authors to correct these errors and improve the clarity of their work. However, the comment could be more helpful if it provided suggestions on how to address these issues or explained why they are important. Overall, the comment is 4 as it effectively points out areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that a specific sentence is confusing and suggests that the authors should clarify it. However, it does not provide any explicit guidance on how to improve the sentence or what specific changes should be made to make it clearer. The authors are left to infer that they need to revise the sentence, but without concrete instructions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific sentence, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the sentence, which is that it is confusing and not immediately obvious. However, the comment does not provide specific guidance on how to clarify the sentence or what aspects are confusing. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that a specific sentence is confusing and suggests that the authors should clarify it. However, the comment does not provide any reasoning, examples, or references to support why the sentence is confusing or how it could be clarified. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific sentence that is confusing and suggests that the authors should clarify it. While it highlights a potential issue with the clarity of the text, it does not provide detailed guidance or suggestions on how to improve the sentence or what specific aspects are confusing. The comment is 3 as it points out a potential weakness, but it lacks depth and actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several instances where citations are missing or needed, specifically in lines 7879, 129130, 156158, and 217218. While it identifies these areas, it does not provide explicit instructions on how to include the missing citations or what specific references should be used. The actions are implicit and somewhat vague, as the authors need to infer that they should include citations but are not given specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the need for citations in lines 7879, 129130, 156158, and 217218. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of claims that require specific citations to support the assertions. For example, the claim about diffusion models outperforming generative adversarial networks is not substantiated with a reference. Similarly, the claim about previous work having limited success is also unsupported. The reviewer requests citations for these claims, which would provide the necessary evidence to support the claims. Therefore, the comment is considered 1 due to the lack of supporting evidence or references.", "helpfulness_rationale": "The review comment identifies specific areas where citations are missing or needed, which is a clear and actionable piece of feedback. It highlights specific lines in the paper where references should be included, providing the authors with a concrete list of places to improve their draft. However, the comment could be more helpful if it offered suggestions on which specific works or references might be relevant for each of these citations. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between Figures 1 and 2, specifically noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This feedback implies that the authors should reconcile these figures to ensure consistency. However, the comment does not provide explicit instructions on how to address this issue, such as suggesting specific changes or clarifications. While the action is implied, it lacks concrete guidance on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the figures, noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Fig 1 is inconsistent with Fig 2, specifically noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This claim is 3 as it highlights a discrepancy between the figures, but it lacks detailed explanation or justification for why this inconsistency is problematic or how it affects the paper\"s overall argument. The authors would need to further investigate and address the issue to fully understand and resolve the discrepancy. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between Figures 1 and 2, noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This feedback highlights an inconsistency in the figures, which could be confusing for readers and may affect the clarity of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending changes to the figures or explaining the rationale behind the discrepancy. While it points out a potential problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. While it highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should clarify or modify the description of N_l^(s) to ensure that each node can attend to its own lowerlevel representation, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the ability of each node to attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. This is a relevant point that could impact the understanding and interpretation of the model. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify the description. While it identifies a potential area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about how the inequality after line 433 follows from Lemma 7. It suggests that the authors should clarify how Lemma 7 is applied to this inequality. While the comment implies that the authors should provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 433\" and \"Lemma 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the inequality after line 433 follows from Lemma 7, and it suggests that the authors should clarify how Lemma 7 is applied. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on how an inequality follows from a lemma. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the logical connection between an inequality after line 433 and Lemma 7. It suggests that the authors should clarify how Lemma 7 is applied to this inequality, which could enhance the clarity and understanding of the paper. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to address this issue. The authors are given a direction to consider but are left to determine the exact steps to take. Therefore, the comment is 3, as it points out a potential area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several areas where the paper\"s main contribution is unclear, specifically regarding the novel properties of the proposed method and how it copes with dynamic largescale multitasking. It points out that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to clarify the main contribution. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations and evidence to support their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, specifically the novel properties of the proposed method and how it copes with dynamic largescale multitasking. It points out that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the clarity of the main idea and the automation process. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear, specifically regarding the novel properties of the proposed method and how it copes with dynamic largescale multitasking. The reviewer suggests that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of specific evidence or references makes the claim 3, as the authors would need to make a significant effort to address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s main contribution, noting that the novel properties of the proposed method and its ability to cope with dynamic largescale multitasking are unclear. It points out that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. This feedback is valuable as it highlights specific areas where the authors need to provide more detailed explanations and evidence to support their claims. However, the comment could be more helpful if it offered suggestions on how to clarify these aspects or provided examples of how similar methods have been effectively communicated. Overall, the comment is 4 as it directs the authors to critical areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to compare their method to token pruning and token combination baselines, in addition to the BERTbaseline. This provides a clear and concrete action for the authors to take, specifying exactly what additional comparisons are needed to strengthen the experiment comparison. The comment is specific and direct, giving the authors a clear path to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment comparison\" and the need to compare the method to token pruning and token combination baselines, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of additional baselines for comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment comparison is weak because it only compares the method to the BERTbaseline. The reviewer suggests that the authors should also compare their method to token pruning and token combination baselines. While the comment identifies a potential issue with the experiment comparison, it does not provide specific examples or references to support the claim that these additional comparisons would strengthen the analysis. The reasoning is 3, as it highlights a potential gap in the analysis but lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experiment comparison, noting that the authors only compare their method to the BERTbaseline. It suggests that the authors should also compare their method to token pruning and token combination baselines. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their experimental analysis by including additional baselines. By addressing this suggestion, the authors can improve the robustness and comprehensiveness of their evaluation. However, the comment could be more helpful if it explained why token pruning and token combination baselines are important or how they might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experimental section should include a comparison to coordinateaware methods, such as TFN or SchNet, in addition to methods that are unaware of the point coordinates. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison to these methods. The comment is specific in identifying the missing comparison and offers concrete guidance on how to enhance the experimental section. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison to coordinateaware methods, such as TFN or SchNet, in addition to methods that are unaware of the point coordinates. This provides clear guidance on how to enhance the experimental section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental section should include a comparison to coordinateaware methods, such as TFN or SchNet, in addition to methods that are unaware of the point coordinates. This claim is 3 as it logically suggests that including such comparisons would provide a more comprehensive evaluation of the methods. However, the comment lacks specific examples or references to these methods, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section, suggesting that a comparison to coordinateaware methods, such as TFN or SchNet, would be beneficial. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the experimental analysis by including a comparison to methods that are aware of the point coordinates. By addressing this point, the authors can improve the comprehensiveness and relevance of their experimental evaluation. However, the comment could be more helpful if it explained why this comparison is important or how it would enhance the understanding of the results. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any specific guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending which weaknesses should be explored or how they could be demonstrated. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the authors did not show the possible weaknesses of the proposed model, but it does not specify which part of the paper this issue pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what weaknesses should be explored or how they could be demonstrated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area for improvement by pointing out that the authors did not show the possible weaknesses of the proposed model. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what specific weaknesses should be explored. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the lack of related work and experimentation with other extractthengenerate methodologies in the paper. It implies that the authors should include a related work section and experiment with other methods to demonstrate the novelty and effectiveness of their proposed system. While the comment does not explicitly instruct the authors to add a related work section or conduct additional experiments, it provides a clear direction for improvement. The action is implicit but concrete, as the authors can infer the need to address these gaps in their work. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises concerns about the lack of related work and experimentation with other extractthengenerate methodologies in the paper. It suggests that the authors should include a related work section and experiment with other methods to demonstrate the novelty and effectiveness of their proposed system. However, the comment does not specify which part of the paper is lacking in this regard, such as the sections where related work or experiments should be included. While the authors can infer that it relates to the methodology or results sections, the comment lacks full grounding. It is specific about the need for related work and experimentation, but without explicit references, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of related work and experimentation with other extractthengenerate methodologies in the paper. It questions what the system offers over previous methodologies and suggests that the absence of a related work section and experiments is problematic. However, the comment does not provide specific examples or references to support this claim, nor does it offer a detailed explanation of why the absence of related work and experiments is significant. Without such evidence or reasoning, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some basis for the concern but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of a related work section and experiments with other extractthengenerate methodologies. It questions what the proposed system offers over previous methodologies and highlights the need for a more comprehensive comparison. This feedback is valuable as it points out a critical area for improvement, particularly in demonstrating the novelty and effectiveness of the proposed system. However, the comment could be more helpful if it provided specific suggestions on how to address this gap, such as recommending specific related work to include or methods to compare with. Overall, the comment is 4 as it directs the authors to a crucial area for enhancement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction of related work is not sufficient and recommends providing more information on the advantages or differences of the proposed method, specifically in comparison to BGLN. While the comment implies that additional work on GLN is needed, it does not explicitly instruct the authors to include this information or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should add more information about GLN. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction of related work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the insufficiency of the introduction of related work and the need for more work on GLN to reflect the advantages or differences of the proposed method, such as the difference from BGLN. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests that more work on GLN is needed to reflect the advantages or differences of the proposed method, specifically in comparison to BGLN. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of related work, noting that it is insufficient and recommends providing more information on the advantages or differences of the proposed method, particularly in comparison to BGLN. This feedback is clear and actionable, as it points out a gap in the paper that needs to be addressed to enhance its comprehensiveness and clarity. However, the comment could be more helpful if it provided specific suggestions on how to present this additional information or what aspects of the method should be highlighted in comparison to BGLN. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used when Variational dropout has inputoutput and recurrent dropout parameters. However, it does not provide any explicit or implicit suggestions for the authors to address this issue. The comment lacks guidance on how the authors might improve their draft in response to this observation. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Moon\"s approach\" and \"Variational dropout,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of hyperparameters, particularly the use of only one dropout rate for Moon\"s approach compared to Variational dropout, which has inputoutput and recurrent dropout parameters. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of hyperparameters in Moon\"s approach, specifically noting that Variational dropout has inputoutput and recurrent dropout parameters, while Moon\"s approach only uses one dropout rate. This observation highlights a potential inconsistency in the paper\"s approach. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this inconsistency is problematic or how it affects the paper\"s conclusions. Without additional context or explanation, the claim remains 3, as it lacks the necessary detail to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the choice of hyperparameters in Moon\"s approach, specifically noting that Variational dropout has inputoutput and recurrent dropout parameters, while Moon\"s approach only uses one dropout rate. This observation highlights a potential inconsistency in the paper\"s approach and prompts the authors to consider whether this choice is justified or if it could be improved. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their approach. While it identifies a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests conducting largerscale experiments with nontrivial dynamics, specifically mentioning gridworlds with walls and other nontrivial tiles. It also suggests conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace. The reviewer provides a clear and specific action for the authors to take, which is to conduct these experiments and compare their results against other approaches. The comment is explicit and provides concrete details on how to implement the suggested changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for largerscale experiments with nontrivial dynamics, specifically mentioning gridworlds with walls and other nontrivial tiles. It also suggests conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace. This provides clear guidance on what aspects of the paper need to be addressed. The comment is also specific in detailing what kind of experiments should be conducted and how they could be conducted, such as using publicly available simulators and comparing against other approaches. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the current experiments are insufficiently largescale and do not include nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. The reviewer questions whether this is due to a lack of time or severe scalability issues with the method. The comment proposes conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace, and suggests using publicly available simulators for these experiments. This provides a logical reasoning for the need to conduct largerscale experiments and suggests a specific direction for improvement. However, the comment lacks specific examples or references to support the claim that conducting these experiments would be beneficial. Therefore, the comment is 3, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending largerscale experiments with nontrivial dynamics, specifically mentioning gridworlds with walls and other nontrivial tiles. It also suggests conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace. The reviewer provides a logical argument that conducting these experiments would help address concerns about scalability and demonstrate the method\"s effectiveness in more complex scenarios. This feedback is 5 as it offers a concrete direction for the authors to enhance their experimental design and substantiate their claims. By following this advice, the authors can significantly improve the robustness and generalizability of their results. Therefore, the comment is rated as 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, it does not provide any guidance on what specific quantitative measurement should be used or how to implement it. The comment lacks explicit instructions or concrete suggestions for the authors to follow, leaving them without a clear path to address the issue. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, namely, a quantitative measurement to assess occupation bias. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors have not provided a quantitative measurement to assess the extent of occupation bias relative to real distributions in society. This is a relevant point that could impact the validity and generalizability of the study. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific quantitative measurement could be used. While it points out a potential weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete suggestions on how to address this issue. The authors are left to infer that they should explore the potential impact of using adaptive gradient methods, but the comment lacks specific guidance on how to conduct this exploration or what specific aspects to focus on. Therefore, the action is implicit and somewhat vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where this issue might be relevant. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the potential impact, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. The comment does not present any claims or opinions but rather seeks clarification or additional information. It is a request for further exploration rather than a statement that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. This is a valuable observation that could lead to a deeper understanding of the methodology and its effects on the results. However, the comment lacks specific guidance or suggestions on how the authors might explore this aspect or what specific experiments or analyses could be conducted to address it. While it points out an important area for consideration, the feedback could be more actionable with additional details or examples. Therefore, the comment is 3, as it provides a direction for further exploration but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a lack of information from 2hop neighbors and questions the effectiveness of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to include information from 2hop neighbors or how to clarify the effectiveness of the method. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the lack of information from 2hop neighbors and questions the effectiveness of the method. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of information and the need to clarify the effectiveness of the method. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"no information from 2hop neighbors is included\" and questions the effectiveness of the method. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the lack of information from 2hop neighbors and questioning the effectiveness of the method. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the clarity of their work. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the binder design needs further optimization and validation, specifically mentioning that ProtPainter only provides empirical conformation estimation. However, it does not provide any explicit guidance on how to optimize or validate the binder design, nor does it suggest specific methods or experiments to conduct. The action is implied but lacks concrete details, leaving the authors with a vague understanding of what steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"binder design\" and \"ProtPainter,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for further optimization and validation of the binder design. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that ProtPainter only provides empirical conformation estimation for binder design, suggesting that further optimization and validation are required. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further optimization and validation, specifically the binder design using ProtPainter. It highlights the need for additional work to ensure the robustness and reliability of the binder design. However, the comment lacks depth and does not provide specific suggestions or examples of how the authors might optimize or validate the binder design. While it points out a potential weakness, it does not offer actionable guidance or detailed advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify how the model in Figure 7 was trained, specifically inquiring about the stimulus used and the duration of the cycle. It also raises a question about whether the time scale of adaptation would shorten if the duration of the cycle changes, referencing a specific work by Smirnakis et al. in Nature 1997. The comment provides clear and direct actions for the authors to take, such as clarifying the training process and addressing the potential impact of cycle duration changes on adaptation. The explicit nature of the request and the concrete details on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the training process and the potential impact of cycle duration changes on the time scale of adaptation. The comment provides a clear direction for the authors to address the issue by asking for clarification on the training process and its potential implications. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the training process of the model in Figure 7, specifically inquiring about the stimulus used and the duration of the cycle. It also references a specific work by Smirnakis et al. in Nature 1997 to support the claim that the time scale of adaptation might change with cycle duration. While the comment does not make a subjective claim or opinion, it does require clarification and evidence to be fully understood. Therefore, it is classified as \"3\" as it provides some basis for the question but lacks detailed justification or references.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area of the paper that requires clarification regarding the training process of the model in Figure 7. It asks for clarification on the stimulus used and the duration of the cycle, which are crucial details for understanding the methodology. Additionally, it raises a relevant question about the potential impact of cycle duration changes on the time scale of adaptation, referencing a specific work by Smirnakis et al. in Nature 1997. This feedback is clear and actionable, providing the authors with a concrete direction for improving the clarity and completeness of their methodology section. However, the comment could be more helpful if it offered suggestions on how to address the potential impact or provided additional references to support the claim. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment raises concerns about the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. It suggests that comparisons should be made between using the same amount of data, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their comparisons and ensure they are using the same amount of data. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparisons made in the table, questioning whether they are comparing apples to apples by using the same amount of data. The comment provides specific examples of comparisons that should be made, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. The reviewer provides specific examples of comparisons that should be made, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. This provides a logical reasoning and specific examples to support the claim, making the comment 4. However, the comment could be strengthened by referencing specific studies or literature that support the importance of using the same amount of data for comparisons. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparisons made in Table 2, questioning whether they are comparing apples to apples by using the same amount of data. It provides specific examples of comparisons that should be made, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. This feedback is clear and actionable, as it guides the authors on how to improve the comparisons in their table to ensure they are making valid and meaningful assessments. By addressing these concerns, the authors can enhance the clarity and robustness of their analysis. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises several issues, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should add references or reconsider the placement of Alg 1, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed instructions on how to execute them.", "grounding_specificity_rationale": "The comment addresses several issues, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. However, it does not specify which part of the paper these issues are located in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides specific concerns, it lacks grounding as it does not specify where these issues are addressed in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. These are specific and actionable points that the authors can address to improve the clarity and completeness of their work. Additionally, the comment highlights a potential oversight in the lack of references to Laplacian eigenmaps, which could be important for the context of the paper. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered additional context or examples to guide the authors. Overall, the comment is 4 as it identifies specific areas for improvement but lacks depth in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology seems independent of the choice of model. It also recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. While the comment implies that the authors should reconsider the inclusion of Section 2.1 and provide more motivation for the CBN approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the section and provide more motivation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology seems independent of the choice of model. It also recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment does not specify which part of Section 2.1 is problematic or where the motivation for the CBN approach should be provided. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting that the ResNet architecture could be better used for motivation and intuition, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology seems independent of the choice of model. The reviewer argues that Batch Normalization is a general technique and that the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment lacks specific examples or references to support the claim that Batch Normalization is a general technique or that the ResNet architecture is not necessary for motivation. Without detailed reasoning or evidence, the claim is 3, as it provides a logical argument but lacks the necessary support to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology seems independent of the choice of model. It recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. This feedback is 3 as it identifies a potential weakness in the paper\"s organization and suggests a way to enhance the motivation and intuition for the proposed methodology. However, the comment could be more helpful if it provided specific guidance on how to reorganize the paper or what specific aspects of the ResNet architecture should be emphasized. Overall, the comment offers some direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a confusion regarding the expected outcome of multiplying in equation (1) by a dense projection matrix, questioning how the resulting matrix can be sparse. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to clarify the explanation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L122,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the expected outcome of multiplying in equation (1) by a dense projection matrix, suggesting that the resulting matrix should be sparse. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the expected outcome of multiplying in equation (1) by a dense projection matrix, suggesting that the resulting matrix should be sparse. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, questioning the expected outcome of multiplying in equation (1) by a dense projection matrix, suggesting that the resulting matrix should be sparse. This feedback highlights a potential confusion in the explanation and provides a clear direction for the authors to clarify their reasoning. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context to help the authors understand the implications of their argument. Overall, the comment is 3 as it points out a specific area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the statement about initialization, suggesting that it should be more carefully stated. It also references a specific paper ([1] Kunstner et al., 2019) to provide context and guidance on how to address the issue. While the comment does not explicitly instruct the authors to revise their statement, it clearly identifies a potential area for improvement and provides a reference for further exploration. The action is implicit but concrete, as the authors can infer that they need to reconsider their statement about initialization and potentially incorporate the reference to enhance their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement about initialization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more careful statement about initialization. The comment provides a reference to a specific paper ([1] Kunstner et al., 2019) to support the claim about initialization. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that initialization plays a role in natural gradient descent (NGD) and suggests that it should be considered as pretraining. The reviewer supports this claim by referencing a specific paper ([1] Kunstner et al., 2019) that discusses the limitations of empirical Fisher approximation for natural gradient descent. This reference provides a logical basis for the claim, as it highlights the importance of initialization in the context of NGD. However, the comment could be strengthened by providing more detailed explanations or examples of how initialization affects NGD. Overall, the claim is 4, as it is supported by a relevant reference but could benefit from additional justification or explanation.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement about initialization, suggesting that it should be more carefully stated. It provides a specific reference to a relevant paper ([1] Kunstner et al., 2019) to support the claim about initialization and its role in natural gradient descent (NGD). This feedback is actionable as it guides the authors to reconsider their statement about initialization and potentially incorporate the reference to enhance their draft. However, the comment could be more helpful if it offered additional suggestions on how to clarify or improve the statement. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the statement \"for every arm a\" in line 200, suggesting that it implies a single optimistic parameter. The reviewer provides a specific suggestion to consider using T_0 = m Sqrt(T) in line 303, which would improve the condition slightly. This feedback is explicit and provides a concrete action for the authors to take, as it clearly specifies what change to make and why it might be beneficial. The authors know exactly what needs to be done to address the issue, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, \"L200\" and \"L303,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the statement \"for every arm a,\" suggesting that it implies a single optimistic parameter, and provides a specific alternative suggestion for improving the condition. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the statement \"for every arm a\" in line 200, suggesting that it implies a single optimistic parameter. The reviewer provides a logical reasoning by pointing out that this statement is misleading, as it does not account for the possibility of multiple optimistic parameters. The comment also suggests an alternative approach by proposing a different condition, which is based on a mathematical calculation. However, the comment lacks specific examples or references to support the claim that the current condition is misleading or inaccurate. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement \"for every arm a\" in line 200, suggesting that it implies a single optimistic parameter. The reviewer provides a specific suggestion to consider using T_0 = m Sqrt(T) in line 303, which could improve the condition slightly. This feedback is clear and actionable, as it guides the authors on how to clarify their statement and potentially enhance the robustness of their analysis. However, the comment could be more helpful if it explained why the current statement is problematic or how the suggested alternative would benefit the paper. Overall, the comment is 4 as it provides a concrete suggestion for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the experimental section is weak and suggests that more experiments are required. However, it does not provide specific guidance on what additional experiments should be conducted or how they should be structured. The authors are left to infer that they need to expand their experimental section, but without concrete suggestions or examples, the action remains vague. Therefore, this comment is 3, as it identifies an area for improvement but lacks detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the experimental section is weak and needs more experiments. However, it does not specify which part of the experimental section is considered weak or what specific experiments are needed. Without explicit references to sections, figures, or experiments, the authors cannot confidently determine which parts of the paper need improvement. The comment lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental section is weak and suggests that more experiments are required. However, it does not provide any specific reasoning or examples to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand why the experimental section is considered weak and what specific experiments are needed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a weakness in the experimental section, suggesting that more experiments are required. However, it lacks specificity and does not provide any guidance on what additional experiments should be conducted or how they could enhance the paper. Without specific suggestions or examples, the authors are left without actionable feedback on how to improve their experimental section. Therefore, the comment is not helpful, as it does not provide the authors with a clear path to address the identified weakness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point identifies four specific errors in the text, including incorrect grammar and spelling. It provides explicit corrections for each error, such as \"Despite being compact\" and \"We refer to multiway arrays.\" Additionally, it points out that \"HPFN to a even deeper ConAC\" should be corrected to \"HPFN to an even deeper ConAC.\" The reviewer also notes that \"Effect of the modelling mixed temporalmodality features\" is not grammatically correct and is unclear. These corrections are direct and concrete, providing the authors with clear guidance on how to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment provides specific corrections to errors in the text, such as incorrect grammar and spelling. It explicitly mentions lines 2, 56, 158, and 265, allowing the authors to accurately identify the parts of the paper being addressed. Additionally, the comment provides specific guidance on how to correct these errors, such as changing \"Despite of being compact\" to \"Despite being compact\" and \"We refer multiway arrays\" to \"We refer to multiway arrays.\" This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of corrections to errors in grammar and spelling, which are factual statements. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific errors in the text, such as incorrect grammar and spelling, and provides clear and actionable feedback to correct them. It also points out that the phrasing \"Effect of the modelling mixed temporalmodality features\" is not grammatically correct and is unclear. This level of detail and specificity helps the authors improve the clarity and accuracy of their draft, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. While the comment implies that the authors should conduct a comparison between the two designs, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a comparison between sequential and combinational designs, but without explicit references to sections or figures, the authors may struggle to identify where this information should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the method may perform better in combinational logic. The comment lacks specific details or examples to support the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. While it identifies a potential area for improvement, the comment lacks specificity and does not provide actionable guidance on how to conduct this comparison or what specific aspects to focus on. The authors are left with a general suggestion but no detailed instructions on how to address the issue. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a discussion of the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While the comment implies that the authors should include this analysis, it does not explicitly instruct them to do so. The action is concrete, as it specifies the metric to be analyzed and provides a clear direction for improvement, but it is somewhat vague because it does not provide detailed guidance on how to conduct the analysis or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. This provides clear guidance on what aspect of the experiment needs further exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline, LDA+LSTM, can capture sequential information and provide topic assignment for each word. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that could be improved by discussing the performance of a baseline model, LDA+LSTM, in terms of the topic switch percent metric. This feedback is clear and actionable, as it prompts the authors to include a discussion of the model\"s performance in their results section. However, the comment could be more helpful if it provided additional context or suggestions on how to interpret or analyze the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of their proposed approach. This feedback is explicit and provides a clear action for the authors to take, which is to include experiments with GPT3.5. The comment is concrete because it specifies the exact change needed to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests including experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of the proposed approach. The authors can infer that it relates to the experimental setup or evaluation, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting the inclusion of GPT3.5. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should include experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of their proposed approach. However, the comment does not provide any supporting evidence or reasoning to justify why GPT3.5 is a more appropriate choice or how it would enhance the evaluation. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of their proposed approach. This feedback is clear and actionable, as it directly advises the authors to include a more costeffective option in their experiments. However, the comment could be more helpful if it explained why GPT3.5 is a better choice or how it would impact the evaluation. Despite this, the suggestion is valuable as it encourages the authors to consider a broader range of options for their experiments. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include bold numbers for the baselines of previous work, specifically for WMT17WIKT, where the best result in terms of BLEU is in the baselines. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what to add, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of bold numbers for the baselines of previous work, particularly for WMT17WIKT where the best result in terms of BLEU is in the baselines. This provides clear guidance on what needs to be added to the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Table 4 should include bold numbers for the baselines of previous work, specifically for WMT17WIKT, where the best result in terms of BLEU is in the baselines. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific issue with Table 4, suggesting that bold numbers should be included for the baselines of previous work, particularly for WMT17WIKT where the best result in terms of BLEU is in the baselines. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of the data. However, the comment could be more helpful if it explained why this change is important or how it would enhance the clarity or impact of the table. Overall, the comment is valuable for guiding the authors in making a specific improvement to their draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of support for the claim about the synergies between DQD and PPO, specifically mentioning the absence of reference to the TD3GA algorithm in the main paper. It also suggests that the comparison to TD3GA should be central to the paper. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include references to the TD3GA algorithm and emphasize the comparison to TD3GA, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the synergies between DQD and PPO, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of reference to the TD3GA algorithm and the need for a central comparison to TD3GA. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the synergies between DQD and PPO are insufficiently supported, specifically mentioning the absence of reference to the TD3GA algorithm in the main paper. The reviewer suggests that the comparison to TD3GA should be central to understanding these synergies. This claim is 3 as it highlights a gap in the paper\"s discussion of the TD3GA algorithm, which is crucial for understanding the synergies. However, the comment lacks specific examples or references to the TD3GA algorithm to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. It also suggests that the comparison to TD3GA should be central to the paper. This feedback is clear and actionable, as it points out a specific gap in the paper\"s discussion and provides a direction for improvement. By addressing these points, the authors can enhance the clarity and robustness of their claims. However, the comment could be more helpful if it offered suggestions on how to incorporate the TD3GA algorithm or provided examples of how it could be integrated into the discussion. Overall, the comment is 4 as it effectively guides the authors on how to strengthen their paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of polishing in figures and empirical results, which affects clarity and confidence in empirical findings. It provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. However, the comment does not explicitly instruct the authors on how to address these issues or provide guidance on how to improve the clarity and polish of the figures and results. The action is implicit and somewhat vague, as the authors can infer that they need to improve the presentation of their results but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the figures and empirical results, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the lack of polishing in figures and empirical results, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. This provides clear guidance on what needs to be addressed to improve the clarity and confidence in empirical findings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks polishing in figures and empirical results, which affects clarity and confidence in empirical findings. The comment provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. These examples provide a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or references to similar issues in the literature, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity and confidence in the empirical findings of the paper. It points out specific problems, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. These observations highlight areas where the paper could be improved to enhance its credibility and impact. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as recommending standard practices for figure presentation or offering guidance on how to improve the robustness of the empirical results. Despite this, the feedback is 4 as it directs the authors\" attention to critical areas needing improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the novelty of the work but points out that the findings are limited due to the expected outcomes of taskspecific finetuning. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation or improve the novelty of their work. There is no guidance on how to enhance the generalizability of the findings or how to differentiate the work from other studies. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the work and its limitations, specifically mentioning the expected outcomes of taskspecific finetuning. However, it does not specify which part of the paper this observation is based on, such as specific sections or results where these findings are discussed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention or improvement. The comment is specific in its critique of the novelty and expected outcomes, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the work is limited due to the expected outcomes of taskspecific finetuning. However, it does not provide any supporting evidence or references to substantiate this claim. The comment lacks specific examples or detailed reasoning to explain why the novelty is limited, making it difficult for the authors to understand and address the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment acknowledges the novelty of the work but points out that the findings are limited due to the expected outcomes of taskspecific finetuning. It suggests that the novelty is expected given the general trend of taskspecific finetuning increasing confidence for specific tasks while potentially reducing generalizability. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or enhance the generalizability of their findings. While it identifies a potential weakness, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper\"s case. It explicitly states that this would further test the conjecture and provide valuable insights, even if the phenomenon weakens in this setting. The comment is clear and provides a direct action for the authors to take, which is to include these numbers in their report. The action is concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes, which would further test the conjecture. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. The comment is specific in suggesting the inclusion of these numbers to strengthen the case, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper\"s case. However, the comment does not provide any supporting evidence or reasoning to justify why this additional information would be beneficial or how it would impact the paper\"s conclusions. Without specific examples or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper\"s case. This feedback is actionable as it provides a clear and specific suggestion for improving the paper by including additional data that could further test the conjecture. The comment also acknowledges the potential weakening of the phenomenon in this setting but emphasizes the importance of including the numbers for their value in stresstesting the conjecture. While the comment is clear and actionable, it could be more helpful if it provided more detailed guidance on how to interpret and present these numbers. Overall, the comment is 4 as it offers a concrete suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of using the number of weight updates as a metric over the number of network updates, given that the brain operates in parallel. It suggests providing additional feedback to improve the paper. However, the comment does not specify what additional feedback is needed or how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information or justification for their choice of metrics, but the comment lacks concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of metrics used in the paper, specifically questioning why the number of weight updates is preferred over the number of network updates, given that the brain operates in parallel. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where this metric is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its question about the choice of metrics, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of metrics used in the paper, specifically questioning why the number of weight updates is preferred over the number of network updates, given that the brain operates in parallel. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or unsuitable. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the choice of metrics used in the paper, specifically questioning why the number of weight updates is preferred over the number of network updates, given that the brain operates in parallel. This is an important point that could impact the interpretation and understanding of the results. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their analysis. While it identifies a potential weakness, it does not offer guidance on how to resolve it, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of the objective should be clarified. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification on the objective, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point poses a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a request for clarification, which is factual in nature and does not involve claims or opinions. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. This is a relevant point that could help the authors clarify the purpose and significance of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this question or improve their explanation. While it identifies an area for clarification, it does not offer actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the evaluation in the paper, including a lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. It also suggests that the paper should explore the effects of varying the number of InContext Examples. While the comment provides explicit actions for the authors to take, such as including more details on the experiment setup and exploring different datasets, it does not specify how to implement these actions or provide concrete guidance on how to address the issues. Therefore, the comment is 3, as it clearly identifies areas for improvement but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation\" and \"experiments\" sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the evaluation, such as the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. The comment suggests exploring the effects of varying the number of InContext Examples and provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not comprehensive and lacks transparency regarding the experiment setup. It specifically mentions the absence of information on the number of different sets of incontent examples used and the lack of exploration of varying the number of InContext Examples. The comment also highlights the reliance on a single dataset, which could limit the generalizability of the results. While the comment provides a logical basis for the critique, it lacks specific examples or references to support the claim about the effects of varying the number of InContext Examples. This makes the claim 3, as it provides a clear rationale but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies several critical issues with the evaluation in the paper, including a lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. It suggests that the paper should explore the effects of varying the number of InContext Examples and provide more comprehensive evaluation. This feedback is clear and actionable, as it directs the authors to address specific areas for improvement in their evaluation methodology. However, it could be more helpful if it offered suggestions on how to implement these changes or provided examples of how other studies have addressed similar issues. Overall, the comment is 4 as it effectively points out areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there is a lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This implies that the authors should include these comparisons in Section 4.3 to showcase the unique advantages or potential shortcomings of their proposed method in a broader context. The comment is clear and provides a specific action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This claim is 3 as it suggests that including these comparisons would provide a broader context for the proposed method. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the importance of these comparisons and determine how they would enhance the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback highlights the importance of including such comparisons to showcase the unique advantages or potential shortcomings of the proposed method in a broader context. By suggesting these comparisons, the comment provides clear and actionable guidance for the authors to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it offered specific examples or references to similar studies that have successfully included such comparisons. Overall, the comment is 4 as it directs the authors to a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. While the comment implies that the authors should include these references, it does not explicitly instruct them to do so or provide guidance on how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include these references. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, it does not specify which part of the paper should include this additional attention or how it should be integrated. The authors can infer that it relates to the literature review or discussion sections, but the comment lacks full grounding as it does not explicitly mention these sections. The suggestion is specific in terms of the references to include, but it is 1 in the context of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, the comment does not provide any reasoning or explanation as to why these references are relevant or how they could enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. While this feedback identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how to integrate these references into the paper or why they are relevant. The comment does not offer suggestions on how to effectively incorporate related work or how it could enhance the paper\"s contribution. As a result, the feedback is 3, as it points out a potential area for improvement but does not provide actionable steps for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. While the comment implies that the paper lacks depth in this area, it does not provide specific guidance on how to address this issue or what aspects of the algorithmic aspects should be covered. The action is implicit and somewhat vague, as the authors can infer that they need to expand on the algorithmic aspects but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. However, it does not specify which part of the paper this suggestion pertains to, such as the sections discussing the algorithmic aspects or the introduction of the Blackwell winner. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the algorithmic aspects should be addressed or how they should be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. This claim is based on the observation that the novelty of the paper seems limited after introducing the Blackwell winner. However, the comment lacks specific examples or detailed reasoning to support why the algorithmic aspects are crucial or how they could enhance the paper\"s contribution. The lack of specific evidence or detailed justification makes the claim 3, as it provides a logical basis but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. This feedback is 3 as it identifies a potential area for improvement by suggesting that the paper could provide more depth on the algorithmic aspects. However, the comment lacks specific guidance on what aspects of the algorithmic aspects should be covered or how they could be integrated into the paper. While it points out a potential weakness, it does not offer detailed suggestions or examples to help the authors address this issue effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should specify what \"valid\" and \"orig\" differ in, as it is not clear from the figure. This is a direct and concrete action for the authors to take, as it provides a specific point of clarification that can be easily addressed. The comment is 5 because it clearly instructs the authors on what to do to improve the clarity of their figure.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of \"valid\" and \"orig\" in the context of Fig. 5. This provides clear guidance on what the authors need to do to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should specify what \"valid\" and \"orig\" differ in, as it is not clear from Fig. 5. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the figure. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Fig. 5, noting that the terms \"valid\" and \"orig\" are not clearly defined. This feedback is clear and actionable, as it provides a direct suggestion for improving the clarity of the figure by specifying what these terms mean. By addressing this point, the authors can enhance the understanding and interpretation of their results. However, the comment could be more helpful if it offered additional context or examples to guide the authors in their clarification efforts. Overall, the comment is 4 as it provides a concrete direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. While the comment implies that the authors should consider including such a comparison, it does not provide specific guidance on which method to compare or how to adapt it to language tasks. The action is implicit and somewhat vague, as the authors need to infer the specific method and steps to implement the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including a comparison to one of the methods mentioned in the computer vision setting, rather than comparing to lossbased sampling. However, it does not specify which method from the computer vision setting should be compared or how it would be relevant to the language task. The authors can infer that the suggestion relates to a method mentioned in the computer vision setting, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential improvement. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some could be adapted to language tasks relatively easily. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim fully. The authors would need to infer the relevance of the computer vision methods and their applicability to language tasks, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. This feedback is 3 as it provides a specific suggestion for improving the draft by including a comparison that could enhance the paper\"s contribution. However, the comment could be more helpful if it included specific examples of methods that could be adapted or how they could be applied to the language task. Overall, the comment offers a clear direction for improvement but lacks detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that there may be a connection between the third point of definition one and properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann. However, it does not provide explicit instructions or guidance on how the authors should explore this connection or what specific aspects of the universal kernel properties should be considered. The action is implicit and somewhat vague, as the authors need to infer that they should explore the connection between their work and universal kernels. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential connection to properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann. This provides clear guidance on what aspect of the paper should be explored further. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a potential connection between the third point of definition one and properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann. However, the comment does not provide any detailed reasoning or explanation of why this connection is relevant or how it could be explored. Without further context or examples, the claim lacks sufficient support to be 5. Therefore, the comment is categorized as 2, as it provides a direction for further exploration but requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment suggests a potential connection between the third point of definition one and properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann. This is a valuable suggestion that could lead to a deeper understanding of the topic and potentially enhance the paper\"s contribution. However, the comment lacks specific guidance on how to explore this connection or what aspects of the universal kernel properties are relevant to the paper. While it points to a potentially interesting direction, the feedback could be more actionable with additional details or examples. Therefore, the comment is 3, as it provides a starting point for the authors to consider but could be more comprehensive with additional guidance."}
